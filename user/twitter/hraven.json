{"_default": {"1": {"vrushalivc": {"issues": [{"url": "https://api.github.com/repos/twitter/hraven/issues/162", "title": "Fix javadoc warnings generated by java 8", "body": "Several warnings are generated by java 1.8 when we update to use later version of maven-javadoc-plugin to be 2.10.4 and maven-release-plugin to be 2.5.3\r\n\r\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-javadoc-plugin:2.10.4:javadoc (default-cli) on project hraven-core: An error has occurred in JavaDocs report generation:\r\n[ERROR]  hraven/hraven-core/src/main/java/com/twitter/hraven/AppAggregationKey.java:57: error: reference not found\r\n[ERROR]  hraven/hraven-core/src/main/java/com/twitter/hraven/AppSummary.java:110: error: unknown tag: returns\r\n[ERROR]  hraven/hraven-core/src/main/java/com/twitter/hraven/AppSummary.java:124: error: identifier expected\r\n[ERROR]  hraven/hraven-core/src/main/java/com/twitter/hraven/CounterMap.java:68: error: unknown tag: emphasis\r\n[ERROR]  hraven/hraven-core/src/main/java/com/twitter/hraven/CounterMap.java:68: error: unknown tag: emphasis\r\n[ERROR]  hraven/hraven-core/src/main/java/com/twitter/hraven/HdfsStatsKey.java:86: error: @param name not found\r\n[ERROR]  hraven/hraven-core/src/main/java/com/twitter/hraven/JobDetails.java:107: error: @param name not found\r\n[ERROR]  hraven/hraven-core/src/main/java/com/twitter/hraven/JobHistoryKeys.java:13: error: reference not found\r\n[ERROR]  hraven/hraven-core/src/main/java/com/twitter/hraven/JobHistoryKeys.java:24: error: reference not found\r\n[ERROR]  hraven/hraven-core/src/main/java/com/twitter/hraven/JobId.java:102: error: @param name not found\r\n[ERROR]  hraven/hraven-core/src/main/java/com/twitter/hraven/TaskDetails.java:122: error: @param name not found\r\n[ERROR]  hraven/hraven-core/src/main/java/com/twitter/hraven/datasource/AppSummaryService.java:231: error: identifier expected\r\n[ERROR]  hraven/hraven-core/src/main/java/com/twitter/hraven/datasource/AppSummaryService.java:614: error: malformed HTML\r\n[ERROR]  hraven/hraven-core/src/main/java/com/twitter/hraven/datasource/AppSummaryService.java:72: error: reference not found\r\n[ERROR]  hraven/hraven-core/src/main/java/com/twitter/hraven/datasource/AppVersionService.java:49: error: reference not found\r\n[ERROR]  hraven/hraven-core/src/main/java/com/twitter/hraven/datasource/HdfsStatsKeyConverter.java:41: error: @param name not found\r\n[ERROR]  hraven/hraven-core/src/main/java/com/twitter/hraven/datasource/HdfsStatsService.java:64: error: reference not found\r\n[ERROR]  hraven/hraven-core/src/main/java/com/twitter/hraven/datasource/JobHistoryByIdService.java:90: error: bad use of '>'\r\n[ERROR]  hraven/hraven-core/src/main/java/com/twitter/hraven/datasource/JobHistoryByIdService.java:46: error: reference not found\r\n[ERROR]  hraven/hraven-core/src/main/java/com/twitter/hraven/datasource/JobHistoryRawService.java:382: error: reference not found\r\n[ERROR]  hraven/hraven-core/src/main/java/com/twitter/hraven/datasource/JobHistoryRawService.java:440: error: reference not found\r\n[ERROR]  hraven/hraven-core/src/main/java/com/twitter/hraven/datasource/JobHistoryRawService.java:461: error: reference not found\r\n[ERROR]  hraven/hraven-core/src/main/java/com/twitter/hraven/datasource/JobHistoryRawService.java:477: error: unknown tag: success\r\n[ERROR]  hraven/hraven-core/src/main/java/com/twitter/hraven/datasource/JobHistoryRawService.java:54: error: reference not found\r\n[ERROR]  hraven/hraven-core/src/main/java/com/twitter/hraven/datasource/MissingColumnInResultException.java:26: error: reference not found\r\n[ERROR]  hraven/hraven-core/src/main/java/com/twitter/hraven/datasource/MissingColumnInResultException.java:28: error: unterminated inline tag\r\n[ERROR]  hraven/hraven-core/src/main/java/com/twitter/hraven/rest/SerializationContext.java:159: error: bad HTML entity", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/162/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/twitter/hraven/issues/158", "title": "Ensure hraven-client does not require hbase dependency at run time", "body": "\r\nthe hRaven client should not depend on any hbase jars at run time. This is important so that clients can make REST calls and expect java objects being returned. \r\n\r\nI believe this class needs to be looked at in more detail, specifically line 63     \r\n\r\nreturn om.readValue(inputStream, type);\r\n\r\nhttps://github.com/twitter/hraven/blob/master/hraven-core/src/main/java/com/twitter/hraven/util/JSONUtil.java\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/158/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/twitter/hraven/issues/144", "title": "Port hRaven to HBase 1.x", "body": "HBase 1.x has new APIS, need to update the hraven code to read/write from hbase 1.x clusters\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/144/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/twitter/hraven/issues/140", "title": "Enhance task API to allow for filtering out of fields", "body": "If similar enhancement can be easily added to flow and job APIs, it will be a good to have\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/140/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commits": [{"url": "https://api.github.com/repos/twitter/hraven/commits/e35996b6e2f016bcd18db0bad320be7c93d95208", "message": "Merge pull request #164 from talglobus/patch-1\n\nFix typo in comment"}, {"url": "https://api.github.com/repos/twitter/hraven/commits/7b427295ca71409af8dc6e9094cc569ba72e9f25", "message": "Merge pull request #163 from pgaref/build_fix\n\nFixing build failure cause by wrong project dependency in pom"}, {"url": "https://api.github.com/repos/twitter/hraven/commits/e0c036c960119be115d52be968850c59fd4f78aa", "message": "[maven-release-plugin] prepare for next development iteration"}, {"url": "https://api.github.com/repos/twitter/hraven/commits/7cf6f67771023dd7ce73154165963b3bbb96e9c0", "message": "[maven-release-plugin] prepare release v1.0.1"}, {"url": "https://api.github.com/repos/twitter/hraven/commits/a1594c37d3642c2b8e0505f7fb4b53a20265a6b9", "message": "Updating release plugin and javadoc plugin versions"}, {"url": "https://api.github.com/repos/twitter/hraven/commits/cc9f6ce2b3273dc0200897bf704edf31ce64564f", "message": "Adding a non null check for jobDetails before invoking getTaskDetails"}, {"url": "https://api.github.com/repos/twitter/hraven/commits/424de31c85ad52c88253a53e151581a9fcd0f5ba", "message": "Updating to next snapshot"}, {"url": "https://api.github.com/repos/twitter/hraven/commits/419699dd1f7ebdc3d7b95419dc0dc3682849fd9d", "message": "Merge pull request #161 from piyushnarang/client-gzip\n\nAdd support to request for compressed payloads from the HRavenRestClient,"}, {"url": "https://api.github.com/repos/twitter/hraven/commits/2089d6990c50720d36c757b46ad7f19ebb9d664d", "message": "Merge pull request #160 from piyushnarang/task_counter_filters\n\nAdd support to filter task / job counters"}, {"url": "https://api.github.com/repos/twitter/hraven/commits/e17ec79dbba0480d3b245f1c7f0fe02ae45820f7", "message": "Setting version to 1.0.0-SNAPSHOT"}, {"url": "https://api.github.com/repos/twitter/hraven/commits/dcbe5902bb5876a32d2a398ad0dbf3bc46e09029", "message": "Setting version to release 1.0.0"}, {"url": "https://api.github.com/repos/twitter/hraven/commits/1163257d1b35a93294205e0426fa344c4be551a3", "message": "Merge pull request #159 from twitter/dogpiledays_hbase1\n\nUpdating hRaven to build/run on hadoop2, hbase 1.x & jre 1.8"}, {"url": "https://api.github.com/repos/twitter/hraven/commits/940907cf3a1a37d265fb534dde3b0ac635b9f098", "message": "removing commented lines from pom"}, {"url": "https://api.github.com/repos/twitter/hraven/commits/449d033b824de480cda66348075f1256d58553b8", "message": "Updating the json serialization for String members"}, {"url": "https://api.github.com/repos/twitter/hraven/commits/7d2bea64dc3a120b922bdeff541b9de436a951b9", "message": "First check in for memory optimizations for jobs"}, {"url": "https://api.github.com/repos/twitter/hraven/commits/37b0750213e0dd0350ffcd91e8f0af25ba90f851", "message": "Merge pull request #156 from jrottinghuis/dogpiledays_hbase1\n\nMerging #156 after discussion with Joep.\r\nThis improves the hbase connections being created when the rest api calls are called.  There now should be one static connection for the entire class in the JVM (modulo weirdness with classloaders).  Each thread creates its own service instance each time, but that should be light weight, using the one single multi-threaded / shared connection. It does not tackle the closing of connections upon jvm termination (which is an existing thing anyways)."}, {"url": "https://api.github.com/repos/twitter/hraven/commits/4f5c2299016e19b858079483256471f34825d5e3", "message": "Merge pull request #155 from gsteelman/piling_the_dogs_kv_cell\n\nRemove KeyValue use in hraven-core"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "dieu": {"issues": [{"url": "https://api.github.com/repos/twitter/hraven/issues/157", "title": "Nice to have hadoop-version-independent API getCounterValue", "body": "Base on the discussion in https://github.com/twitter/scalding/pull/1645.", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/157/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "benpence": {"issues": [{"url": "https://api.github.com/repos/twitter/hraven/issues/139", "title": "HRavenRestClient should encode URL path parameters", "body": "The [HRaven rest client ](https://github.com/twitter/hraven/blob/master/hraven-core/src/main/java/com/twitter/hraven/rest/client/HRavenRestClient.java#L102) should encode parameters used in the URL. Characters such as '/' can lead to problems accessing the endpoint.\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/139/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "rubanm": {"issues": [{"url": "https://api.github.com/repos/twitter/hraven/issues/138", "title": "A separate hraven-client module", "body": "It would be nice to have just the rest client as a separate `hraven-client` module so that clients can pull in just the required dependencies. Perhaps, everything under `hraven-core/src/main/java/com/twitter/hraven/rest` can go there.\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/138/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "sjlee": {"issues": [{"url": "https://api.github.com/repos/twitter/hraven/issues/134", "title": "merge #132 to master", "body": "", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/134/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "COLLABORATOR"}], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/twitter/hraven/issues/comments/20761879", "body": "LGTM.\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/20761879/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "COLLABORATOR"}, {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/20761994", "body": "This can be closed as we merged #8.\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/20761994/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "COLLABORATOR"}, {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/21128664", "body": "Fixed by pull request #12.\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/21128664/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "COLLABORATOR"}, {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/21232467", "body": ":+1: \n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/21232467/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "COLLABORATOR"}], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5102951", "body": "Bit pedantic, but it may be good to make this final. Also, is it intentional that you're passing in JobFilePreprocessor rather than this class (JobFile)?\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5102951/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "COLLABORATOR"}, {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5105235", "body": "Sorry for a late comment, but it would be good to have a consistent naming style. I believe the standard for naming variables is the camel case (\"confMatcher\") rather than hyphens (\"conf_matcher\").\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5105235/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "COLLABORATOR"}, {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5261325", "body": "It is the number of available bytes to read in the buffer. It's a variable in ByteArrayInputStream which ByteArrayWrapper extends (see http://grepcode.com/file/repository.grepcode.com/java/root/jdk/openjdk/6-b14/java/io/ByteArrayInputStream.java#106). In this case, it is the same as the byte array size.\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5261325/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "COLLABORATOR"}, {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5283965", "body": "It would be good to re-word this javadoc, as it's no longer an abstract class and thus there are no \"subclasses\".\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5283965/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "COLLABORATOR"}, {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5283977", "body": "Since this is now an interface, there is no need to say \"abstract\". The same for the other methods.\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5283977/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "COLLABORATOR"}, {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5284097", "body": "Since this class doesn't extend any, the super() call is superfluous. In fact, the (default) constructor itself is superfluous...\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5284097/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "COLLABORATOR"}, {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5284114", "body": "I don't quite understand how jobHistoryListener is supposed to be used. It looks like it is initialized every time parse() is called? First, is this class never used in a multi-threaded environment? Is it intended that every time parse() is called, the jobHistoryListener instance keeps getting recreated?\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5284114/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "COLLABORATOR"}, {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5284140", "body": "Indeed this is not javadoc as it doesn't start with two *'s. :) We should fix that and remove (non-javadoc)?\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5284140/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "COLLABORATOR"}, {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5284142", "body": "Ditto\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5284142/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "COLLABORATOR"}, {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5284160", "body": "I think \n\nLOG.error(\"your log message\", ioe);\n\nwould do what these 2 lines are doing.\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5284160/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "COLLABORATOR"}, {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5284161", "body": "Ditto\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5284161/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "COLLABORATOR"}]}, "vrushalic": {"issues": [{"url": "https://api.github.com/repos/twitter/hraven/issues/129", "title": "Calculate job cost based on hadoop2 counters of megabyte millis", "body": " As per https://issues.apache.org/jira/browse/MAPREDUCE-5464\nneed to update hRaven cost calculations to use the hadoop2 counter of megabytemillis instead of calculating megabytemillis on our own\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/129/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/issues/120", "title": "In Preprocessor, check timestamp of directory before listing all files in that dir", "body": "An optimization that can be done in the Preprocessor: check timestamp of directory before listing all files in that directory. This will avoid putting unnecessary load on the NN \n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/120/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/issues/97", "title": "Aggregate app per day and per week during hRaven Proccessing of each job", "body": "Create per day and per week aggregations in hRaven\n\nCan do the aggregation at the Processing step itself\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/97/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/issues/90", "title": "Add task level REST apis to hRaven", "body": "Currently hRaven supports job, flow and app summary level rest apis.\nWill be good to add task level rest apis to hRaven\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/90/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/issues/55", "title": "Extend hRaven to include hdfs usage", "body": "Presently hRaven includes job level statistics. It collects run time data and statistics from map reduce jobs running on Hadoop clusters and stores the collected job history in an easily queryable format.\n\nIt will be good to extend hRaven capabilities and add in hdfs usage statistics. This involves two broad aspects - collection and query apis (rest endpoints). \n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/55/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/issues/39", "title": "refactor enums in JobHistoryFileParserHadoop2 into separate classes", "body": "there are some enums in the JobHistoryFileParserHadoop2 class. will be good to refactor them out into individual classes\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/39/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/twitter/hraven/issues/comments/20848989", "body": "LGTM\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/20848989/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/21200468", "body": "LGTM\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/21200468/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/21225689", "body": "Updated the files with the review recommendations\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/21225689/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/21363590", "body": "Updated as per review comments for exceptions, documentation and formatting\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/21363590/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/21759866", "body": "One known limitation in JobHistoryParser is being tracked in https://issues.apache.org/jira/browse/MAPREDUCE-5432\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/21759866/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/21820219", "body": "Adding a note after discussing with Sangjin: This pull request is for reviewing purposes only. Will NOT be merging this till the pom dependencies are cleared up.\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/21820219/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/21831148", "body": "Closing this pull request after discussion with Gary. Will generate a new pull request shortly. \n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/21831148/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/22149161", "body": "I have not yet added a mapping between old keys and new keys between 1 .0 and 2.0. For instance,  in 1.0 there was a \"TOTAL_MAPS\" and in 2.0, it now is \"totalMaps\".  Will add it if needed after discussion.\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/22149161/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/23280070", "body": "Thanks Gary! I will fix these and update the request today.\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/23280070/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/23378561", "body": "pull request merged to master \n\nhttps://github.com/twitter/hraven/pull/18\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/23378561/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/23435146", "body": "Discussed with Gary about this, looks good to me!\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/23435146/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/23540097", "body": "Looks good to me.\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/23540097/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/26528814", "body": "This exception is probably ignored in later versions of jackson libraries, hence was not encountered with 1.9.6 jackson libraries but is seen in 1.5.2.\n\nThis exception is thrown because the JobDetails class does not have a setter for the list of TaskDetails objects that it contains. The JSON deserializer expects a setter and does not find it, hence the exception.\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/26528814/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/26777129", "body": "Fixed and merged as part of pull #25 \n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/26777129/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/27843577", "body": "Noting some of the discussion Joep and I had on whether to add the hadoop version to the raw table and the tasks table. \n\nFor the raw table, there is a i:jobconf_filename and in hadoop2, all history filenames have a .jhist extension. Also, at the raw file loading time, we don't quite know the hadoop version, we could find out, but it's not available outright. It could be determined by peeking into the first few bytes of the file.\n\nRight now, job history seems to be the only place to insert this hraven-created version. We  presently don't see a strong use case for having tasks reflect the hadoop version. If we were to insert per task attempt, that would be several more puts (like 70k additional puts as we noticed in one particular case that had 70k tasks). So we were wondering if that is really needed? We could make an additional get call to the job history table for that task's job and determine the hadoop version. An hbase get should be reasonably fast.\n\nIf we see the need for raw tables and task tables to have the hadoop version, we can always add it later. \n\nI plan to update the pull request with setting the version in hadoop1 history file processing as well.\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/27843577/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/28103566", "body": "Due to discrepancies in hadoop1 and hadoop2 configuration keys, we need to ensure we store a consistent config param name in hRaven database. Since till now, hRaven did not look inside the config object to check the parameter keys, but we now need to add that. Hence this pull request for issues #28 and #29 \n\nAbout the pull request:\n\nFor username\n    if hadoop2 setting mapreduce.job.user.name is set, use that (in JobDescFactoryBase.java)\n    user.name from the configuration is to be used for both hadoop1 and hadoop2 going forward.\n    (I confirmed that we cannot set \"user.name\" in a pig script to be something other than the user who is submitting the job)\n\nFor queue/pool name\n    there different config parameters that define which queue/pool a job runs in\n    for hadoop2, it is set by property mapreduce.job.queuename\n    for fair scheduler in hadoop1, it's the poolname set by mapred.fairscheduler.pool\n    for capacity scheduler in hadoop1, it's set by mapred.job.queue.name\n    for fifo, there is nothing set because there is no queue, it's default queue\n\nHence for queues, we define an hRaven specific queue property called \"queue\". We check for the above and set the \"queue\" property in the configuration object accordingly.\n\nWe also take care of a present bug in hadoop2, where the queuename contains the string \"default\" as noted in Issue #29 \n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/28103566/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/28109781", "body": "Incorporated the review changes suggested by Maysam and Sangjin. Accordingly created some utility functions for getting user and queue names\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/28109781/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/28259519", "body": "Updating the pull request to not include the user.name put for hadoop2. Since the username is part of the rowkey, it can always be deduced and an extra column is not a must-have. \n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/28259519/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5103230", "body": "Good catch. I will change this.\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5103230/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5104651", "body": "checked in an update\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5104651/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5121212", "body": "yes, done\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5121212/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5260717", "body": "for my understanding - where does count come from?\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5260717/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5273726", "body": "Thanks\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5273726/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5281948", "body": "Sounds good. I debated on this and then thought it might be clearer to send back a false than have the exception inside. But will change this to throw the exception from the implementation side itself rather than returning\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5281948/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5281972", "body": "changing the name and to an interface\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5281972/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5282275", "body": "Yes, I actually wanted to use a entire file here and check the puts returned. But that turned out to be too much of task of generating a generic history file and I reverted back to some string.\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5282275/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5284028", "body": "Yes correct, removing them now\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5284028/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5284246", "body": "Yes, this can be removed now. Earlier it was extending a base class.\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5284246/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5284283", "body": "This is how it is being used presently:\nhttps://github.com/twitter/hraven/blob/master/hraven-etl/src/main/java/com/twitter/hraven/mapreduce/JobFileTableMapper.java#L176\n\nThe intention of this check in is to retain the same behavior.\n\nThe parse method should be called once per job history file. There should be a job history listener per job history file. I don't think multiple threads would be parsing the same job history ever.\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5284283/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}]}, "Yohan-Bismuth": {"issues": [{"url": "https://api.github.com/repos/twitter/hraven/issues/117", "title": "hraven with hbase 0.96+", "body": "Hi, I was having trouble to make hraven work with hbase 0.96 (there seemed to be some api incompatibilities). I made a patch on https://github.com/criteo/hraven, I dont know if you have some interest in it, maybe you could have a look ?\nBy the way, i added a small feature to put hraven tables in a namespace (since hbase 0.96 offers this possibility)\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/117/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "hcoyote": {"issues": [{"url": "https://api.github.com/repos/twitter/hraven/issues/87", "title": "jobFileProcessor.sh complains about missing arguments.", "body": "Running from origin/master.\n\nI have things patched up enough to get the jobFilePreprocessor.sh and jobFileLoader.sh  connecting to our Hadoop environment.  The last step in hraven-etl.sh invokes jobFileProcessor.sh, but this throws errors about missing arguments.\n\nI poked around in the code and it's not really clear what these should be.  machinetype appears like it should be set to \"default\" if not explicitly set, but the arg processor makes this argument required.  Additionally, I can't find a great deal of discussion on what's supposed to be in the cost properties.\n\n```\nERROR: Missing required options: z, m\n\nusage: JobFileProcessor  [-b <batch-size>] -c <cluster> [-d] -m\n       <machinetype> [-p <processFileSubstring>] [-r] [-t <thread-count>]\n       -z <costfile>\n -b,--batchSize <batch-size>                        The number of files to\n                                                    process in one batch.\n                                                    Default 100\n -c,--cluster <cluster>                             cluster for which jobs\n                                                    are processed\n -d,--debug                                         switch on DEBUG log\n                                                    level\n -m,--machineType <machinetype>                     The type of machine\n                                                    this job ran on\n  -p,--processFileSubstring <processFileSubstring>   use only those process\n                                                     records where the\n                                                     process file path\n                                                     contains the provided\n                                                     string. Useful when\n                                                     processing production\n                                                     jobs in parallel to\n                                                     historic loads.\n  -r,--reprocess                                     Reprocess only those\n                                                     records that have been\n                                                     marked to be\n                                                     reprocessed. Otherwise\n                                                     process all rows\n                                                     indicated in the\n                                                     processing records,\n                                                     but successfully\n                                                     processed job files\n                                                     are skipped.\n  -t,--threads <thread-count>                        Number of parallel\n                                                     threads to use to run\n                                                     Hadoop jobs\n                                                     simultaniously.\n                                                     Default = 1\n  -z,--costFile <costfile>                           The cost properties\n                                                     file on local disk\n```\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/87/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/issues/86", "title": "Allow hbase table prefix to be configurable at run-time", "body": "In our HBase environment, we namespace tables in order to group them and more easily identify which project they're associated with.\n\nCurrently, the table names are hardcoded in ./hraven-core/src/main/java/com/twitter/hraven/Constants.java unless you set IS_DEV (which sets PREFIX to \"dev.\") or you just override what PREFIX is set to.  Both options require rebuilding hraven.\n\nIt would be great if this were a run-time option that could be set without having to rebuild.\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/86/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "santhu404": {"issues": [{"url": "https://api.github.com/repos/twitter/hraven/issues/70", "title": "Add skip count to REST calls", "body": "Current REST calls support LIMIT to limit the number of records fetched. With support of SKIP records, now the REST calls makes pagination easy on the server side for processing and returning of the results.\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/70/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "talglobus": {"issues": [], "commits": [{"url": "https://api.github.com/repos/twitter/hraven/commits/11d84a147d97b71a5211a65cf7ef9021e871181f", "message": "Fix typo"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "pgaref": {"issues": [], "commits": [{"url": "https://api.github.com/repos/twitter/hraven/commits/c61806640b1dd08c8cccc681b2aec52d9ee2cb85", "message": "Fixing build failure cause by wrong project dependency in pom"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "maysamyabandeh": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/twitter/hraven/pulls/116", "title": "Integrating HadoopJobMonitor to hRaven", "body": "", "author_association": "NONE"}], "issue_comments": [{"url": "https://api.github.com/repos/twitter/hraven/issues/comments/28105893", "body": "Ship it! Overall looks good to me.\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/28105893/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "angadsingh": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/twitter/hraven/pulls/115", "title": "Create debian from hraven-assembly using jdeb maven plugin", "body": "mvn clean package will produce a .deb in hraven-assembly/target/\n", "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/pulls/112", "title": "Sample falcon config for hraven", "body": "See http://falcon.incubator.apache.org/ for details\n", "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/pulls/111", "title": "bugfix: getLastSuccessfulProcessRecord not taking processingDirectory", "body": "Needed for example, for the ability to run hraven in an idempotent way for each day/shard's run and being able to rerun a shard's run and expect hraven to just resume instead of reprocessing everything.\n", "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/pulls/109", "title": "Hbase 0.90.x compatibility [remove dependency of fuzzy row filter]", "body": "", "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/pulls/108", "title": "Set tmpjars for hadoop", "body": "to be able to find hraven-core and other required libs.\n\nthis is needed when hraven jobs are spawned from oozie/falcon.\n", "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/pulls/107", "title": "ability to specify minModificationTimeMillis as arg", "body": "as an argument to JobFilePreProcessor. Only files after this timestamp will be picked up. Still honor lastProcessRecord.\n", "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/pulls/105", "title": "Path exclusion/inclusion filtering", "body": "Ability to specify include and exclude substrings for job history files.\n\nAlso for this to work, added logic to FileLister.pruneListBySize method to prune orphan job confs and renamed to just pruneList\n", "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/pulls/104", "title": "Prefix hraven to all hbase tables", "body": "Useful to namespace hraven tables separately in a production hbase cluster.\n", "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/pulls/103", "title": "glob list instead of simple hdfs list and pattern support for input", "body": "Right now hraven accepts a simple hdfs path as input folder and will fetch all job history + conf files underneath it. This pull request adds support for specifying a pattern with wildcards (*) and using hdfs api's globStatus method to list files instead of hraven's recursive listFiles method. This way one can easily shard hraven's job to different years/months/days.\n", "author_association": "NONE"}, {"url": "https://api.github.com/repos/twitter/hraven/pulls/102", "title": "Refactoring hraven for multiple sink support", "body": "Generic object model and abstraction for output records of JobFileProcessor's mapper instead of directly emitting Hbase puts at the lowest level of code hierarchy. Used MultipleOutputs to allow sinking to different sinks (graphite, hbase, etc.) and handle specifically writing of records at the sink's OutputFormat level.  Added graphite sink and refactored hbase storage to work as a sink. Changes no hraven behaviour.\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "shrijeet": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/twitter/hraven/pulls/101", "title": "Upgrade jackson and jersey", "body": "The patch upgrades jackson to 2.x and jersey 1.8.x. Jackson 2.x has moved to new namespace, the changes in java files are mostly fixing imports based on new name space. Additionally CustomDeserializerFactory has been removed, the new approach uses Module for adding custom deserializers.\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "caniszczyk": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/twitter/hraven/issues/comments/20019428", "body": "@ghelmling, what do you think? :)\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/20019428/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commit_comments": [], "review_comments": []}, "ghelmling": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/twitter/hraven/issues/comments/20700941", "body": "Fixed by pull request #7 \n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/20700941/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/20849728", "body": "Fixed.\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/20849728/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/21202998", "body": "+1, looks good!\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/21202998/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/23131855", "body": "Two minor comments to resolve: mixed static and instance context, and a wording fix in an exception message.  Otherwise this looks good to merge to me.\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/23131855/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/23435477", "body": "Merged to master.\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/23435477/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5281296", "body": "I think this should be an interface, rather than an abstract class, since there is no shared implementation.  Also I think naming this \"JobHistoryFileParser\" would be better than \"JobHistoryFileDecipher\".  The word \"decipher\" implies that the log files are obfuscated or encrypted in some way.\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5281296/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5281342", "body": "This method should similarly be named parse()\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5281342/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5281429", "body": "Should the parse() implementation throw this exception, rather than returning a boolean and creating it here?  The implementation itself will have more context on what actually went wrong.\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5281429/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5281673", "body": "For the moment, it doesn't seem like we need the JobKey parameter here, only the InputStream for the history file.\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5281673/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5281742", "body": "Do we need to retain this reference to a parser instance?  I think it would be better to remove this, make the createJobHistoryFileParser() method static, and have it always return a new instance.  Unless we suspect that creating a parser for 2.0 will be an expensive operation.\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5281742/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5281795", "body": "I think it would be safer to throw an exception here instead of returning null.  Calling this will a null InputStream is really an error case in my opinion.\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5281795/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5281846", "body": "throw IllegalArgumentException here, since 2.0 is not supported yet.\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5281846/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5282123", "body": "It would be better to use something like the actual 1.0 history file format here, something like this string:\n\n\"Meta VERSION=\\\"1\\\" .\\n\" +\n\"Job JOBID=\\\"job_201301010000_12345\\\"\" \n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/pulls/comments/5282123/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}, "jrottinghuis": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/twitter/hraven/issues/comments/26558927", "body": "We debated downgrading Jackson to 1.8.8 because that is what Hadoop 2.x ships with, but we can deal with that separately if that becomes an issue.\n", "reactions": {"url": "https://api.github.com/repos/twitter/hraven/issues/comments/26558927/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commit_comments": [], "review_comments": []}}}}