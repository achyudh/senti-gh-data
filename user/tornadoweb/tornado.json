{"_default": {"1": {"fabiopedrosa": {"issues": [{"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2250", "title": "Timeout with HEAD method of AsyncHTTPClient on valid URL", "body": "I can't get AsyncHTTPClient to do a simple HEAD request.\r\n\r\nNot working:\r\n```python\r\n#!/usr/bin/env python\r\nimport logging\r\nfrom tornado import ioloop\r\nfrom tornado.web import gen\r\nfrom tornado.httpclient import AsyncHTTPClient\r\nlogging.basicConfig(level=logging.DEBUG)\r\n\r\n\r\n@gen.coroutine\r\ndef test():\r\n    url = \"https://r1---sn-8vq54vox2u-apne.googlevideo.com/videoplayback?id=o-ABEpJv56sbPNCpoxbZ3qozgf0zGDm0AsOL3wDoIuiF-X&mm=31&mn=sn-8vq54vox2u-apne&key=yt6&ip=94.62.195.82&sparams=aitags%2Cclen%2Cdur%2Cei%2Cgir%2Cid%2Cinitcwndbps%2Cip%2Cipbits%2Citag%2Ckeepalive%2Clmt%2Cmime%2Cmm%2Cmn%2Cms%2Cmv%2Cpl%2Crequiressl%2Csource%2Cexpire&ms=au&mt=1516129845&gir=yes&ipbits=0&clen=19042515&initcwndbps=892500&aitags=133%2C134%2C135%2C160%2C242%2C243%2C244%2C278&signature=D48A9A627BDA2EFBCD8F8B6096F50FBDE075AE0A.818C7A69100014D461D43FB9BAE7DC1F90FCDF08&mv=m&expire=1516151561&mime=video%2Fmp4&dur=257.857&pl=16&itag=135&keepalive=yes&source=youtube&requiressl=yes&lmt=1391370300661141&ei=qU5eWt2CA5iE0wWdqLTQCw&ratebypass=yes\"\r\n    client = AsyncHTTPClient()\r\n    try:\r\n        response = yield client.fetch(url, method=\"HEAD\")\r\n        print response.status\r\n        print response.headers\r\n    except:\r\n        logging.exception(\"error\")\r\n\r\n    ioloop.IOLoop.current().stop()\r\n\r\n\r\nif __name__ == '__main__':\r\n    test()\r\n    ioloop.IOLoop.current().start()\r\n```\r\n\r\nworking just fine:\r\n\r\n```python\r\nimport requests\r\nurl = \"https://r1---sn-8vq54vox2u-apne.googlevideo.com/videoplayback?id=o-ABEpJv56sbPNCpoxbZ3qozgf0zGDm0AsOL3wDoIuiF-X&mm=31&mn=sn-8vq54vox2u-apne&key=yt6&ip=94.62.195.82&sparams=aitags%2Cclen%2Cdur%2Cei%2Cgir%2Cid%2Cinitcwndbps%2Cip%2Cipbits%2Citag%2Ckeepalive%2Clmt%2Cmime%2Cmm%2Cmn%2Cms%2Cmv%2Cpl%2Crequiressl%2Csource%2Cexpire&ms=au&mt=1516129845&gir=yes&ipbits=0&clen=19042515&initcwndbps=892500&aitags=133%2C134%2C135%2C160%2C242%2C243%2C244%2C278&signature=D48A9A627BDA2EFBCD8F8B6096F50FBDE075AE0A.818C7A69100014D461D43FB9BAE7DC1F90FCDF08&mv=m&expire=1516151561&mime=video%2Fmp4&dur=257.857&pl=16&itag=135&keepalive=yes&source=youtube&requiressl=yes&lmt=1391370300661141&ei=qU5eWt2CA5iE0wWdqLTQCw&ratebypass=yes\"\r\nr = requests.request('HEAD', url)\r\nprint r.headers\r\n```", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2250/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "Deathangel908": {"issues": [{"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2243", "title": "'autoreload=true' throws 'KeyboardInterrupt' while debugging with python3.6", "body": "To reproduce the issue you can use [default example](http://www.tornadoweb.org/en/stable/#hello-world): \r\n\r\n```\r\nimport tornado.ioloop\r\nimport tornado.web\r\n\r\nclass MainHandler(tornado.web.RequestHandler):\r\n    def get(self):\r\n        self.write(\"Hellof, world!\")\r\n\r\ndef make_app():\r\n    return tornado.web.Application([\r\n        (r\"/\", MainHandler),\r\n    ], debug=True, autoreload=True)\r\n\r\nif __name__ == \"__main__\":\r\n    app = make_app()\r\n    app.listen(8888)\r\n    tornado.ioloop.IOLoop.current().start()\r\n```\r\n\r\nPycharm starts the script with \r\n`/usr/bin/python3.6 /opt/pycharm-eap/helpers/pydev/pydevd.py --multiproc --qt-support=auto --client 127.0.0.1 --port 33261 --file file_name.py`\r\nIf I edit the file and then save it I receive \r\n```\r\nFailed to import the site module\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.6/site.py\", line 73, in <module>\r\n    import os\r\n  File \"/usr/lib/python3.6/os.py\", line 652, in <module>\r\n    from _collections_abc import MutableMapping\r\n  File \"/usr/lib/python3.6/_collections_abc.py\", line 288, in <module>\r\n    Iterator.register(str_iterator)\r\n  File \"/usr/lib/python3.6/abc.py\", line 158, in register\r\n    if issubclass(subclass, cls):\r\n  File \"/usr/lib/python3.6/abc.py\", line 207, in __subclasscheck__\r\n    ok = cls.__subclasshook__(subclass)\r\nKeyboardInterrupt\r\n```\r\n\r\nThis issue reproduces with `python 3.6`. On `python 2.7` autoreload works ok. I also tried to turn off `Safe write` in pycharm, but that doesn't affect it at all. \r\n  \r\n  ", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2243/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "bdarnell": {"issues": [{"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2239", "title": "release: 5.0", "body": "A companion to #2234, this issue is a place to track or suggest issues/PRs that aren't yet fixed/merged in master but should be included in the 5.0 release.\r\n\r\n(The fact that this is empty doesn't mean that I'm planning to take master as it is for 5.0. I haven't done a pass over the queue yet to see what makes my list. I'm just opening this up to suggestions before I finish that)", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2239/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}], "commits": [{"url": "https://api.github.com/repos/tornadoweb/tornado/commits/67abb73db1fed569ae14b9acb3be2bbd949ccba1", "message": "Merge pull request #2249 from bdarnell/pipe-iostream\n\niostream: Use file objects instead of raw descriptors in PipeIOStream"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/commits/5ab1eba2c28af1e9e6365fca9cebe9b9e6837fce", "message": "netutil_test: Disable error tests on TwistedResolver\n\nThese tests are flaky with the new \"messages to stderr are errors\"\ncheck."}, {"url": "https://api.github.com/repos/tornadoweb/tornado/commits/374575517384829e9b1b015bb833c2346a91f479", "message": "test: Count writes to stderr as failures\n\nPython 3 logs warnings in destructors if objects responsible for file\ndescriptors are not explicitly closed. These warnings were previously\nbeing ignored by our test suite unless a human was looking at the log\noutput, but several recent PRs have introduced these issues. This\nchange ensures we catch them (and fixes the most recent one in\nprocess_test. The leak has always been there, but the previous commit\ncaused it to be logged)."}, {"url": "https://api.github.com/repos/tornadoweb/tornado/commits/f5df1e4df7ca149342957f71bf4f98710f6cccdf", "message": "Merge pull request #2248 from bdarnell/work\n\nioloop,gen,asyncio: Improvements to IOLoop GC"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/commits/e964f989399b6a961b3e97e723f03fbe5fc620bc", "message": "ioloop,asyncio: Be more careful to restore old asyncio loop\n\nAny asyncio event loop that was created but neither closed nor set as\ncurrent for some thread will log a warning at the end of the test (in\na way that doesn't cause the test to fail). Fix a bug in\nmake_current() (in which multiple calls would clobber\nself.old_asyncio) and use it more consistently when \"current\" status\nchanges."}, {"url": "https://api.github.com/repos/tornadoweb/tornado/commits/2d7fb199ca91d0e6fb521f347fa1807efe7e121e", "message": "ioloop: Make clear_current work if called first in a thread\n\nFixes #2240"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/commits/1294b0765ff3041342d45bc5a6539a5c8aa2370f", "message": "asyncio: AsyncIOMainLoop.close now closes the underlying loop"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/commits/023a9ac87aa2de87585b71b8fee213346f4b590c", "message": "Merge pull request #2245 from ploxiln/shebang_exec\n\nmake executable git and shebang consistent on various source files"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/commits/e5a214825d0c8374e6dc335b96643582948128de", "message": "Merge pull request #2244 from bdarnell/lint-ci\n\nbuild: Enforce flake8-cleanliness in CI"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/commits/19e54b091fd640d0b9a6b8bedcc02438017fd197", "message": "lint: Check doctest code too"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/commits/3d9ae0e3759f29d5c4c79e56cb727c8ad4d337bf", "message": "lint: Un-skip a few rules"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/commits/f7a7026c8b189d240b2452f0d9ef069df93dcc19", "message": "build: Enforce flake8-cleanliness in CI"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/commits/61bfba41f283340a223f1e31d3691cee12916065", "message": "Merge pull request #2237 from ploxiln/flake8_trivial\n\ntrivial flake8/pyflakes style fixes"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/commits/0a06d4a4099017e8a2a5407f0c3c2e97dbfa235c", "message": "Merge branch 'branch4.5'"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/commits/8e9e75502ff910629663c4cdd7779d43ea2dd150", "message": "Correct version and date on 4.5.3 release notes"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/commits/1cd0e9dde37018558d5ef7aab75df66eb841d9ec", "message": "Merge pull request #2242 from bdarnell/release-4.5.3\n\nRelease 4.5.3"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/commits/09c63c55e05674a51f2cce86d5fda090843afb3a", "message": "Release notes for 4.5.3"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/commits/7be09af39047c8e528946e3dea10f1309be78953", "message": "Get tests passing on latest version of pypy3"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/commits/716ab7d509a44bb00c5cbfec37ad3d16cdcd2618", "message": "Update travis-ci python versions to match master.\n\n2.7.8 is no longer available and \"pypy3\" is old and has\nother issues."}, {"url": "https://api.github.com/repos/tornadoweb/tornado/commits/b525e423c3d143f3e67dba26fea2f1103b9bb6d4", "message": "test: More robust ipv6 detection\n\nThere are many ways ipv6 can be disabled or broken (and it just\nstopped working on travis-ci), so instead of checking flags like\nsocket.has_ipv6, attempt to actually bind to an ipv6 address.\n\nCloses #2185"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/commits/84bb2e285e15415bb86cbdf2326b19f0debb80fd", "message": "testing: Connect to 127.0.0.1 instead of localhost\n\nThe servers used in tests are only listening for ipv4, not ipv6\n(to avoid spurious firewall prompts on macos). In what is apparently\na recent macos change, connecting to `localhost` when the ipv6 port\nis unbound now incurs a 200ms delay, slowing a full test run down\nby a factor of 20."}], "pull_requests": [{"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/1641", "title": "Workaround conflict between new certifi and old openssl.", "body": "Fixes #1534\n", "author_association": "OWNER"}], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/comments/62094", "body": "The goal is to let you configure verbosity (and maybe other things, but mostly verbosity) on a per-module basis.  The tornado.httpclient module in particular is so noisy at the debug level that I end up doing all my application logging at info or higher so I never have to turn on --logging=debug.  This change seems like a step in that direction (although I haven't yet tried to use any non-global logging configuration yet myself).  The need to explicitly define a logger using redundant information is lame, but seems to be how the logging module was (over-)designed to be used.  Did you have something else in mind for module-level logging configuration?\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/62094/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/68108", "body": "So there's another problem with doing things this way.  The root-level logging functions (logging.info(), etc) will call logging.basicConfig() for you if no logging configuration has been done.  If you're using module-level loggers this doesn't happen, so if you're using tornado without tornado.options (which sets up logging in parse_command_line) the only log output you'll get is \"no handlers could be found for logger \"tornado.web\"\".  The recommended fix (file:///opt/local/share/doc/python26-doc/library/logging.html#configuring-logging-for-a-library) is apparently to add a null handler to each logger, which is A) incredibly verbose since you're expected to write your own NullHandler class and B) not really what you want since it means that the library's log output will go to /dev/null in the absence of explicit logging configuration.  This is absurd.  It looks like the only way to get reasonable out-of-the-box behavior is to just use the root logger.  It looks like handler.addFilter can be used to get the kind of per-module verbosity settings that I wanted without multiple loggers, so I think I'll switch everything back to the root logger and try adding a --vmodule-like filter.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/68108/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/68184", "body": "The trouble is that since IOLoop effectively swallows and logs all exceptions, I feel it's important to ensure that tornado's logging is visible by default out of the box.  I don't see any good way to do that with per-module loggers without adding handlers at import time (which sqlalchemy does and it's annoying to work around).\n\nAre you attaching different handlers to the different loggers, or are you just using them to set different levels?  If it's the latter, I think a logging.Filter that inspects the record's module attribute is a good alternative (and will work automatically even for libraries that take the easy way out and just use the root logger).  \n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/68184/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/80306", "body": "I'm not sure it makes sense to talk about REST here, since websockets are inherently non-restful (e.g. the resources being transferred here are the messages, which are not url-addressable).  While I can see some use cases for maintaining a sort of state machine by passing a different callback to receive_message, it seems to me that this is an uncommon use case (and has the unusual failure mode of leaving the connection in a dormant state where incoming messages are silently ignored if you fail to call either receive_message or close).  A single callback for all messages is also more consistent with the javascript side of the API.  However, on rereading the code, it does look like the one-shot behavior was intentional (e.g. the callback is passed around in the functools.partial closures rather than being an attribute of the handler).  I'm inclined to revert receive_message to its previous one-shot behavior and add a new method to set a repeating callback (or maybe just refactor the whole interface so it automatically listens for messages and invokes self.on_message for each one).\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/80306/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/84027", "body": "jehiah:  True, but logging.error is used for plenty of non-fatal errors so I felt that sending a fatal error to logging.error might not get noticed.  Standard error is used for other fatal errors including syntax errors at import time and errors from options.parse_command_line (unless you take special steps to catch them), so I felt it was the most appropriate channel for this fatal error.\n\nakheron:  Excellent, thanks for the pointer.  I'll take a look at multi_socket_action.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/84027/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/86277", "body": "FYI I have now reverted this change.  We might add a simpler interface in the future, but for now a separate call to receive_message is required for each message.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/86277/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/86858", "body": "swax, the issue is that each time the callback is passed through the receive_message/_on_frame_type/_on_end_delimiter cycle it gets wrapped in another layer of async_callback.  \n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/86858/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}], "review_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/1039664", "body": "By precedent elsewhere in the module, this should use the compute_etag method, and allow for that method to return None to suppress the generation of an Etag header.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/1039664/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/1039675", "body": "Ah, so maybe we can't just use compute_etag since this needs to be a classmethod.  Maybe call it compute_etag_for_path to echo the existing RequestHandler method but emphasize that it's based on something other than \"self\".\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/1039675/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/1369400", "body": "Why does this need to save the configuration?  It doesn't look like it touches the global config.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/1369400/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/1838447", "body": "I think this needs to be a deepcopy because the values are mutable lists (otherwise if the query and body both had values with the same key things would be weird)\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/1838447/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/3992303", "body": "What is the Task(None) for?  Why is this line not simply \"yield Task(self.io_loop.add_callback)\" as seen in other gen tests?\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/3992303/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/4310666", "body": "According to http://tools.ietf.org/html/draft-ietf-httpbis-p5-range-22#section-4.2, Content-Range is undefined on response codes other than 206 and 416.  Unless chrome needs the Content-Range header to be present on this 200 response, this set_header call should be moved into the if block as well.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/4310666/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/5941976", "body": "mock._Call doesn't look like a public interface.  It's also not ideal that we call getLogger three times even if the first one returns a value.  I don't mind that we do it since this is not performance-critical code but I don't like tests that depend on this kind of implementation detail.  I'd probably just use an 'or' expression instead of 'any' in the test.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/5941976/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/5941981", "body": "There's no reason for outside code to call this method so it should probably start with an underscore.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/5941981/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/5966769", "body": "What's up with this \"and False\"?  \n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/5966769/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/5966813", "body": "`GoogleOAuth2Mixin.authorize_redirect` should differ from `OAuth2Mixin.authorize_redirect` only in google-specific ways.  We don't construct absolute urls in the base class or in the facebook mixin, so we shouldn't here either (I think this may mean that some doc examples are wrong).  `overwrites` should probably be named `extra_params` for consistency.  Are scope and response_type standard enough to include in the base class?  If so then I'd rather just get rid of this method so callers won't have to think about the inheritance relationship and what's different between the two.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/5966813/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/5966819", "body": "`FacebookGraphMixin` uses `parse_qs_bytes` to read its access token.  Do you know anything about this difference?  Should we be looking at the Content-Type or something instead of blindly using json for google and parse_qs_bytes for facebook? (is FacebookGraphMixin even working?) \n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/5966819/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}]}, "legnaleurc": {"issues": [{"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2209", "title": "Support streaming API for AsyncHTTPClient ", "body": "Mostly like this:\r\nhttps://aiohttp.readthedocs.io/en/stable/client.html#streaming-response-content\r\n\r\nThis could probably solve some usage like #157.\r\n\r\nIt is hard to control the flow by `streaming_callback`, and it does not support async function as well.\r\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2209/reactions", "total_count": 4, "+1": 4, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "lxkaka": {"issues": [{"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2207", "title": "http headers are  capitalized", "body": "Is there any probability do not capitalize the customized http header.\r\nfor example:\r\n{'authtoken': '1234'} will be capitalized through tornado.httputil.HttpHeaders {'Authtoken': '1234'}.\r\nThis can bring troubles for some servers. ", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2207/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "MaxLFarrell": {"issues": [{"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2206", "title": "Web Socket Disconnecting With Small Files", "body": "Web socket disconnects on messages with < 2 mb of base64. Some smaller files will work tested up to 300 kb will work. Otherwise it will just disconnect the client.\r\n\r\n**Relevant code:**\r\n**Client (using [websockets](https://github.com/aaugustin/websockets/)):**\r\n```\r\nwith open(\"private/\" + file, \"rb\") as f:\r\n    responsef = base64.b64encode(f.read()).decode()\r\n    responsej = json.dumps({\"file\": responsef})\r\n    await websocket.send(\"22::\" + responsej + \"||\" + client)\r\n```\r\n**Server:**\r\n```\r\nmh, mb = message.split(\"::\")\r\nresponse, client = mb.split(\"||\")\r\nself.clientd[client + \".client\"].write_message(\"22::\" + response)\r\n```", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2206/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "risboo6909": {"issues": [{"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2196", "title": "Address family support in OverrideResolver", "body": "I was trying to write tests for my code which uses ```ThreadedResolver``` to resolve ip addrs of a list of hosts. Each host may have both ```ipv4``` and ```ipv6``` addrs simultaneously or just one of them, so the goal of the tests was to ensure that my code, which uses ```ThreadedResolver``` to obtain those addrs, behaves as expected. \r\n\r\nIf I understand the [docs](http://www.tornadoweb.org/en/stable/netutil.html?highlight=overrideresolver#tornado.netutil.OverrideResolver) right, ```OverrideResolver``` is the right tool to test code that uses various kinds of resolvers. But it appears that I can't easily assign both addrs to one host using ```OverrideResolver``` because it lacks of addr family parameter. My solution is to copypaste the [code](http://www.tornadoweb.org/en/stable/_modules/tornado/netutil.html#OverrideResolver) of ```OverrideResolver``` into a separate file in my project and add an additional ```family``` parameter to ```resolve``` method so it can map triplets of ```(host, port, family)``` into ```(host, port)```. And it works as expected now.\r\n\r\nI propose to add ```family``` parameter into ```OverriderResolver's``` ```resolve``` method for it to cover wider range of use cases.", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2196/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "sc-syf": {"issues": [{"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2190", "title": "wsgi: HEAD raises \"Tried to write more data than Content-Length\"", "body": "refers to:[Running WSGI apps on Tornado servers](http://www.tornadoweb.org/en/stable/wsgi.html#running-wsgi-apps-on-tornado-servers), I deployed Django project to tornado server. \r\nBut It will raise HTTP 500 sometimes(can not control, and the 500 error is accidental)\uff0c and while use \r\n`curl --head 127.0.0.1:8888` \r\nit will raise Exception:\r\n```\r\nERROR:tornado.application:Uncaught exception HEAD / (127.0.0.1)\r\nHTTPServerRequest(protocol='http', host='127.0.0.1:8888', method='HEAD', uri='/', version='HTTP/1.1', remote_ip='127.0.0.1', headers={'Host': '127.0.0.1:8888', 'User-Agent': 'curl/7.54.0', 'Accept': '*/*'})\r\nTraceback (most recent call last):\r\n  File \"/Users/xxx/.py3/lib/python3.6/site-packages/tornado/web.py\", line 1446, in _execute\r\n    result = self.prepare()\r\n  File \"/Users/xxx/.py3/lib/python3.6/site-packages/tornado/web.py\", line 2706, in prepare\r\n    self.fallback(self.request)\r\n  File \"/Users/xxx/.py3/lib/python3.6/site-packages/tornado/wsgi.py\", line 304, in __call__\r\n    request.connection.write_headers(start_line, header_obj, chunk=body)\r\n  File \"/Users/xxx/.py3/lib/python3.6/site-packages/tornado/http1connection.py\", line 398, in write_headers\r\n    data += self._format_chunk(chunk)\r\n  File \"/Users/xxx/.py3/lib/python3.6/site-packages/tornado/http1connection.py\", line 410, in _format_chunk\r\n    \"Tried to write more data than Content-Length\")\r\ntornado.httputil.HTTPOutputError: Tried to write more data than Content-Length\r\nERROR:tornado.access:500 HEAD / (127.0.0.1) 5.99ms\r\n```\r\nDjango version: 1.11.7\r\nTornado version: 4.5.2\r\nPython: 3.6.0\r\n\r\np.s. while degrade the Django version to 1.9.*, everything is ok.", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2190/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "pitrou": {"issues": [{"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2189", "title": "asyncio Futures can hang if created from the wrong thread", "body": "This snippet: https://gist.github.com/pitrou/d0ed381729ef9045491263774311e9f0 worked before changeset ac13ee5f64cd3bceb1628dbcbbfc77445358038f, but fails afterwards. The reason is `asyncio` sets the `._loop` attribute on its Future objects when said future is created, depending on the current thread's loop. If you create an asyncio Future from a thread and use it from another one, it will never awaken the proper event loop. \r\n\r\nThis seems to be biting us hard and is also very hard to debug, unfortunately. @mrocklin\r\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2189/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2188", "title": "`set_result` can raise on cancelled future", "body": "If some executing `gen.coroutine` has its future cancelled by some other code, a spurious error is logged when the generator finishes:\r\n```\r\ntornado.application - ERROR - Exception in callback functools.partial(<function wrap.<locals>.null_wrapper at 0x7fd9840a70d0>, <Future finished result=None>)\r\nTraceback (most recent call last):\r\n  File \"/home/antoine/tornado/tornado/gen.py\", line 1065, in run\r\n    yielded = self.gen.send(value)\r\nStopIteration\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/antoine/tornado/tornado/ioloop.py\", line 687, in _run_callback\r\n    ret = callback()\r\n  File \"/home/antoine/tornado/tornado/stack_context.py\", line 277, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"/home/antoine/tornado/tornado/gen.py\", line 1155, in inner\r\n    self.run()\r\n  File \"/home/antoine/tornado/tornado/gen.py\", line 1084, in run\r\n    self.result_future.set_result(_value_from_stopiteration(e))\r\nasyncio.base_futures.InvalidStateError: invalid state\r\n```\r\n\r\nThe following patch seems to be a quick fix, but perhaps there is a better resolution.\r\n```\r\ndiff --git a/tornado/gen.py b/tornado/gen.py\r\nindex 533ccb7..18ef4de 100644\r\n--- a/tornado/gen.py\r\n+++ b/tornado/gen.py\r\n@@ -1080,7 +1080,8 @@ class Runner(object):\r\n                         raise LeakedCallbackError(\r\n                             \"finished without waiting for callbacks %r\" %\r\n                             self.pending_callbacks)\r\n-                    self.result_future.set_result(_value_from_stopiteration(e))\r\n+                    if not self.result_future.cancelled():\r\n+                        self.result_future.set_result(_value_from_stopiteration(e))\r\n                     self.result_future = None\r\n                     self._deactivate_stack_context()\r\n                     return\r\n```\r\n\r\n@bdarnell ", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2188/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2176", "title": "Add IOStream.read_into()", "body": "For better performance on large reads, it would be useful to expose a `readinto` or `recv_into`-like operation on `IOStream`. The API could read like:\r\n```python\r\n    def read_into(self, buf, callback=None, partial=False):\r\n        \"\"\"Asynchronously read a number of bytes.\r\n\r\n        ``buf`` must be a writable buffer into which data will be read.\r\n        If a callback is given, it will be run with the number of read\r\n        bytes as an argument; if not, this method returns a `.Future`.\r\n\r\n        If ``partial`` is true, the callback is run as soon as any bytes\r\n        have been read.  Otherwise, it is run when the ``buf`` has been\r\n        entirely filled with read data.\r\n        \"\"\"\r\n```\r\n\r\n@bdarnell, what do you think? Is this something you would like to see? See performance analysis at https://mail.python.org/pipermail/async-sig/2017-October/000392.html\r\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2176/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2171", "title": "Make IOStream class configurable", "body": "In the light of the recent performance discussion, it could be useful to make the IOStream classes configurable. I'm thinking of something like this:\r\n```\r\nclass MyTCPClient(TCPClient):\r\n    IOStream = MyIOStream\r\n\r\nclass MyTCPServer(TCPServer):\r\n    IOStream = MyIOStream\r\n\r\nclass MyIOStream(IOStream):\r\n    SSLIOStream = MySSLIOStream\r\n```\r\n\r\n(note TCPServer can use `start_tls` instead of having its own reference to SSLIOStream)", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2171/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commits": [{"url": "https://api.github.com/repos/tornadoweb/tornado/commits/81dd461da39e7dd9dcd060a958437795bafeb533", "message": "iostream: Use file objects instead of raw descriptors in PipeIOStream\n\nThis makes the implementation of PipeIOStream more compatible with\nsocket streams, and allows for more of the test suite to be used with\nit.\n\nExtracted from PR #2193"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/commits/8c513117fcae553aa938427159de029da4f56edf", "message": "Issue #2229: allow GCing of suspended coroutines\n\nA suspended coroutine should be GCed if the underlying loop is closed\nand no other outside reference exists to it.  However, a suspended coroutine\nwith a refcycle would be kept alive by the _futures_to_runners mapping.\nInstead use a private attribute on the future."}, {"url": "https://api.github.com/repos/tornadoweb/tornado/commits/a91106195905a9cfb1c40cb2cdcc1c94bf46cde9", "message": "Don't keep any reference to memoryviews\n\nSee https://github.com/tornadoweb/tornado/pull/2008 for reasons\nwhy this might be necessary."}, {"url": "https://api.github.com/repos/tornadoweb/tornado/commits/fdc577f15f329303d2d5b3fdb6eb811eb6f0caf2", "message": "Release memoryviews explicitly\n\nSee https://github.com/tornadoweb/tornado/pull/2008 for reasons why this\nmight be necessary."}], "pull_requests": [{"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/2199", "title": "Fix bind_sockets(\"localhost\") on Travis-CI container builds", "body": "We noticed that moving from a VM build to a container build would trigger errors in socket.bind():\r\nhttps://github.com/dask/distributed/pull/1563\r\n", "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/2193", "title": "Fix #2176: Add IOStream.read_into()", "body": "Fix #2176: Add IOStream.read_into()", "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/2175", "title": "Fix #2171: Make IOStream class configurable", "body": "", "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/2085", "title": "Add IOLoop.is_running()", "body": "This provides a public API to replace the private `_running` flag specific to PollIOLoop.\r\nAlso mirrors equivalent APIs provided by asyncio and Twisted.", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "anonymousch": {"issues": [{"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2181", "title": "websocket: Define interface between protocol and handler/conn", "body": "https://github.com/tornadoweb/tornado/blob/5ee7f4573e7542bc2c2dc4f5b5d162ad58499383/tornado/websocket.py#L497\r\n\r\nIn old version, this line use \"self.request.path\", but  request no \"path\" attribute\uff0cso  this line \"path\" maybe modified as \"url\". ", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2181/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "adamrothman": {"issues": [{"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2164", "title": "Expose HTTP request handling time", "body": "Until recently, I had my Tornado applications using `HTTPServerRequest::request_time` to report request handling latencies. While conducting some tests with users in a bandwidth-constrained environment, I noticed that our request timings were downright awful.\r\n\r\nI found this surprising, given that nothing significant had changed in the application prior to the test. After some fruitless exploration, a coworker suggested that Tornado might be including the time taken by the client to complete transmission of the request in `request_time`. Using the server and client scripts below, I verified that this is in fact the case.\r\n\r\n```python\r\nimport asyncio\r\nimport logging\r\nfrom time import time\r\n\r\nfrom tornado.httpserver import HTTPServer\r\nfrom tornado.platform.asyncio import AsyncIOMainLoop\r\nfrom tornado.web import Application\r\nfrom tornado.web import RequestHandler\r\n\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\n\r\nclass TestHandler(RequestHandler):\r\n\r\n    def post(self):\r\n        logger.info('request received')\r\n\r\n    # Lifecycle\r\n\r\n    def prepare(self):\r\n        self.start_time = time()\r\n\r\n    def on_finish(self):\r\n        tornado_time = self.request.request_time()\r\n        logger.info(f'Tornado says request took {tornado_time} s')\r\n\r\n        my_time = time() - self.start_time\r\n        logger.info(f'I say it took {my_time} s')\r\n\r\n\r\nif __name__ == '__main__':\r\n    logging.basicConfig(level=logging.INFO)\r\n    AsyncIOMainLoop().install()\r\n\r\n    app = Application(\r\n        handlers=[('/', TestHandler)],\r\n        autoescape=None,\r\n        debug=True,\r\n    )\r\n\r\n    server = HTTPServer(app)\r\n    server.listen(8080)\r\n\r\n    loop = asyncio.get_event_loop()\r\n    loop.run_forever()\r\n```\r\n\r\n```python\r\nfrom time import sleep\r\n\r\nimport requests\r\n\r\n\r\nclass SlowFile:\r\n\r\n    lines = [\r\n        b'Now is the time',\r\n        b'for all good men',\r\n        b'to come to the aid',\r\n        b'of their country',\r\n    ]\r\n\r\n    def __iter__(self):\r\n        for l in type(self).lines:\r\n            sleep(2)\r\n            yield l\r\n\r\n\r\ndef main():\r\n    f = SlowFile()\r\n    requests.post('http://localhost:8080', data=f)\r\n\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n```\r\n\r\nTornado reports over 8 seconds, when the actual handling latency is well under a second.\r\n\r\nI understand the reasons for exposing this cumulative number, but I also imagine that most server app developers are more interested in the number they can affect more directly \u2013 the actual handling latency. That is, the delta between when a request is fully received and when the response is fully sent.\r\n\r\nIt's easy enough to implement this myself in a `RequestHandler` subclass, but it seems useful enough that maybe Tornado should just expose it.\r\n\r\nWhat do you think @bdarnell?", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2164/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "mrocklin": {"issues": [{"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2147", "title": "Zero copy send", "body": "It would be convenient to reduce CPU use when sending large memoryviews of data.  I've brought this up a couple of times \r\n\r\n- https://github.com/tornadoweb/tornado/issues/1685\r\n- https://github.com/tornadoweb/tornado/pull/1691\r\n\r\nAnd it has been raised by @bryevdv for websockets\r\n\r\n- https://github.com/tornadoweb/tornado/issues/2102\r\n\r\nPreviously I've closed my issues saying that this wasn't yet a bottleneck for my applications (dask).  However now several users are using Dask on HPC systems with fast multi-GB interconnects and this has now become a bottleneck.  I'd like to revisit the issue.\r\n\r\nAre there any objections or known challenges to handling memoryviews all the way from user input to system call?  (other than developer time of course)  I'm able to spend some cycles on this problem, but I'd like to verify that it's feasible and check in with core devs to see if there is anything that I should be aware of before starting.", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2147/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2110", "title": "IOStream._handle_write blocks when _write_buffer is large", "body": "When dumping a gigabyte or so into an IOStream I observe my event loop pausing for long periods of time (about a second).  I believe that this is due to long atomic calls to `_handle_write` that continue looping while the `_write_buffer` still has data.  This can cause some unpleasant blocking in the application.\r\n\r\nIs it feasible to have `_handle_write` yield from time to time during large writes?", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2110/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "cpointner": {"issues": [{"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2145", "title": "Proxy Setting doesn't work for HTTPs", "body": "Currently the only option to have working proxy support is to use the CurlAsyncHTTPClient together with the proxy_host and proxy_port args. Unfortunately the way this is implemented is flawed which results in not working HTTPs Proxy support (using HTTP Connect). The curl library wants the option [HTTPPROXYTUNNEL](https://curl.haxx.se/libcurl/c/CURLOPT_HTTPPROXYTUNNEL.html) in that case.\r\n\r\nThe easiest way to fix this would be to simply remove [this line](https://github.com/tornadoweb/tornado/blob/master/tornado/curl_httpclient.py#L365) as curl will then use the environment variables http_proxy and https_proxy and will set the HTTPPROXYTUNNEL option if needed. As stated in #754 using the well known environment variables is the standard way to configure proxies and they should imho be honored by tornado as well.", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2145/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "rajasankar": {"issues": [{"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2140", "title": "Need more parameters for auth get_authenticated_user method", "body": "Google OAuth2 has changed the parameters to be passed to change the code to access_token. \r\n\r\nparams = { 'code':code,\r\n                               'client_id':self.settings['google_oauth']['key'],\r\n                                'client_secret':self.settings['google_oauth']['secret'],\r\n                                'redirect_uri':'http://localhost',\r\n                                'grant_type':'authorization_code',\r\n                                 }\r\n\r\nAs these params cant be passed in the current get_authenticated_user method, OAuth2 method fails to get access_token. \r\n\r\nI have used to requests to get the token and it works fine. \r\n\r\nExtra params option is coded in authorize_redirect , so it can be added in get_authenticated_user\r\n\r\nI havent tested for Facebook/Twitter, get_authenticated_user method for FacebookGraphMixin has extra fields and option to pass client_id and client_secret. \r\n\r\nSame can be added for get_authenticated_user in GoogleOAuth2Mixin", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2140/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "tsantor": {"issues": [{"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2136", "title": "WebSocketProtocol13.periodic_ping exception", "body": "We are running a Tornado TCP server on a Windows server 2012 machine. This machine handles both an HTTP-based dashboard and 21 TCP Websocket connected clients. Occasionally in the logs we will see the following error. It seems to be at a very low level of the Websocket13 protocol. But from a networking standpoint what does it mean? Why would the write buffer not be greater than or equal to 0?\r\n\r\n    [ERROR] [2017-08-17 11:54:14 AM] [tornado.application] Exception in callback <bound method WebSocketProtocol13.periodic_ping of <tornado.websocket.WebSocketProtocol13 object at 0x01D7AD30>>\r\n\r\n    Traceback (most recent call last):\r\n\r\n    File \"C:\\Python27\\lib\\site-packages\\tornado\\ioloop.py\", line 1026, in _run\r\n\r\n        return self.callback()\r\n\r\n    File \"C:\\Python27\\lib\\site-packages\\tornado\\websocket.py\", line 1030, in periodic_ping\r\n\r\n        self.write_ping(b'')\r\n\r\n    File \"C:\\Python27\\lib\\site-packages\\tornado\\websocket.py\", line 790, in write_ping\r\n\r\n        self._write_frame(True, 0x9, data)\r\n\r\n    File \"C:\\Python27\\lib\\site-packages\\tornado\\websocket.py\", line 768, in _write_frame\r\n\r\n        return self.stream.write(frame)\r\n\r\n    File \"C:\\Python27\\lib\\site-packages\\tornado\\iostream.py\", line 406, in write\r\n\r\n        self._handle_write()\r\n\r\n    File \"C:\\Python27\\lib\\site-packages\\tornado\\iostream.py\", line 847, in _handle_write\r\n\r\n        assert self._write_buffer_size >= 0\r\n\r\n    AssertionError", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2136/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "chenasraf": {"issues": [{"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2131", "title": "IOError: fd already registered", "body": "Not sure what's going on. Our code doesn't handle its own IO loop and relies on the implementations inside tornado's defaults - and I keep getting this error:\r\n\r\n```\r\n2017-08-10 12:10:11,581 http1connection 67799:731 tornado.general ERROR Uncaught exception\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python2.7/site-packages/tornado/http1connection.py\", line 722, in _server_request_loop\r\n    ret = yield conn.read_response(request_delegate)\r\n  File \"/usr/local/lib/python2.7/site-packages/tornado/gen.py\", line 1055, in run\r\n    value = future.result()\r\n  File \"/usr/local/lib/python2.7/site-packages/tornado/concurrent.py\", line 238, in result\r\n    raise_exc_info(self._exc_info)\r\n  File \"/usr/local/lib/python2.7/site-packages/tornado/gen.py\", line 1069, in run\r\n    yielded = self.gen.send(value)\r\n  File \"/usr/local/lib/python2.7/site-packages/tornado/http1connection.py\", line 245, in _read_message\r\n    self.stream.set_close_callback(self._on_connection_close)\r\n  File \"/usr/local/lib/python2.7/site-packages/tornado/iostream.py\", line 420, in set_close_callback\r\n    self._maybe_add_error_listener()\r\n  File \"/usr/local/lib/python2.7/site-packages/tornado/iostream.py\", line 941, in _maybe_add_error_listener\r\n    self._add_io_state(ioloop.IOLoop.READ)\r\n  File \"/usr/local/lib/python2.7/site-packages/tornado/iostream.py\", line 971, in _add_io_state\r\n    self.fileno(), self._handle_events, self._state)\r\n  File \"/usr/local/lib/python2.7/site-packages/tornado/ioloop.py\", line 728, in add_handler\r\n    self._impl.register(fd, events | self.ERROR)\r\n  File \"/usr/local/lib/python2.7/site-packages/tornado/platform/kqueue.py\", line 40, in register\r\n    raise IOError(\"fd %s already registered\" % fd)\r\nIOError: fd 12 already registered\r\n2017-08-10 12:10:11,582 ioloop 67799:741 tornado.general DEBUG Error deleting fd from IOLoop\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python2.7/site-packages/tornado/ioloop.py\", line 739, in remove_handler\r\n    self._impl.unregister(fd)\r\n  File \"/usr/local/lib/python2.7/site-packages/tornado/platform/kqueue.py\", line 50, in unregister\r\n    self._control(fd, events, select.KQ_EV_DELETE)\r\n  File \"/usr/local/lib/python2.7/site-packages/tornado/platform/kqueue.py\", line 63, in _control\r\n    self._kqueue.control([kevent], 0)\r\nOSError: [Errno 2] No such file or directory\r\n```\r\n\r\nAnd I mean me, specifically, and I don't know where to start debugging.\r\nIt happens on one process which relies on other services that run similarly, each as its own process, but none of them give out this error.\r\n\r\nI'm not sure a de-facto solution is available but I'd at least like to find where I can even begin to find the source of this problem. Any ideas?", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2131/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ssb22": {"issues": [{"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2127", "title": "CurlAsyncHTTPClient should warn when max_clients exceeded", "body": "`max_clients` in `CurlAsyncHTTPClient` defaults to 10 (which seems low for high-load applications), and there is no option to warn when its `_process_queue` can't fit all `self._requests` into `self._free_list`. Surplus requests are queued\u2014but deadlock can occur if we're fetching from a back-end server which will not respond to the requests in progress until the queued requests are sent.\r\n\r\nIn my application, I needed to do some processing both downstream and upstream of a legacy proxy which I must treat as a \"black box\".  So when a request `R0` comes in from the client, I do things to it and then send a request `R1` to the black box.  Then the black box makes a request `R2` back to me on a different port, and I do things to that and send a request `R3` elsewhere.  When I get the response from `R3`, I can send the reply for the black box's request `R2`, and that will cause the black box to reply to my `R1` request and finally I can reply to `R0`.  Notice that I won't get the response from `R1` until I've finished servicing `R2`, which I can't do until I've sent and handled `R3`.  So `R1` depends on `R3`, so if `R3` is put into a queue waiting for `R1` to finish, I'm in trouble.  Of course there are many ways I can work around this problem: I can set a larger value of `max_clients` to decrease the chances of that queue having to come into play, or I can run a completely different Tornado process for the other port, or something.  But the issue was I had a deadlock and (for a few hours) no idea why.  If there were some way of turning off the queue and raising an exception if I overload `_free_list`, or at least logging a warning, that would have saved some debugging.  Thanks.", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2127/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "jayanth1991": {"issues": [{"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2122", "title": "SSL: DECRYPTION_FAILED_OR_BAD_RECORD_MAC", "body": "I see these warnings in my tornado logs when a client is attempt to send some data over a websocket to the server using a CA authorized certificate.\r\n\r\nHere is the full error:\r\n` WARNING iostream.py:659: error on read: [SSL: DECRYPTION_FAILED_OR_BAD_RECORD_MAC] decryption failed or bad record mac (_ssl.c:1754)`\r\n\r\nWhen this happens my connection is dropped immediately.\r\nI am running Ubuntu 16.04 on AWS with kernel:\r\n`Linux ip-[MASKED] 4.4.0-1022-aws #31-Ubuntu SMP Tue Jun 27 11:27:55 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux`\r\n\r\nOpenSSL version:\r\n`OpenSSL 1.0.2g  1 Mar 2016`\r\n\r\nShould I be concerned?\r\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2122/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "bryevdv": {"issues": [{"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2102", "title": "Reduce Websocket copies / accept memoryviews", "body": "\r\nSince masking of inbound (client->server) message is mandated by RFC, a copy in that case is unavoidable. However outbound masking (server->client) is *not* mandated, and appears to be turned off by default:\r\n\r\nhttps://github.com/tornadoweb/tornado/blob/master/tornado/websocket.py#L587\r\nhttps://github.com/tornadoweb/tornado/blob/master/tornado/websocket.py#L461-L462\r\n\r\n(It is set to `True` in the WS client connection class, as expected)\r\n\r\nThis outbound case is the most relevant and important one for Bokeh, so any improvements to reduce copies on outbound messages would be beneficial for Bokeh users. \r\n\r\nBelow are some ideas from tracing through the code, I am sure there are many details I am not familiar with, but perhaps this can start a discussion. \r\n\r\n---\r\n\r\nAllow `write_messages` to accept a `memoryview`. Then in `_write_frame`, instead of doing all these concatenations:\r\n\r\nhttps://github.com/tornadoweb/tornado/blob/master/tornado/websocket.py#L762-L767\r\n\r\n Place the message chunks on the stream write buffer individually. I am not sure if multiple calls to `self.stream.write(chunk)` would suffice (I'm guessing not), or if `iostream.write` would have be modified to accept multiple ordered chunks. However, it seems that `iostream.write` is already capable of storing a list of pending writes when the write buffer is \"frozen\". Currently all of these buffers get concatenated:\r\n\r\nhttps://github.com/tornadoweb/tornado/blob/master/tornado/iostream.py#L840\r\n\r\nBut perhaps instead of concatenating before clearing pending writes, the list of buffers could be copied instead, then `_handle_write` could loop over these, instead of expecting one concatenated array.\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/2102/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "bp1222": {"issues": [], "commits": [{"url": "https://api.github.com/repos/tornadoweb/tornado/commits/3e10b90e162c5b2548d7dd0b8ef9a138999b3d23", "message": "Alter documentation to correctly state behavior (#2114)\n\nCorrectly document that the result of Condition.wait() is\r\nnot to raise a TimeoutError, but rather False."}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "jehiah": {"issues": [], "commits": [{"url": "https://api.github.com/repos/tornadoweb/tornado/commits/bfcf34a95b1de4a7fd8a02b6465da8c73c693760", "message": "demos/file_uploader: add missing __name__ == __main__ stanza"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/commits/8906b3afd899bafd575135c01bb7a99bab752a8e", "message": "make executable bit and shebang consistent on various source files\n\nsetup.py is intended to be run with \"python setup.py install\"\n\nsources in the tornado module which have main functions/clauses\nare intended to be run with \"python -m tornado.xxx\"\n\nvarious demos and scripts can be run directly"}], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/comments/83996", "body": "the rest of tornado does not use `print >> sys.stderr` so it would be nice to switch this to logging.error()\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/83996/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/84148", "body": "I guess i should clarify that i'm thinking of cases where logging.error would be redirected to a common log store like syslog or scribe, but the stderr message could just be lost. I see the benefits of logging to sys.stderr as it is directly prior to existing the process, so perhaps both makes sense in this case?\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/84148/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "review_comments": []}, "ploxiln": {"issues": [], "commits": [{"url": "https://api.github.com/repos/tornadoweb/tornado/commits/f1f7d2ef8a5428ad64877191a4efafa47b9fe752", "message": "fix HTTPInputError reference for improperly terminated chunked request\n\nbug introduced in #2225"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/commits/17210e382571b87eb1bd80972a79c9f2f4e92adc", "message": "http: read final crlf of chunked requests\n\notherwise a subsequent request on the same connection\nwill fail to be parsed\n\nthanks to @eeelin for the bug report"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "Lancher": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/2221", "title": "fix autoreload argv perservation", "body": "#1983 \r\nI think I just follow your ideas. The testcase is done by two process one is to touch the `__init__.py` file and the other is the `autoreload` process, but I not sure if it is appropriate because it kind of integration test not unit test.\r\n\r\nI have another version of testcase which work for python2 because for python>=3.4, the `tornado._reload()` will run the module use current `spec` which is `testapp` not the `tornado._reload()`.\r\n\r\n```\r\nclass AutoreloadTest(unittest.TestCase):\r\n\r\n    def test_reload_module_with_argv_preservation_only_for_python2(self):\r\n        main = \"\"\"\\\r\nimport os\r\nimport sys\r\nfrom tornado import autoreload\r\n\r\n# This import will fail if path is not set up correctly\r\nimport testapp\r\nprint(autoreload._original_argv)\r\nif 'TESTAPP_STARTED' not in os.environ:\r\n    os.environ['TESTAPP_STARTED'] = '1'\r\n    sys.stdout.flush()\r\n    autoreload._reload()\r\nelse:\r\n    sys.stdout.flush()\r\n    autoreload.add_reload_hook(lambda: os._exit(0))\r\n    autoreload._reload()\r\n\"\"\"\r\n\r\n        # Create temporary test application\r\n        path = mkdtemp()\r\n        os.mkdir(os.path.join(path, 'testapp'))\r\n        open(os.path.join(path, 'testapp/__init__.py'), 'w').close()\r\n        with open(os.path.join(path, 'testapp/__main__.py'), 'w') as f:\r\n            f.write(main)\r\n\r\n        # Make sure the tornado module under test is available to the test\r\n        # application\r\n        pythonpath = os.getcwd()\r\n        if 'PYTHONPATH' in os.environ:\r\n            pythonpath += os.pathsep + os.environ['PYTHONPATH']\r\n\r\n        p = Popen(\r\n            [sys.executable, '-m', 'tornado.autoreload', '-m', 'testapp'], stdout=subprocess.PIPE,\r\n            cwd=path, env=dict(os.environ, PYTHONPATH=pythonpath),\r\n            universal_newlines=True)\r\n        out = p.communicate()[0]\r\n        self.assertEqual((str([os.path.join(os.path.dirname(os.path.abspath(tornado.autoreload.__file__)),\r\n                                            'autoreload.py'), '-m', 'testapp']) + '\\n') * 2, out)\r\n```", "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/1517", "title": "TCPClient with connection timeout support.", "body": "Hi, I close the previous pull-request because of some mess.\n\n1) Add `timemout` parameter to the TCPClient.connect. Use self._future to record the current undone future.\n\n2) Add a testcase which connect to a non-routable IP address to simulate the connection timeout event.\n\nThanks\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "luojiebin": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/2217", "title": "Finish return future", "body": "Fix issue #2061 ", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "eklitzke": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/2139", "title": "Allow custom loader callbacks in parse_config_file()", "body": "This change is pretty straightforward: it allows users to pass a custom callback to `options.parse_config_file()` to load the config path in some custom way. I intend to use this on a personal project to load YAML configs. The test case I added loads a JSON config using the builtin Python `json` module, to avoid introducing new dependencies.", "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/2026", "title": "make http clients implement the context manager protocol", "body": "This lets you use HTTPClient and AsyncHTTPClient as context managers. The `__exit__` method closes the underlying client.", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "jonmorehouse": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/2103", "title": "ioloop: add loop iteration callback", "body": "I wanted to try and build better metrics around _how_ long the `ioloop` is blocked in a few applications.\r\n\r\nSpecifically, I tried to do something like:\r\n\r\n```python\r\ndef ioloop_blocked_callback(signal, frame, threshold_ms):\r\n        metrics.incr('ioloop_blocked', tags={'duration': '{}ms'.format(threshold_ms)})\r\n\r\n    for threshold in range(50, 2000, 50):\r\n        tornado.ioloop.set_blocking_signal(threshold, functools.partial(ioloop_blocked, threshold_ms=threshold))\r\n```\r\nwhich led me to realized that we couldn't actually set more than one blocked threshold.\r\n\r\nDigging in a bit further, I was thinking it might be generally useful to add a `hook` which allows us to run a callback on each iteration of the ioloop. Specifically, here, I'm curious about how long an iteration takes as well as how much work its doing. My assumption, is that its probably just as good to understand _how_ long iterations are taking because you could use it to help understand how saturated the `ioloop` is. For instance, if we're consistently returning a lot of event pairs, we know we're saturating the `ioloop`, right? \r\n\r\nI ended up implementing a `callback` with _this_ branch where I wrote metrics for the following code to try and pull out some of this context. Here's some pseudo code:\r\n\r\n```python\r\n  iter_start_ts = time.time()\r\n\r\n    def iter_callback(ncallbacks, nevents):\r\n        global iter_start_ts\r\n\r\n        metrics.incr('io_loop_iteration.count')\r\n        metrics.timing('io_loop_iteration.latency', time.time() - iter_start_ts)\r\n        metrics.histogram('io_loop_iteration.callbacks', ncallbacks)\r\n        metrics.histogram('io_loop_iteration.events', nevents)\r\n\r\n        iter_start_ts = time.time()\r\n\r\n    tornado.ioloop.IOLoop.instance().set_loop_iter_callback(iter_callback)\r\n```\r\n\r\nMaybe there's a better way to do something like this and get these metrics, which I'd totally be open to trying!\r\n\r\n**PS** oops - I meant to open this PR on my own fork first!", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ptylenda": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/2040", "title": "Unable to use non-ascii characters in user/password for basic auth in curl_httpclient", "body": "The issue has been described in #2039.", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "judeaugustinej": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/1959", "title": "Adding example for testing in tornado.", "body": "I have add 3 example, one for http server, https server and last one for database backed tornado app.", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "stiletto": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/1898", "title": "RFC 5987 support for 'filename' in Content-Disposition", "body": "This pull request adds support for non-english filenames encoded as specified in RFC 5987.\r\n``` filename*=utf-8''%D0%B4%D0%B6%D0%B8%D0%B3%D1%83%D1%80%D0%B4%D0%B0.jpg ```", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "pantuza": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/1880", "title": "Simple refactoring: Isolating parameters as class member variables", "body": "This pull request has only simple modifications on the Waker class.\r\n\r\nGenerally, I've isolated parameters like, buffer size, local address and maximum number of queued connections to be a class members. Ii turns the class more extensible. \r\n\r\nNo big logic modification or interface changes were made.  ", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "shubham0704": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/1868", "title": "added ajax demo", "body": "Along with demo for handling cross origin requests\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "horejsek": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/1756", "title": "Mocks for async tornado functions", "body": "Hi. I created some mocks to be able mock-out some async tornado functions. I used them a lot in several projects and I wanted to make library, but I think it can be included in Tornado which is more handy.\n\nI made it in separate module because it needs also mock library which has to be installed prior Python 3.3. So it's not problem if someone don't want use those mocks in older Python but wants use testing module.\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "eyj": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/1752", "title": "Fail early if a v1 cookie is submitted to a service configured with v2", "body": "Currently, if 'secret' is a dict and a v1 cookie is submitted, the utf8() function that is later called on secret in the v1 signing function throws a ValueError. The correct behaviour would be to return None.\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "gnprice": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/1735", "title": "Add an optional script to install mypy", "body": "(This branch is stacked on top of #1733 -- only the last commit is new.)\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "Maillol": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/1714", "title": "Update options to have same behavior from config file or command line", "body": "Currently, Tornado raise an error when we use types option in configuration file such as \noptions.define('datetime', type=datetime.datetime)\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "murisimov": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/1658", "title": "Add handling of external log rotation", "body": "Recently I've ran into a problem with logrotate and tornado. When log is being rotated by an external utility, tornado doesn't know that and keeps streaming to an old log, which by that moment can be renamed or even moved to another directory. So i've made this change to my app to handle log rotation, it uses WatchedFileHandler from logging.handlers:\n\n```\n# parse_command_line() function sets RotatingFileHandler as main logger,\n# but we need WatchedFileHandler since we want be robust to guys like logrotate.\nlog_handler = logging.handlers.WatchedFileHandler(options.log_file_prefix) # Prepare handler\nlog_handler.setFormatter(LogFormatter(color=False)) # Set tornado-style log formatting\n\nlog = logging.getLogger()  # Get main logger\nlog.handlers = [] # Remove all handlers (actually it's just the RotatingFileHandler in our case)\nlog.addHandler(log_handler) # Set handler that we really need.\nlog.propagate = False # Prevent duplicate logging\n```\n\nAnd then i thought, why not add this option to tornado? Seems like it could be useful.\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "marrrvin": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/1628", "title": "Add ability to pass max_restarts into process.fork_processes call in \u2026", "body": "", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "mqingyn": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/1622", "title": "add simple_httpclient connection pool support", "body": "Keep-Alive pooling to SimpleAsyncHTTPClient per #1457 .\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "sema": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/1618", "title": "Make StackContext threadsafe", "body": "We are seeing some unexpected behavior from StackContext when sharing StackContexts between multiple threads. Most notably, user-supplied contexts created and mannaged by StackContext are exited before being entered, and are sometimes entered/exited by different threads.\n\nLet me explain the underlying race fixed by this PR by giving a brief overview of StackContext.\n\n``````\n- When entering a context, create an instance of StackContext and\n  add add this instance to the current \"context stack\"\n- If execution transfers to another thread (using the wraps helper method), copy the current\n  \"context stack\" and apply that in the new thread when execution starts\n- A context stack can be entered/exited by traversing the stack and calling enter/exit on all\n  StackContext et al. instances. This is how the `wraps` helper method enters/exits in new threads.\n- StackContext has an internal pointer to user-supplied context factories, and an\n  internal stack of entered user-supplied contexts.\n\nThe relevant logic inside StackContext for entering/exiting contexts.\n\n```\ndef __init__(self, context_factory):\n    self.context_factory = context_factory\n    self.contexts = []\n    self.active = True\n\ndef enter(self):\n    context = self.context_factory()\n    self.contexts.append(context)\n    context.__enter__()\n\ndef exit(self, type, value, traceback):\n    context = self.contexts.pop()\n    context.__exit__(type, value, traceback)\n```\n``````\n\nHowever, the above code does not work as expected if the request context is used across multiple\nthreads together with wraps. The following executing illustrates the issue:\n1. thread A enters a context, creating the instance (alpha) and adds it to self.contexts\n2. thread A schedules a function to run on thread B using `wraps`\n3. thread B enters the context, creating the instance (bravo) and adds it to self.contexts\n4. thread A exits its context, popping (bravo)  of the stack and calling exit on it\n- In the above case, the exit by thread A pops the instance created by thread B and calls exit\n  on this instance.\n- There exists a race between `enter` and `exit` where thread A executes the two first\n  statements of enter (create instance and add it to contexts) and thread B executes exit\n  (pop the newly added instance from contexts and call exit on it). As a result, context\n  instances may be created and \"exited\" before \"entered\".\n\nThe solution to this issue is to manage the context instances using a thread local.\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "jonathanstrong": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/1603", "title": "Django-style kwargs for reverse_url", "body": "This adds Django-style url kwargs for Application.reverse_url without breaking the current args-only API. URLSpec.find_groups has been changed to a shameless theft of the core Django function that powers their url reverse functionality: django.utils.regex_helper.normalize. \n\nExample:\n\n```\n>>> import tornado.web\n>>> optional_kwarg_scheme = r'so-many-possibilities(?:/kwarg1/(?P<kwarg1>\\d+))?(?:/kwarg2/(?P<kwarg2>\\w+))?$'\n>>> u = tornado.web.URLSpec(optional_kwarg_scheme, None, 'options')\n>>> u.reverse()\n'so-many-possibilities'\n>>> u.reverse(kwarg1=1)\n'so-many-possibilities/kwarg1/1'\n>>> u.reverse(kwarg2='a')\n'so-many-possibilities/kwarg2/a'\n>>> u.reverse(kwarg1=1, kwarg2='a')\n'so-many-possibilities/kwarg1/1/kwarg2/a'\n```\n\nNotes: \n- Like the one this replaces, reverse does no checking that the kwargs (or args) match the regex scheme, other than that the kwarg keys must matched the named groups, so you could do this: \n\n```\n>>> u.reverse(kwarg1='a')\n'so-many-possibilities/kwarg1/a'\n```\n\nwhich creates a bad url. If desired, URLSpec.reverse could be changed to check the final result is a match to self.regex.\n- I noticed that this had come up a few years ago, and it seems like some kw functionality was added, but I've found this to be quite helpful in django url routing. \n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "rudyryk": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/1569", "title": "Fix #1543 and add hello world example for running on asyncio event loop", "body": "", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "mehmetkose": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/1481", "title": "Added localization demo", "body": "I think people are looking for details on the localization;\nhttps://groups.google.com/forum/#!topic/python-tornado/olR9J3ThH8I\nI wrote a localization demo quickly. Maybe this could help better understanding.\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "drewmiller": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/1457", "title": "Initial work on Keep-Alive", "body": "An initial attempt at adding Connection: Keep-Alive pooling to SimpleAsyncHTTPClient per #324.\n\nIn order to prevent duplication of the url-parsing step, I converted the current process to a class method that is called and compared against idle connections if the reuse_connections attribute is set. If a new connection is required, the \"_ConnectionBase\" namedtuple is passed as a parameter to the private _HTTPConnection class so that re-parsing is not necessary.\n\nPlease let me know what we can do to improve the testing here.\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "anandology": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/1455", "title": "Support for incremental template rendering", "body": "The current implementation generates the template as a big string. This pull request, tries to make that an iterator.\n\nInstead of appending the generated output to a buffer, it yield each item making the function a generator. With this it'll be possible to give away control in the middle of a template.\n\nI've also added a `render_async` function to `RequestHandler` class.\n\nAn example to try this out is available at:\nhttps://gist.github.com/anandology/16189f58c7486885fe45\n\nAll the tests in the testsuite are passing.\n\nMy non-scientific benchmark is showing that the generator version is running slightly faster than original version.\n\n**Possible Issues**:\n- The `_Node.generate` now returns a generator instead of a string. This could potentially break backward compatibility.\n- `render_async` may not the most appropriate name for that function.\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "sangsta": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/1364", "title": "Reset waker if it errors out.", "body": "This is the diff that fixes the issue discussed in the following thread:\nhttps://groups.google.com/forum/#!topic/python-tornado/oNE8KcdflqQ\nIf the Waker's reader socket encounters an ECONNRESET error, the ioloop spins, causing 100% CPU usage. We fix this by resetting the waker whenever we encounter this error.\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "caseymrm": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/47248", "body": "We'd love some help testing performance Pykler, let us know what you discover.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/47248/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/47553", "body": "Thanks, done!\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/47553/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/47554", "body": "Thanks, done!\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/47554/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commit_comments": [], "review_comments": []}, "greut": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/47446", "body": "web.by fires up a thread; I've done it by using an external worker.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/47446/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "finiteloop": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/47940", "body": "I don't like this as a default behavior, but I think an addslashes decorator would be useful.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/47940/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/49491", "body": "Fixed, thanks\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/49491/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/49492", "body": "That is not really a solution because it makes Tornado insecure. See http://groups.google.com/group/python-tornado/msg/2add351bb61376fd and the rest of the thread for more secure potential solutions.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/49492/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/53870", "body": "Thanks, fixed\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/53870/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/53871", "body": "Thanks, fixed\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/53871/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/53873", "body": "Subclassing is probably the only reasonable way right now. Thinking about better ways to do this in the future, but that is the best way currently.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/53873/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/53874", "body": "We will consider this for future releases.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/53874/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/53877", "body": "Can you explain the use case? Why do you want to prevent Unicode escaping?\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/53877/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/56770", "body": "Good idea, we will add this in the next release.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/56770/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commit_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/comments/62087", "body": "I really don't like this change - why did we commit this? What is the goal?\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/62087/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "review_comments": []}, "joerussbowman": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/48539", "body": "And I see addslashed and removeslashes decorators have already been added :) And I agree, it's a good solution. Thanks.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/48539/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commit_comments": [], "review_comments": []}, "severb": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/49624", "body": "You can also accomplish the same thing using key.indices(size).\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/49624/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "jed": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/54704", "body": "Well, in my case, I'm doing string matching on the client that is impeded by escaping (the strings no longer match). This is definitely something that can be solved in Javascript, but it seems to me that Tornado (which is awesome by the way) might be better off providing the options that Python users expect for JSON.\n\nTo be honest, I'm not sure why escaping is the default for simplejson, since most text needs no escaping, and it doubles the size of the payload for some languages (like Japanese).\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/54704/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "lucky": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/55294", "body": "You probably want [subprocess](http://docs.python.org/library/subprocess.html).\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/55294/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "csytan": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/55570", "body": "Here's a patch:\n\n```\ndiff --git a/tornado/web.py b/tornado/web.py\nindex 08047a4..bc626a8 100644\n--- a/tornado/web.py\n+++ b/tornado/web.py\n@@ -590,6 +590,9 @@ class RequestHandler(object):\n\n         See http://en.wikipedia.org/wiki/Cross-site_request_forgery\n         \"\"\"\n+        if self.request.headers.get(\"X-Requested-With\") == \"XMLHttpRequest\":\n+            return\n+        \n         token = self.get_argument(\"_xsrf\", None)\n         if not token:\n             raise HTTPError(403, \"'_xsrf' argument missing from POST\")\n```\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/55570/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/72200", "body": "As I understand, no, since modification of request headers needs to be done programmatically using javascript, flash, java, etc.  These environments implement the \"same origin policy\" so that requests may only be sent to the same domain that the scripts are served from.\n\nHere's some more info if you're interested:\nhttp://code.google.com/p/browsersec/wiki/Part2#Same-origin_policy\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/72200/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "sirpengi": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/65228", "body": "I did self.db.execute(\"UPDATE t SET %s = %%s WHERE id =%%s\" % (field), value, id)\nThough I'm not too happy with how it looks.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/65228/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "Kuze": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/65403", "body": "After building out a few models like this I came to the same conclusion, it doesn't look so clean, extremely repetitive, and error prone. I think as advertised Tornado's database.py is really for light use, so I've decided to bite the bullet and go with Elixir. I'm finding to be a good fit and more.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/65403/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "gmr": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/68306", "body": "Hmm this is not the right solution.  I am seeing an issue with no_keep_alive = True due to an issue with tornado not handling redirects properly with Cherokee with keep-alives on.  Will open another ticket when I track this down further.  I do think line 127 should be qualified, but see that the no_keep_alive is passed into HTTPServer and not application.settings\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/68306/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/68311", "body": "The fix for this is:\n\n```\n    if not self.request.connection.no_keep_alive:\n        if not self.request.supports_http_1_1():\n            if self.request.headers.get(\"Connection\") == \"Keep-Alive\":\n                self.set_header(\"Connection\", \"Keep-Alive\")\n```\n\nIt should not be telling the browser to keep-alive if no_keep_alive is set.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/68311/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commit_comments": [], "review_comments": []}, "araddon": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/71779", "body": "Wouldn't you be able to forge the http header X-Requested-With if you are an attacker and bypass this protection mechanism?  \n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/71779/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "cactus": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/72074", "body": "It would also be useful for doing json 'pretty printing' with the `indent` and `sort_keys` arguments.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/72074/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "joo": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/72366", "body": "Agree\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/72366/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "elephantum": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/74334", "body": "that seems to be general problem which is caused by inconsistency between epoll.c and select.epoll in py2.6\n\nepoll.c raises OSError, while select.epoll raises IOError.\n\nmay be the best way to fix this is to alter epoll.c and tornado to use IOError like select.epoll does\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/74334/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/77157", "body": "I'm sorry, where did you find the usage of C-extension for HTTPHeaders?\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/77157/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/comments/59217", "body": "You're wrong. Logical operators are traditionally lazy in almost any language to permit this kind of notation.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/59217/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/59294", "body": "Sorry, I was wrong and was sure that I've deleted my comment. But somehow it wasn't deleted.\n\nOn the topic: here \"if self.handlers\" is used to test list on emptiness. Your suggestion wont work in case self.handlers == [].\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/59294/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "review_comments": []}, "stevvooe": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/74523", "body": "This sounds reasonable.\n\nIs this project being maintained? There hasn't been any activity on it in month and I don't want to maintain a fork for simple bug fixes.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/74523/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "sashka": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/82715", "body": "Silently closed by original authors.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/issues/comments/82715/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "Twisol": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/comments/59064", "body": "Won't this else still be executed if self.handlers doesn't exist? The previous version didn't have an self.handlers check, either, so it seems like either the self.handlers check could be removed, or it should look like this...\n\n```\nif self.handlers:\n    if self.handlers[-1][0].pattern == '.*$':\n        # stuff\n    else:\n        # stuff\n```\n\nOr am I wrong?\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/59064/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/59291", "body": "No, I'm talking about the else! If the if is false, the else will get called. If there is no list of handlers, there will still be an action done assuming the handlers exist.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/59291/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/59298", "body": "Good catch. In that case, neither will the original code, because if handlers is empty (quite reasonable here), the first test will fail. This went from a nitpick to a bug, if I'm seeing this right. (EDIT: No, wait, it does the right thing precisely because it's empty. len(self.handlers) would be clearer, I think, but...)\n\nI think we can assume that handlers will always exist, can't we? They're set up in the __init__ method. If we can't (or don't want to) assume that, we have to check it somehow. (EDIT: this line not really relevant in light of the first edit)\n\nActually, for that matter, why do we create a local 'hanndlers' list in that same function, then only append to it once later and not do anything else with it? Was it, maybe, intended that the appends in this if-else section were meant to append to that local variable? I honestly don't know, I haven't spent much time with Tornado's internals. Just pointing out little things that I'm not quite getting. :)\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/59298/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "review_comments": []}, "bickfordb": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/comments/68168", "body": "That's unfortunate: this made debugging and using Tornado significantly easier for me.   Global logging configuration (e.g. 'logging.getLogger(\"tornado.web\").setLevel(logging.ERROR)' seems to work fine. \n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/68168/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/68435", "body": "That make sense to me.  In my application I'm configuring root handlers to log to stderr + scribe globally in my run script.  I missed the \"no loggers configured\" message and the fact that module-logged messages aren't visible by default.  \n\nThis isn't the first time the logging module has been a pain point for me.  I started working on [what I believe is] a better logging library called \"logit\" (http://github.com/bickfordb/logit) if anyone reading this is interested in contributing or has any ideas.  \n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/68435/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "review_comments": []}, "cv12": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/comments/74787", "body": "Can you please explain the purpose of the time independent compare?  Why didn't the simple compare suffice?  Thanks in advance for your explanation.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/74787/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/75007", "body": "Thanks.  Very helpful.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/75007/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "review_comments": []}, "akheron": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/comments/74815", "body": "A normal comparison leaks timing information to an attacker. Because a normal compare exits as soon as the first inequal byte is encountered, an attacker could determine the value of the hash byte by byte, by looking at how long the comparison takes.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/74815/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/83997", "body": "I think that the upper bound of 1024 for file descriptors can be overcome by using curl_multi_socket_action() and CURLMOPT_SOCKETFUNCTION instead of curl_multi_perform() and curl_multi_fdset(). See http://curl.haxx.se/libcurl/c/curl_multi_socket_action.html for the C API. There also seems to be a fork of tornado that has a version of httpclient that uses this new API: http://github.com/sris/tornado/blob/master/tornado/httpclient2.py\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/83997/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "review_comments": []}, "nadako": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/comments/77835", "body": "Why close socket on empty chunk?\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/77835/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "review_comments": []}, "swax": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/comments/80276", "body": "I thought calling receive_message, to get the next message, was by design. So that we can choose whether to get another message, or have a different function handle the next message. I think if the receive_message callback was meant to be auto-called, it would have been part of the websocket constructor.  Also this breaks anyone currently using websockets. Can you please double check this?\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/80276/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/80300", "body": "I don't think having two ways to do the same thing is the best answer. I liked the simple design before and the confusion seems to stem from a documentation deficiency in the header of the file. Can you get this change reviewed by other contributors?\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/80300/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/86566", "body": "inferno, I can see a recursion error happening if the recv buffer for the websocket is always full. Meaning when read_until is called in websocket.py, it is always immediately raising the callback, instead of passing the callback to the ioloop and returning. Is this what you were seeing, and was it actually happening in production, what were the circumstances? I like bdarnell's on_message solution. Implementers already make use of on_accept and on_close, so an on_message override makes sense.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/86566/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/87129", "body": "Ah ok. Guess that's fixed with the revert. I checked out that other potential recursion issue - if sys.getrecursionlimit > # packets in the iostream read buffer then there'd be a max recursion error. Luckily the read buffer is at 4k and sys.getrecursionlimit is 1000 (on my machine at least.) So it's pretty unlikely to pop up.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/87129/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "review_comments": []}, "dlo": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/comments/80278", "body": "Maybe a better solution would be to add a parameter to `receive_message` such as `auto_call` that allows the user to specify whether or not the callback should be auto-called. This would necessitate adding another class variable but I think it may be worth it.\n\nI say this because I probably wasted several hours playing around with this class until I realized that the callback wasn't automatic, thinking that either 1) my browser's websocket implementation was broken or 2) there was a bug in this class. Even after I realized it was neither, I had already found numerous references on the web from people who thought that tornado was broken because of this limitation. Not to mention that the issue tracker had this specific issue listed as a problem.\n\nHere's how I think this could work:\n\n```\ndef __init__(self, application, request):\n    tornado.web.RequestHandler.__init__(self, application, request)\n    self.stream = request.connection.stream\n    self.auto_call = True\n```\n\nor\n\n```\ndef receive_message(self, callback, auto_call = True):\n    \"\"\"Calls callback when the browser calls send() on this Web Socket.\"\"\"\n    callback = self.async_callback(callback)\n    self.auto_call = auto_call\n    self.stream.read_bytes(\n        1, functools.partial(self._on_frame_type, callback))\n```\n\nAnd in both cases:\n\n```\ndef _on_end_delimiter(self, callback, frame):\n    callback(frame[:-1].decode(\"utf-8\", \"replace\"))\n    if self.auto_call:\n        self.receive_message(callback)\n```\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/80278/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/80302", "body": "I'm assuming it was reviewed when it was merged into master.\n\nOn another note, the use case for **not** keeping the connection open (or using a different callback at the same socket) seems to be very limited and against REST philosophy. Can you give an example of what sort of usage you would hope to get by reverting to the previous functionality?\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/80302/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "review_comments": []}, "garyburd": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/comments/82961", "body": "If there's no pending data and the peer has performed an orderly shutdown, then recv returns an empty chunk.  \n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/82961/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "review_comments": []}, "rickardb": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/comments/85798", "body": "With this code the callback is decorated for each message, causing an maximum recursion depth error.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/comments/85798/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "review_comments": []}, "jparise": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/19556", "body": "Because this is intended to attack the newline added by the base64 encoding, perhaps `rstrip()` would be slightly more explicit/efficient?\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/19556/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/61329", "body": "Could this be made even more useful by having it return the number of days until expiration?\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/61329/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/291505", "body": "I think you should protect the `MySQLdb` and `psycopg2` imports so that neither is required until the point that the user selects a particular database connection type.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/291505/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/291522", "body": "Instead of using enumeration-ish constants for `db_type`, what if you either passed in a string (containing the letters \"mysql\" or \"postgresql\") or the desired connection class object (`MysqlConnection` or `PostgresConnection`)?\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/291522/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/292076", "body": "I suppose I don't really see the practical benefit of:\n\n```\nfrom database import MYSQL, Connection\nc = Connection('localhost', 'database', MYSQL)\n```\n\nover:\n\n```\nfrom database import Connection\nc = Connection('localhost', 'database', 'mysql')\n```\n\nI'm still typing the letters \"mysql\", and both cases will result in some sort of runtime failure if I mispel it.  If that `MYSQL` symbol wrapped a particularly interesting value (other than just a faux enum) and was used in more than one place (other than the `create()` factory method), I'd consider it more useful.\n\nMy opinion here is rather Python-specific, by the way, because it doesn't actually have enumerations in the strict typing sense.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/292076/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/912950", "body": "Shouldn't this always be `\"1.0\"`?  The rest of the `tornado.auth` code is pretty much hardwired to handle either version 1.0 or 1.0a, and if we always need to send 1.0 in the 1.0a case, all cases are covered.\n\nThis also makes the `_oauth_version_to_send()` method unnecessary.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/912950/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/1921528", "body": "If we're going to verify the time value, it would be more complete to test `<= 0`.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/1921528/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}, "kzahel": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/19558", "body": "base64.b64encode would be even more efficient, I was simply reporting the bug\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/19558/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}]}, "e98cuenc": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/253726", "body": "it should be: \"... to implement a simple\"\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/253726/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}]}, "jonchu": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/292028", "body": "Yea, I agree. I'll go ahead and do this.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/292028/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/292030", "body": "Passing in strings seems really ugly to me. There's a reason why enums exist, and when code gets a lot larger, strings become unmaintainable and generally exhibit bad code smell.\n\nI like the idea of passing in the class object itself, but I'll need to ponder this a little more before I go ahead and do that.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/292030/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/292354", "body": "I decided the right thing to do was remove the static method and factory class altogether and just allow the programmer to use duck typing. :)\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/292354/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}]}, "alekstorm": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/1039696", "body": "Right, because it's a classmethod, and because it takes the file path, rather than the response body. I'll change the name.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/1039696/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}, "grimley517": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/3730927", "body": "Sorry I know that this is a bit of a newbie comment, but what does this line do?  It does not look like a future statement, I can't find the documentation for the @ decorator. \n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/3730927/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}]}, "wsantos": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/3731681", "body": "Look \u00e1t. Line 91. \n\nEnviado via iPad\n\nEm 10/04/2013, \u00e0s 07:05, Brian Jones notifications@github.com escreveu:\n\n> In tornado/auth.py:\n> \n> > @@ -1096,6 +1096,7 @@ class FacebookGraphMixin(OAuth2Mixin):\n> >      _OAUTH_AUTHORIZE_URL = \"https://graph.facebook.com/oauth/authorize?\"\n> >      _OAUTH_NO_CALLBACKS = False\n> > -    @_auth_return_future\n> >    def get_authenticated_user(self, redirect_uri, client_id, client_secret,\n> >   Sorry I know that this is a bit of a newbie comment, but what does this line do? It does not look like a future statement, I can't find the documentation for the @ decorator.\n> \n> \u2014\n> Reply to this email directly or view it on GitHub.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/3731681/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}, "homm": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/3992389", "body": "I tried to make sure that Task arguments also released.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/3992389/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}, "wolever": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/4310684", "body": "Done.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/4310684/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}, "gagern": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/6045753", "body": "Whoops! Looks like something I added as a temporary hack during debugging, and then accidentially left in place. This explains why I had two places stripping quotation marks: this one and my own line 452. I guess I'd better remove lines 442 through 444. My code doesn't provide a replacement for line 444, though. That came from f249ee3ea9a2a6a4b479da3b34be29af5d1a0a63, which copied it from cpython, where it was added in http://hg.python.org/cpython/rev/846ba2972d7c. But that line can be safely removed, since `email.utils` will [remove quotes](http://hg.python.org/cpython/file/7a125913a375/Lib/email/utils.py#l234) and later on [add quotes without escaping existing ones](http://hg.python.org/cpython/file/7a125913a375/Lib/email/utils.py#l317). To play it safe, I'll include backslashes and quotation marks in my doctest.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/6045753/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}]}, "sclm": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/6102710", "body": "Thanks for taking the time to look at this:\n1. I've updated this so that we no longer construct the absolute URL, I think you're correct about the examples, and I'll take a look at that in a bit.\n2. I've renamed that for consistency.\n3. scope and response_type are both part of the oauth2 spec, with scope a \"SHOULD\" that is required by Google when doing it.  Facebook seems to be the exception in not using the scope.  For response_type, that is a required param with only \"code\" set as a defined value.  I think we may want to merge this into the base class since they're given, with scope defaulting to null and implementations allowing for a default scope and response_type defaulting to \"code\"\n\nDoes 3 make sense?  I'm starting a branch that makes those changes to the base class for you to take a look at.\n", "reactions": {"url": "https://api.github.com/repos/tornadoweb/tornado/pulls/comments/6102710/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}}}}