{"_default": {"1": {"rawkintrevo": {"issues": [], "commits": [{"url": "https://api.github.com/repos/apache/mahout/commits/7dff35bc3c61c3e0b95e8e59406742be15203a69", "message": "WEBSITE-NOJIRA Direct download on homepage button"}, {"url": "https://api.github.com/repos/apache/mahout/commits/84f389140c3781ace210ad9fc977f0d464666644", "message": "WEBSITE-NOJIRA Add mahout-version"}, {"url": "https://api.github.com/repos/apache/mahout/commits/71ce4bf599f7abe8508724d124fa4554153055c6", "message": "WEBSITE-NOJIRA Added Clustering to Navbar"}, {"url": "https://api.github.com/repos/apache/mahout/commits/5c51c60180b05f5ea70ef7b86daf62c7e250ef08", "message": "WEBSITE-NOJIRA Added mahout-version variable"}, {"url": "https://api.github.com/repos/apache/mahout/commits/36da4cf3d4982e246191a3ec7eac2495a25f8a86", "message": "WEBSITE-NOJIRA Added Fn for news"}, {"url": "https://api.github.com/repos/apache/mahout/commits/d53d444374c874a89abd87042a4bdd6a57915258", "message": "WEBSITE-NOJIRA Fix Mahout Overview Link"}, {"url": "https://api.github.com/repos/apache/mahout/commits/4c1d12e39801ca7e2fa1170190d77e150ff11d66", "message": "WEBSITE-NOJIRA Fix Download link, etc."}, {"url": "https://api.github.com/repos/apache/mahout/commits/b9895898d799ae913ad2b37e10b4ae75467b5e37", "message": "EMPTY commit to kick re-establish asf-pages mirror"}, {"url": "https://api.github.com/repos/apache/mahout/commits/6141be782e271748c9839de1e2b837eabb25033c", "message": "WEBSITE-NOJIRA Fix API Docs Link"}, {"url": "https://api.github.com/repos/apache/mahout/commits/1c528a194ebad97f24934685e7bfd9872ebe3019", "message": "WEBSITE-NOJIRA Various website fixes"}, {"url": "https://api.github.com/repos/apache/mahout/commits/ca8b4935c4014397ee4ffc7cd7964dce0979cdf6", "message": "doap_Mahout.rdf"}, {"url": "https://api.github.com/repos/apache/mahout/commits/5a07b51b4f85ea54ee234bd8e2bc320f49f8968c", "message": "WEBSITE removed themes- no longer used- updated how-to-update-website.md"}, {"url": "https://api.github.com/repos/apache/mahout/commits/fc36bef157dc47d9572c4cfd460067e1916910a0", "message": "MAHOUT-1981 Update build_site.sh to not commit entire website"}, {"url": "https://api.github.com/repos/apache/mahout/commits/03918713563bf6aac55299d7239c4e042795faf0", "message": "MAHOUT-1981 Missing Gemfile Added"}, {"url": "https://api.github.com/repos/apache/mahout/commits/9beddd3108ae453091a21a881c6693016f5f2012", "message": "MAHOUT-1981 Merged site updates, fixed navbars, Mathjax"}, {"url": "https://api.github.com/repos/apache/mahout/commits/4f2108c576daaa3198671568eaa619266e787b1a", "message": "[WEBSITE] Small change to make sure publishing"}, {"url": "https://api.github.com/repos/apache/mahout/commits/8a7bd9156880f3f12509c64cda62ac389cbb4f7d", "message": "[WEBSITE] Updating Front Site Config"}, {"url": "https://api.github.com/repos/apache/mahout/commits/9fe4aadc731ffecf3996992b51b8044c880b0e94", "message": "[WEBSITE] Download Javadocs if not present"}, {"url": "https://api.github.com/repos/apache/mahout/commits/1e6584d78e8dc83c04fd1c29a8b01d7e63b6005d", "message": "[WEBSITE] Issues with build_site.sh"}, {"url": "https://api.github.com/repos/apache/mahout/commits/697eae12c513f15e97a18b8a4e143fdc53064b7f", "message": "[WEBSITE] Deleted frontsite"}, {"url": "https://api.github.com/repos/apache/mahout/commits/2483037dc65fd69a508759f241e62709ea780af3", "message": "testing for infra"}, {"url": "https://api.github.com/repos/apache/mahout/commits/52154565410a7ebb9f9cdfe13ad9f039c1f8abb7", "message": "sync asf-site to github with empty"}, {"url": "https://api.github.com/repos/apache/mahout/commits/c80e00f894779b9c937eea280b3b7c39d07ed610", "message": "[WEBSITE] Jekyll build path command updates"}, {"url": "https://api.github.com/repos/apache/mahout/commits/2613883f2f6af05e69cdcc5945a456480747566e", "message": "[WEBSITE] Update how-to-update-website instructions"}, {"url": "https://api.github.com/repos/apache/mahout/commits/f0a246a341cdf66e1ff727a469ed268c00b7ebfe", "message": "[WEBSITE] Build_site.sh lost executable again"}], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/347", "title": "[WIP][NO-JIRA] Mahout Cylons Demo Donation", "body": "### Purpose of PR:\r\nThe so-called \"Cylons demo\" was well received at multiple talks in early Fall 2017, and there has been interest in continuing work on the project.  The Cylon demo showcases Mahout in the following ways:\r\n- A more robust use of the \"Eigenfaces Demo\" (on Apache Spark)\r\n- How Mahout \"precanned\" algos can be chopped up and used in Flink Streaming Applications\r\n- How Mahout facilitates the so-called \"Lambda style\" machine learning paradigm by training an offline\r\nmodel in Apache Spark and utilizing it in Apache Flink with Apache Solr as the \"model server\" as well as a so called \"Kappa\" style by continuously training and applying a Canopy Function.\r\n\r\nAs this was originally a demo- it is somewhat 'dirty' to say the least. Much work is to be done to fully integrate this as a nice clean demo- especially with respect to documentation.  \r\n\r\nNote that a working drone is NOT required to run this demo as one can tie into any RSTP video feed and there are many public ones available (as well as creating one with many webcams). \r\n\r\nOpening this as a WIP PR that others may contribute and help me get it ready for merging into the trunk. \r\n\r\n### Important ToDos\r\nPlease mark each with an \"x\"\r\n- [ ] A JIRA ticket exists (if not, please create this first)[https://issues.apache.org/jira/browse/ZEPPELIN/]\r\n- [ ] Title of PR is \"MAHOUT-XXXX Brief Description of Changes\" where XXXX is the JIRA number.\r\n- [ ] Created unit tests where appropriate\r\n- [ ] Added licenses correct on newly added files\r\n- [ ] Assigned JIRA to self\r\n- [ ] Added documentation in scala docs/java docs, and to website\r\n- [ ] Successfully built and ran all unit tests, verified that all tests pass locally.\r\n\r\nIf all of these things aren't complete, but you still feel it is\r\nappropriate to open a PR, please add [WIP] after MAHOUT-XXXX before the\r\ndescriptions- e.g. \"MAHOUT-XXXX [WIP] Description of Change\"\r\n\r\nDoes this change break earlier versions?\r\n\r\nIs this the beginning of a larger project for which a feature branch should be made?\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "andrewmusselman": {"issues": [], "commits": [{"url": "https://api.github.com/repos/apache/mahout/commits/b887ab3653590c854f2b118162114f1133b9534d", "message": "Merge branch 'master' into mahout-1981"}, {"url": "https://api.github.com/repos/apache/mahout/commits/9a2055e7b7bd1788b0b7523367772650ffdb6b53", "message": "NOJIRA: Shrinking the home page splash area vertically, moving ASF logo to the top."}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13259038", "body": "Would be nice to have a workflow where the changelog changes along with the bug though; I'd be okay dealing with conflicts on this file unless things get really crazy.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13259038/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}, "kunalcsc630": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/354", "title": "Fixed grammatical error", "body": "### Purpose of PR:\r\nPlease give a short description of what this PR is for.\r\n\r\n\r\n### Important ToDos\r\nPlease mark each with an \"x\"\r\n- [ ] A JIRA ticket exists (if not, please create this first)[https://issues.apache.org/jira/browse/ZEPPELIN/]\r\n- [ ] Title of PR is \"MAHOUT-XXXX Brief Description of Changes\" where XXXX is the JIRA number.\r\n- [ ] Created unit tests where appropriate\r\n- [ ] Added licenses correct on newly added files\r\n- [ ] Assigned JIRA to self\r\n- [ ] Added documentation in scala docs/java docs, and to website\r\n- [ ] Successfully built and ran all unit tests, verified that all tests pass locally.\r\n\r\nIf all of these things aren't complete, but you still feel it is\r\nappropriate to open a PR, please add [WIP] after MAHOUT-XXXX before the\r\ndescriptions- e.g. \"MAHOUT-XXXX [WIP] Description of Change\"\r\n\r\nDoes this change break earlier versions?\r\n\r\nIs this the beginning of a larger project for which a feature branch should be made?\r\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "davidtmiller": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/352", "title": "Mahout 1981 - Front End Design Update", "body": "### Purpose of PR:\r\nPlease give a short description of what this PR is for.\r\n\r\n\r\n### Important ToDos\r\nPlease mark each with an \"x\"\r\n- [ ] A JIRA ticket exists (if not, please create this first)[https://issues.apache.org/jira/browse/ZEPPELIN/]\r\n- [ ] Title of PR is \"MAHOUT-XXXX Brief Description of Changes\" where XXXX is the JIRA number.\r\n- [ ] Created unit tests where appropriate\r\n- [ ] Added licenses correct on newly added files\r\n- [ ] Assigned JIRA to self\r\n- [ ] Added documentation in scala docs/java docs, and to website\r\n- [ ] Successfully built and ran all unit tests, verified that all tests pass locally.\r\n\r\nIf all of these things aren't complete, but you still feel it is\r\nappropriate to open a PR, please add [WIP] after MAHOUT-XXXX before the\r\ndescriptions- e.g. \"MAHOUT-XXXX [WIP] Description of Change\"\r\n\r\nDoes this change break earlier versions?\r\n\r\nIs this the beginning of a larger project for which a feature branch should be made?\r\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "andrewpalumbo": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/349", "title": "[WIP]MAHOUT-2027: spark-ec2 launch scripts with ViennaCL/JCuda installation", "body": "### Purpose of PR:\r\nPlease give a short description of what this PR is for.\r\n\r\n\r\n### Important ToDos\r\nPlease mark each with an \"x\"\r\n- [ x] A JIRA ticket exists (if not, please create this first)[https://issues.apache.org/jira/browse/ZEPPELIN/]\r\n- [ x] Title of PR is \"MAHOUT-XXXX Brief Description of Changes\" where XXXX is the JIRA number.\r\n- [ ] Created unit tests where appropriate\r\n- [x ] Added licenses correct on newly added files\r\n- [x ] Assigned JIRA to self\r\n- [ ] Added documentation in scala docs/java docs, and to website\r\n- [ ] Successfully built and ran all unit tests, verified that all tests pass locally.\r\n\r\nIf all of these things aren't complete, but you still feel it is\r\nappropriate to open a PR, please add [WIP] after MAHOUT-XXXX before the\r\ndescriptions- e.g. \"MAHOUT-XXXX [WIP] Description of Change\"\r\n\r\nDoes this change break earlier versions?\r\nno - exampe\r\nIs this the beginning of a larger project for which a feature branch should be made?\r\nno", "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/318", "title": "[WIP]MAHOUT-1974 (dense cuda multiplication)", "body": "### Purpose of PR:\r\nPlease give a short description of what this PR is for.\r\n\r\n\r\n### Important ToDos\r\nPlease mark each with an \"x\"\r\n- [x] A JIRA ticket exists (if not, please create this first)[https://issues.apache.org/jira/browse/MAHOUT/]\r\n- [x] Title of PR is \"MAHOUT-XXXX Brief Description of Changes\" where XXXX is the JIRA number.\r\n- [x] Created unit tests where appropriate\r\n- [ ] Added licenses correct on newly added files\r\n- [ ] Assigned JIRA to self\r\n- [ ] Added documentation in scala docs/java docs, and to website\r\n- [ ] Successfully built and ran all unit tests, verified that all tests pass locally.\r\n\r\nIf all of these things aren't complete, but you still feel it is\r\nappropriate to open a PR, please add [WIP] after MAHOUT-XXXX before the\r\ndescriptions- e.g. \"MAHOUT-XXXX [WIP] Description of Change\"\r\n\r\nDoes this change break earlier versions?\r\n\r\nIs this the beginning of a larger project for which a feature branch should be made?\r\n", "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/129", "title": "MAHOUT-1706: remove dependency jars from /lib in the binary distribution", "body": "The mahout distribution currently is shipping ~56 MB of dependecy jars in the /lib directory of the distribution.   These are only added to the classpath by /bin/mahout in the binary distribution. It seems that we can remove them from the distribution. (we need to get the size of the distribution down)\n\nAny input is appreciated. \n", "author_association": "MEMBER"}], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/apache/mahout/comments/10927850", "body": "I can't remember at the moment if it was only the spark-shell module that needed them or if others did as well. \u00a0I believe it had something to do with the spark-1.2 upgrade, part of which made it into master. \u00a0\n\nPutting them in the shell pom may work. \u00a0\n\nSent from my Verizon Wireless 4G LTE smartphone\n\n<div>-------- Original message --------</div><div>From: Pat Ferrel notifications@github.com </div><div>Date:04/27/2015  5:36 PM  (GMT-05:00) </div><div>To: apache/mahout mahout@noreply.github.com </div><div>Cc: Andrew Palumbo ap.dev@outlook.com </div><div>Subject: Re: [mahout] added scala dependencies in math-scala to fix spark-shell (71165a5) </div><div>\n</div>Are these required for all scala modules? Can this be put in spark-shell pom instead?\n\n\u2014\nReply to this email directly or view it on GitHub.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/10927850/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/apache/mahout/comments/16715391", "body": "LGTM\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/16715391/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/apache/mahout/comments/18009403", "body": "yep looks like.. I can fix it.  I was also thinking the name should be refactored to `densityAnalysis` so that `true` = `isDense`\\- seems more intuituive.  what do you think? Does sparsityAnalysis have any specific meaning outside of here?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/18009403/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/apache/mahout/comments/18009913", "body": "yes that would make sense.  I've done the Refactoring and the fix, and have a jira open to add densitAnalysis() in other places.  am just leaving for the day, so will push the open PR now and make note of this in the current jira or create a new one soon. \n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/18009913/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}], "review_comments": []}, "BruceKuiLiu": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/346", "title": "Consider returning a zero length array rather than null.", "body": "It is often a better design to return a length zero array rather than a null reference to indicate that there are no results (i.e., an empty list of results).\r\nThis way, no explicit check for null is needed by clients of the method.\r\nOn the other hand, using null to indicate \"there is no answer to this question\" is probably appropriate.\r\nhttp://findbugs.sourceforge.net/bugDescriptions.html#PZLA_PREFER_ZERO_LENGTH_ARRAYS\r\n\r\n\r\n", "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/345", "title": "Remove the redundant null check statements of a non-null value.", "body": "This IfStatement is a redundant check of a known non-null otherObj because the null check of otherObj is contained in the previous instanceof check.\r\nhttp://findbugs.sourceforge.net/bugDescriptions.html#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE\r\n\r\n", "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/344", "title": "Add an IfStatement to check the return value of resultFile.delete().", "body": "This statement returns a value that is not checked.\r\nThe return value should be checked since it can indicate an unusual or unexpected function execution.\r\nThe statement returns false if the file could not be successfully deleted (rather than throwing an Exception).\r\nIf the result was not checked, developers would not notice if the statement signals an unexpected behavior by returning an atypical return value.\r\nhttp://findbugs.sourceforge.net/bugDescriptions.html#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE\r\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "holdenk": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/340", "title": "MAHOUT-2015 [WIP]: Expose Mahout's OLS algorithm in the Spark ML API", "body": "### Purpose of PR:\r\nExpose Mahout's OLS algorithm in the Spark ML API\r\n\r\n### Important ToDos\r\nPlease mark each with an \"x\"\r\n- [ X] A JIRA ticket exists (if not, please create this first)[https://issues.apache.org/jira/browse/ZEPPELIN/]\r\n- [ X ] Title of PR is \"MAHOUT-XXXX Brief Description of Changes\" where XXXX is the JIRA number.\r\n- [ X ] Created unit tests where appropriate\r\n- [ X ] Added licenses correct on newly added files\r\n- [ X ] Assigned JIRA to self\r\n- [ ] Added documentation in scala docs/java docs, and to website\r\n- [ ] Successfully built and ran all unit tests, verified that all tests pass locally.\r\n\r\nIf all of these things aren't complete, but you still feel it is\r\nappropriate to open a PR, please add [WIP] after MAHOUT-XXXX before the\r\ndescriptions- e.g. \"MAHOUT-XXXX [WIP] Description of Change\"\r\n\r\nDoes this change break earlier versions?\r\n\r\nNo\r\n\r\nIs this the beginning of a larger project for which a feature branch should be made?\r\n\r\nNo", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "dustinvanstee": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/335", "title": "MAHOUT-2000 [WIP] Add maven profile for Spark 2.2", "body": "### Purpose of PR: Add spark 2.2 into travisCI framework and add a maven spark 2.2 profile.\r\n\r\n\r\n### Important ToDos\r\nPlease mark each with an \"x\"\r\n- [x] A JIRA ticket exists (if not, please create this first)[https://issues.apache.org/jira/browse/ZEPPELIN/]\r\n- [ x] Title of PR is \"MAHOUT-XXXX Brief Description of Changes\" where XXXX is the JIRA number.\r\n- [ ] Created unit tests where appropriate\r\n- [ ] Added licenses correct on newly added files\r\n- [x ] Assigned JIRA to self\r\n- [ ] Added documentation in scala docs/java docs, and to website\r\n- [ ] Successfully built and ran all unit tests, verified that all tests pass locally.\r\n\r\nIf all of these things aren't complete, but you still feel it is\r\nappropriate to open a PR, please add [WIP] after MAHOUT-XXXX before the\r\ndescriptions- e.g. \"MAHOUT-XXXX [WIP] Description of Change\"\r\n\r\nDoes this change break earlier versions?\r\n\r\nIs this the beginning of a larger project for which a feature branch should be made?\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "AdityaAS": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/334", "title": "[WIP] MAHOUT-1991 - Add DBSCAN", "body": "DBSCAN - Google Summer of Code '17 - Apache Software Foundation (Apache Mahout)\r\n\r\nGoals: Implement DBSCAN algorithm\r\n\r\nWork done:\r\n- Coded Sequential and Distributed versions of DBSCAN\r\n- Added docs and unit tests\r\nWork left to do:\r\n- Improve distributed DBSCAN to make it more accurate\r\n- Include cluster quality index calculation\r\n\r\nAdded the sequential version of the algorithm. Docs and Unit Tests where appropriate.\r\nWill be adding rtree module and the approximate distributed algorithm soon.\r\n\r\nLink to a short report describing the whole project can be found [here](https://docs.google.com/document/d/11sLJkwAftR2-Fmglju8c7dGTf1i3trkbEV2Zr9OlilU/edit?usp=sharing).\r\n\r\n@rawkintrevo do help me out.\r\n\r\n### Important ToDos\r\nPlease mark each with an \"x\"\r\n- [x] A JIRA ticket exists (if not, please create this first)[https://issues.apache.org/jira/browse/ZEPPELIN/]\r\n- [x] Title of PR is \"MAHOUT-XXXX Brief Description of Changes\" where XXXX is the JIRA number.\r\n- [x] Created unit tests where appropriate\r\n- [x] Added licenses correct on newly added files\r\n- [x] Assigned JIRA to self\r\n- [x] Added documentation in scala docs/java docs, and to website\r\n- [x] Successfully built and ran all unit tests, verified that all tests pass locally.\r\n\r\nIf all of these things aren't complete, but you still feel it is\r\nappropriate to open a PR, please add [WIP] after MAHOUT-XXXX before the\r\ndescriptions- e.g. \"MAHOUT-XXXX [WIP] Description of Change\"\r\n\r\nDoes this change break earlier versions?\r\n\r\nIs this the beginning of a larger project for which a feature branch should be made?\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "nsakharnykh": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/310", "title": "MAHOUT-1974 CUDA support", "body": "Initial PR for CUDA bindings support through JCuda", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "skanjila": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/279", "title": "Mahout 1904", "body": "Added a helper function to pass fail the method, first cut of this as an iteration to be reviewed.", "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/245", "title": "Mahout 1869", "body": "Added the ability to dump output to csv file\n", "author_association": "NONE"}], "issue_comments": [{"url": "https://api.github.com/repos/apache/mahout/issues/comments/45238065", "body": "Ok I'll be doing a more substantial commit that might help us see how the APIs around a DataFrame\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45238065/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "BertrandDechoux": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/265", "title": "Add optional manual configuration of AtA's number of partitions.", "body": "```scala\r\n// Determine how many partitions the new matrix would need approximately. We base that on\r\n// geometry only, but it may eventually not be that adequate. Indeed, A'A tends to be much more\r\n// dense in reality than the source.\r\n```\r\nAllow override when estimation is not adequate because AtA is indeed more dense...", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "MaineC": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/240", "title": "Add one year mahout blog post draft.", "body": "The outline as offered by @smarthi with a bit of boiler plate. Needs some more love and content in the individual sections.\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "manognavemulapati": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/181", "title": "An alternative scaling method for Baum Welch for HMM.", "body": "This implements an alternative scaling method (called rescaling) for Baum Welch algorithm for unsupervised HMM training. The new scaling method partially addresses Mahout-627. The existing scaling method  based on log scaling is not numerically stable when tried with the Mapreduce version of Baum Welch proposed for Mahout-627. With the rescaling method, I am able to successfully run the Mapreduce version of Baum Welch on long training sequences. Further details and references are given in the following writeup.\nImplementation of an Alternative Scaling for Baum-Welch Algorithm for Hidden Markov Model (HMM) in Apache Mahout -- http://manognavemulapati.github.io/mahout/HMMScaling.pdf.\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "michellemay": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/174", "title": "MAHOUT-1786: Make classes implements Serializable for Spark 1.5+", "body": "Add some \"implements Serializable\" for Apache Spark 1.5+\nThere might be other classes that would benefit from the same modification.\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "sugaE": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/131", "title": "Fix bug: Add commit after executeUpdate", "body": "It will not write database without commit().\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ghost": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/70", "title": "Non-negative Matrix Factorization and Probabilistic Matrix Factorization", "body": "Non-negative Matrix Factorization, using classical multiplicative update rule.\nProbabilistic Matrix Factorization, using stochastic gradient descent\n\nUse Movielens dataset  to test, get reasonable result. \n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "mihaipitu": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/35", "title": "Sparse Linear Methods (SLIM) Recommender with two optimization techniques", "body": "The SLIM algorithm generates efficient recommendations and its performance is shown in the original paper (http://glaros.dtc.umn.edu/gkhome/fetch/papers/SLIM2011icdm.pdf). The study demonstrates that SLIM outperforms traditional algorithms (such as itemkNN, userkNN, SVD or other Matrix Factorization approaches) on various data-sets in terms of time efficiency and recommendation quality.\r\nSLIM's optimization problem can be solved using Least Square optimization (designed for explicit feedback datasets) and Bayesian Personalized Ranking (designed for implicit feedback datasets).", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "dlyubimov": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/apache/mahout/issues/comments/44071171", "body": "ok i think this is more or less it for now, untill we do more API tweaking to fit \"multiple sink\" model of Stratosphere. But at least all currently working api is fully abstracted and moved out to math-scala module with 0 Spark (or Hadoop) dependencies. Please feel free to dig in and point out how i am being stupid :) \n\n:8ball: \n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44071171/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44353426", "body": "Please include jira #.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44353426/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44496355", "body": "looks benign to me.\n\nNeed review from folks that were working on Hadoop 2 integration, to make sure this is in line with the rest of the effort. MAHOUT-1565\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44496355/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44713857", "body": "A slight nuisance here is that A' cannot be checkpointed. This is because the keys of A, in the most general case, are not `Int`s.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44713857/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44714458", "body": "perhaps a better test is needed that introduces some random jitter into the input.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44714458/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45017407", "body": "Want to commit it now. 90% is bug fixes and refactoring. Added zip-optimization for identically distributed elementwise operators, etc.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45017407/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45156215", "body": "FunctionalView matrix introduced general concept of dense/sparse matrix. surprisingly, abstract matrix has none. So MatrixWritable just tries to look at a row view to figure this out. Perhaps the isDense functionality should be added to AbstractMatrix in the first place?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45156215/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45167847", "body": "do we need help committing this? Are we committing this?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45167847/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45236939", "body": "Ok, this is still is too little substance for review, and did not seem to generate much new ideas either. Plus i am probably will not be spending much time on it any time soon.\n\nWithdrawing request for the time being \n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45236939/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45237262", "body": "I Like Pat's github avatar :+1: \n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45237262/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45239528", "body": "i don't even know that cartoon, just thought is was funny. Yeah, thinking of it, it is how i used to feel most of the time looking at my colleagues' code at work \n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45239528/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45252464", "body": "this is work in progress. We get it :)\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45252464/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45401402", "body": "also added (pretty naive) auto parallelism adjustments\n\n```\n(A+B) auto_||\n```\n\nwhich looks at spark.default.parallelism (P), assumes better parallelism is acheved if partitions are bumped up to round-ups of 0.95 \\* P or 1.80 \\* (P) whichever is closer. if current partition set is already greater (in cardinality) than rounded-up 1.80 \\* (P), all is left as is.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45401402/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45553612", "body": "i will commit it soon then\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45553612/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45557670", "body": "Pat, so, we are not going to use this for merging into merging, i take it? I will close it, you can keep working on your other requests.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45557670/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commit_comments": [{"url": "https://api.github.com/repos/apache/mahout/comments/6656953", "body": "I still dont get it. This implementation counts positive elements, not nonzeroes.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/6656953/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/6666688", "body": "Considerations of negative interactions of co-occurence analysis are irrelevant since you are implementing contract that has nothing to do with any particular algorithm you may be using it for.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/6666688/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/10723951", "body": "who-a?...\n\nOn Tue, Apr 14, 2015 at 1:55 AM, Stevo Slavi\u0107 notifications@github.com\nwrote:\n\n> directory names of submodules do not match artifactId, e.g. they do not\n> have mahout prefix\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/apache/mahout/commit/f7b69fabf1253b5e735e269c9410459d91816cdd#commitcomment-10708902\n> .\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/10723951/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/10724331", "body": "I am not in favor of renaming artifacts in general, and in this particular case as well. \n\nIn general, because renaming artifacts create incredible operational and legal headaches on the scale you can't even begin to imagine, in certain places :)\n\nin particular, because If \"samsara\" is to refer to computing environment, (let's say algebra environment in particular), then its code is not contained in any single module. instead, it's dispersed around.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/10724331/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/18009341", "body": "I think there's a bug in this line. If we return true for dense outcome of the analysis, the comparison should be reversed to `>`  in this line.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/18009341/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/18009547", "body": "uhm, yes, density makes more sense.\n\nOn Fri, Jun 24, 2016 at 1:45 PM, Andrew Palumbo notifications@github.com\nwrote:\n\n> yep looks like.. I can fix it. I was also thinking the name should be\n> refactored to densityAnalysis so that true = isDense- seems more\n> intuituive. what do you think? Does sparsityAnalysis have any specific\n> meaning outside of here?\n> \n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> https://github.com/apache/mahout/commit/d9940489d2f849d36af396d603f6170ab560e505#commitcomment-18009403,\n> or mute the thread\n> https://github.com/notifications/unsubscribe/AAf7_5MT7tIGk-w7SYJYCoXuNOvpQxiuks5qPEHggaJpZM4I-G2e\n> .\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/18009547/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/18009583", "body": "I also think it should be more thorough to use shallow initialization, especially in the case when input is already coming as dense and is using dense vectors. right now it looks like this would be copying it. \n\ne.g.:\n\n```\n    val block = new SparseRowMatrix(vectors.size, blockncol, vectors, true, true)\n\n    // Test the density of the data. If the matrix does not meet the\n    // requirements for density, convert the Vectors to a sparse Matrix.\n    val resBlock = if (sparsityAnalysis(block)) {\n      val shallow = vectors.forall(_.isInstanceOf[DenseVector])\n      if (shallow) {\n        // I don't like it but at this point this is the only way to avoid copying with DenseMatrix\n        // initialized by DenseVectors:\n        val vclass = classOf[DenseVector]\n        val valAttr = vclass.getField(\"values\")\n        // Use shallow initialization over backing array of Doubles.\n        new DenseMatrix(vectors.map(v \u21d2 valAttr.get(v).asInstanceOf[Array[Double]]),true)\n      } else {\n        dense(vectors)\n      }\n\n    } else {\n\n      // Sparse matrix: we already created it as a sparse matrix wrapper. There may be a path\n      // to improvement in case the payload comes in as dense vectors, but analysis says they\n      // are really sparse so shallow wrapper doesn't make much sense and we would need to\n      // copy the data into truly sparse vectors in order to truly save memory here. TODO\n      block\n    }\n```\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/18009583/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/18009657", "body": "although... reflection to extract values[] doesn't work. i think this need a patch on dense matrix that accepts array of vectors and `shallowIfPossible` flag that would do shallow init if incoming vectors are DenseVectors.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/18009657/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/18009705", "body": "i guess we really need to patch dense(vecs) implementation to implement shallow initialization where possible. Or have it as \n\n```\ndef dense[R](rows:R*)(shallowIfPossible:Boolean=true) \n```\n\n?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/18009705/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/18009875", "body": "no.. this form doesn't work either.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/18009875/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "review_comments": [{"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13257657", "body": "I think it'd be better to add this when (after) you will be doing a squash pull. Otherwise you'd be merging this file with other changes. This file is guaranteed to change by other commits every time. Although most likely this conflict will be handled automatically by git. \n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13257657/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13518008", "body": "I don't think we need to bring any dfs utils into scala. First, why is it not covered by Hadoop \"glob\"s or tons of hdfs helpers that Sean had created? Second, i think it needs to be shared by all platforms hence it probably needs to go where this common stuff resides in java. \n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13518008/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13518011", "body": "i guess license is coming.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13518011/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13688078", "body": "is that where the major problem was? is that because assignment of sequential vector to sequential vector is that slow? or this is an assignment of random vector to a sequential vector? (sequential to sequential actually should be ok methinks). \n\nAnyway I don't see any immediate problems, and the quality of your work usually doesn't require any deep scrutiny, so i'd say ship it. Actually the sooner the better, because i am very close to actually give it all a good spanking\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13688078/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13687695", "body": "we don't use vector.set and vector.get in scala. we use dsl which would look simply  \n\n```\nacc(elem.index) += 1\n```\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13687695/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13687718", "body": "No need to re align. IDEA scala plugin does a good job donig style indentation. Are you using IDEA?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13687718/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13687795", "body": "There are few doubts there. \n(1) DSL follows R. Which R function this mimics? If none, can we get away with doing it on java side? ( i guess we can't get around it if you want to do it for DRMs). \n(2) the name IMO is misleading given description. nonZeroCounts()?\n(3) The implementation (both in-core and distributed, BTW) seem to contradict the description. It looks like implementation actually counts number of _non-negative_ elements rather than what description portrays.\n(4) I would like Sebastian's feedback on this too, since he is both the primary co-occurrence author and understands R-like semantics idea very deeply.  If there's a better semantics (like I suspect it should be), he should know that.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13687795/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13688228", "body": "a line too long? (style?)\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13688228/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13711381", "body": "it looks like, to me. don't have time to look in depth. but distributed code definitely counts non-negatives with explicit inline conditional >0\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13711381/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13711414", "body": "it is very easy to tweak tests though to check if in doubt\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13711414/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13770844", "body": "Since this returns double, correct style is to say 1.0 or 0.0 not 1 or 0 on java side regardless of implicit conversion\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13770844/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13770924", "body": "style: spacing?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13770924/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}, "jfarrell": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/apache/mahout/issues/comments/44318648", "body": "MAHOUT-1529 not linking to jira as discussed in INFRA-7801\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44318648/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "nishkamravi2": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/apache/mahout/issues/comments/44354961", "body": "JIRA: MAHOUT-1565 (https://issues.apache.org/jira/browse/MAHOUT-1565)\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44354961/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44501707", "body": "Removed MAHOUT_OPTS from bin/mahout and bin/mahout.cmd\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44501707/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "sscdotopen": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/apache/mahout/issues/comments/44743038", "body": "looks good to me, +1 for including this\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44743038/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45234269", "body": "Its not allowed to redistribute the movielens dataset.\n\nOn 06/05/2014 05:28 PM, Pat Ferrel wrote:\n\n> I could use a little advice here. The epinions and movielens tests in the examples folder. Should they be put into the build?\n> \n> Pros: good example data.\n> Cons: the reading and writing are not parallel and so only work locally. It is easy to change the Spark context to use a cluster but the data still has to be local. These tests would be easier to maintain if they were attached to the ItemSimilarityDriver, which will handle cluster storage and execution and will be maintained better.\n> \n> I'd rather move them out into an ItemSimilarityDriver examples folder and will do this if no one objects. They will not be build tests, obviously, since they take too long.\n> \n> ---\n> \n> Reply to this email directly or view it on GitHub:\n> https://github.com/apache/mahout/pull/8#issuecomment-45234064\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45234269/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13169806", "body": "I don't think we should assign memory to map & reduce tasks ourselves.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13169806/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13425122", "body": "we can remove the .parallel. import\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13425122/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13425161", "body": "no @author tags allowed in ASF code\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13425161/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13425174", "body": "remove @author again\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13425174/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13713951", "body": "drmA is already binary here, so we could use colSums\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13713951/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13713968", "body": "drmB is already binary here, so we could use colSums\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13713968/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13714024", "body": "you can trust getNumNonZeroElements.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13714024/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}]}, "pferrel": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/apache/mahout/issues/comments/45234064", "body": "I could use a little advice here. The epinions and movielens tests in the examples folder. Should they be put into the build?\n\nPros: good example data.\nCons: the reading and writing are not HDFS, they use java i/o and so only work locally. It is easy to change the Spark context to use a cluster but the data still has to be local. These tests would be easier to maintain if they were attached to the ItemSimilarityDriver, which will handle cluster storage and execution and will be maintained better.\n\nI'd rather move them out into an ItemSimilarityDriver examples folder and will do this if no one objects. They will not be build tests, obviously, since they take too long.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45234064/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45234551", "body": "yes, but downloading is described in the comments\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45234551/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45235053", "body": "I guess I'm suggesting that examples like these might be good in the right place. Not as build tests but as usage examples. As long as they use only supported code (read/write for instance)\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45235053/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45238498", "body": "You a Ren and Stimpy fan or is it just the way you feel sometimes?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45238498/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45241940", "body": "Hah, that's me looking at my own code\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45241940/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45252176", "body": "Please do not commit this to the master!\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45252176/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45413683", "body": "In general the problem is the one stated in the top description. If I need to create a new DrmLike+RDD please advise.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45413683/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45421615", "body": "I think I found the answer. \n\n```\n  val drmInteractions = drmWrap[Int](indexedInteractions, numRows, numColumns)\n```\n\nThis creates a CheckpointedDrm, with an rdd and DrmLike[Int] trait interface. Seems to work even!\n\nLikely due to my Scala ignorance I couldn't find a scaladoc for the helpers in the package object. I did find a reference to drmWrap in the PDF but couldn't find a scaladoc. Are scaladocs just a wip or did I miss it somewhere? \n\nFor anyone reading this, look at the helper functions in the package.scala files peppered throughout. Some are Spark specific and some just Scala helpers, be sure to lookup the use of Scala package objects. \n\nAnyway, block is removed, more to do before merging.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45421615/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45560733", "body": "According to the instructions I merge from my branch anyway. I can close it right? The instruction for closing without merging?\n\nI assume you got my mail about finding the blocker now there are some questions about the cooccurrence algo itself.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45560733/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commit_comments": [{"url": "https://api.github.com/repos/apache/mahout/comments/6657027", "body": "Negative interactions?\n\nI guess It is possible input, I\u2019ll change that.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/6657027/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/6657099", "body": "BTW where are the tests for MatrixOps?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/6657099/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/6663830", "body": "nevemind, rather obvious.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/6663830/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/6664314", "body": "Oops, fixed. Added to the test cases.\n\nOn Jun 12, 2014, at 8:22 PM, Dmitriy Lyubimov notifications@github.com wrote:\n\nI still dont get it. This implementation counts positive elements, not nonzeroes.\n\n\u2014\nReply to this email directly or view it on GitHub.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/6664314/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/6666770", "body": "I agree and said that in several places.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/6666770/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/8585771", "body": "Building for hadoop 1.2.1 I get the following compile error:\n\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project mahout-integration: Compilation failure: Compilation failure:\n[ERROR] /Users/pat/mahout/integration/src/main/java/org/apache/mahout/utils/ConcatenateVectorsJob.java:[116,73] cannot find symbol\n[ERROR] symbol  : method file(org.apache.hadoop.fs.Path)\n[ERROR] location: class org.apache.hadoop.io.SequenceFile.Reader\n[ERROR] /Users/pat/mahout/integration/src/main/java/org/apache/mahout/utils/ConcatenateVectorsJob.java:[116,16] internal error; cannot instantiate org.apache.hadoop.io.SequenceFile.Reader.<init> at org.apache.hadoop.io.SequenceFile.Reader to ()\n\nIs this hadoop 2 dependant? \n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/8585771/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/8585996", "body": "Yeah, that's what I thought. I went back to Gokhan's commit and all it well.\n\nIs there some reason you can't use the old API for that line? Isn't the main point the precondition? \n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/8585996/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/10684389", "body": "huh? I thought the next version was 0.10.1?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/10684389/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/10927175", "body": "Are these required for all scala modules? Can this be put in spark-shell pom instead?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/10927175/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "review_comments": [{"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13520938", "body": "It will walk a dir tree finding file by pattern match, not implemented yet and AFAIK not implemented in HDFS which will look in a single dir for pattern matched file names. I'll look to see if Sean did something like this already.\n\nI'm not satisfied with the packaging yet so I agree. If you know of something that does this be happy to take it out.\n\nYes, I will double check that everything has the license statement.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13520938/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13520946", "body": "This recursive search is very common in log file organization and a goal of this is to allow direct reading of log files in production environments.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13520946/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13706588", "body": "Yeah, figured that was ugly and should be > 0 but since iterating nonZero it does work. I'll change this.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13706588/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13706737", "body": "yes, I don't see what they did here. it looks correct in the editor. I get this occasionally and haven't figured it out. Often with diffs that you are merging. I end up merging white space that looks identical.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13706737/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13706797", "body": "OK, well thanks for reviewing!\n\nI avoided the numNonZero from Java because it is an upper limit and didn't want to confuse this with that. This is the actual count. But nonZeroCounts is fine if you prefer. It does seem more descriptive.\n\nComment on non-negative below\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13706797/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13708030", "body": "err actually nonZeroCounts doesn't work because we need to indicate column. Java verbose style might be numNonZeroColElements. I await a better suggestion. This is a vector like colSums and the Java getNumNonZeroElements is an Int and isn't reliable?\n\nThe distributed check will never catch a 0 since we iterate nonZero but it is wrong and I'll fix. The inCore? I assume you mean the MatrixOps version. I'll comment there.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13708030/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13708276", "body": "Are you saying this doesn't count non-zero elements?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13708276/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13709105", "body": "Sorry, I never pay much attention to that. What's the limit?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13709105/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13714291", "body": "colCounts or whatever we call it is just as efficient, is distributed and tells the reader what is the important value. \n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13714291/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13714354", "body": "got it, I'll remove the comment since we do rely on it in the code\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13714354/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}, "smarthi": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/apache/mahout/comments/8585978", "body": "It's using hadoop 2 api and is not backward compatible hadoop 1.x. I can revert that back this weekend \n\nSent from my iPhone\n\n> On Nov 15, 2014, at 9:41 AM, Pat Ferrel notifications@github.com wrote:\n> \n> Building for hadoop 1.2.1 I get the following compile error:\n> \n> [ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project mahout-integration: Compilation failure: Compilation failure:\n> [ERROR] /Users/pat/mahout/integration/src/main/java/org/apache/mahout/utils/ConcatenateVectorsJob.java:[116,73] cannot find symbol\n> [ERROR] symbol : method file(org.apache.hadoop.fs.Path)\n> [ERROR] location: class org.apache.hadoop.io.SequenceFile.Reader\n> [ERROR] /Users/pat/mahout/integration/src/main/java/org/apache/mahout/utils/ConcatenateVectorsJob.java:[116,16] internal error; cannot instantiate org.apache.hadoop.io.SequenceFile.Reader. at org.apache.hadoop.io.SequenceFile.Reader to ()\n> \n> Is this hadoop 2 dependant?\n> \n> \u2014\n> Reply to this email directly or view it on GitHub.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/8585978/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/apache/mahout/comments/10708415", "body": "Change that to 'mahout-samsara'\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/10708415/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/apache/mahout/comments/10724487", "body": "@sslavic  Revert the change and lets mark this Jira as 'Won't Fix'.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/10724487/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}], "review_comments": []}, "hasonhai": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/apache/mahout/comments/10410504", "body": "Hi,\nThank you very much for the patch! I succeeded building mahout on my machine.\n\nBut I try some example and it didn't work. Can anybody help me checking these:\n- k-Means Clustering: # mahout org.apache.mahout.clustering.syntheticcontrol.kmeans.Job\n- Canopy Clustering : # mahout org.apache.mahout.clustering.syntheticcontrol.canopy.Job\n- Fuzzy k-Means Clustering: # mahout org.apache.mahout.clustering.syntheticcontrol.fuzzykmeans.Job\n\nThe console told that the path to \"cluster\" doesn't exist. Even though it was always there. I could not find any help from other sources.\n\n```\n15/03/26 12:15:07 INFO mapreduce.Job: Task Id : attempt_1426848955524_0062_m_000000_2, Status : FAILED\nError: java.lang.IllegalStateException: output/clusters-0\n        at org.apache.mahout.common.iterator.sequencefile.SequenceFileDirValueIterable.iterator(SequenceFileDirValueIterable.java:78)\n        at org.apache.mahout.clustering.classify.ClusterClassifier.readFromSeqFiles(ClusterClassifier.java:208)\n        at org.apache.mahout.clustering.iterator.CIMapper.setup(CIMapper.java:44)\n        at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:142)\n        at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:784)\n        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)\n       at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)\n       at java.security.AccessController.doPrivileged(Native Method)\n       at javax.security.auth.Subject.doAs(Subject.java:415)\n       at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n       at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)\nCaused by: java.io.FileNotFoundException: File output/clusters-0 does not exist\n        at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:376)\n        at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1485)\n        at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1525)\n        at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:570)\n        at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1485)\n        at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1525)\n        at org.apache.mahout.common.iterator.sequencefile.SequenceFileDirValueIterator.<init>(SequenceFileDirValueIterator.java:70)\n        at org.apache.mahout.common.iterator.sequencefile.SequenceFileDirValueIterable.iterator(SequenceFileDirValueIterable.java:76)\n        ... 10 more\n\n15/03/26 12:15:16 INFO mapreduce.Job:  map 100% reduce 0%\n15/03/26 12:15:17 INFO mapreduce.Job:  map 100% reduce 100%\n15/03/26 12:15:17 INFO mapreduce.Job: Job job_1426848955524_0062 failed with state FAILED due to: Task failed task_1426848955524_0062_m_000000\nJob failed as tasks failed. failedMaps:1 failedReduces:0\n\n15/03/26 12:15:17 INFO mapreduce.Job: Counters: 9\n        Job Counters\n                Failed map tasks=4\n                Launched map tasks=4\n                Other local map tasks=3\n                Rack-local map tasks=1\n                Total time spent by all maps in occupied slots (ms)=23087\n                Total time spent by all reduces in occupied slots (ms)=0\n                Total time spent by all map tasks (ms)=23087\n                Total vcore-seconds taken by all map tasks=23087\n                Total megabyte-seconds taken by all map tasks=23641088\nException in thread \"main\" java.lang.InterruptedException: Cluster Iteration 1 failed processing output/clusters-1\n        at org.apache.mahout.clustering.iterator.ClusterIterator.iterateMR(ClusterIterator.java:183)\n        at org.apache.mahout.clustering.kmeans.KMeansDriver.buildClusters(KMeansDriver.java:224)\n        at org.apache.mahout.clustering.kmeans.KMeansDriver.run(KMeansDriver.java:147)\n        at org.apache.mahout.clustering.syntheticcontrol.kmeans.Job.run(Job.java:135)\n        at org.apache.mahout.clustering.syntheticcontrol.kmeans.Job.main(Job.java:60)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:71)\n        at org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)\n        at org.apache.hadoop.util.ProgramDriver.driver(ProgramDriver.java:152)\n        at org.apache.mahout.driver.MahoutDriver.main(MahoutDriver.java:195)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at org.apache.hadoop.util.RunJar.run(RunJar.java:221)\n        at org.apache.hadoop.util.RunJar.main(RunJar.java:136)\n```\n\nThank a lot if anybody can help.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/10410504/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "review_comments": []}, "sslavic": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/apache/mahout/comments/10684431", "body": "Patch release 0.10.1 is possible, only as bug fix for 0.10.0. If/when needed, we can create necessary branch for the bug fix, from 0.10.0 tag.\nNext minor release will be 0.11.0 because many of the planned tickets are either major new features (Flink support) or breaking backward compatibility, e.g. artifact name changes like MAHOUT-1680 and MAHOUT-1681 or dependency changes in MAHOUT-1685.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/10684431/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/apache/mahout/comments/10708902", "body": "directory names of submodules do not match artifactId, e.g. they do not have mahout prefix\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/10708902/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/apache/mahout/comments/10905269", "body": "Wasn't it agreed that branch 0.10.x is meant for next bugfix release and master for future major changes?\n\nVersion in POM files was not changed.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/10905269/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}], "review_comments": []}}, "2": {"rawkintrevo": {"issues": [], "commits": [{"url": "https://api.github.com/repos/apache/mahout/commits/7dff35bc3c61c3e0b95e8e59406742be15203a69", "message": "WEBSITE-NOJIRA Direct download on homepage button"}, {"url": "https://api.github.com/repos/apache/mahout/commits/84f389140c3781ace210ad9fc977f0d464666644", "message": "WEBSITE-NOJIRA Add mahout-version"}, {"url": "https://api.github.com/repos/apache/mahout/commits/71ce4bf599f7abe8508724d124fa4554153055c6", "message": "WEBSITE-NOJIRA Added Clustering to Navbar"}, {"url": "https://api.github.com/repos/apache/mahout/commits/5c51c60180b05f5ea70ef7b86daf62c7e250ef08", "message": "WEBSITE-NOJIRA Added mahout-version variable"}, {"url": "https://api.github.com/repos/apache/mahout/commits/36da4cf3d4982e246191a3ec7eac2495a25f8a86", "message": "WEBSITE-NOJIRA Added Fn for news"}, {"url": "https://api.github.com/repos/apache/mahout/commits/d53d444374c874a89abd87042a4bdd6a57915258", "message": "WEBSITE-NOJIRA Fix Mahout Overview Link"}, {"url": "https://api.github.com/repos/apache/mahout/commits/4c1d12e39801ca7e2fa1170190d77e150ff11d66", "message": "WEBSITE-NOJIRA Fix Download link, etc."}, {"url": "https://api.github.com/repos/apache/mahout/commits/b9895898d799ae913ad2b37e10b4ae75467b5e37", "message": "EMPTY commit to kick re-establish asf-pages mirror"}, {"url": "https://api.github.com/repos/apache/mahout/commits/6141be782e271748c9839de1e2b837eabb25033c", "message": "WEBSITE-NOJIRA Fix API Docs Link"}, {"url": "https://api.github.com/repos/apache/mahout/commits/1c528a194ebad97f24934685e7bfd9872ebe3019", "message": "WEBSITE-NOJIRA Various website fixes"}, {"url": "https://api.github.com/repos/apache/mahout/commits/ca8b4935c4014397ee4ffc7cd7964dce0979cdf6", "message": "doap_Mahout.rdf"}, {"url": "https://api.github.com/repos/apache/mahout/commits/5a07b51b4f85ea54ee234bd8e2bc320f49f8968c", "message": "WEBSITE removed themes- no longer used- updated how-to-update-website.md"}, {"url": "https://api.github.com/repos/apache/mahout/commits/fc36bef157dc47d9572c4cfd460067e1916910a0", "message": "MAHOUT-1981 Update build_site.sh to not commit entire website"}, {"url": "https://api.github.com/repos/apache/mahout/commits/03918713563bf6aac55299d7239c4e042795faf0", "message": "MAHOUT-1981 Missing Gemfile Added"}, {"url": "https://api.github.com/repos/apache/mahout/commits/9beddd3108ae453091a21a881c6693016f5f2012", "message": "MAHOUT-1981 Merged site updates, fixed navbars, Mathjax"}, {"url": "https://api.github.com/repos/apache/mahout/commits/4f2108c576daaa3198671568eaa619266e787b1a", "message": "[WEBSITE] Small change to make sure publishing"}, {"url": "https://api.github.com/repos/apache/mahout/commits/8a7bd9156880f3f12509c64cda62ac389cbb4f7d", "message": "[WEBSITE] Updating Front Site Config"}, {"url": "https://api.github.com/repos/apache/mahout/commits/9fe4aadc731ffecf3996992b51b8044c880b0e94", "message": "[WEBSITE] Download Javadocs if not present"}, {"url": "https://api.github.com/repos/apache/mahout/commits/1e6584d78e8dc83c04fd1c29a8b01d7e63b6005d", "message": "[WEBSITE] Issues with build_site.sh"}, {"url": "https://api.github.com/repos/apache/mahout/commits/697eae12c513f15e97a18b8a4e143fdc53064b7f", "message": "[WEBSITE] Deleted frontsite"}, {"url": "https://api.github.com/repos/apache/mahout/commits/2483037dc65fd69a508759f241e62709ea780af3", "message": "testing for infra"}, {"url": "https://api.github.com/repos/apache/mahout/commits/52154565410a7ebb9f9cdfe13ad9f039c1f8abb7", "message": "sync asf-site to github with empty"}, {"url": "https://api.github.com/repos/apache/mahout/commits/c80e00f894779b9c937eea280b3b7c39d07ed610", "message": "[WEBSITE] Jekyll build path command updates"}, {"url": "https://api.github.com/repos/apache/mahout/commits/2613883f2f6af05e69cdcc5945a456480747566e", "message": "[WEBSITE] Update how-to-update-website instructions"}, {"url": "https://api.github.com/repos/apache/mahout/commits/f0a246a341cdf66e1ff727a469ed268c00b7ebfe", "message": "[WEBSITE] Build_site.sh lost executable again"}], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/347", "title": "[WIP][NO-JIRA] Mahout Cylons Demo Donation", "body": "### Purpose of PR:\r\nThe so-called \"Cylons demo\" was well received at multiple talks in early Fall 2017, and there has been interest in continuing work on the project.  The Cylon demo showcases Mahout in the following ways:\r\n- A more robust use of the \"Eigenfaces Demo\" (on Apache Spark)\r\n- How Mahout \"precanned\" algos can be chopped up and used in Flink Streaming Applications\r\n- How Mahout facilitates the so-called \"Lambda style\" machine learning paradigm by training an offline\r\nmodel in Apache Spark and utilizing it in Apache Flink with Apache Solr as the \"model server\" as well as a so called \"Kappa\" style by continuously training and applying a Canopy Function.\r\n\r\nAs this was originally a demo- it is somewhat 'dirty' to say the least. Much work is to be done to fully integrate this as a nice clean demo- especially with respect to documentation.  \r\n\r\nNote that a working drone is NOT required to run this demo as one can tie into any RSTP video feed and there are many public ones available (as well as creating one with many webcams). \r\n\r\nOpening this as a WIP PR that others may contribute and help me get it ready for merging into the trunk. \r\n\r\n### Important ToDos\r\nPlease mark each with an \"x\"\r\n- [ ] A JIRA ticket exists (if not, please create this first)[https://issues.apache.org/jira/browse/ZEPPELIN/]\r\n- [ ] Title of PR is \"MAHOUT-XXXX Brief Description of Changes\" where XXXX is the JIRA number.\r\n- [ ] Created unit tests where appropriate\r\n- [ ] Added licenses correct on newly added files\r\n- [ ] Assigned JIRA to self\r\n- [ ] Added documentation in scala docs/java docs, and to website\r\n- [ ] Successfully built and ran all unit tests, verified that all tests pass locally.\r\n\r\nIf all of these things aren't complete, but you still feel it is\r\nappropriate to open a PR, please add [WIP] after MAHOUT-XXXX before the\r\ndescriptions- e.g. \"MAHOUT-XXXX [WIP] Description of Change\"\r\n\r\nDoes this change break earlier versions?\r\n\r\nIs this the beginning of a larger project for which a feature branch should be made?\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "andrewmusselman": {"issues": [], "commits": [{"url": "https://api.github.com/repos/apache/mahout/commits/b887ab3653590c854f2b118162114f1133b9534d", "message": "Merge branch 'master' into mahout-1981"}, {"url": "https://api.github.com/repos/apache/mahout/commits/9a2055e7b7bd1788b0b7523367772650ffdb6b53", "message": "NOJIRA: Shrinking the home page splash area vertically, moving ASF logo to the top."}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13259038", "body": "Would be nice to have a workflow where the changelog changes along with the bug though; I'd be okay dealing with conflicts on this file unless things get really crazy.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13259038/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}, "kunalcsc630": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/354", "title": "Fixed grammatical error", "body": "### Purpose of PR:\r\nPlease give a short description of what this PR is for.\r\n\r\n\r\n### Important ToDos\r\nPlease mark each with an \"x\"\r\n- [ ] A JIRA ticket exists (if not, please create this first)[https://issues.apache.org/jira/browse/ZEPPELIN/]\r\n- [ ] Title of PR is \"MAHOUT-XXXX Brief Description of Changes\" where XXXX is the JIRA number.\r\n- [ ] Created unit tests where appropriate\r\n- [ ] Added licenses correct on newly added files\r\n- [ ] Assigned JIRA to self\r\n- [ ] Added documentation in scala docs/java docs, and to website\r\n- [ ] Successfully built and ran all unit tests, verified that all tests pass locally.\r\n\r\nIf all of these things aren't complete, but you still feel it is\r\nappropriate to open a PR, please add [WIP] after MAHOUT-XXXX before the\r\ndescriptions- e.g. \"MAHOUT-XXXX [WIP] Description of Change\"\r\n\r\nDoes this change break earlier versions?\r\n\r\nIs this the beginning of a larger project for which a feature branch should be made?\r\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "davidtmiller": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/352", "title": "Mahout 1981 - Front End Design Update", "body": "### Purpose of PR:\r\nPlease give a short description of what this PR is for.\r\n\r\n\r\n### Important ToDos\r\nPlease mark each with an \"x\"\r\n- [ ] A JIRA ticket exists (if not, please create this first)[https://issues.apache.org/jira/browse/ZEPPELIN/]\r\n- [ ] Title of PR is \"MAHOUT-XXXX Brief Description of Changes\" where XXXX is the JIRA number.\r\n- [ ] Created unit tests where appropriate\r\n- [ ] Added licenses correct on newly added files\r\n- [ ] Assigned JIRA to self\r\n- [ ] Added documentation in scala docs/java docs, and to website\r\n- [ ] Successfully built and ran all unit tests, verified that all tests pass locally.\r\n\r\nIf all of these things aren't complete, but you still feel it is\r\nappropriate to open a PR, please add [WIP] after MAHOUT-XXXX before the\r\ndescriptions- e.g. \"MAHOUT-XXXX [WIP] Description of Change\"\r\n\r\nDoes this change break earlier versions?\r\n\r\nIs this the beginning of a larger project for which a feature branch should be made?\r\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "andrewpalumbo": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/349", "title": "[WIP]MAHOUT-2027: spark-ec2 launch scripts with ViennaCL/JCuda installation", "body": "### Purpose of PR:\r\nPlease give a short description of what this PR is for.\r\n\r\n\r\n### Important ToDos\r\nPlease mark each with an \"x\"\r\n- [ x] A JIRA ticket exists (if not, please create this first)[https://issues.apache.org/jira/browse/ZEPPELIN/]\r\n- [ x] Title of PR is \"MAHOUT-XXXX Brief Description of Changes\" where XXXX is the JIRA number.\r\n- [ ] Created unit tests where appropriate\r\n- [x ] Added licenses correct on newly added files\r\n- [x ] Assigned JIRA to self\r\n- [ ] Added documentation in scala docs/java docs, and to website\r\n- [ ] Successfully built and ran all unit tests, verified that all tests pass locally.\r\n\r\nIf all of these things aren't complete, but you still feel it is\r\nappropriate to open a PR, please add [WIP] after MAHOUT-XXXX before the\r\ndescriptions- e.g. \"MAHOUT-XXXX [WIP] Description of Change\"\r\n\r\nDoes this change break earlier versions?\r\nno - exampe\r\nIs this the beginning of a larger project for which a feature branch should be made?\r\nno", "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/318", "title": "[WIP]MAHOUT-1974 (dense cuda multiplication)", "body": "### Purpose of PR:\r\nPlease give a short description of what this PR is for.\r\n\r\n\r\n### Important ToDos\r\nPlease mark each with an \"x\"\r\n- [x] A JIRA ticket exists (if not, please create this first)[https://issues.apache.org/jira/browse/MAHOUT/]\r\n- [x] Title of PR is \"MAHOUT-XXXX Brief Description of Changes\" where XXXX is the JIRA number.\r\n- [x] Created unit tests where appropriate\r\n- [ ] Added licenses correct on newly added files\r\n- [ ] Assigned JIRA to self\r\n- [ ] Added documentation in scala docs/java docs, and to website\r\n- [ ] Successfully built and ran all unit tests, verified that all tests pass locally.\r\n\r\nIf all of these things aren't complete, but you still feel it is\r\nappropriate to open a PR, please add [WIP] after MAHOUT-XXXX before the\r\ndescriptions- e.g. \"MAHOUT-XXXX [WIP] Description of Change\"\r\n\r\nDoes this change break earlier versions?\r\n\r\nIs this the beginning of a larger project for which a feature branch should be made?\r\n", "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/129", "title": "MAHOUT-1706: remove dependency jars from /lib in the binary distribution", "body": "The mahout distribution currently is shipping ~56 MB of dependecy jars in the /lib directory of the distribution.   These are only added to the classpath by /bin/mahout in the binary distribution. It seems that we can remove them from the distribution. (we need to get the size of the distribution down)\n\nAny input is appreciated. \n", "author_association": "MEMBER"}], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/apache/mahout/comments/10927850", "body": "I can't remember at the moment if it was only the spark-shell module that needed them or if others did as well. \u00a0I believe it had something to do with the spark-1.2 upgrade, part of which made it into master. \u00a0\n\nPutting them in the shell pom may work. \u00a0\n\nSent from my Verizon Wireless 4G LTE smartphone\n\n<div>-------- Original message --------</div><div>From: Pat Ferrel notifications@github.com </div><div>Date:04/27/2015  5:36 PM  (GMT-05:00) </div><div>To: apache/mahout mahout@noreply.github.com </div><div>Cc: Andrew Palumbo ap.dev@outlook.com </div><div>Subject: Re: [mahout] added scala dependencies in math-scala to fix spark-shell (71165a5) </div><div>\n</div>Are these required for all scala modules? Can this be put in spark-shell pom instead?\n\n\u2014\nReply to this email directly or view it on GitHub.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/10927850/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/apache/mahout/comments/16715391", "body": "LGTM\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/16715391/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/apache/mahout/comments/18009403", "body": "yep looks like.. I can fix it.  I was also thinking the name should be refactored to `densityAnalysis` so that `true` = `isDense`\\- seems more intuituive.  what do you think? Does sparsityAnalysis have any specific meaning outside of here?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/18009403/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/apache/mahout/comments/18009913", "body": "yes that would make sense.  I've done the Refactoring and the fix, and have a jira open to add densitAnalysis() in other places.  am just leaving for the day, so will push the open PR now and make note of this in the current jira or create a new one soon. \n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/18009913/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}], "review_comments": []}, "BruceKuiLiu": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/346", "title": "Consider returning a zero length array rather than null.", "body": "It is often a better design to return a length zero array rather than a null reference to indicate that there are no results (i.e., an empty list of results).\r\nThis way, no explicit check for null is needed by clients of the method.\r\nOn the other hand, using null to indicate \"there is no answer to this question\" is probably appropriate.\r\nhttp://findbugs.sourceforge.net/bugDescriptions.html#PZLA_PREFER_ZERO_LENGTH_ARRAYS\r\n\r\n\r\n", "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/345", "title": "Remove the redundant null check statements of a non-null value.", "body": "This IfStatement is a redundant check of a known non-null otherObj because the null check of otherObj is contained in the previous instanceof check.\r\nhttp://findbugs.sourceforge.net/bugDescriptions.html#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE\r\n\r\n", "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/344", "title": "Add an IfStatement to check the return value of resultFile.delete().", "body": "This statement returns a value that is not checked.\r\nThe return value should be checked since it can indicate an unusual or unexpected function execution.\r\nThe statement returns false if the file could not be successfully deleted (rather than throwing an Exception).\r\nIf the result was not checked, developers would not notice if the statement signals an unexpected behavior by returning an atypical return value.\r\nhttp://findbugs.sourceforge.net/bugDescriptions.html#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE\r\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "holdenk": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/340", "title": "MAHOUT-2015 [WIP]: Expose Mahout's OLS algorithm in the Spark ML API", "body": "### Purpose of PR:\r\nExpose Mahout's OLS algorithm in the Spark ML API\r\n\r\n### Important ToDos\r\nPlease mark each with an \"x\"\r\n- [ X] A JIRA ticket exists (if not, please create this first)[https://issues.apache.org/jira/browse/ZEPPELIN/]\r\n- [ X ] Title of PR is \"MAHOUT-XXXX Brief Description of Changes\" where XXXX is the JIRA number.\r\n- [ X ] Created unit tests where appropriate\r\n- [ X ] Added licenses correct on newly added files\r\n- [ X ] Assigned JIRA to self\r\n- [ ] Added documentation in scala docs/java docs, and to website\r\n- [ ] Successfully built and ran all unit tests, verified that all tests pass locally.\r\n\r\nIf all of these things aren't complete, but you still feel it is\r\nappropriate to open a PR, please add [WIP] after MAHOUT-XXXX before the\r\ndescriptions- e.g. \"MAHOUT-XXXX [WIP] Description of Change\"\r\n\r\nDoes this change break earlier versions?\r\n\r\nNo\r\n\r\nIs this the beginning of a larger project for which a feature branch should be made?\r\n\r\nNo", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "dustinvanstee": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/335", "title": "MAHOUT-2000 [WIP] Add maven profile for Spark 2.2", "body": "### Purpose of PR: Add spark 2.2 into travisCI framework and add a maven spark 2.2 profile.\r\n\r\n\r\n### Important ToDos\r\nPlease mark each with an \"x\"\r\n- [x] A JIRA ticket exists (if not, please create this first)[https://issues.apache.org/jira/browse/ZEPPELIN/]\r\n- [ x] Title of PR is \"MAHOUT-XXXX Brief Description of Changes\" where XXXX is the JIRA number.\r\n- [ ] Created unit tests where appropriate\r\n- [ ] Added licenses correct on newly added files\r\n- [x ] Assigned JIRA to self\r\n- [ ] Added documentation in scala docs/java docs, and to website\r\n- [ ] Successfully built and ran all unit tests, verified that all tests pass locally.\r\n\r\nIf all of these things aren't complete, but you still feel it is\r\nappropriate to open a PR, please add [WIP] after MAHOUT-XXXX before the\r\ndescriptions- e.g. \"MAHOUT-XXXX [WIP] Description of Change\"\r\n\r\nDoes this change break earlier versions?\r\n\r\nIs this the beginning of a larger project for which a feature branch should be made?\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "AdityaAS": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/334", "title": "[WIP] MAHOUT-1991 - Add DBSCAN", "body": "DBSCAN - Google Summer of Code '17 - Apache Software Foundation (Apache Mahout)\r\n\r\nGoals: Implement DBSCAN algorithm\r\n\r\nWork done:\r\n- Coded Sequential and Distributed versions of DBSCAN\r\n- Added docs and unit tests\r\nWork left to do:\r\n- Improve distributed DBSCAN to make it more accurate\r\n- Include cluster quality index calculation\r\n\r\nAdded the sequential version of the algorithm. Docs and Unit Tests where appropriate.\r\nWill be adding rtree module and the approximate distributed algorithm soon.\r\n\r\nLink to a short report describing the whole project can be found [here](https://docs.google.com/document/d/11sLJkwAftR2-Fmglju8c7dGTf1i3trkbEV2Zr9OlilU/edit?usp=sharing).\r\n\r\n@rawkintrevo do help me out.\r\n\r\n### Important ToDos\r\nPlease mark each with an \"x\"\r\n- [x] A JIRA ticket exists (if not, please create this first)[https://issues.apache.org/jira/browse/ZEPPELIN/]\r\n- [x] Title of PR is \"MAHOUT-XXXX Brief Description of Changes\" where XXXX is the JIRA number.\r\n- [x] Created unit tests where appropriate\r\n- [x] Added licenses correct on newly added files\r\n- [x] Assigned JIRA to self\r\n- [x] Added documentation in scala docs/java docs, and to website\r\n- [x] Successfully built and ran all unit tests, verified that all tests pass locally.\r\n\r\nIf all of these things aren't complete, but you still feel it is\r\nappropriate to open a PR, please add [WIP] after MAHOUT-XXXX before the\r\ndescriptions- e.g. \"MAHOUT-XXXX [WIP] Description of Change\"\r\n\r\nDoes this change break earlier versions?\r\n\r\nIs this the beginning of a larger project for which a feature branch should be made?\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "nsakharnykh": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/310", "title": "MAHOUT-1974 CUDA support", "body": "Initial PR for CUDA bindings support through JCuda", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "skanjila": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/279", "title": "Mahout 1904", "body": "Added a helper function to pass fail the method, first cut of this as an iteration to be reviewed.", "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/245", "title": "Mahout 1869", "body": "Added the ability to dump output to csv file\n", "author_association": "NONE"}], "issue_comments": [{"url": "https://api.github.com/repos/apache/mahout/issues/comments/45238065", "body": "Ok I'll be doing a more substantial commit that might help us see how the APIs around a DataFrame\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45238065/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "BertrandDechoux": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/265", "title": "Add optional manual configuration of AtA's number of partitions.", "body": "```scala\r\n// Determine how many partitions the new matrix would need approximately. We base that on\r\n// geometry only, but it may eventually not be that adequate. Indeed, A'A tends to be much more\r\n// dense in reality than the source.\r\n```\r\nAllow override when estimation is not adequate because AtA is indeed more dense...", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "MaineC": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/240", "title": "Add one year mahout blog post draft.", "body": "The outline as offered by @smarthi with a bit of boiler plate. Needs some more love and content in the individual sections.\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "manognavemulapati": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/181", "title": "An alternative scaling method for Baum Welch for HMM.", "body": "This implements an alternative scaling method (called rescaling) for Baum Welch algorithm for unsupervised HMM training. The new scaling method partially addresses Mahout-627. The existing scaling method  based on log scaling is not numerically stable when tried with the Mapreduce version of Baum Welch proposed for Mahout-627. With the rescaling method, I am able to successfully run the Mapreduce version of Baum Welch on long training sequences. Further details and references are given in the following writeup.\nImplementation of an Alternative Scaling for Baum-Welch Algorithm for Hidden Markov Model (HMM) in Apache Mahout -- http://manognavemulapati.github.io/mahout/HMMScaling.pdf.\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "michellemay": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/174", "title": "MAHOUT-1786: Make classes implements Serializable for Spark 1.5+", "body": "Add some \"implements Serializable\" for Apache Spark 1.5+\nThere might be other classes that would benefit from the same modification.\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "sugaE": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/131", "title": "Fix bug: Add commit after executeUpdate", "body": "It will not write database without commit().\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ghost": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/70", "title": "Non-negative Matrix Factorization and Probabilistic Matrix Factorization", "body": "Non-negative Matrix Factorization, using classical multiplicative update rule.\nProbabilistic Matrix Factorization, using stochastic gradient descent\n\nUse Movielens dataset  to test, get reasonable result. \n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "mihaipitu": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/35", "title": "Sparse Linear Methods (SLIM) Recommender with two optimization techniques", "body": "The SLIM algorithm generates efficient recommendations and its performance is shown in the original paper (http://glaros.dtc.umn.edu/gkhome/fetch/papers/SLIM2011icdm.pdf). The study demonstrates that SLIM outperforms traditional algorithms (such as itemkNN, userkNN, SVD or other Matrix Factorization approaches) on various data-sets in terms of time efficiency and recommendation quality.\r\nSLIM's optimization problem can be solved using Least Square optimization (designed for explicit feedback datasets) and Bayesian Personalized Ranking (designed for implicit feedback datasets).", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "dlyubimov": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/apache/mahout/issues/comments/44071171", "body": "ok i think this is more or less it for now, untill we do more API tweaking to fit \"multiple sink\" model of Stratosphere. But at least all currently working api is fully abstracted and moved out to math-scala module with 0 Spark (or Hadoop) dependencies. Please feel free to dig in and point out how i am being stupid :) \n\n:8ball: \n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44071171/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44353426", "body": "Please include jira #.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44353426/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44496355", "body": "looks benign to me.\n\nNeed review from folks that were working on Hadoop 2 integration, to make sure this is in line with the rest of the effort. MAHOUT-1565\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44496355/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44713857", "body": "A slight nuisance here is that A' cannot be checkpointed. This is because the keys of A, in the most general case, are not `Int`s.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44713857/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44714458", "body": "perhaps a better test is needed that introduces some random jitter into the input.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44714458/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45017407", "body": "Want to commit it now. 90% is bug fixes and refactoring. Added zip-optimization for identically distributed elementwise operators, etc.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45017407/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45156215", "body": "FunctionalView matrix introduced general concept of dense/sparse matrix. surprisingly, abstract matrix has none. So MatrixWritable just tries to look at a row view to figure this out. Perhaps the isDense functionality should be added to AbstractMatrix in the first place?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45156215/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45167847", "body": "do we need help committing this? Are we committing this?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45167847/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45236939", "body": "Ok, this is still is too little substance for review, and did not seem to generate much new ideas either. Plus i am probably will not be spending much time on it any time soon.\n\nWithdrawing request for the time being \n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45236939/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45237262", "body": "I Like Pat's github avatar :+1: \n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45237262/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45239528", "body": "i don't even know that cartoon, just thought is was funny. Yeah, thinking of it, it is how i used to feel most of the time looking at my colleagues' code at work \n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45239528/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45252464", "body": "this is work in progress. We get it :)\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45252464/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45401402", "body": "also added (pretty naive) auto parallelism adjustments\n\n```\n(A+B) auto_||\n```\n\nwhich looks at spark.default.parallelism (P), assumes better parallelism is acheved if partitions are bumped up to round-ups of 0.95 \\* P or 1.80 \\* (P) whichever is closer. if current partition set is already greater (in cardinality) than rounded-up 1.80 \\* (P), all is left as is.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45401402/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45553612", "body": "i will commit it soon then\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45553612/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45557670", "body": "Pat, so, we are not going to use this for merging into merging, i take it? I will close it, you can keep working on your other requests.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45557670/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commit_comments": [{"url": "https://api.github.com/repos/apache/mahout/comments/6656953", "body": "I still dont get it. This implementation counts positive elements, not nonzeroes.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/6656953/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/6666688", "body": "Considerations of negative interactions of co-occurence analysis are irrelevant since you are implementing contract that has nothing to do with any particular algorithm you may be using it for.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/6666688/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/10723951", "body": "who-a?...\n\nOn Tue, Apr 14, 2015 at 1:55 AM, Stevo Slavi\u0107 notifications@github.com\nwrote:\n\n> directory names of submodules do not match artifactId, e.g. they do not\n> have mahout prefix\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/apache/mahout/commit/f7b69fabf1253b5e735e269c9410459d91816cdd#commitcomment-10708902\n> .\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/10723951/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/10724331", "body": "I am not in favor of renaming artifacts in general, and in this particular case as well. \n\nIn general, because renaming artifacts create incredible operational and legal headaches on the scale you can't even begin to imagine, in certain places :)\n\nin particular, because If \"samsara\" is to refer to computing environment, (let's say algebra environment in particular), then its code is not contained in any single module. instead, it's dispersed around.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/10724331/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/18009341", "body": "I think there's a bug in this line. If we return true for dense outcome of the analysis, the comparison should be reversed to `>`  in this line.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/18009341/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/18009547", "body": "uhm, yes, density makes more sense.\n\nOn Fri, Jun 24, 2016 at 1:45 PM, Andrew Palumbo notifications@github.com\nwrote:\n\n> yep looks like.. I can fix it. I was also thinking the name should be\n> refactored to densityAnalysis so that true = isDense- seems more\n> intuituive. what do you think? Does sparsityAnalysis have any specific\n> meaning outside of here?\n> \n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> https://github.com/apache/mahout/commit/d9940489d2f849d36af396d603f6170ab560e505#commitcomment-18009403,\n> or mute the thread\n> https://github.com/notifications/unsubscribe/AAf7_5MT7tIGk-w7SYJYCoXuNOvpQxiuks5qPEHggaJpZM4I-G2e\n> .\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/18009547/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/18009583", "body": "I also think it should be more thorough to use shallow initialization, especially in the case when input is already coming as dense and is using dense vectors. right now it looks like this would be copying it. \n\ne.g.:\n\n```\n    val block = new SparseRowMatrix(vectors.size, blockncol, vectors, true, true)\n\n    // Test the density of the data. If the matrix does not meet the\n    // requirements for density, convert the Vectors to a sparse Matrix.\n    val resBlock = if (sparsityAnalysis(block)) {\n      val shallow = vectors.forall(_.isInstanceOf[DenseVector])\n      if (shallow) {\n        // I don't like it but at this point this is the only way to avoid copying with DenseMatrix\n        // initialized by DenseVectors:\n        val vclass = classOf[DenseVector]\n        val valAttr = vclass.getField(\"values\")\n        // Use shallow initialization over backing array of Doubles.\n        new DenseMatrix(vectors.map(v \u21d2 valAttr.get(v).asInstanceOf[Array[Double]]),true)\n      } else {\n        dense(vectors)\n      }\n\n    } else {\n\n      // Sparse matrix: we already created it as a sparse matrix wrapper. There may be a path\n      // to improvement in case the payload comes in as dense vectors, but analysis says they\n      // are really sparse so shallow wrapper doesn't make much sense and we would need to\n      // copy the data into truly sparse vectors in order to truly save memory here. TODO\n      block\n    }\n```\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/18009583/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/18009657", "body": "although... reflection to extract values[] doesn't work. i think this need a patch on dense matrix that accepts array of vectors and `shallowIfPossible` flag that would do shallow init if incoming vectors are DenseVectors.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/18009657/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/18009705", "body": "i guess we really need to patch dense(vecs) implementation to implement shallow initialization where possible. Or have it as \n\n```\ndef dense[R](rows:R*)(shallowIfPossible:Boolean=true) \n```\n\n?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/18009705/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/18009875", "body": "no.. this form doesn't work either.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/18009875/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "review_comments": [{"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13257657", "body": "I think it'd be better to add this when (after) you will be doing a squash pull. Otherwise you'd be merging this file with other changes. This file is guaranteed to change by other commits every time. Although most likely this conflict will be handled automatically by git. \n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13257657/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13518008", "body": "I don't think we need to bring any dfs utils into scala. First, why is it not covered by Hadoop \"glob\"s or tons of hdfs helpers that Sean had created? Second, i think it needs to be shared by all platforms hence it probably needs to go where this common stuff resides in java. \n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13518008/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13518011", "body": "i guess license is coming.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13518011/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13688078", "body": "is that where the major problem was? is that because assignment of sequential vector to sequential vector is that slow? or this is an assignment of random vector to a sequential vector? (sequential to sequential actually should be ok methinks). \n\nAnyway I don't see any immediate problems, and the quality of your work usually doesn't require any deep scrutiny, so i'd say ship it. Actually the sooner the better, because i am very close to actually give it all a good spanking\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13688078/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13687695", "body": "we don't use vector.set and vector.get in scala. we use dsl which would look simply  \n\n```\nacc(elem.index) += 1\n```\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13687695/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13687718", "body": "No need to re align. IDEA scala plugin does a good job donig style indentation. Are you using IDEA?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13687718/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13687795", "body": "There are few doubts there. \n(1) DSL follows R. Which R function this mimics? If none, can we get away with doing it on java side? ( i guess we can't get around it if you want to do it for DRMs). \n(2) the name IMO is misleading given description. nonZeroCounts()?\n(3) The implementation (both in-core and distributed, BTW) seem to contradict the description. It looks like implementation actually counts number of _non-negative_ elements rather than what description portrays.\n(4) I would like Sebastian's feedback on this too, since he is both the primary co-occurrence author and understands R-like semantics idea very deeply.  If there's a better semantics (like I suspect it should be), he should know that.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13687795/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13688228", "body": "a line too long? (style?)\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13688228/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13711381", "body": "it looks like, to me. don't have time to look in depth. but distributed code definitely counts non-negatives with explicit inline conditional >0\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13711381/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13711414", "body": "it is very easy to tweak tests though to check if in doubt\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13711414/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13770844", "body": "Since this returns double, correct style is to say 1.0 or 0.0 not 1 or 0 on java side regardless of implicit conversion\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13770844/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13770924", "body": "style: spacing?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13770924/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}, "jfarrell": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/apache/mahout/issues/comments/44318648", "body": "MAHOUT-1529 not linking to jira as discussed in INFRA-7801\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44318648/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "nishkamravi2": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/apache/mahout/issues/comments/44354961", "body": "JIRA: MAHOUT-1565 (https://issues.apache.org/jira/browse/MAHOUT-1565)\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44354961/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44501707", "body": "Removed MAHOUT_OPTS from bin/mahout and bin/mahout.cmd\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44501707/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "sscdotopen": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/apache/mahout/issues/comments/44743038", "body": "looks good to me, +1 for including this\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44743038/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45234269", "body": "Its not allowed to redistribute the movielens dataset.\n\nOn 06/05/2014 05:28 PM, Pat Ferrel wrote:\n\n> I could use a little advice here. The epinions and movielens tests in the examples folder. Should they be put into the build?\n> \n> Pros: good example data.\n> Cons: the reading and writing are not parallel and so only work locally. It is easy to change the Spark context to use a cluster but the data still has to be local. These tests would be easier to maintain if they were attached to the ItemSimilarityDriver, which will handle cluster storage and execution and will be maintained better.\n> \n> I'd rather move them out into an ItemSimilarityDriver examples folder and will do this if no one objects. They will not be build tests, obviously, since they take too long.\n> \n> ---\n> \n> Reply to this email directly or view it on GitHub:\n> https://github.com/apache/mahout/pull/8#issuecomment-45234064\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45234269/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13169806", "body": "I don't think we should assign memory to map & reduce tasks ourselves.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13169806/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13425122", "body": "we can remove the .parallel. import\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13425122/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13425161", "body": "no @author tags allowed in ASF code\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13425161/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13425174", "body": "remove @author again\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13425174/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13713951", "body": "drmA is already binary here, so we could use colSums\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13713951/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13713968", "body": "drmB is already binary here, so we could use colSums\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13713968/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13714024", "body": "you can trust getNumNonZeroElements.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13714024/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}]}, "pferrel": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/apache/mahout/issues/comments/45234064", "body": "I could use a little advice here. The epinions and movielens tests in the examples folder. Should they be put into the build?\n\nPros: good example data.\nCons: the reading and writing are not HDFS, they use java i/o and so only work locally. It is easy to change the Spark context to use a cluster but the data still has to be local. These tests would be easier to maintain if they were attached to the ItemSimilarityDriver, which will handle cluster storage and execution and will be maintained better.\n\nI'd rather move them out into an ItemSimilarityDriver examples folder and will do this if no one objects. They will not be build tests, obviously, since they take too long.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45234064/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45234551", "body": "yes, but downloading is described in the comments\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45234551/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45235053", "body": "I guess I'm suggesting that examples like these might be good in the right place. Not as build tests but as usage examples. As long as they use only supported code (read/write for instance)\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45235053/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45238498", "body": "You a Ren and Stimpy fan or is it just the way you feel sometimes?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45238498/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45241940", "body": "Hah, that's me looking at my own code\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45241940/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45252176", "body": "Please do not commit this to the master!\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45252176/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45413683", "body": "In general the problem is the one stated in the top description. If I need to create a new DrmLike+RDD please advise.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45413683/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45421615", "body": "I think I found the answer. \n\n```\n  val drmInteractions = drmWrap[Int](indexedInteractions, numRows, numColumns)\n```\n\nThis creates a CheckpointedDrm, with an rdd and DrmLike[Int] trait interface. Seems to work even!\n\nLikely due to my Scala ignorance I couldn't find a scaladoc for the helpers in the package object. I did find a reference to drmWrap in the PDF but couldn't find a scaladoc. Are scaladocs just a wip or did I miss it somewhere? \n\nFor anyone reading this, look at the helper functions in the package.scala files peppered throughout. Some are Spark specific and some just Scala helpers, be sure to lookup the use of Scala package objects. \n\nAnyway, block is removed, more to do before merging.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45421615/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45560733", "body": "According to the instructions I merge from my branch anyway. I can close it right? The instruction for closing without merging?\n\nI assume you got my mail about finding the blocker now there are some questions about the cooccurrence algo itself.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45560733/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commit_comments": [{"url": "https://api.github.com/repos/apache/mahout/comments/6657027", "body": "Negative interactions?\n\nI guess It is possible input, I\u2019ll change that.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/6657027/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/6657099", "body": "BTW where are the tests for MatrixOps?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/6657099/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/6663830", "body": "nevemind, rather obvious.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/6663830/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/6664314", "body": "Oops, fixed. Added to the test cases.\n\nOn Jun 12, 2014, at 8:22 PM, Dmitriy Lyubimov notifications@github.com wrote:\n\nI still dont get it. This implementation counts positive elements, not nonzeroes.\n\n\u2014\nReply to this email directly or view it on GitHub.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/6664314/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/6666770", "body": "I agree and said that in several places.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/6666770/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/8585771", "body": "Building for hadoop 1.2.1 I get the following compile error:\n\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project mahout-integration: Compilation failure: Compilation failure:\n[ERROR] /Users/pat/mahout/integration/src/main/java/org/apache/mahout/utils/ConcatenateVectorsJob.java:[116,73] cannot find symbol\n[ERROR] symbol  : method file(org.apache.hadoop.fs.Path)\n[ERROR] location: class org.apache.hadoop.io.SequenceFile.Reader\n[ERROR] /Users/pat/mahout/integration/src/main/java/org/apache/mahout/utils/ConcatenateVectorsJob.java:[116,16] internal error; cannot instantiate org.apache.hadoop.io.SequenceFile.Reader.<init> at org.apache.hadoop.io.SequenceFile.Reader to ()\n\nIs this hadoop 2 dependant? \n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/8585771/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/8585996", "body": "Yeah, that's what I thought. I went back to Gokhan's commit and all it well.\n\nIs there some reason you can't use the old API for that line? Isn't the main point the precondition? \n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/8585996/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/10684389", "body": "huh? I thought the next version was 0.10.1?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/10684389/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/10927175", "body": "Are these required for all scala modules? Can this be put in spark-shell pom instead?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/10927175/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "review_comments": [{"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13520938", "body": "It will walk a dir tree finding file by pattern match, not implemented yet and AFAIK not implemented in HDFS which will look in a single dir for pattern matched file names. I'll look to see if Sean did something like this already.\n\nI'm not satisfied with the packaging yet so I agree. If you know of something that does this be happy to take it out.\n\nYes, I will double check that everything has the license statement.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13520938/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13520946", "body": "This recursive search is very common in log file organization and a goal of this is to allow direct reading of log files in production environments.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13520946/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13706588", "body": "Yeah, figured that was ugly and should be > 0 but since iterating nonZero it does work. I'll change this.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13706588/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13706737", "body": "yes, I don't see what they did here. it looks correct in the editor. I get this occasionally and haven't figured it out. Often with diffs that you are merging. I end up merging white space that looks identical.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13706737/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13706797", "body": "OK, well thanks for reviewing!\n\nI avoided the numNonZero from Java because it is an upper limit and didn't want to confuse this with that. This is the actual count. But nonZeroCounts is fine if you prefer. It does seem more descriptive.\n\nComment on non-negative below\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13706797/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13708030", "body": "err actually nonZeroCounts doesn't work because we need to indicate column. Java verbose style might be numNonZeroColElements. I await a better suggestion. This is a vector like colSums and the Java getNumNonZeroElements is an Int and isn't reliable?\n\nThe distributed check will never catch a 0 since we iterate nonZero but it is wrong and I'll fix. The inCore? I assume you mean the MatrixOps version. I'll comment there.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13708030/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13708276", "body": "Are you saying this doesn't count non-zero elements?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13708276/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13709105", "body": "Sorry, I never pay much attention to that. What's the limit?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13709105/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13714291", "body": "colCounts or whatever we call it is just as efficient, is distributed and tells the reader what is the important value. \n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13714291/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13714354", "body": "got it, I'll remove the comment since we do rely on it in the code\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13714354/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}, "smarthi": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/apache/mahout/comments/8585978", "body": "It's using hadoop 2 api and is not backward compatible hadoop 1.x. I can revert that back this weekend \n\nSent from my iPhone\n\n> On Nov 15, 2014, at 9:41 AM, Pat Ferrel notifications@github.com wrote:\n> \n> Building for hadoop 1.2.1 I get the following compile error:\n> \n> [ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project mahout-integration: Compilation failure: Compilation failure:\n> [ERROR] /Users/pat/mahout/integration/src/main/java/org/apache/mahout/utils/ConcatenateVectorsJob.java:[116,73] cannot find symbol\n> [ERROR] symbol : method file(org.apache.hadoop.fs.Path)\n> [ERROR] location: class org.apache.hadoop.io.SequenceFile.Reader\n> [ERROR] /Users/pat/mahout/integration/src/main/java/org/apache/mahout/utils/ConcatenateVectorsJob.java:[116,16] internal error; cannot instantiate org.apache.hadoop.io.SequenceFile.Reader. at org.apache.hadoop.io.SequenceFile.Reader to ()\n> \n> Is this hadoop 2 dependant?\n> \n> \u2014\n> Reply to this email directly or view it on GitHub.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/8585978/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/apache/mahout/comments/10708415", "body": "Change that to 'mahout-samsara'\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/10708415/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/apache/mahout/comments/10724487", "body": "@sslavic  Revert the change and lets mark this Jira as 'Won't Fix'.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/10724487/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}], "review_comments": []}, "hasonhai": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/apache/mahout/comments/10410504", "body": "Hi,\nThank you very much for the patch! I succeeded building mahout on my machine.\n\nBut I try some example and it didn't work. Can anybody help me checking these:\n- k-Means Clustering: # mahout org.apache.mahout.clustering.syntheticcontrol.kmeans.Job\n- Canopy Clustering : # mahout org.apache.mahout.clustering.syntheticcontrol.canopy.Job\n- Fuzzy k-Means Clustering: # mahout org.apache.mahout.clustering.syntheticcontrol.fuzzykmeans.Job\n\nThe console told that the path to \"cluster\" doesn't exist. Even though it was always there. I could not find any help from other sources.\n\n```\n15/03/26 12:15:07 INFO mapreduce.Job: Task Id : attempt_1426848955524_0062_m_000000_2, Status : FAILED\nError: java.lang.IllegalStateException: output/clusters-0\n        at org.apache.mahout.common.iterator.sequencefile.SequenceFileDirValueIterable.iterator(SequenceFileDirValueIterable.java:78)\n        at org.apache.mahout.clustering.classify.ClusterClassifier.readFromSeqFiles(ClusterClassifier.java:208)\n        at org.apache.mahout.clustering.iterator.CIMapper.setup(CIMapper.java:44)\n        at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:142)\n        at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:784)\n        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)\n       at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)\n       at java.security.AccessController.doPrivileged(Native Method)\n       at javax.security.auth.Subject.doAs(Subject.java:415)\n       at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n       at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)\nCaused by: java.io.FileNotFoundException: File output/clusters-0 does not exist\n        at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:376)\n        at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1485)\n        at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1525)\n        at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:570)\n        at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1485)\n        at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1525)\n        at org.apache.mahout.common.iterator.sequencefile.SequenceFileDirValueIterator.<init>(SequenceFileDirValueIterator.java:70)\n        at org.apache.mahout.common.iterator.sequencefile.SequenceFileDirValueIterable.iterator(SequenceFileDirValueIterable.java:76)\n        ... 10 more\n\n15/03/26 12:15:16 INFO mapreduce.Job:  map 100% reduce 0%\n15/03/26 12:15:17 INFO mapreduce.Job:  map 100% reduce 100%\n15/03/26 12:15:17 INFO mapreduce.Job: Job job_1426848955524_0062 failed with state FAILED due to: Task failed task_1426848955524_0062_m_000000\nJob failed as tasks failed. failedMaps:1 failedReduces:0\n\n15/03/26 12:15:17 INFO mapreduce.Job: Counters: 9\n        Job Counters\n                Failed map tasks=4\n                Launched map tasks=4\n                Other local map tasks=3\n                Rack-local map tasks=1\n                Total time spent by all maps in occupied slots (ms)=23087\n                Total time spent by all reduces in occupied slots (ms)=0\n                Total time spent by all map tasks (ms)=23087\n                Total vcore-seconds taken by all map tasks=23087\n                Total megabyte-seconds taken by all map tasks=23641088\nException in thread \"main\" java.lang.InterruptedException: Cluster Iteration 1 failed processing output/clusters-1\n        at org.apache.mahout.clustering.iterator.ClusterIterator.iterateMR(ClusterIterator.java:183)\n        at org.apache.mahout.clustering.kmeans.KMeansDriver.buildClusters(KMeansDriver.java:224)\n        at org.apache.mahout.clustering.kmeans.KMeansDriver.run(KMeansDriver.java:147)\n        at org.apache.mahout.clustering.syntheticcontrol.kmeans.Job.run(Job.java:135)\n        at org.apache.mahout.clustering.syntheticcontrol.kmeans.Job.main(Job.java:60)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:71)\n        at org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)\n        at org.apache.hadoop.util.ProgramDriver.driver(ProgramDriver.java:152)\n        at org.apache.mahout.driver.MahoutDriver.main(MahoutDriver.java:195)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at org.apache.hadoop.util.RunJar.run(RunJar.java:221)\n        at org.apache.hadoop.util.RunJar.main(RunJar.java:136)\n```\n\nThank a lot if anybody can help.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/10410504/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "review_comments": []}, "sslavic": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/apache/mahout/comments/10684431", "body": "Patch release 0.10.1 is possible, only as bug fix for 0.10.0. If/when needed, we can create necessary branch for the bug fix, from 0.10.0 tag.\nNext minor release will be 0.11.0 because many of the planned tickets are either major new features (Flink support) or breaking backward compatibility, e.g. artifact name changes like MAHOUT-1680 and MAHOUT-1681 or dependency changes in MAHOUT-1685.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/10684431/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/apache/mahout/comments/10708902", "body": "directory names of submodules do not match artifactId, e.g. they do not have mahout prefix\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/10708902/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/apache/mahout/comments/10905269", "body": "Wasn't it agreed that branch 0.10.x is meant for next bugfix release and master for future major changes?\n\nVersion in POM files was not changed.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/10905269/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}], "review_comments": []}}, "3": {"rawkintrevo": {"issues": [], "commits": [{"url": "https://api.github.com/repos/apache/mahout/commits/7dff35bc3c61c3e0b95e8e59406742be15203a69", "message": "WEBSITE-NOJIRA Direct download on homepage button"}, {"url": "https://api.github.com/repos/apache/mahout/commits/84f389140c3781ace210ad9fc977f0d464666644", "message": "WEBSITE-NOJIRA Add mahout-version"}, {"url": "https://api.github.com/repos/apache/mahout/commits/71ce4bf599f7abe8508724d124fa4554153055c6", "message": "WEBSITE-NOJIRA Added Clustering to Navbar"}, {"url": "https://api.github.com/repos/apache/mahout/commits/5c51c60180b05f5ea70ef7b86daf62c7e250ef08", "message": "WEBSITE-NOJIRA Added mahout-version variable"}, {"url": "https://api.github.com/repos/apache/mahout/commits/36da4cf3d4982e246191a3ec7eac2495a25f8a86", "message": "WEBSITE-NOJIRA Added Fn for news"}, {"url": "https://api.github.com/repos/apache/mahout/commits/d53d444374c874a89abd87042a4bdd6a57915258", "message": "WEBSITE-NOJIRA Fix Mahout Overview Link"}, {"url": "https://api.github.com/repos/apache/mahout/commits/4c1d12e39801ca7e2fa1170190d77e150ff11d66", "message": "WEBSITE-NOJIRA Fix Download link, etc."}, {"url": "https://api.github.com/repos/apache/mahout/commits/b9895898d799ae913ad2b37e10b4ae75467b5e37", "message": "EMPTY commit to kick re-establish asf-pages mirror"}, {"url": "https://api.github.com/repos/apache/mahout/commits/6141be782e271748c9839de1e2b837eabb25033c", "message": "WEBSITE-NOJIRA Fix API Docs Link"}, {"url": "https://api.github.com/repos/apache/mahout/commits/1c528a194ebad97f24934685e7bfd9872ebe3019", "message": "WEBSITE-NOJIRA Various website fixes"}, {"url": "https://api.github.com/repos/apache/mahout/commits/ca8b4935c4014397ee4ffc7cd7964dce0979cdf6", "message": "doap_Mahout.rdf"}, {"url": "https://api.github.com/repos/apache/mahout/commits/5a07b51b4f85ea54ee234bd8e2bc320f49f8968c", "message": "WEBSITE removed themes- no longer used- updated how-to-update-website.md"}, {"url": "https://api.github.com/repos/apache/mahout/commits/fc36bef157dc47d9572c4cfd460067e1916910a0", "message": "MAHOUT-1981 Update build_site.sh to not commit entire website"}, {"url": "https://api.github.com/repos/apache/mahout/commits/03918713563bf6aac55299d7239c4e042795faf0", "message": "MAHOUT-1981 Missing Gemfile Added"}, {"url": "https://api.github.com/repos/apache/mahout/commits/9beddd3108ae453091a21a881c6693016f5f2012", "message": "MAHOUT-1981 Merged site updates, fixed navbars, Mathjax"}, {"url": "https://api.github.com/repos/apache/mahout/commits/4f2108c576daaa3198671568eaa619266e787b1a", "message": "[WEBSITE] Small change to make sure publishing"}, {"url": "https://api.github.com/repos/apache/mahout/commits/8a7bd9156880f3f12509c64cda62ac389cbb4f7d", "message": "[WEBSITE] Updating Front Site Config"}, {"url": "https://api.github.com/repos/apache/mahout/commits/9fe4aadc731ffecf3996992b51b8044c880b0e94", "message": "[WEBSITE] Download Javadocs if not present"}, {"url": "https://api.github.com/repos/apache/mahout/commits/1e6584d78e8dc83c04fd1c29a8b01d7e63b6005d", "message": "[WEBSITE] Issues with build_site.sh"}, {"url": "https://api.github.com/repos/apache/mahout/commits/697eae12c513f15e97a18b8a4e143fdc53064b7f", "message": "[WEBSITE] Deleted frontsite"}, {"url": "https://api.github.com/repos/apache/mahout/commits/2483037dc65fd69a508759f241e62709ea780af3", "message": "testing for infra"}, {"url": "https://api.github.com/repos/apache/mahout/commits/52154565410a7ebb9f9cdfe13ad9f039c1f8abb7", "message": "sync asf-site to github with empty"}, {"url": "https://api.github.com/repos/apache/mahout/commits/c80e00f894779b9c937eea280b3b7c39d07ed610", "message": "[WEBSITE] Jekyll build path command updates"}, {"url": "https://api.github.com/repos/apache/mahout/commits/2613883f2f6af05e69cdcc5945a456480747566e", "message": "[WEBSITE] Update how-to-update-website instructions"}, {"url": "https://api.github.com/repos/apache/mahout/commits/f0a246a341cdf66e1ff727a469ed268c00b7ebfe", "message": "[WEBSITE] Build_site.sh lost executable again"}], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/347", "title": "[WIP][NO-JIRA] Mahout Cylons Demo Donation", "body": "### Purpose of PR:\r\nThe so-called \"Cylons demo\" was well received at multiple talks in early Fall 2017, and there has been interest in continuing work on the project.  The Cylon demo showcases Mahout in the following ways:\r\n- A more robust use of the \"Eigenfaces Demo\" (on Apache Spark)\r\n- How Mahout \"precanned\" algos can be chopped up and used in Flink Streaming Applications\r\n- How Mahout facilitates the so-called \"Lambda style\" machine learning paradigm by training an offline\r\nmodel in Apache Spark and utilizing it in Apache Flink with Apache Solr as the \"model server\" as well as a so called \"Kappa\" style by continuously training and applying a Canopy Function.\r\n\r\nAs this was originally a demo- it is somewhat 'dirty' to say the least. Much work is to be done to fully integrate this as a nice clean demo- especially with respect to documentation.  \r\n\r\nNote that a working drone is NOT required to run this demo as one can tie into any RSTP video feed and there are many public ones available (as well as creating one with many webcams). \r\n\r\nOpening this as a WIP PR that others may contribute and help me get it ready for merging into the trunk. \r\n\r\n### Important ToDos\r\nPlease mark each with an \"x\"\r\n- [ ] A JIRA ticket exists (if not, please create this first)[https://issues.apache.org/jira/browse/ZEPPELIN/]\r\n- [ ] Title of PR is \"MAHOUT-XXXX Brief Description of Changes\" where XXXX is the JIRA number.\r\n- [ ] Created unit tests where appropriate\r\n- [ ] Added licenses correct on newly added files\r\n- [ ] Assigned JIRA to self\r\n- [ ] Added documentation in scala docs/java docs, and to website\r\n- [ ] Successfully built and ran all unit tests, verified that all tests pass locally.\r\n\r\nIf all of these things aren't complete, but you still feel it is\r\nappropriate to open a PR, please add [WIP] after MAHOUT-XXXX before the\r\ndescriptions- e.g. \"MAHOUT-XXXX [WIP] Description of Change\"\r\n\r\nDoes this change break earlier versions?\r\n\r\nIs this the beginning of a larger project for which a feature branch should be made?\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "andrewmusselman": {"issues": [], "commits": [{"url": "https://api.github.com/repos/apache/mahout/commits/b887ab3653590c854f2b118162114f1133b9534d", "message": "Merge branch 'master' into mahout-1981"}, {"url": "https://api.github.com/repos/apache/mahout/commits/9a2055e7b7bd1788b0b7523367772650ffdb6b53", "message": "NOJIRA: Shrinking the home page splash area vertically, moving ASF logo to the top."}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13259038", "body": "Would be nice to have a workflow where the changelog changes along with the bug though; I'd be okay dealing with conflicts on this file unless things get really crazy.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13259038/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}, "kunalcsc630": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/354", "title": "Fixed grammatical error", "body": "### Purpose of PR:\r\nPlease give a short description of what this PR is for.\r\n\r\n\r\n### Important ToDos\r\nPlease mark each with an \"x\"\r\n- [ ] A JIRA ticket exists (if not, please create this first)[https://issues.apache.org/jira/browse/ZEPPELIN/]\r\n- [ ] Title of PR is \"MAHOUT-XXXX Brief Description of Changes\" where XXXX is the JIRA number.\r\n- [ ] Created unit tests where appropriate\r\n- [ ] Added licenses correct on newly added files\r\n- [ ] Assigned JIRA to self\r\n- [ ] Added documentation in scala docs/java docs, and to website\r\n- [ ] Successfully built and ran all unit tests, verified that all tests pass locally.\r\n\r\nIf all of these things aren't complete, but you still feel it is\r\nappropriate to open a PR, please add [WIP] after MAHOUT-XXXX before the\r\ndescriptions- e.g. \"MAHOUT-XXXX [WIP] Description of Change\"\r\n\r\nDoes this change break earlier versions?\r\n\r\nIs this the beginning of a larger project for which a feature branch should be made?\r\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "davidtmiller": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/352", "title": "Mahout 1981 - Front End Design Update", "body": "### Purpose of PR:\r\nPlease give a short description of what this PR is for.\r\n\r\n\r\n### Important ToDos\r\nPlease mark each with an \"x\"\r\n- [ ] A JIRA ticket exists (if not, please create this first)[https://issues.apache.org/jira/browse/ZEPPELIN/]\r\n- [ ] Title of PR is \"MAHOUT-XXXX Brief Description of Changes\" where XXXX is the JIRA number.\r\n- [ ] Created unit tests where appropriate\r\n- [ ] Added licenses correct on newly added files\r\n- [ ] Assigned JIRA to self\r\n- [ ] Added documentation in scala docs/java docs, and to website\r\n- [ ] Successfully built and ran all unit tests, verified that all tests pass locally.\r\n\r\nIf all of these things aren't complete, but you still feel it is\r\nappropriate to open a PR, please add [WIP] after MAHOUT-XXXX before the\r\ndescriptions- e.g. \"MAHOUT-XXXX [WIP] Description of Change\"\r\n\r\nDoes this change break earlier versions?\r\n\r\nIs this the beginning of a larger project for which a feature branch should be made?\r\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "andrewpalumbo": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/349", "title": "[WIP]MAHOUT-2027: spark-ec2 launch scripts with ViennaCL/JCuda installation", "body": "### Purpose of PR:\r\nPlease give a short description of what this PR is for.\r\n\r\n\r\n### Important ToDos\r\nPlease mark each with an \"x\"\r\n- [ x] A JIRA ticket exists (if not, please create this first)[https://issues.apache.org/jira/browse/ZEPPELIN/]\r\n- [ x] Title of PR is \"MAHOUT-XXXX Brief Description of Changes\" where XXXX is the JIRA number.\r\n- [ ] Created unit tests where appropriate\r\n- [x ] Added licenses correct on newly added files\r\n- [x ] Assigned JIRA to self\r\n- [ ] Added documentation in scala docs/java docs, and to website\r\n- [ ] Successfully built and ran all unit tests, verified that all tests pass locally.\r\n\r\nIf all of these things aren't complete, but you still feel it is\r\nappropriate to open a PR, please add [WIP] after MAHOUT-XXXX before the\r\ndescriptions- e.g. \"MAHOUT-XXXX [WIP] Description of Change\"\r\n\r\nDoes this change break earlier versions?\r\nno - exampe\r\nIs this the beginning of a larger project for which a feature branch should be made?\r\nno", "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/318", "title": "[WIP]MAHOUT-1974 (dense cuda multiplication)", "body": "### Purpose of PR:\r\nPlease give a short description of what this PR is for.\r\n\r\n\r\n### Important ToDos\r\nPlease mark each with an \"x\"\r\n- [x] A JIRA ticket exists (if not, please create this first)[https://issues.apache.org/jira/browse/MAHOUT/]\r\n- [x] Title of PR is \"MAHOUT-XXXX Brief Description of Changes\" where XXXX is the JIRA number.\r\n- [x] Created unit tests where appropriate\r\n- [ ] Added licenses correct on newly added files\r\n- [ ] Assigned JIRA to self\r\n- [ ] Added documentation in scala docs/java docs, and to website\r\n- [ ] Successfully built and ran all unit tests, verified that all tests pass locally.\r\n\r\nIf all of these things aren't complete, but you still feel it is\r\nappropriate to open a PR, please add [WIP] after MAHOUT-XXXX before the\r\ndescriptions- e.g. \"MAHOUT-XXXX [WIP] Description of Change\"\r\n\r\nDoes this change break earlier versions?\r\n\r\nIs this the beginning of a larger project for which a feature branch should be made?\r\n", "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/129", "title": "MAHOUT-1706: remove dependency jars from /lib in the binary distribution", "body": "The mahout distribution currently is shipping ~56 MB of dependecy jars in the /lib directory of the distribution.   These are only added to the classpath by /bin/mahout in the binary distribution. It seems that we can remove them from the distribution. (we need to get the size of the distribution down)\n\nAny input is appreciated. \n", "author_association": "MEMBER"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "BruceKuiLiu": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/346", "title": "Consider returning a zero length array rather than null.", "body": "It is often a better design to return a length zero array rather than a null reference to indicate that there are no results (i.e., an empty list of results).\r\nThis way, no explicit check for null is needed by clients of the method.\r\nOn the other hand, using null to indicate \"there is no answer to this question\" is probably appropriate.\r\nhttp://findbugs.sourceforge.net/bugDescriptions.html#PZLA_PREFER_ZERO_LENGTH_ARRAYS\r\n\r\n\r\n", "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/345", "title": "Remove the redundant null check statements of a non-null value.", "body": "This IfStatement is a redundant check of a known non-null otherObj because the null check of otherObj is contained in the previous instanceof check.\r\nhttp://findbugs.sourceforge.net/bugDescriptions.html#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE\r\n\r\n", "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/344", "title": "Add an IfStatement to check the return value of resultFile.delete().", "body": "This statement returns a value that is not checked.\r\nThe return value should be checked since it can indicate an unusual or unexpected function execution.\r\nThe statement returns false if the file could not be successfully deleted (rather than throwing an Exception).\r\nIf the result was not checked, developers would not notice if the statement signals an unexpected behavior by returning an atypical return value.\r\nhttp://findbugs.sourceforge.net/bugDescriptions.html#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE\r\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "holdenk": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/340", "title": "MAHOUT-2015 [WIP]: Expose Mahout's OLS algorithm in the Spark ML API", "body": "### Purpose of PR:\r\nExpose Mahout's OLS algorithm in the Spark ML API\r\n\r\n### Important ToDos\r\nPlease mark each with an \"x\"\r\n- [ X] A JIRA ticket exists (if not, please create this first)[https://issues.apache.org/jira/browse/ZEPPELIN/]\r\n- [ X ] Title of PR is \"MAHOUT-XXXX Brief Description of Changes\" where XXXX is the JIRA number.\r\n- [ X ] Created unit tests where appropriate\r\n- [ X ] Added licenses correct on newly added files\r\n- [ X ] Assigned JIRA to self\r\n- [ ] Added documentation in scala docs/java docs, and to website\r\n- [ ] Successfully built and ran all unit tests, verified that all tests pass locally.\r\n\r\nIf all of these things aren't complete, but you still feel it is\r\nappropriate to open a PR, please add [WIP] after MAHOUT-XXXX before the\r\ndescriptions- e.g. \"MAHOUT-XXXX [WIP] Description of Change\"\r\n\r\nDoes this change break earlier versions?\r\n\r\nNo\r\n\r\nIs this the beginning of a larger project for which a feature branch should be made?\r\n\r\nNo", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "dustinvanstee": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/335", "title": "MAHOUT-2000 [WIP] Add maven profile for Spark 2.2", "body": "### Purpose of PR: Add spark 2.2 into travisCI framework and add a maven spark 2.2 profile.\r\n\r\n\r\n### Important ToDos\r\nPlease mark each with an \"x\"\r\n- [x] A JIRA ticket exists (if not, please create this first)[https://issues.apache.org/jira/browse/ZEPPELIN/]\r\n- [ x] Title of PR is \"MAHOUT-XXXX Brief Description of Changes\" where XXXX is the JIRA number.\r\n- [ ] Created unit tests where appropriate\r\n- [ ] Added licenses correct on newly added files\r\n- [x ] Assigned JIRA to self\r\n- [ ] Added documentation in scala docs/java docs, and to website\r\n- [ ] Successfully built and ran all unit tests, verified that all tests pass locally.\r\n\r\nIf all of these things aren't complete, but you still feel it is\r\nappropriate to open a PR, please add [WIP] after MAHOUT-XXXX before the\r\ndescriptions- e.g. \"MAHOUT-XXXX [WIP] Description of Change\"\r\n\r\nDoes this change break earlier versions?\r\n\r\nIs this the beginning of a larger project for which a feature branch should be made?\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "AdityaAS": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/334", "title": "[WIP] MAHOUT-1991 - Add DBSCAN", "body": "DBSCAN - Google Summer of Code '17 - Apache Software Foundation (Apache Mahout)\r\n\r\nGoals: Implement DBSCAN algorithm\r\n\r\nWork done:\r\n- Coded Sequential and Distributed versions of DBSCAN\r\n- Added docs and unit tests\r\nWork left to do:\r\n- Improve distributed DBSCAN to make it more accurate\r\n- Include cluster quality index calculation\r\n\r\nAdded the sequential version of the algorithm. Docs and Unit Tests where appropriate.\r\nWill be adding rtree module and the approximate distributed algorithm soon.\r\n\r\nLink to a short report describing the whole project can be found [here](https://docs.google.com/document/d/11sLJkwAftR2-Fmglju8c7dGTf1i3trkbEV2Zr9OlilU/edit?usp=sharing).\r\n\r\n@rawkintrevo do help me out.\r\n\r\n### Important ToDos\r\nPlease mark each with an \"x\"\r\n- [x] A JIRA ticket exists (if not, please create this first)[https://issues.apache.org/jira/browse/ZEPPELIN/]\r\n- [x] Title of PR is \"MAHOUT-XXXX Brief Description of Changes\" where XXXX is the JIRA number.\r\n- [x] Created unit tests where appropriate\r\n- [x] Added licenses correct on newly added files\r\n- [x] Assigned JIRA to self\r\n- [x] Added documentation in scala docs/java docs, and to website\r\n- [x] Successfully built and ran all unit tests, verified that all tests pass locally.\r\n\r\nIf all of these things aren't complete, but you still feel it is\r\nappropriate to open a PR, please add [WIP] after MAHOUT-XXXX before the\r\ndescriptions- e.g. \"MAHOUT-XXXX [WIP] Description of Change\"\r\n\r\nDoes this change break earlier versions?\r\n\r\nIs this the beginning of a larger project for which a feature branch should be made?\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "nsakharnykh": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/310", "title": "MAHOUT-1974 CUDA support", "body": "Initial PR for CUDA bindings support through JCuda", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "skanjila": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/279", "title": "Mahout 1904", "body": "Added a helper function to pass fail the method, first cut of this as an iteration to be reviewed.", "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/245", "title": "Mahout 1869", "body": "Added the ability to dump output to csv file\n", "author_association": "NONE"}], "issue_comments": [{"url": "https://api.github.com/repos/apache/mahout/issues/comments/45238065", "body": "Ok I'll be doing a more substantial commit that might help us see how the APIs around a DataFrame\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45238065/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "BertrandDechoux": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/265", "title": "Add optional manual configuration of AtA's number of partitions.", "body": "```scala\r\n// Determine how many partitions the new matrix would need approximately. We base that on\r\n// geometry only, but it may eventually not be that adequate. Indeed, A'A tends to be much more\r\n// dense in reality than the source.\r\n```\r\nAllow override when estimation is not adequate because AtA is indeed more dense...", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "MaineC": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/240", "title": "Add one year mahout blog post draft.", "body": "The outline as offered by @smarthi with a bit of boiler plate. Needs some more love and content in the individual sections.\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "manognavemulapati": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/181", "title": "An alternative scaling method for Baum Welch for HMM.", "body": "This implements an alternative scaling method (called rescaling) for Baum Welch algorithm for unsupervised HMM training. The new scaling method partially addresses Mahout-627. The existing scaling method  based on log scaling is not numerically stable when tried with the Mapreduce version of Baum Welch proposed for Mahout-627. With the rescaling method, I am able to successfully run the Mapreduce version of Baum Welch on long training sequences. Further details and references are given in the following writeup.\nImplementation of an Alternative Scaling for Baum-Welch Algorithm for Hidden Markov Model (HMM) in Apache Mahout -- http://manognavemulapati.github.io/mahout/HMMScaling.pdf.\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "michellemay": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/174", "title": "MAHOUT-1786: Make classes implements Serializable for Spark 1.5+", "body": "Add some \"implements Serializable\" for Apache Spark 1.5+\nThere might be other classes that would benefit from the same modification.\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "sugaE": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/131", "title": "Fix bug: Add commit after executeUpdate", "body": "It will not write database without commit().\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ghost": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/70", "title": "Non-negative Matrix Factorization and Probabilistic Matrix Factorization", "body": "Non-negative Matrix Factorization, using classical multiplicative update rule.\nProbabilistic Matrix Factorization, using stochastic gradient descent\n\nUse Movielens dataset  to test, get reasonable result. \n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "mihaipitu": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/35", "title": "Sparse Linear Methods (SLIM) Recommender with two optimization techniques", "body": "The SLIM algorithm generates efficient recommendations and its performance is shown in the original paper (http://glaros.dtc.umn.edu/gkhome/fetch/papers/SLIM2011icdm.pdf). The study demonstrates that SLIM outperforms traditional algorithms (such as itemkNN, userkNN, SVD or other Matrix Factorization approaches) on various data-sets in terms of time efficiency and recommendation quality.\r\nSLIM's optimization problem can be solved using Least Square optimization (designed for explicit feedback datasets) and Bayesian Personalized Ranking (designed for implicit feedback datasets).", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "dlyubimov": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/apache/mahout/issues/comments/44071171", "body": "ok i think this is more or less it for now, untill we do more API tweaking to fit \"multiple sink\" model of Stratosphere. But at least all currently working api is fully abstracted and moved out to math-scala module with 0 Spark (or Hadoop) dependencies. Please feel free to dig in and point out how i am being stupid :) \n\n:8ball: \n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44071171/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44353426", "body": "Please include jira #.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44353426/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44496355", "body": "looks benign to me.\n\nNeed review from folks that were working on Hadoop 2 integration, to make sure this is in line with the rest of the effort. MAHOUT-1565\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44496355/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44713857", "body": "A slight nuisance here is that A' cannot be checkpointed. This is because the keys of A, in the most general case, are not `Int`s.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44713857/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44714458", "body": "perhaps a better test is needed that introduces some random jitter into the input.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44714458/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45017407", "body": "Want to commit it now. 90% is bug fixes and refactoring. Added zip-optimization for identically distributed elementwise operators, etc.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45017407/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45156215", "body": "FunctionalView matrix introduced general concept of dense/sparse matrix. surprisingly, abstract matrix has none. So MatrixWritable just tries to look at a row view to figure this out. Perhaps the isDense functionality should be added to AbstractMatrix in the first place?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45156215/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45167847", "body": "do we need help committing this? Are we committing this?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45167847/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45236939", "body": "Ok, this is still is too little substance for review, and did not seem to generate much new ideas either. Plus i am probably will not be spending much time on it any time soon.\n\nWithdrawing request for the time being \n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45236939/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45237262", "body": "I Like Pat's github avatar :+1: \n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45237262/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45239528", "body": "i don't even know that cartoon, just thought is was funny. Yeah, thinking of it, it is how i used to feel most of the time looking at my colleagues' code at work \n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45239528/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45252464", "body": "this is work in progress. We get it :)\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45252464/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45401402", "body": "also added (pretty naive) auto parallelism adjustments\n\n```\n(A+B) auto_||\n```\n\nwhich looks at spark.default.parallelism (P), assumes better parallelism is acheved if partitions are bumped up to round-ups of 0.95 \\* P or 1.80 \\* (P) whichever is closer. if current partition set is already greater (in cardinality) than rounded-up 1.80 \\* (P), all is left as is.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45401402/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45553612", "body": "i will commit it soon then\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45553612/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45557670", "body": "Pat, so, we are not going to use this for merging into merging, i take it? I will close it, you can keep working on your other requests.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45557670/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13257657", "body": "I think it'd be better to add this when (after) you will be doing a squash pull. Otherwise you'd be merging this file with other changes. This file is guaranteed to change by other commits every time. Although most likely this conflict will be handled automatically by git. \n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13257657/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13518008", "body": "I don't think we need to bring any dfs utils into scala. First, why is it not covered by Hadoop \"glob\"s or tons of hdfs helpers that Sean had created? Second, i think it needs to be shared by all platforms hence it probably needs to go where this common stuff resides in java. \n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13518008/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13518011", "body": "i guess license is coming.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13518011/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13688078", "body": "is that where the major problem was? is that because assignment of sequential vector to sequential vector is that slow? or this is an assignment of random vector to a sequential vector? (sequential to sequential actually should be ok methinks). \n\nAnyway I don't see any immediate problems, and the quality of your work usually doesn't require any deep scrutiny, so i'd say ship it. Actually the sooner the better, because i am very close to actually give it all a good spanking\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13688078/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13687695", "body": "we don't use vector.set and vector.get in scala. we use dsl which would look simply  \n\n```\nacc(elem.index) += 1\n```\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13687695/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13687718", "body": "No need to re align. IDEA scala plugin does a good job donig style indentation. Are you using IDEA?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13687718/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13687795", "body": "There are few doubts there. \n(1) DSL follows R. Which R function this mimics? If none, can we get away with doing it on java side? ( i guess we can't get around it if you want to do it for DRMs). \n(2) the name IMO is misleading given description. nonZeroCounts()?\n(3) The implementation (both in-core and distributed, BTW) seem to contradict the description. It looks like implementation actually counts number of _non-negative_ elements rather than what description portrays.\n(4) I would like Sebastian's feedback on this too, since he is both the primary co-occurrence author and understands R-like semantics idea very deeply.  If there's a better semantics (like I suspect it should be), he should know that.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13687795/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13688228", "body": "a line too long? (style?)\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13688228/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13711381", "body": "it looks like, to me. don't have time to look in depth. but distributed code definitely counts non-negatives with explicit inline conditional >0\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13711381/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13711414", "body": "it is very easy to tweak tests though to check if in doubt\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13711414/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13770844", "body": "Since this returns double, correct style is to say 1.0 or 0.0 not 1 or 0 on java side regardless of implicit conversion\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13770844/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13770924", "body": "style: spacing?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13770924/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}, "jfarrell": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/apache/mahout/issues/comments/44318648", "body": "MAHOUT-1529 not linking to jira as discussed in INFRA-7801\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44318648/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "nishkamravi2": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/apache/mahout/issues/comments/44354961", "body": "JIRA: MAHOUT-1565 (https://issues.apache.org/jira/browse/MAHOUT-1565)\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44354961/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44501707", "body": "Removed MAHOUT_OPTS from bin/mahout and bin/mahout.cmd\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44501707/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "sscdotopen": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/apache/mahout/issues/comments/44743038", "body": "looks good to me, +1 for including this\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44743038/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45234269", "body": "Its not allowed to redistribute the movielens dataset.\n\nOn 06/05/2014 05:28 PM, Pat Ferrel wrote:\n\n> I could use a little advice here. The epinions and movielens tests in the examples folder. Should they be put into the build?\n> \n> Pros: good example data.\n> Cons: the reading and writing are not parallel and so only work locally. It is easy to change the Spark context to use a cluster but the data still has to be local. These tests would be easier to maintain if they were attached to the ItemSimilarityDriver, which will handle cluster storage and execution and will be maintained better.\n> \n> I'd rather move them out into an ItemSimilarityDriver examples folder and will do this if no one objects. They will not be build tests, obviously, since they take too long.\n> \n> ---\n> \n> Reply to this email directly or view it on GitHub:\n> https://github.com/apache/mahout/pull/8#issuecomment-45234064\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45234269/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13169806", "body": "I don't think we should assign memory to map & reduce tasks ourselves.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13169806/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13425122", "body": "we can remove the .parallel. import\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13425122/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13425161", "body": "no @author tags allowed in ASF code\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13425161/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13425174", "body": "remove @author again\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13425174/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13713951", "body": "drmA is already binary here, so we could use colSums\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13713951/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13713968", "body": "drmB is already binary here, so we could use colSums\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13713968/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13714024", "body": "you can trust getNumNonZeroElements.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13714024/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}]}, "pferrel": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/apache/mahout/issues/comments/45234064", "body": "I could use a little advice here. The epinions and movielens tests in the examples folder. Should they be put into the build?\n\nPros: good example data.\nCons: the reading and writing are not HDFS, they use java i/o and so only work locally. It is easy to change the Spark context to use a cluster but the data still has to be local. These tests would be easier to maintain if they were attached to the ItemSimilarityDriver, which will handle cluster storage and execution and will be maintained better.\n\nI'd rather move them out into an ItemSimilarityDriver examples folder and will do this if no one objects. They will not be build tests, obviously, since they take too long.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45234064/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45234551", "body": "yes, but downloading is described in the comments\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45234551/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45235053", "body": "I guess I'm suggesting that examples like these might be good in the right place. Not as build tests but as usage examples. As long as they use only supported code (read/write for instance)\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45235053/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45238498", "body": "You a Ren and Stimpy fan or is it just the way you feel sometimes?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45238498/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45241940", "body": "Hah, that's me looking at my own code\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45241940/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45252176", "body": "Please do not commit this to the master!\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45252176/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45413683", "body": "In general the problem is the one stated in the top description. If I need to create a new DrmLike+RDD please advise.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45413683/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45421615", "body": "I think I found the answer. \n\n```\n  val drmInteractions = drmWrap[Int](indexedInteractions, numRows, numColumns)\n```\n\nThis creates a CheckpointedDrm, with an rdd and DrmLike[Int] trait interface. Seems to work even!\n\nLikely due to my Scala ignorance I couldn't find a scaladoc for the helpers in the package object. I did find a reference to drmWrap in the PDF but couldn't find a scaladoc. Are scaladocs just a wip or did I miss it somewhere? \n\nFor anyone reading this, look at the helper functions in the package.scala files peppered throughout. Some are Spark specific and some just Scala helpers, be sure to lookup the use of Scala package objects. \n\nAnyway, block is removed, more to do before merging.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45421615/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45560733", "body": "According to the instructions I merge from my branch anyway. I can close it right? The instruction for closing without merging?\n\nI assume you got my mail about finding the blocker now there are some questions about the cooccurrence algo itself.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45560733/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13520938", "body": "It will walk a dir tree finding file by pattern match, not implemented yet and AFAIK not implemented in HDFS which will look in a single dir for pattern matched file names. I'll look to see if Sean did something like this already.\n\nI'm not satisfied with the packaging yet so I agree. If you know of something that does this be happy to take it out.\n\nYes, I will double check that everything has the license statement.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13520938/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13520946", "body": "This recursive search is very common in log file organization and a goal of this is to allow direct reading of log files in production environments.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13520946/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13706588", "body": "Yeah, figured that was ugly and should be > 0 but since iterating nonZero it does work. I'll change this.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13706588/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13706737", "body": "yes, I don't see what they did here. it looks correct in the editor. I get this occasionally and haven't figured it out. Often with diffs that you are merging. I end up merging white space that looks identical.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13706737/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13706797", "body": "OK, well thanks for reviewing!\n\nI avoided the numNonZero from Java because it is an upper limit and didn't want to confuse this with that. This is the actual count. But nonZeroCounts is fine if you prefer. It does seem more descriptive.\n\nComment on non-negative below\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13706797/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13708030", "body": "err actually nonZeroCounts doesn't work because we need to indicate column. Java verbose style might be numNonZeroColElements. I await a better suggestion. This is a vector like colSums and the Java getNumNonZeroElements is an Int and isn't reliable?\n\nThe distributed check will never catch a 0 since we iterate nonZero but it is wrong and I'll fix. The inCore? I assume you mean the MatrixOps version. I'll comment there.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13708030/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13708276", "body": "Are you saying this doesn't count non-zero elements?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13708276/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13709105", "body": "Sorry, I never pay much attention to that. What's the limit?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13709105/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13714291", "body": "colCounts or whatever we call it is just as efficient, is distributed and tells the reader what is the important value. \n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13714291/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13714354", "body": "got it, I'll remove the comment since we do rely on it in the code\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13714354/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}}, "4": {"rawkintrevo": {"issues": [], "commits": [{"url": "https://api.github.com/repos/apache/mahout/commits/7dff35bc3c61c3e0b95e8e59406742be15203a69", "message": "WEBSITE-NOJIRA Direct download on homepage button"}, {"url": "https://api.github.com/repos/apache/mahout/commits/84f389140c3781ace210ad9fc977f0d464666644", "message": "WEBSITE-NOJIRA Add mahout-version"}, {"url": "https://api.github.com/repos/apache/mahout/commits/71ce4bf599f7abe8508724d124fa4554153055c6", "message": "WEBSITE-NOJIRA Added Clustering to Navbar"}, {"url": "https://api.github.com/repos/apache/mahout/commits/5c51c60180b05f5ea70ef7b86daf62c7e250ef08", "message": "WEBSITE-NOJIRA Added mahout-version variable"}, {"url": "https://api.github.com/repos/apache/mahout/commits/36da4cf3d4982e246191a3ec7eac2495a25f8a86", "message": "WEBSITE-NOJIRA Added Fn for news"}, {"url": "https://api.github.com/repos/apache/mahout/commits/d53d444374c874a89abd87042a4bdd6a57915258", "message": "WEBSITE-NOJIRA Fix Mahout Overview Link"}, {"url": "https://api.github.com/repos/apache/mahout/commits/4c1d12e39801ca7e2fa1170190d77e150ff11d66", "message": "WEBSITE-NOJIRA Fix Download link, etc."}, {"url": "https://api.github.com/repos/apache/mahout/commits/b9895898d799ae913ad2b37e10b4ae75467b5e37", "message": "EMPTY commit to kick re-establish asf-pages mirror"}, {"url": "https://api.github.com/repos/apache/mahout/commits/6141be782e271748c9839de1e2b837eabb25033c", "message": "WEBSITE-NOJIRA Fix API Docs Link"}, {"url": "https://api.github.com/repos/apache/mahout/commits/1c528a194ebad97f24934685e7bfd9872ebe3019", "message": "WEBSITE-NOJIRA Various website fixes"}, {"url": "https://api.github.com/repos/apache/mahout/commits/ca8b4935c4014397ee4ffc7cd7964dce0979cdf6", "message": "doap_Mahout.rdf"}, {"url": "https://api.github.com/repos/apache/mahout/commits/5a07b51b4f85ea54ee234bd8e2bc320f49f8968c", "message": "WEBSITE removed themes- no longer used- updated how-to-update-website.md"}, {"url": "https://api.github.com/repos/apache/mahout/commits/fc36bef157dc47d9572c4cfd460067e1916910a0", "message": "MAHOUT-1981 Update build_site.sh to not commit entire website"}, {"url": "https://api.github.com/repos/apache/mahout/commits/03918713563bf6aac55299d7239c4e042795faf0", "message": "MAHOUT-1981 Missing Gemfile Added"}, {"url": "https://api.github.com/repos/apache/mahout/commits/9beddd3108ae453091a21a881c6693016f5f2012", "message": "MAHOUT-1981 Merged site updates, fixed navbars, Mathjax"}, {"url": "https://api.github.com/repos/apache/mahout/commits/4f2108c576daaa3198671568eaa619266e787b1a", "message": "[WEBSITE] Small change to make sure publishing"}, {"url": "https://api.github.com/repos/apache/mahout/commits/8a7bd9156880f3f12509c64cda62ac389cbb4f7d", "message": "[WEBSITE] Updating Front Site Config"}, {"url": "https://api.github.com/repos/apache/mahout/commits/9fe4aadc731ffecf3996992b51b8044c880b0e94", "message": "[WEBSITE] Download Javadocs if not present"}, {"url": "https://api.github.com/repos/apache/mahout/commits/1e6584d78e8dc83c04fd1c29a8b01d7e63b6005d", "message": "[WEBSITE] Issues with build_site.sh"}, {"url": "https://api.github.com/repos/apache/mahout/commits/697eae12c513f15e97a18b8a4e143fdc53064b7f", "message": "[WEBSITE] Deleted frontsite"}, {"url": "https://api.github.com/repos/apache/mahout/commits/2483037dc65fd69a508759f241e62709ea780af3", "message": "testing for infra"}, {"url": "https://api.github.com/repos/apache/mahout/commits/52154565410a7ebb9f9cdfe13ad9f039c1f8abb7", "message": "sync asf-site to github with empty"}, {"url": "https://api.github.com/repos/apache/mahout/commits/c80e00f894779b9c937eea280b3b7c39d07ed610", "message": "[WEBSITE] Jekyll build path command updates"}, {"url": "https://api.github.com/repos/apache/mahout/commits/2613883f2f6af05e69cdcc5945a456480747566e", "message": "[WEBSITE] Update how-to-update-website instructions"}, {"url": "https://api.github.com/repos/apache/mahout/commits/f0a246a341cdf66e1ff727a469ed268c00b7ebfe", "message": "[WEBSITE] Build_site.sh lost executable again"}], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/347", "title": "[WIP][NO-JIRA] Mahout Cylons Demo Donation", "body": "### Purpose of PR:\r\nThe so-called \"Cylons demo\" was well received at multiple talks in early Fall 2017, and there has been interest in continuing work on the project.  The Cylon demo showcases Mahout in the following ways:\r\n- A more robust use of the \"Eigenfaces Demo\" (on Apache Spark)\r\n- How Mahout \"precanned\" algos can be chopped up and used in Flink Streaming Applications\r\n- How Mahout facilitates the so-called \"Lambda style\" machine learning paradigm by training an offline\r\nmodel in Apache Spark and utilizing it in Apache Flink with Apache Solr as the \"model server\" as well as a so called \"Kappa\" style by continuously training and applying a Canopy Function.\r\n\r\nAs this was originally a demo- it is somewhat 'dirty' to say the least. Much work is to be done to fully integrate this as a nice clean demo- especially with respect to documentation.  \r\n\r\nNote that a working drone is NOT required to run this demo as one can tie into any RSTP video feed and there are many public ones available (as well as creating one with many webcams). \r\n\r\nOpening this as a WIP PR that others may contribute and help me get it ready for merging into the trunk. \r\n\r\n### Important ToDos\r\nPlease mark each with an \"x\"\r\n- [ ] A JIRA ticket exists (if not, please create this first)[https://issues.apache.org/jira/browse/ZEPPELIN/]\r\n- [ ] Title of PR is \"MAHOUT-XXXX Brief Description of Changes\" where XXXX is the JIRA number.\r\n- [ ] Created unit tests where appropriate\r\n- [ ] Added licenses correct on newly added files\r\n- [ ] Assigned JIRA to self\r\n- [ ] Added documentation in scala docs/java docs, and to website\r\n- [ ] Successfully built and ran all unit tests, verified that all tests pass locally.\r\n\r\nIf all of these things aren't complete, but you still feel it is\r\nappropriate to open a PR, please add [WIP] after MAHOUT-XXXX before the\r\ndescriptions- e.g. \"MAHOUT-XXXX [WIP] Description of Change\"\r\n\r\nDoes this change break earlier versions?\r\n\r\nIs this the beginning of a larger project for which a feature branch should be made?\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "andrewmusselman": {"issues": [], "commits": [{"url": "https://api.github.com/repos/apache/mahout/commits/b887ab3653590c854f2b118162114f1133b9534d", "message": "Merge branch 'master' into mahout-1981"}, {"url": "https://api.github.com/repos/apache/mahout/commits/9a2055e7b7bd1788b0b7523367772650ffdb6b53", "message": "NOJIRA: Shrinking the home page splash area vertically, moving ASF logo to the top."}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13259038", "body": "Would be nice to have a workflow where the changelog changes along with the bug though; I'd be okay dealing with conflicts on this file unless things get really crazy.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13259038/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}, "kunalcsc630": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/354", "title": "Fixed grammatical error", "body": "### Purpose of PR:\r\nPlease give a short description of what this PR is for.\r\n\r\n\r\n### Important ToDos\r\nPlease mark each with an \"x\"\r\n- [ ] A JIRA ticket exists (if not, please create this first)[https://issues.apache.org/jira/browse/ZEPPELIN/]\r\n- [ ] Title of PR is \"MAHOUT-XXXX Brief Description of Changes\" where XXXX is the JIRA number.\r\n- [ ] Created unit tests where appropriate\r\n- [ ] Added licenses correct on newly added files\r\n- [ ] Assigned JIRA to self\r\n- [ ] Added documentation in scala docs/java docs, and to website\r\n- [ ] Successfully built and ran all unit tests, verified that all tests pass locally.\r\n\r\nIf all of these things aren't complete, but you still feel it is\r\nappropriate to open a PR, please add [WIP] after MAHOUT-XXXX before the\r\ndescriptions- e.g. \"MAHOUT-XXXX [WIP] Description of Change\"\r\n\r\nDoes this change break earlier versions?\r\n\r\nIs this the beginning of a larger project for which a feature branch should be made?\r\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "davidtmiller": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/352", "title": "Mahout 1981 - Front End Design Update", "body": "### Purpose of PR:\r\nPlease give a short description of what this PR is for.\r\n\r\n\r\n### Important ToDos\r\nPlease mark each with an \"x\"\r\n- [ ] A JIRA ticket exists (if not, please create this first)[https://issues.apache.org/jira/browse/ZEPPELIN/]\r\n- [ ] Title of PR is \"MAHOUT-XXXX Brief Description of Changes\" where XXXX is the JIRA number.\r\n- [ ] Created unit tests where appropriate\r\n- [ ] Added licenses correct on newly added files\r\n- [ ] Assigned JIRA to self\r\n- [ ] Added documentation in scala docs/java docs, and to website\r\n- [ ] Successfully built and ran all unit tests, verified that all tests pass locally.\r\n\r\nIf all of these things aren't complete, but you still feel it is\r\nappropriate to open a PR, please add [WIP] after MAHOUT-XXXX before the\r\ndescriptions- e.g. \"MAHOUT-XXXX [WIP] Description of Change\"\r\n\r\nDoes this change break earlier versions?\r\n\r\nIs this the beginning of a larger project for which a feature branch should be made?\r\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "andrewpalumbo": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/349", "title": "[WIP]MAHOUT-2027: spark-ec2 launch scripts with ViennaCL/JCuda installation", "body": "### Purpose of PR:\r\nPlease give a short description of what this PR is for.\r\n\r\n\r\n### Important ToDos\r\nPlease mark each with an \"x\"\r\n- [ x] A JIRA ticket exists (if not, please create this first)[https://issues.apache.org/jira/browse/ZEPPELIN/]\r\n- [ x] Title of PR is \"MAHOUT-XXXX Brief Description of Changes\" where XXXX is the JIRA number.\r\n- [ ] Created unit tests where appropriate\r\n- [x ] Added licenses correct on newly added files\r\n- [x ] Assigned JIRA to self\r\n- [ ] Added documentation in scala docs/java docs, and to website\r\n- [ ] Successfully built and ran all unit tests, verified that all tests pass locally.\r\n\r\nIf all of these things aren't complete, but you still feel it is\r\nappropriate to open a PR, please add [WIP] after MAHOUT-XXXX before the\r\ndescriptions- e.g. \"MAHOUT-XXXX [WIP] Description of Change\"\r\n\r\nDoes this change break earlier versions?\r\nno - exampe\r\nIs this the beginning of a larger project for which a feature branch should be made?\r\nno", "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/318", "title": "[WIP]MAHOUT-1974 (dense cuda multiplication)", "body": "### Purpose of PR:\r\nPlease give a short description of what this PR is for.\r\n\r\n\r\n### Important ToDos\r\nPlease mark each with an \"x\"\r\n- [x] A JIRA ticket exists (if not, please create this first)[https://issues.apache.org/jira/browse/MAHOUT/]\r\n- [x] Title of PR is \"MAHOUT-XXXX Brief Description of Changes\" where XXXX is the JIRA number.\r\n- [x] Created unit tests where appropriate\r\n- [ ] Added licenses correct on newly added files\r\n- [ ] Assigned JIRA to self\r\n- [ ] Added documentation in scala docs/java docs, and to website\r\n- [ ] Successfully built and ran all unit tests, verified that all tests pass locally.\r\n\r\nIf all of these things aren't complete, but you still feel it is\r\nappropriate to open a PR, please add [WIP] after MAHOUT-XXXX before the\r\ndescriptions- e.g. \"MAHOUT-XXXX [WIP] Description of Change\"\r\n\r\nDoes this change break earlier versions?\r\n\r\nIs this the beginning of a larger project for which a feature branch should be made?\r\n", "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/129", "title": "MAHOUT-1706: remove dependency jars from /lib in the binary distribution", "body": "The mahout distribution currently is shipping ~56 MB of dependecy jars in the /lib directory of the distribution.   These are only added to the classpath by /bin/mahout in the binary distribution. It seems that we can remove them from the distribution. (we need to get the size of the distribution down)\n\nAny input is appreciated. \n", "author_association": "MEMBER"}], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/apache/mahout/comments/10927850", "body": "I can't remember at the moment if it was only the spark-shell module that needed them or if others did as well. \u00a0I believe it had something to do with the spark-1.2 upgrade, part of which made it into master. \u00a0\n\nPutting them in the shell pom may work. \u00a0\n\nSent from my Verizon Wireless 4G LTE smartphone\n\n<div>-------- Original message --------</div><div>From: Pat Ferrel notifications@github.com </div><div>Date:04/27/2015  5:36 PM  (GMT-05:00) </div><div>To: apache/mahout mahout@noreply.github.com </div><div>Cc: Andrew Palumbo ap.dev@outlook.com </div><div>Subject: Re: [mahout] added scala dependencies in math-scala to fix spark-shell (71165a5) </div><div>\n</div>Are these required for all scala modules? Can this be put in spark-shell pom instead?\n\n\u2014\nReply to this email directly or view it on GitHub.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/10927850/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/apache/mahout/comments/16715391", "body": "LGTM\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/16715391/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/apache/mahout/comments/18009403", "body": "yep looks like.. I can fix it.  I was also thinking the name should be refactored to `densityAnalysis` so that `true` = `isDense`\\- seems more intuituive.  what do you think? Does sparsityAnalysis have any specific meaning outside of here?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/18009403/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/apache/mahout/comments/18009913", "body": "yes that would make sense.  I've done the Refactoring and the fix, and have a jira open to add densitAnalysis() in other places.  am just leaving for the day, so will push the open PR now and make note of this in the current jira or create a new one soon. \n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/18009913/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}], "review_comments": []}, "BruceKuiLiu": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/346", "title": "Consider returning a zero length array rather than null.", "body": "It is often a better design to return a length zero array rather than a null reference to indicate that there are no results (i.e., an empty list of results).\r\nThis way, no explicit check for null is needed by clients of the method.\r\nOn the other hand, using null to indicate \"there is no answer to this question\" is probably appropriate.\r\nhttp://findbugs.sourceforge.net/bugDescriptions.html#PZLA_PREFER_ZERO_LENGTH_ARRAYS\r\n\r\n\r\n", "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/345", "title": "Remove the redundant null check statements of a non-null value.", "body": "This IfStatement is a redundant check of a known non-null otherObj because the null check of otherObj is contained in the previous instanceof check.\r\nhttp://findbugs.sourceforge.net/bugDescriptions.html#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE\r\n\r\n", "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/344", "title": "Add an IfStatement to check the return value of resultFile.delete().", "body": "This statement returns a value that is not checked.\r\nThe return value should be checked since it can indicate an unusual or unexpected function execution.\r\nThe statement returns false if the file could not be successfully deleted (rather than throwing an Exception).\r\nIf the result was not checked, developers would not notice if the statement signals an unexpected behavior by returning an atypical return value.\r\nhttp://findbugs.sourceforge.net/bugDescriptions.html#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE\r\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "holdenk": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/340", "title": "MAHOUT-2015 [WIP]: Expose Mahout's OLS algorithm in the Spark ML API", "body": "### Purpose of PR:\r\nExpose Mahout's OLS algorithm in the Spark ML API\r\n\r\n### Important ToDos\r\nPlease mark each with an \"x\"\r\n- [ X] A JIRA ticket exists (if not, please create this first)[https://issues.apache.org/jira/browse/ZEPPELIN/]\r\n- [ X ] Title of PR is \"MAHOUT-XXXX Brief Description of Changes\" where XXXX is the JIRA number.\r\n- [ X ] Created unit tests where appropriate\r\n- [ X ] Added licenses correct on newly added files\r\n- [ X ] Assigned JIRA to self\r\n- [ ] Added documentation in scala docs/java docs, and to website\r\n- [ ] Successfully built and ran all unit tests, verified that all tests pass locally.\r\n\r\nIf all of these things aren't complete, but you still feel it is\r\nappropriate to open a PR, please add [WIP] after MAHOUT-XXXX before the\r\ndescriptions- e.g. \"MAHOUT-XXXX [WIP] Description of Change\"\r\n\r\nDoes this change break earlier versions?\r\n\r\nNo\r\n\r\nIs this the beginning of a larger project for which a feature branch should be made?\r\n\r\nNo", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "dustinvanstee": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/335", "title": "MAHOUT-2000 [WIP] Add maven profile for Spark 2.2", "body": "### Purpose of PR: Add spark 2.2 into travisCI framework and add a maven spark 2.2 profile.\r\n\r\n\r\n### Important ToDos\r\nPlease mark each with an \"x\"\r\n- [x] A JIRA ticket exists (if not, please create this first)[https://issues.apache.org/jira/browse/ZEPPELIN/]\r\n- [ x] Title of PR is \"MAHOUT-XXXX Brief Description of Changes\" where XXXX is the JIRA number.\r\n- [ ] Created unit tests where appropriate\r\n- [ ] Added licenses correct on newly added files\r\n- [x ] Assigned JIRA to self\r\n- [ ] Added documentation in scala docs/java docs, and to website\r\n- [ ] Successfully built and ran all unit tests, verified that all tests pass locally.\r\n\r\nIf all of these things aren't complete, but you still feel it is\r\nappropriate to open a PR, please add [WIP] after MAHOUT-XXXX before the\r\ndescriptions- e.g. \"MAHOUT-XXXX [WIP] Description of Change\"\r\n\r\nDoes this change break earlier versions?\r\n\r\nIs this the beginning of a larger project for which a feature branch should be made?\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "AdityaAS": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/334", "title": "[WIP] MAHOUT-1991 - Add DBSCAN", "body": "DBSCAN - Google Summer of Code '17 - Apache Software Foundation (Apache Mahout)\r\n\r\nGoals: Implement DBSCAN algorithm\r\n\r\nWork done:\r\n- Coded Sequential and Distributed versions of DBSCAN\r\n- Added docs and unit tests\r\nWork left to do:\r\n- Improve distributed DBSCAN to make it more accurate\r\n- Include cluster quality index calculation\r\n\r\nAdded the sequential version of the algorithm. Docs and Unit Tests where appropriate.\r\nWill be adding rtree module and the approximate distributed algorithm soon.\r\n\r\nLink to a short report describing the whole project can be found [here](https://docs.google.com/document/d/11sLJkwAftR2-Fmglju8c7dGTf1i3trkbEV2Zr9OlilU/edit?usp=sharing).\r\n\r\n@rawkintrevo do help me out.\r\n\r\n### Important ToDos\r\nPlease mark each with an \"x\"\r\n- [x] A JIRA ticket exists (if not, please create this first)[https://issues.apache.org/jira/browse/ZEPPELIN/]\r\n- [x] Title of PR is \"MAHOUT-XXXX Brief Description of Changes\" where XXXX is the JIRA number.\r\n- [x] Created unit tests where appropriate\r\n- [x] Added licenses correct on newly added files\r\n- [x] Assigned JIRA to self\r\n- [x] Added documentation in scala docs/java docs, and to website\r\n- [x] Successfully built and ran all unit tests, verified that all tests pass locally.\r\n\r\nIf all of these things aren't complete, but you still feel it is\r\nappropriate to open a PR, please add [WIP] after MAHOUT-XXXX before the\r\ndescriptions- e.g. \"MAHOUT-XXXX [WIP] Description of Change\"\r\n\r\nDoes this change break earlier versions?\r\n\r\nIs this the beginning of a larger project for which a feature branch should be made?\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "nsakharnykh": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/310", "title": "MAHOUT-1974 CUDA support", "body": "Initial PR for CUDA bindings support through JCuda", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "skanjila": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/279", "title": "Mahout 1904", "body": "Added a helper function to pass fail the method, first cut of this as an iteration to be reviewed.", "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/245", "title": "Mahout 1869", "body": "Added the ability to dump output to csv file\n", "author_association": "NONE"}], "issue_comments": [{"url": "https://api.github.com/repos/apache/mahout/issues/comments/45238065", "body": "Ok I'll be doing a more substantial commit that might help us see how the APIs around a DataFrame\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45238065/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "BertrandDechoux": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/265", "title": "Add optional manual configuration of AtA's number of partitions.", "body": "```scala\r\n// Determine how many partitions the new matrix would need approximately. We base that on\r\n// geometry only, but it may eventually not be that adequate. Indeed, A'A tends to be much more\r\n// dense in reality than the source.\r\n```\r\nAllow override when estimation is not adequate because AtA is indeed more dense...", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "MaineC": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/240", "title": "Add one year mahout blog post draft.", "body": "The outline as offered by @smarthi with a bit of boiler plate. Needs some more love and content in the individual sections.\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "manognavemulapati": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/181", "title": "An alternative scaling method for Baum Welch for HMM.", "body": "This implements an alternative scaling method (called rescaling) for Baum Welch algorithm for unsupervised HMM training. The new scaling method partially addresses Mahout-627. The existing scaling method  based on log scaling is not numerically stable when tried with the Mapreduce version of Baum Welch proposed for Mahout-627. With the rescaling method, I am able to successfully run the Mapreduce version of Baum Welch on long training sequences. Further details and references are given in the following writeup.\nImplementation of an Alternative Scaling for Baum-Welch Algorithm for Hidden Markov Model (HMM) in Apache Mahout -- http://manognavemulapati.github.io/mahout/HMMScaling.pdf.\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "michellemay": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/174", "title": "MAHOUT-1786: Make classes implements Serializable for Spark 1.5+", "body": "Add some \"implements Serializable\" for Apache Spark 1.5+\nThere might be other classes that would benefit from the same modification.\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "sugaE": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/131", "title": "Fix bug: Add commit after executeUpdate", "body": "It will not write database without commit().\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ghost": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/70", "title": "Non-negative Matrix Factorization and Probabilistic Matrix Factorization", "body": "Non-negative Matrix Factorization, using classical multiplicative update rule.\nProbabilistic Matrix Factorization, using stochastic gradient descent\n\nUse Movielens dataset  to test, get reasonable result. \n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "mihaipitu": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/apache/mahout/pulls/35", "title": "Sparse Linear Methods (SLIM) Recommender with two optimization techniques", "body": "The SLIM algorithm generates efficient recommendations and its performance is shown in the original paper (http://glaros.dtc.umn.edu/gkhome/fetch/papers/SLIM2011icdm.pdf). The study demonstrates that SLIM outperforms traditional algorithms (such as itemkNN, userkNN, SVD or other Matrix Factorization approaches) on various data-sets in terms of time efficiency and recommendation quality.\r\nSLIM's optimization problem can be solved using Least Square optimization (designed for explicit feedback datasets) and Bayesian Personalized Ranking (designed for implicit feedback datasets).", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "dlyubimov": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/apache/mahout/issues/comments/44071171", "body": "ok i think this is more or less it for now, untill we do more API tweaking to fit \"multiple sink\" model of Stratosphere. But at least all currently working api is fully abstracted and moved out to math-scala module with 0 Spark (or Hadoop) dependencies. Please feel free to dig in and point out how i am being stupid :) \n\n:8ball: \n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44071171/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44353426", "body": "Please include jira #.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44353426/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44496355", "body": "looks benign to me.\n\nNeed review from folks that were working on Hadoop 2 integration, to make sure this is in line with the rest of the effort. MAHOUT-1565\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44496355/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44713857", "body": "A slight nuisance here is that A' cannot be checkpointed. This is because the keys of A, in the most general case, are not `Int`s.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44713857/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44714458", "body": "perhaps a better test is needed that introduces some random jitter into the input.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44714458/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45017407", "body": "Want to commit it now. 90% is bug fixes and refactoring. Added zip-optimization for identically distributed elementwise operators, etc.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45017407/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45156215", "body": "FunctionalView matrix introduced general concept of dense/sparse matrix. surprisingly, abstract matrix has none. So MatrixWritable just tries to look at a row view to figure this out. Perhaps the isDense functionality should be added to AbstractMatrix in the first place?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45156215/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45167847", "body": "do we need help committing this? Are we committing this?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45167847/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45236939", "body": "Ok, this is still is too little substance for review, and did not seem to generate much new ideas either. Plus i am probably will not be spending much time on it any time soon.\n\nWithdrawing request for the time being \n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45236939/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45237262", "body": "I Like Pat's github avatar :+1: \n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45237262/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45239528", "body": "i don't even know that cartoon, just thought is was funny. Yeah, thinking of it, it is how i used to feel most of the time looking at my colleagues' code at work \n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45239528/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45252464", "body": "this is work in progress. We get it :)\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45252464/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45401402", "body": "also added (pretty naive) auto parallelism adjustments\n\n```\n(A+B) auto_||\n```\n\nwhich looks at spark.default.parallelism (P), assumes better parallelism is acheved if partitions are bumped up to round-ups of 0.95 \\* P or 1.80 \\* (P) whichever is closer. if current partition set is already greater (in cardinality) than rounded-up 1.80 \\* (P), all is left as is.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45401402/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45553612", "body": "i will commit it soon then\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45553612/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45557670", "body": "Pat, so, we are not going to use this for merging into merging, i take it? I will close it, you can keep working on your other requests.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45557670/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commit_comments": [{"url": "https://api.github.com/repos/apache/mahout/comments/6656953", "body": "I still dont get it. This implementation counts positive elements, not nonzeroes.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/6656953/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/6666688", "body": "Considerations of negative interactions of co-occurence analysis are irrelevant since you are implementing contract that has nothing to do with any particular algorithm you may be using it for.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/6666688/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/10723951", "body": "who-a?...\n\nOn Tue, Apr 14, 2015 at 1:55 AM, Stevo Slavi\u0107 notifications@github.com\nwrote:\n\n> directory names of submodules do not match artifactId, e.g. they do not\n> have mahout prefix\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/apache/mahout/commit/f7b69fabf1253b5e735e269c9410459d91816cdd#commitcomment-10708902\n> .\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/10723951/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/10724331", "body": "I am not in favor of renaming artifacts in general, and in this particular case as well. \n\nIn general, because renaming artifacts create incredible operational and legal headaches on the scale you can't even begin to imagine, in certain places :)\n\nin particular, because If \"samsara\" is to refer to computing environment, (let's say algebra environment in particular), then its code is not contained in any single module. instead, it's dispersed around.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/10724331/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/18009341", "body": "I think there's a bug in this line. If we return true for dense outcome of the analysis, the comparison should be reversed to `>`  in this line.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/18009341/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/18009547", "body": "uhm, yes, density makes more sense.\n\nOn Fri, Jun 24, 2016 at 1:45 PM, Andrew Palumbo notifications@github.com\nwrote:\n\n> yep looks like.. I can fix it. I was also thinking the name should be\n> refactored to densityAnalysis so that true = isDense- seems more\n> intuituive. what do you think? Does sparsityAnalysis have any specific\n> meaning outside of here?\n> \n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> https://github.com/apache/mahout/commit/d9940489d2f849d36af396d603f6170ab560e505#commitcomment-18009403,\n> or mute the thread\n> https://github.com/notifications/unsubscribe/AAf7_5MT7tIGk-w7SYJYCoXuNOvpQxiuks5qPEHggaJpZM4I-G2e\n> .\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/18009547/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/18009583", "body": "I also think it should be more thorough to use shallow initialization, especially in the case when input is already coming as dense and is using dense vectors. right now it looks like this would be copying it. \n\ne.g.:\n\n```\n    val block = new SparseRowMatrix(vectors.size, blockncol, vectors, true, true)\n\n    // Test the density of the data. If the matrix does not meet the\n    // requirements for density, convert the Vectors to a sparse Matrix.\n    val resBlock = if (sparsityAnalysis(block)) {\n      val shallow = vectors.forall(_.isInstanceOf[DenseVector])\n      if (shallow) {\n        // I don't like it but at this point this is the only way to avoid copying with DenseMatrix\n        // initialized by DenseVectors:\n        val vclass = classOf[DenseVector]\n        val valAttr = vclass.getField(\"values\")\n        // Use shallow initialization over backing array of Doubles.\n        new DenseMatrix(vectors.map(v \u21d2 valAttr.get(v).asInstanceOf[Array[Double]]),true)\n      } else {\n        dense(vectors)\n      }\n\n    } else {\n\n      // Sparse matrix: we already created it as a sparse matrix wrapper. There may be a path\n      // to improvement in case the payload comes in as dense vectors, but analysis says they\n      // are really sparse so shallow wrapper doesn't make much sense and we would need to\n      // copy the data into truly sparse vectors in order to truly save memory here. TODO\n      block\n    }\n```\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/18009583/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/18009657", "body": "although... reflection to extract values[] doesn't work. i think this need a patch on dense matrix that accepts array of vectors and `shallowIfPossible` flag that would do shallow init if incoming vectors are DenseVectors.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/18009657/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/18009705", "body": "i guess we really need to patch dense(vecs) implementation to implement shallow initialization where possible. Or have it as \n\n```\ndef dense[R](rows:R*)(shallowIfPossible:Boolean=true) \n```\n\n?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/18009705/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/18009875", "body": "no.. this form doesn't work either.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/18009875/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "review_comments": [{"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13257657", "body": "I think it'd be better to add this when (after) you will be doing a squash pull. Otherwise you'd be merging this file with other changes. This file is guaranteed to change by other commits every time. Although most likely this conflict will be handled automatically by git. \n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13257657/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13518008", "body": "I don't think we need to bring any dfs utils into scala. First, why is it not covered by Hadoop \"glob\"s or tons of hdfs helpers that Sean had created? Second, i think it needs to be shared by all platforms hence it probably needs to go where this common stuff resides in java. \n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13518008/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13518011", "body": "i guess license is coming.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13518011/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13688078", "body": "is that where the major problem was? is that because assignment of sequential vector to sequential vector is that slow? or this is an assignment of random vector to a sequential vector? (sequential to sequential actually should be ok methinks). \n\nAnyway I don't see any immediate problems, and the quality of your work usually doesn't require any deep scrutiny, so i'd say ship it. Actually the sooner the better, because i am very close to actually give it all a good spanking\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13688078/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13687695", "body": "we don't use vector.set and vector.get in scala. we use dsl which would look simply  \n\n```\nacc(elem.index) += 1\n```\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13687695/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13687718", "body": "No need to re align. IDEA scala plugin does a good job donig style indentation. Are you using IDEA?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13687718/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13687795", "body": "There are few doubts there. \n(1) DSL follows R. Which R function this mimics? If none, can we get away with doing it on java side? ( i guess we can't get around it if you want to do it for DRMs). \n(2) the name IMO is misleading given description. nonZeroCounts()?\n(3) The implementation (both in-core and distributed, BTW) seem to contradict the description. It looks like implementation actually counts number of _non-negative_ elements rather than what description portrays.\n(4) I would like Sebastian's feedback on this too, since he is both the primary co-occurrence author and understands R-like semantics idea very deeply.  If there's a better semantics (like I suspect it should be), he should know that.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13687795/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13688228", "body": "a line too long? (style?)\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13688228/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13711381", "body": "it looks like, to me. don't have time to look in depth. but distributed code definitely counts non-negatives with explicit inline conditional >0\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13711381/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13711414", "body": "it is very easy to tweak tests though to check if in doubt\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13711414/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13770844", "body": "Since this returns double, correct style is to say 1.0 or 0.0 not 1 or 0 on java side regardless of implicit conversion\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13770844/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13770924", "body": "style: spacing?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13770924/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}, "jfarrell": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/apache/mahout/issues/comments/44318648", "body": "MAHOUT-1529 not linking to jira as discussed in INFRA-7801\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44318648/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "nishkamravi2": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/apache/mahout/issues/comments/44354961", "body": "JIRA: MAHOUT-1565 (https://issues.apache.org/jira/browse/MAHOUT-1565)\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44354961/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44501707", "body": "Removed MAHOUT_OPTS from bin/mahout and bin/mahout.cmd\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44501707/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "sscdotopen": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/apache/mahout/issues/comments/44743038", "body": "looks good to me, +1 for including this\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/44743038/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45234269", "body": "Its not allowed to redistribute the movielens dataset.\n\nOn 06/05/2014 05:28 PM, Pat Ferrel wrote:\n\n> I could use a little advice here. The epinions and movielens tests in the examples folder. Should they be put into the build?\n> \n> Pros: good example data.\n> Cons: the reading and writing are not parallel and so only work locally. It is easy to change the Spark context to use a cluster but the data still has to be local. These tests would be easier to maintain if they were attached to the ItemSimilarityDriver, which will handle cluster storage and execution and will be maintained better.\n> \n> I'd rather move them out into an ItemSimilarityDriver examples folder and will do this if no one objects. They will not be build tests, obviously, since they take too long.\n> \n> ---\n> \n> Reply to this email directly or view it on GitHub:\n> https://github.com/apache/mahout/pull/8#issuecomment-45234064\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45234269/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13169806", "body": "I don't think we should assign memory to map & reduce tasks ourselves.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13169806/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13425122", "body": "we can remove the .parallel. import\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13425122/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13425161", "body": "no @author tags allowed in ASF code\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13425161/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13425174", "body": "remove @author again\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13425174/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13713951", "body": "drmA is already binary here, so we could use colSums\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13713951/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13713968", "body": "drmB is already binary here, so we could use colSums\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13713968/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13714024", "body": "you can trust getNumNonZeroElements.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13714024/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}]}, "pferrel": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/apache/mahout/issues/comments/45234064", "body": "I could use a little advice here. The epinions and movielens tests in the examples folder. Should they be put into the build?\n\nPros: good example data.\nCons: the reading and writing are not HDFS, they use java i/o and so only work locally. It is easy to change the Spark context to use a cluster but the data still has to be local. These tests would be easier to maintain if they were attached to the ItemSimilarityDriver, which will handle cluster storage and execution and will be maintained better.\n\nI'd rather move them out into an ItemSimilarityDriver examples folder and will do this if no one objects. They will not be build tests, obviously, since they take too long.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45234064/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45234551", "body": "yes, but downloading is described in the comments\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45234551/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45235053", "body": "I guess I'm suggesting that examples like these might be good in the right place. Not as build tests but as usage examples. As long as they use only supported code (read/write for instance)\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45235053/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45238498", "body": "You a Ren and Stimpy fan or is it just the way you feel sometimes?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45238498/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45241940", "body": "Hah, that's me looking at my own code\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45241940/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45252176", "body": "Please do not commit this to the master!\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45252176/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45413683", "body": "In general the problem is the one stated in the top description. If I need to create a new DrmLike+RDD please advise.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45413683/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45421615", "body": "I think I found the answer. \n\n```\n  val drmInteractions = drmWrap[Int](indexedInteractions, numRows, numColumns)\n```\n\nThis creates a CheckpointedDrm, with an rdd and DrmLike[Int] trait interface. Seems to work even!\n\nLikely due to my Scala ignorance I couldn't find a scaladoc for the helpers in the package object. I did find a reference to drmWrap in the PDF but couldn't find a scaladoc. Are scaladocs just a wip or did I miss it somewhere? \n\nFor anyone reading this, look at the helper functions in the package.scala files peppered throughout. Some are Spark specific and some just Scala helpers, be sure to lookup the use of Scala package objects. \n\nAnyway, block is removed, more to do before merging.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45421615/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45560733", "body": "According to the instructions I merge from my branch anyway. I can close it right? The instruction for closing without merging?\n\nI assume you got my mail about finding the blocker now there are some questions about the cooccurrence algo itself.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/issues/comments/45560733/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commit_comments": [{"url": "https://api.github.com/repos/apache/mahout/comments/6657027", "body": "Negative interactions?\n\nI guess It is possible input, I\u2019ll change that.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/6657027/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/6657099", "body": "BTW where are the tests for MatrixOps?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/6657099/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/6663830", "body": "nevemind, rather obvious.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/6663830/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/6664314", "body": "Oops, fixed. Added to the test cases.\n\nOn Jun 12, 2014, at 8:22 PM, Dmitriy Lyubimov notifications@github.com wrote:\n\nI still dont get it. This implementation counts positive elements, not nonzeroes.\n\n\u2014\nReply to this email directly or view it on GitHub.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/6664314/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/6666770", "body": "I agree and said that in several places.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/6666770/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/8585771", "body": "Building for hadoop 1.2.1 I get the following compile error:\n\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project mahout-integration: Compilation failure: Compilation failure:\n[ERROR] /Users/pat/mahout/integration/src/main/java/org/apache/mahout/utils/ConcatenateVectorsJob.java:[116,73] cannot find symbol\n[ERROR] symbol  : method file(org.apache.hadoop.fs.Path)\n[ERROR] location: class org.apache.hadoop.io.SequenceFile.Reader\n[ERROR] /Users/pat/mahout/integration/src/main/java/org/apache/mahout/utils/ConcatenateVectorsJob.java:[116,16] internal error; cannot instantiate org.apache.hadoop.io.SequenceFile.Reader.<init> at org.apache.hadoop.io.SequenceFile.Reader to ()\n\nIs this hadoop 2 dependant? \n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/8585771/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/8585996", "body": "Yeah, that's what I thought. I went back to Gokhan's commit and all it well.\n\nIs there some reason you can't use the old API for that line? Isn't the main point the precondition? \n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/8585996/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/10684389", "body": "huh? I thought the next version was 0.10.1?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/10684389/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/comments/10927175", "body": "Are these required for all scala modules? Can this be put in spark-shell pom instead?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/10927175/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "review_comments": [{"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13520938", "body": "It will walk a dir tree finding file by pattern match, not implemented yet and AFAIK not implemented in HDFS which will look in a single dir for pattern matched file names. I'll look to see if Sean did something like this already.\n\nI'm not satisfied with the packaging yet so I agree. If you know of something that does this be happy to take it out.\n\nYes, I will double check that everything has the license statement.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13520938/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13520946", "body": "This recursive search is very common in log file organization and a goal of this is to allow direct reading of log files in production environments.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13520946/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13706588", "body": "Yeah, figured that was ugly and should be > 0 but since iterating nonZero it does work. I'll change this.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13706588/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13706737", "body": "yes, I don't see what they did here. it looks correct in the editor. I get this occasionally and haven't figured it out. Often with diffs that you are merging. I end up merging white space that looks identical.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13706737/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13706797", "body": "OK, well thanks for reviewing!\n\nI avoided the numNonZero from Java because it is an upper limit and didn't want to confuse this with that. This is the actual count. But nonZeroCounts is fine if you prefer. It does seem more descriptive.\n\nComment on non-negative below\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13706797/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13708030", "body": "err actually nonZeroCounts doesn't work because we need to indicate column. Java verbose style might be numNonZeroColElements. I await a better suggestion. This is a vector like colSums and the Java getNumNonZeroElements is an Int and isn't reliable?\n\nThe distributed check will never catch a 0 since we iterate nonZero but it is wrong and I'll fix. The inCore? I assume you mean the MatrixOps version. I'll comment there.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13708030/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13708276", "body": "Are you saying this doesn't count non-zero elements?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13708276/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13709105", "body": "Sorry, I never pay much attention to that. What's the limit?\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13709105/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13714291", "body": "colCounts or whatever we call it is just as efficient, is distributed and tells the reader what is the important value. \n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13714291/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13714354", "body": "got it, I'll remove the comment since we do rely on it in the code\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/pulls/comments/13714354/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}, "smarthi": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/apache/mahout/comments/8585978", "body": "It's using hadoop 2 api and is not backward compatible hadoop 1.x. I can revert that back this weekend \n\nSent from my iPhone\n\n> On Nov 15, 2014, at 9:41 AM, Pat Ferrel notifications@github.com wrote:\n> \n> Building for hadoop 1.2.1 I get the following compile error:\n> \n> [ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project mahout-integration: Compilation failure: Compilation failure:\n> [ERROR] /Users/pat/mahout/integration/src/main/java/org/apache/mahout/utils/ConcatenateVectorsJob.java:[116,73] cannot find symbol\n> [ERROR] symbol : method file(org.apache.hadoop.fs.Path)\n> [ERROR] location: class org.apache.hadoop.io.SequenceFile.Reader\n> [ERROR] /Users/pat/mahout/integration/src/main/java/org/apache/mahout/utils/ConcatenateVectorsJob.java:[116,16] internal error; cannot instantiate org.apache.hadoop.io.SequenceFile.Reader. at org.apache.hadoop.io.SequenceFile.Reader to ()\n> \n> Is this hadoop 2 dependant?\n> \n> \u2014\n> Reply to this email directly or view it on GitHub.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/8585978/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/apache/mahout/comments/10708415", "body": "Change that to 'mahout-samsara'\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/10708415/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/apache/mahout/comments/10724487", "body": "@sslavic  Revert the change and lets mark this Jira as 'Won't Fix'.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/10724487/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}], "review_comments": []}, "hasonhai": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/apache/mahout/comments/10410504", "body": "Hi,\nThank you very much for the patch! I succeeded building mahout on my machine.\n\nBut I try some example and it didn't work. Can anybody help me checking these:\n- k-Means Clustering: # mahout org.apache.mahout.clustering.syntheticcontrol.kmeans.Job\n- Canopy Clustering : # mahout org.apache.mahout.clustering.syntheticcontrol.canopy.Job\n- Fuzzy k-Means Clustering: # mahout org.apache.mahout.clustering.syntheticcontrol.fuzzykmeans.Job\n\nThe console told that the path to \"cluster\" doesn't exist. Even though it was always there. I could not find any help from other sources.\n\n```\n15/03/26 12:15:07 INFO mapreduce.Job: Task Id : attempt_1426848955524_0062_m_000000_2, Status : FAILED\nError: java.lang.IllegalStateException: output/clusters-0\n        at org.apache.mahout.common.iterator.sequencefile.SequenceFileDirValueIterable.iterator(SequenceFileDirValueIterable.java:78)\n        at org.apache.mahout.clustering.classify.ClusterClassifier.readFromSeqFiles(ClusterClassifier.java:208)\n        at org.apache.mahout.clustering.iterator.CIMapper.setup(CIMapper.java:44)\n        at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:142)\n        at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:784)\n        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)\n       at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)\n       at java.security.AccessController.doPrivileged(Native Method)\n       at javax.security.auth.Subject.doAs(Subject.java:415)\n       at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n       at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)\nCaused by: java.io.FileNotFoundException: File output/clusters-0 does not exist\n        at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:376)\n        at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1485)\n        at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1525)\n        at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:570)\n        at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1485)\n        at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1525)\n        at org.apache.mahout.common.iterator.sequencefile.SequenceFileDirValueIterator.<init>(SequenceFileDirValueIterator.java:70)\n        at org.apache.mahout.common.iterator.sequencefile.SequenceFileDirValueIterable.iterator(SequenceFileDirValueIterable.java:76)\n        ... 10 more\n\n15/03/26 12:15:16 INFO mapreduce.Job:  map 100% reduce 0%\n15/03/26 12:15:17 INFO mapreduce.Job:  map 100% reduce 100%\n15/03/26 12:15:17 INFO mapreduce.Job: Job job_1426848955524_0062 failed with state FAILED due to: Task failed task_1426848955524_0062_m_000000\nJob failed as tasks failed. failedMaps:1 failedReduces:0\n\n15/03/26 12:15:17 INFO mapreduce.Job: Counters: 9\n        Job Counters\n                Failed map tasks=4\n                Launched map tasks=4\n                Other local map tasks=3\n                Rack-local map tasks=1\n                Total time spent by all maps in occupied slots (ms)=23087\n                Total time spent by all reduces in occupied slots (ms)=0\n                Total time spent by all map tasks (ms)=23087\n                Total vcore-seconds taken by all map tasks=23087\n                Total megabyte-seconds taken by all map tasks=23641088\nException in thread \"main\" java.lang.InterruptedException: Cluster Iteration 1 failed processing output/clusters-1\n        at org.apache.mahout.clustering.iterator.ClusterIterator.iterateMR(ClusterIterator.java:183)\n        at org.apache.mahout.clustering.kmeans.KMeansDriver.buildClusters(KMeansDriver.java:224)\n        at org.apache.mahout.clustering.kmeans.KMeansDriver.run(KMeansDriver.java:147)\n        at org.apache.mahout.clustering.syntheticcontrol.kmeans.Job.run(Job.java:135)\n        at org.apache.mahout.clustering.syntheticcontrol.kmeans.Job.main(Job.java:60)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:71)\n        at org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)\n        at org.apache.hadoop.util.ProgramDriver.driver(ProgramDriver.java:152)\n        at org.apache.mahout.driver.MahoutDriver.main(MahoutDriver.java:195)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at org.apache.hadoop.util.RunJar.run(RunJar.java:221)\n        at org.apache.hadoop.util.RunJar.main(RunJar.java:136)\n```\n\nThank a lot if anybody can help.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/10410504/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "review_comments": []}, "sslavic": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/apache/mahout/comments/10684431", "body": "Patch release 0.10.1 is possible, only as bug fix for 0.10.0. If/when needed, we can create necessary branch for the bug fix, from 0.10.0 tag.\nNext minor release will be 0.11.0 because many of the planned tickets are either major new features (Flink support) or breaking backward compatibility, e.g. artifact name changes like MAHOUT-1680 and MAHOUT-1681 or dependency changes in MAHOUT-1685.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/10684431/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/apache/mahout/comments/10708902", "body": "directory names of submodules do not match artifactId, e.g. they do not have mahout prefix\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/10708902/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/apache/mahout/comments/10905269", "body": "Wasn't it agreed that branch 0.10.x is meant for next bugfix release and master for future major changes?\n\nVersion in POM files was not changed.\n", "reactions": {"url": "https://api.github.com/repos/apache/mahout/comments/10905269/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}], "review_comments": []}}}}