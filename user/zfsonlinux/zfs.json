{"_default": {"1": {"danielkza": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7059", "title": "Scrub gets stuck, becomes unstoppable and locks up user processes in uninterruptible sleep", "body": "Type                    | Version/Name\r\n---                     | ---\r\nDistribution Name       | Fedora\r\nDistribution Version    | 27\r\nLinux Kernel            | 4.14.13\r\nArchitecture            | x86_64\r\nZFS Version             | 0.7.5\r\nSPL Version             | 0.7.5\r\n\r\n### Describe the problem you're observing\r\n\r\nAfter a routine scrub starting on the background, some programs seem stuck in uninterruptible IO due to ZFS. Attempting\r\nto pause or stop the scrub does not work - the `zpool` command hangs and also becomes unkillable.\r\n\r\nHere is the `/proc/PID/stack` of the stuck `zpool`:\r\n\r\n```\r\n[<ffffffffc11f1c23>] cv_wait_common+0x113/0x130 [spl]\r\n[<ffffffffc11f1c55>] __cv_wait+0x15/0x20 [spl]\r\n[<ffffffffc182972d>] txg_wait_synced+0xdd/0x120 [zfs]\r\n[<ffffffffc1801f36>] dsl_sync_task+0x176/0x260 [zfs]\r\n[<ffffffffc180041e>] dsl_scrub_set_pause_resume+0x3e/0x40 [zfs]\r\n[<ffffffffc181e511>] spa_scrub_pause_resume+0x31/0x60 [zfs]\r\n[<ffffffffc1858f85>] zfs_ioc_pool_scan+0xb5/0xc0 [zfs]\r\n[<ffffffffc18592d6>] zfsdev_ioctl+0x1d6/0x600 [zfs]\r\n[<ffffffff9429f575>] do_vfs_ioctl+0xa5/0x610\r\n[<ffffffff9429fb59>] SyS_ioctl+0x79/0x90\r\n[<ffffffff94a0008d>] entry_SYSCALL_64_fastpath+0x20/0x83\r\n```\r\n\r\nAnd of one of the stuck user processes:\r\n\r\n```\r\n[<ffffffff940d7746>] io_schedule+0x16/0x40\r\n[<ffffffffc11f1bb9>] cv_wait_common+0xa9/0x130 [spl]\r\n[<ffffffffc11f1c98>] __cv_wait_io+0x18/0x20 [spl]\r\n[<ffffffffc187f7f2>] zio_wait+0xf2/0x1b0 [zfs]\r\n[<ffffffffc17c38d3>] dbuf_read+0x6e3/0x910 [zfs]\r\n[<ffffffffc17c5c19>] __dbuf_hold_impl+0x549/0x600 [zfs]\r\n[<ffffffffc17c5d71>] dbuf_hold_impl+0xa1/0xd0 [zfs]\r\n[<ffffffffc17c5e33>] dbuf_hold+0x33/0x60 [zfs]\r\n[<ffffffffc17cf1cd>] dmu_buf_hold_noread+0x8d/0x100 [zfs]\r\n[<ffffffffc17cf26f>] dmu_buf_hold+0x2f/0x80 [zfs]\r\n[<ffffffffc1845a5e>] zap_lockdir+0x4e/0xb0 [zfs]\r\n[<ffffffffc1845c3a>] zap_cursor_retrieve+0x17a/0x2e0 [zfs]\r\n[<ffffffffc1869abc>] zfs_readdir+0x13c/0x460 [zfs]\r\n[<ffffffffc1886911>] zpl_iterate+0x51/0x80 [zfs]\r\n[<ffffffff9429fce0>] iterate_dir+0x170/0x1a0\r\n[<ffffffff942a046a>] SyS_getdents+0xaa/0x140\r\n[<ffffffff94a0008d>] entry_SYSCALL_64_fastpath+0x20/0x83\r\n[<ffffffffffffffff>] 0xffffffffffffffff\r\n```\r\n\r\nHere is the affected pool status:\r\n\r\n```\r\n  pool: daniel-pc-media\r\n state: ONLINE\r\n  scan: scrub in progress since Thu Jan 18 03:29:02 2018\r\n    102G scanned out of 2,45T at 2,60M/s, 263h46m to go\r\n    0B repaired, 4,06% done\r\nconfig:\r\n\r\n    NAME                                 STATE     READ WRITE CKSUM\r\n    daniel-pc-media                      ONLINE       0     0     0\r\n      mirror-0                           ONLINE       0     0     0\r\n        ata-ST4000DM000-1F2168_Z301QGEZ  ONLINE       0     0     0\r\n        ata-ST4000DM000-1F2168_Z301QGCM  ONLINE       0     0     0\r\n```\r\n\r\nThere seems to be no progress actually being made, as none of the counters advance (other than the expected ETA).\r\n\r\n### Describe how to reproduce the problem\r\n\r\nNot able to so far. I can provide more observations of the running system if it doesn't force me to restart by\r\nbecoming unstable/unusable.\r\n\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n\r\nNothing of interest or related to ZFS is present in the kernel logs.\r\nThe problem *might* have been triggered by suspending and resuming the computer, but I was not monitoring the scrub before that, so I can't be sure.\r\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7059/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "makhomed": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7057", "title": "tasks txg_sync and zfs blocked for more than 120 seconds", "body": "### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       |  CentOS Linux\r\nDistribution Version    | 7.4.1708\r\nLinux Kernel                 |  3.10.0-693.11.6.el7\r\nArchitecture                 | x86_64\r\nZFS Version                  | 0.7.5-1\r\nSPL Version                  | 0.7.5-1\r\n\r\nZFS installed from zfs-kmod repo, ```baseurl=http://download.zfsonlinux.org/epel/7.4/kmod/$basearch/```\r\n\r\n### Describe the problem you're observing\r\n\r\nMessages in /var/log/messages about blocked tasks.\r\n\r\n### Describe how to reproduce the problem\r\n\r\nSorry, but I do not found way how to reproduce this bug.\r\nMay be stack trace will help to find root cause of this bug?\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n```\r\n\r\nJan 17 17:26:45 kvm-hardware-node kernel: INFO: task txg_sync:10906 blocked for more than 120 seconds.\r\nJan 17 17:26:45 kvm-hardware-node kernel: \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\nJan 17 17:26:45 kvm-hardware-node kernel: txg_sync        D ffff883f6a256eb0     0 10906      2 0x00000000\r\nJan 17 17:26:45 kvm-hardware-node kernel: Call Trace:\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04ddf57>] ? taskq_dispatch_ent+0x57/0x170 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff816ab6d9>] schedule+0x29/0x70\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff816a90e9>] schedule_timeout+0x239/0x2c0\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc07ba30f>] ? zio_taskq_dispatch+0x8f/0xa0 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc07ba352>] ? zio_issue_async+0x12/0x20 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc07bebcc>] ? zio_nowait+0xbc/0x150 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff816aac5d>] io_schedule_timeout+0xad/0x130\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff810b31a6>] ? prepare_to_wait_exclusive+0x56/0x90\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff816aacf8>] io_schedule+0x18/0x20\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04e24a2>] cv_wait_common+0xb2/0x150 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff810b34b0>] ? wake_up_atomic_t+0x30/0x30\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04e2598>] __cv_wait_io+0x18/0x20 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc07be49b>] zio_wait+0x10b/0x1b0 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc07346cf>] dsl_pool_sync+0xbf/0x440 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc07527c7>] spa_sync+0x437/0xdf0 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff810c6452>] ? default_wake_function+0x12/0x20\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff810bf074>] ? __wake_up+0x44/0x50\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0766a91>] txg_sync_thread+0x301/0x510 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0766790>] ? txg_fini+0x2a0/0x2a0 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04dcfa1>] thread_generic_wrapper+0x71/0x80 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04dcf30>] ? __thread_exit+0x20/0x20 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff810b252f>] kthread+0xcf/0xe0\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff810b2460>] ? insert_kthread_work+0x40/0x40\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff816b8798>] ret_from_fork+0x58/0x90\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff810b2460>] ? insert_kthread_work+0x40/0x40\r\nJan 17 17:26:45 kvm-hardware-node kernel: INFO: task zfs:21118 blocked for more than 120 seconds.\r\nJan 17 17:26:45 kvm-hardware-node kernel: \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\nJan 17 17:26:45 kvm-hardware-node kernel: zfs             D ffff883f79a38000     0 21118   8250 0x00000080\r\nJan 17 17:26:45 kvm-hardware-node kernel: Call Trace:\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff816ab6d9>] schedule+0x29/0x70\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04e2515>] cv_wait_common+0x125/0x150 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff810b34b0>] ? wake_up_atomic_t+0x30/0x30\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04e2555>] __cv_wait+0x15/0x20 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0765a2f>] txg_wait_synced+0xef/0x140 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0727d50>] ? dsl_dataset_snapshot_check_impl+0x210/0x210 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc073d017>] dsl_sync_task+0x177/0x270 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc07289d0>] ? dsl_dataset_snapshot_sync_impl+0x760/0x760 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0727d50>] ? dsl_dataset_snapshot_check_impl+0x210/0x210 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc07289d0>] ? dsl_dataset_snapshot_sync_impl+0x760/0x760 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0728dc3>] dsl_dataset_snapshot+0x133/0x2e0 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0479157>] ? nvlist_remove_all+0x77/0xd0 [znvpair]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0479655>] ? nvlist_add_common.part.51+0x325/0x430 [znvpair]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff811df99c>] ? __kmalloc_node+0x5c/0x2b0\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04db31d>] ? spl_kmem_alloc_impl+0xcd/0x170 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04db31d>] ? spl_kmem_alloc_impl+0xcd/0x170 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04db31d>] ? spl_kmem_alloc_impl+0xcd/0x170 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0479fc2>] ? nvlist_lookup_common.part.71+0xa2/0xb0 [znvpair]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0796868>] zfs_ioc_snapshot+0x348/0x3b0 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0798606>] zfsdev_ioctl+0x1d6/0x650 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff8121710d>] do_vfs_ioctl+0x33d/0x540\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff816b3801>] ? __do_page_fault+0x171/0x450\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff812173b1>] SyS_ioctl+0xa1/0xc0\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff816b89fd>] system_call_fastpath+0x16/0x1b\r\n```", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7057/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "beren12": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7056", "title": "Improve snapshot listing error message", "body": "### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Debian\r\nDistribution Version    | 9\r\nLinux Kernel                 | 4.13.13-1~bpo9+1\r\nArchitecture                 | x64\r\nZFS Version                  | 0.7.4\r\nSPL Version                  | 0.7.4\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\nlisting snapshots for a single dataset fails unless -r is used, but this is not mentioned in the error message. -r is not needed to list all snapshots, so it can be a confusing behavior.\r\n\r\n### Describe how to reproduce the problem\r\n\r\n```\r\nzfs list -t snap rpool\r\n```\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n\r\n```\r\nzfs list -t snap rpool\r\ncannot open 'rpool': missing '@' delimiter in snapshot name\r\n```\r\n\r\nCould we amend the error message to also give a hint? Or possibly be consistent and list all snapshots without -r, just as giving no dataset does? Bookmarks might also need the same edit, ike here:\r\n\r\n```diff\r\n--- lib/libzfs/libzfs_dataset.c\t2018-01-17 10:07:12.178817043 -0500\r\n+++ lib/libzfs/libzfs_dataset.c.new\t2018-01-17 10:06:47.307290884 -0500\r\n@@ -175,7 +175,7 @@\r\n \tif (type == ZFS_TYPE_SNAPSHOT && strchr(path, '@') == NULL) {\r\n \t\tif (hdl != NULL)\r\n \t\t\tzfs_error_aux(hdl, dgettext(TEXT_DOMAIN,\r\n-\t\t\t    \"missing '@' delimiter in snapshot name\"));\r\n+\t\t\t    \"missing '@' delimiter in snapshot name, did you mean to use -r?\"));\r\n \t\treturn (0);\r\n \t}\r\n```", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7056/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "behlendorf": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7052", "title": "zfs load-key double free", "body": "### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | CentOS\r\nDistribution Version    | 7\r\nLinux Kernel                 | 3.10.0-693.11.6.1\r\nArchitecture                 | x86_64\r\nZFS Version                  | zfs-0.7.0-246-gd658b2c\r\nSPL Version                  | master\r\n\r\n### Describe the problem you're observing\r\n\r\nWhen zfs is built with `--enable-debug --enable-debuginfo` and an incorrect passphrase is provided to `zfs load-key` followed by an empty one a \"double free or leak\" is reported.  Observed during manual testing.\r\n\r\n### Describe how to reproduce the problem\r\n\r\nAt build time `--enable-debug --enable-debuginfo`, then,\r\n\r\n```sh\r\n$ truncate -s 512M /var/tmp/vdev\r\n$ zpool create tank /var/tmp/vdev\r\n$ zfs create -o encryption=on -o keyformat=passphrase tank/fs\r\nEnter passphrase: password\r\nRe-enter passphrase: password\r\n$ zfs unload-key -a\r\n```\r\n\r\nReload the key giving the wrong password first \"password1\" which is correctly rejected.  Then just hit enter when prompted again.\r\n\r\n```sh\r\n$ zfs load-key -a\r\nEnter passphrase for 'tank/fs': password1\r\nKey load error: Incorrect key provided for 'tank/fs'.\r\nEnter passphrase for 'tank/fs': <empty>\r\nKey load error: Passphrase too short (min 8).\r\n*** Error in `cmd/zfs/.libs/lt-zfs': double free or corruption (fasttop): 0x000000000061f150 ***\r\n======= Backtrace: =========\r\n/lib64/libc.so.6(+0x7c619)[0x2aaaacc65619]\r\nlib/libzfs/.libs/libzfs.so.2(zfs_crypto_load_key+0xf3)[0x2aaaab109023]\r\ncmd/zfs/.libs/lt-zfs[0x406557]\r\ncmd/zfs/.libs/lt-zfs[0x405d41]\r\ncmd/zfs/.libs/lt-zfs[0x408298]\r\ncmd/zfs/.libs/lt-zfs[0x4051ef]\r\n/lib64/libc.so.6(__libc_start_main+0xf5)[0x2aaaacc0ac05]\r\ncmd/zfs/.libs/lt-zfs[0x405318]\r\n...\r\n```", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7052/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7026", "title": "Test case history_004_pos", "body": "### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | all\r\nDistribution Version    | all\r\nLinux Kernel                 | all\r\nArchitecture                 | all\r\nZFS Version                  | zfs-0.7.0-230-gb02beca\r\nSPL Version                  | 0.7\r\n\r\n### Describe the problem you're observing\r\n\r\nRarely observed failure of history_004_pos during automated testing.\r\n\r\n### Describe how to reproduce the problem\r\n\r\nReproducible by the buildbot.\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n\r\n\r\nhttp://build.zfsonlinux.org/builders/Amazon%202%20x86_64%20Release%20%28TEST%29/builds/105/\r\n\r\n```\r\nTest: /usr/share/zfs/zfs-tests/tests/functional/history/history_004_pos (run as root) [00:04] [FAIL]\r\n02:51:58.52 ASSERTION: 'zpool history' can cope with simultaneous commands.\r\n02:52:01.35 umount: testpool/clone3: mountpoint not found\r\n02:52:01.35 cannot unmount 'testpool/clone3': umount failed\r\n02:52:01.55 cannot create 'testpool/clone3': dataset already exists\r\n02:52:01.62 cannot promote 'testpool/clone3': not a cloned filesystem\r\n02:52:01.66 cannot destroy 'testpool/testfs3': filesystem has children\r\n02:52:01.66 use '-r' to destroy the following datasets:\r\n02:52:01.66 testpool/testfs3@snap\r\n02:52:01.81 cannot create 'testpool/testfs3': dataset already exists\r\n02:52:01.92 cannot create snapshot 'testpool/testfs3@snap': dataset already exists\r\n02:52:02.69 The entries count error: entry_count=297  orig_count = 103\r\n02:52:02.69 NOTE: Performing test-fail callback (/usr/share/zfs/zfs-tests/callbacks/zfs_dbgmsg.ksh)\r\n```", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7026/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/3da3488e6339ff2dc5c7f3da8c8a0c552d018d68", "message": "Fix shellcheck v0.4.6 warnings\n\nResolve new warnings reported after upgrading to shellcheck\r\nversion 0.4.6.  This patch contains no functional changes.\r\n\r\n* egrep is non-standard and deprecated. Use grep -E instead. [SC2196]\r\n* Check exit code directly with e.g. 'if mycmd;', not indirectly\r\n  with $?.  [SC2181]  Suppressed.\r\n\r\nReviewed-by: George Melikov <mail@gmelikov.ru>\r\nReviewed-by: Giuseppe Di Natale <dinatale2@llnl.gov>\r\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nCloses #7040"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/e1a0850c3570ae53df5779bc656f17b98b86f160", "message": "Force ztest to always use /dev/urandom\n\nFor ztest, which is solely for testing, using a pseudo random\r\nis entirely reasonable.  Using /dev/urandom ensures the system\r\nentropy pool doesn't get depleted thus stalling the testing.\r\nThis is a particular problem when testing in VMs.\r\n\r\nReviewed-by: Tim Chase <tim@chase2k.com>\r\nReviewed by: Thomas Caputi <tcaputi@datto.com>\r\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nCloses #7017 \r\nCloses #7036"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/fed90353d799acbc5e81b0dfadc6d649b0f2e8b5", "message": "Support -fsanitize=address with --enable-asan\n\nWhen --enable-asan is provided to configure then build all user\r\nspace components with fsanitize=address.  For kernel support\r\nuse the Linux KASAN feature instead.\r\n\r\nhttps://github.com/google/sanitizers/wiki/AddressSanitizer\r\n\r\nWhen using gcc version 4.8 any test case which intentionally\r\ngenerates a core dump will fail when using --enable-asan.\r\nThe default behavior is to disable core dumps and only newer\r\nversions allow this behavior to be controled at run time with\r\nthe ASAN_OPTIONS environment variable.\r\n\r\nAdditionally, this patch includes some build system cleanup.\r\n\r\n* Rules.am updated to set the minimum AM_CFLAGS, AM_CPPFLAGS,\r\n  and AM_LDFLAGS.  Any additional flags should be added on a\r\n  per-Makefile basic.  The --enable-debug and --enable-asan\r\n  options apply to all user space binaries and libraries.\r\n\r\n* Compiler checks consolidated in always-compiler-options.m4\r\n  and renamed for consistency.\r\n\r\n* -fstack-check compiler flag was removed, this functionality\r\n  is provided by asan when configured with --enable-asan.\r\n\r\n* Split DEBUG_CFLAGS in to DEBUG_CFLAGS, DEBUG_CPPFLAGS, and\r\n  DEBUG_LDFLAGS.\r\n\r\n* Moved default kernel build flags in to module/Makefile.in and\r\n  split in to ZFS_MODULE_CFLAGS and ZFS_MODULE_CPPFLAGS.  These\r\n  flags are set with the standard ccflags-y kbuild mechanism.\r\n\r\n* -Wframe-larger-than checks applied only to binaries or\r\n  libraries which include source files which are built in\r\n  both user space and kernel space.  This restriction is\r\n  relaxed for user space only utilities.\r\n\r\n* -Wno-unused-but-set-variable applied only to libzfs and\r\n  libzpool.  The remaining warnings are the result of an\r\n  ASSERT using a variable when is always declared.\r\n\r\n* -D_POSIX_PTHREAD_SEMANTICS and -D__EXTENSIONS__ dropped\r\n  because they are Solaris specific and thus not needed.\r\n\r\n* Ensure $GDB is defined as gdb by default in zloop.sh.\r\n\r\nSigned-off-by: DHE <git@dehacked.net>\r\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nCloses #7027"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/7e7f5132779a04da0070cf6e6ffd8e9b5f7692de", "message": "Disable history_004_pos\n\nOccasionally observed failure of history_004_pos due to the test\r\ncase not being 100% reliable.  In order to prevent false positives\r\ndisable this test case until it can be made reliable.\r\n\r\nReviewed-by: George Melikov <mail@gmelikov.ru>\r\nReviewed-by: Giuseppe Di Natale <dinatale2@llnl.gov>\r\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nIssue #7026 \r\nCloses #7028"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/bfe27ace0de64838d50ff351396423a481de6c84", "message": "Fix unused variable warnings\n\nResolved unused variable warnings observed after restricting\n-Wno-unused-but-set-variable to only libzfs and libzpool.\n\nReviewed-by: DHE <git@dehacked.net>\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\nCloses #6941"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/06401e42221d2f5130065caf70f8276ba4d19acd", "message": "Fix ztest_verify_dnode_bt() test case\n\nIn ztest_verify_dnode_bt the ztest_object_lock must be held in\norder to safely verify the unused bonus space.\n\nReviewed-by: DHE <git@dehacked.net>\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\nCloses #6941"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/b02becaa00aef3d25b30588bf49affbf1e9a84a4", "message": "Reduce codecov PR comments\n\nAttempt to reduce the number of comments posted by codecov\r\nto PR requests.  Based on the codecov documenation setting\r\n\"require_changes=yes\" and \"behavior=once\" should result in\r\na single comment under most circumstances.\r\n\r\nhttps://docs.codecov.io/v4.3.6/docs/pull-request-comments\r\n\r\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nIssue #7022 \r\nCloses #7025"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/0873bb6337452e3e028e40f5dad945b30deab185", "message": "Fix ARC hit rate\n\nWhen the compressed ARC feature was added in commit d3c2ae1\r\nthe method of reference counting in the ARC was modified.  As\r\npart of this accounting change the arc_buf_add_ref() function\r\nwas removed entirely.\r\n\r\nThis would have be fine but the arc_buf_add_ref() function\r\nserved a second undocumented purpose of updating the ARC access\r\ninformation when taking a hold on a dbuf.  Without this logic\r\nin place a cached dbuf would not migrate its associated\r\narc_buf_hdr_t to the MFU list.  This would negatively impact\r\nthe ARC hit rate, particularly on systems with a small ARC.\r\n\r\nThis change reinstates the missing call to arc_access() from\r\ndbuf_hold() by implementing a new arc_buf_access() function.\r\n\r\nReviewed-by: Giuseppe Di Natale <dinatale2@llnl.gov>\r\nReviewed-by: Tony Hutter <hutter2@llnl.gov>\r\nReviewed-by: Tim Chase <tim@chase2k.com>\r\nReviewed by: George Wilson <george.wilson@delphix.com>\r\nReviewed-by: George Melikov <mail@gmelikov.ru>\r\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nCloses #6171 \r\nCloses #6852 \r\nCloses #6989"}], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6999", "title": "Extend deadman logic", "body": "### Description\r\n\r\nThe intent of this patch is extend the existing deadman code such that it's flexible enough to be used by both ztest and on production systems.  The proposed changes include:\r\n\r\n* Added a new `zfs_deadman_failmode` module option which is used to dynamically control the behavior of the deadman.  It's loosely modeled after, but independant from, the pool failmode property.  It can be set to wait, continue, or panic.\r\n\r\n    * wait     - Wait for the \"hung\" I/O (default)\r\n    * continue - Attempt to recover from a \"hung\" I/O\r\n    * panic    - Panic the system\r\n\r\n* Added a new `zfs_deadman_ziotime_ms` module option which is analogous to zfs_deadman_synctime_ms` except instead of applying to a pool TXG sync it applies to zio_wait().  A   default value of 300s is used to define a \"hung\" zio.\r\n\r\n* The ztest deadman thread has been re-enabled by default, aligned with the upstream OpenZFS code, and then extended to terminate the process when it takes significantly longer to complete than expected.\r\n\r\n* The -G option was added to ztest to print the internal debug log when a fatal error is encountered.  This same option was previously added to zdb in commit fa603f82.  Update zloop.sh to unconditionally pass -G to obtain additional debugging.\r\n\r\n* The FM_EREPORT_ZFS_DELAY event which was previously posted when the deadman detect a \"hung\" pool has been replaced by a new dedicated FM_EREPORT_ZFS_DEADMAN event.\r\n\r\n* The proposed recovery logic attempts to restart a \"hung\"  zio by calling zio_interrupt() on any outstanding leaf zios.  We may want to further restrict this to zios in either the  ZIO_STAGE_VDEV_IO_START or ZIO_STAGE_VDEV_IO_DONE stages.  Calling zio_interrupt() is expected to only be useful for cases when an IO has been submitted to the physical device\r\n  but for some reasonable the completion callback hasn't been called by the lower layers.  This shouldn't be possible but  has been observed and may be caused by kernel/driver bugs.\r\n\r\n* The 'zfs_deadman_synctime_ms' default value was reduced from 1000s to 600s.\r\n\r\n* Depending on how ztest fails there may be no cache file to move.  This should not be considered fatal, collect the logs which are available and carry on.\r\n\r\n### Motivation and Context\r\n\r\nAdd some of the needed infrastructure to make it possible to root cause `ztest` \"hangs\" observed during automated testing.  With this change applied at least basic debugging information will be collected for any \"hangs\".  This change can be further augmented with improvements to the debugging infrastructure.\r\n\r\nIssue #6901.\r\n\r\n### How Has This Been Tested?\r\n\r\nLocally by running `zloop.sh` in-tree for approximated 4 days.  Over this time period the deadman behaved as expected and properly terminated `ztest` when it appeared to be hung.  Further analysis of the debug logs and cores obtained is still needed.  The expectation is they will provide some statistical insight in the most often observed failures.\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [x] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [x] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "OWNER"}], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/147559", "body": "Thanks, I hadn't noticed the rendering issue.  Fixed by commit bbf3a3575c0b5795d3e4ddc27523258dc61ffa88.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/147559/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/195492", "body": "I'm not particularly happy with all this grubbing around in /dev/ either for 'zpool import', but for the moment I view it as a short term solution.  The longer term solution, which is well under way, is to be tightly integrated with libblkid.  There has been a patch submitted upstream and accepted by the maintainers to correctly identify a disk which belongs to a zfs pool.  Once a version of libblkid with this change filters back in to the distributions we can simply consult libblkid for the list of zfs devices and avoid checking /dev/.  In fact all the code on the zfs side is already in place for this.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/195492/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/282533", "body": "- Removed Makefile-sample, with the full integration in the build system it isn't needed.\n- Added all autogen.sh products (Makefile.in, configure) using the following versions of the utils.  Using the same versions of the tools minimizes how much change there is in the autogen products and makes it easier to review.\n  \n  autoconf (GNU Autoconf) 2.63\n  automake (GNU automake) 1.11.1\n  ltmain.sh (GNU libtool) 2.2.6b\n- Added the CDDL header to zvol_id_main.c, including correctly attributing the source.\n- Minor stray whitespace cleanup.\n- Update kmem_free() in zvol_remove_minors() to match  kmem_zalloc()'s use of MAXNAMELEN.  If we fail to do the the memory account code will flag this is a memory leak.  It's critical to ensure you alloc/free both use the same size for the buffer.\n- Add <sys/stat.h> header in zvol_id_main.c, without it my build was failing on RHEL6.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/282533/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/282739", "body": "Sorry!  I've force updated my branch to include the Makefile.in... in and the process obliterated the previous review comments.  We need to figure out how to handle this best, I'd really like to be landing one nice concise commit to fix an issue.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/282739/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/383680", "body": "The zvol will be created with unique /dev/zdN names and then the /dev/zvol/pool/dataset links are created with udev rules.  This is exactly how normal block devices work such as /dev/sda with /dev/disk/by-_/_ links created with udev.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/383680/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/384675", "body": "This behavior is forced by the Linux kernel.  The special device files created under /dev/\\* has certain limitations including a maximum name length and certain reserved characters.  To avoid these limitations the standard solution is to create simple unique names at the top level /dev/\\* and symlink them with udev.  That's why all persistent storage devices work this way.  As you say you should never use these top level devices because their names may change.  This is equally true for /dev/sda, /dev/hda, and /dev/zd1.  The above comment is the code was simply an example test case and does not show a real usage scenario.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/384675/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/409945", "body": "I'm pretty sure dbuf_hold_impl() is called in other contexts.  I've love to revert this too but it's going to take more convincing that this is safe...  but that's for pointing it out, I'd actually forgotten about this particular hack!\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/409945/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/512022", "body": "I didn't either at the time or I would have added it to the original patch.  I only noticed later when it annoyed me.  :)\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/512022/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}], "review_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11254", "body": "This file should be readded exactly for the reasons mentioned in the file.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11254/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11255", "body": "Yes, please remove them.  They are currently unused hooks and they cause compile errors on older platforms.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11255/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11259", "body": "A version of this file was already added to the dracut subdirectory.  If you want to make changes/rewrite it that's fine but let's just keep one copy of it around with the other dracut code.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11259/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}]}, "wphilips": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7050", "title": "zfs-dracut boot failure with out of date zpool.cache - zfs_force not working", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       |  Fedora \r\nDistribution Version    |  26 \r\nLinux Kernel                 |  any (e.g., 4.14.6-200.fc26.x86_64)\r\nArchitecture                 |  x86_64\r\nZFS Version                  |   v0.7.5-1\r\nSPL Version                  |  v0.7.5-1\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\nI have several systems with root and boot on zfs. The systems boot with grub initramfs \r\nis generated by dracut with zfs-dracut-0.7.5-1.fc26.x86_64\r\n\r\nThe problem occurs whenever significant changes are made to the zpools attached to the\r\nsystem, or even when adding empty disks.  Very often, dracut enters the emergency shell\r\nbecause it cannot import the pools based on the zpool.cache file. Even adding zfs_force \r\nas a kernel option does not work. E.g., I tried:\r\n\r\nlinux16 /boot/@/vmlinuz-4.14.13-200.fc26.x86_64 root=zfs:ssd/fc26 boot=ssd ro rd_NO_PLYMOUTH audit=0 zfs_force=1\r\n\r\n\r\nThe reason seems to be that the zpoool.cache file does not reflect the current (changed) configuration of the system. It is not clear why zfs.force  or zfs_force does not work.\r\n\r\n\r\nHere are 2 use cases:\r\n\r\n1. to defragment  the pool on which the zfs root is installed, I attach a new disk, create a new\r\nzpool on it, copy all the data, remove the old disk, reboot and change some grub parameters so\r\nthat it boots the new bool. Before the reboot, zpool.cache refers to the old pool on the old disk.\r\nRunning 'dracut -f ...' will therefore copy the \"old\" zpool.cache into initamfs. After boot, the disks\r\nhave changed and this zpool.cache is outdated. \r\n\r\n2. in a system with 3 rpools, I remove one of the disks which contains a non-essential \r\nrpool (after exporting it). I then add two new empty disks. The system boots into the dracut \r\nshell even though the root pool has not changed. The now missing, but non-essential pool\r\nprevents a normal boot.\r\n\r\n\r\nIt is possible to somewhat prevent these problems by removing zpool.cache, then running\r\ndracut and then rebooting. In this case, often dracut still enters the emergency shell claiming\r\nthat the pool(s) are in use in another system, but by force importing them in the dracut shell\r\nand rebooting it is possible to boot the system. Then it is possible to recreate zpool.cache, \r\nand rerun dracut to create a working system. Alternatively, one can continue to use the initramfs\r\nwith the missing zpool.cache.\r\n\r\nIt is probably also possible to create a zpool.cache file for the future new configuration, but it probably \r\ninvolves deleting the current one and it is easy to make a mistake.\r\n\r\nIn any case, make a simple mistake or  forget to take these  \"preventive\" measures \r\nand you end up with a system which will always enter the dracut emergency shell with \r\nno way to recover (except if you have e.g., a usb boot disk with zfs at hand. Even then\r\nit is really hard to recover).\r\n\r\nIn the good old days it also use to be  possible to fix problems in the dracut shell and then continue to boot. These days, systemd prevents this from working (probably related to the message \"transaction is destructive\")\r\n\r\nWhile fixing the zfs_force option would help, adding a configuration option to dracut to never \r\ncreate zfs.cache and/or adding a kernel command line option to ignore zpool.cache might \r\nalso help.\r\n \r\n\r\nPS. Even better would be to fix dracut or systemd so that a boot can continue after fixing problems \r\nin dracut. For instance, in the emergency shell you would remove the zpool.cache file and \r\nthen type some command to continue boot. However, that is probably a more general (non zfsonlinux)\r\nissue.\r\n\r\n\r\n\r\n\r\n\r\n\r\n### Describe how to reproduce the problem\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n<!-- \r\n*IMPORTANT* - Please mark logs and text output from terminal commands \r\nor else Github will not display them correctly. \r\nAn example is provided below.\r\n\r\nExample:\r\n```\r\nthis is an example how log text should be marked (wrap it with ```)\r\n```\r\n-->\r\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7050/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "Menion2k": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7046", "title": "aarch64 and arm64 mismatch", "body": "Hello\r\nIt seems that there is a problem handling the ARCH on arm64 targets\r\nFrom the BUILD detection I see that the ARCH is set to aarch64. The compilation is ok, but aarch64 is not a DEB or RPM architecture, because it is defined as \"arm64\"\r\nThe result is that the make deb fails with the error:\r\n\r\n> spl-0.7.5-1.aarch64.rpm is for architecture aarch64 ; the package cannot be built on this system\r\n\r\nI guess that somewhere in the Makefile the BUILD system architecture shall be converted to a valid package architecture\r\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7046/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "jhammond-intel": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7045", "title": "pool suspension due to delayed MMP writes needs a better error message", "body": "### System information\r\nDistribution Name       | *\r\nDistribution Version    | *\r\nLinux Kernel                 | * \r\nArchitecture                 | *\r\nZFS Version                  | 0.7.5\r\nSPL Version                  | 0.7.5\r\n\r\nThis is related to Lustre issue https://jira.hpdd.intel.com/browse/LU-9845.\r\n\r\nWhen an MMP thread suspends a pool because \"no MMP write has succeeded in over mmp_interval * mmp_fail_intervals nanoseconds\" the only message we see on the console is \"WARNING: Pool 'blahblah' has encountered an uncorrectable I/O failure and has been suspended.\" This is not really informative enough and probably a bit misleading. We encountered these mysteriously suspended pool in our test clusters and were only able to attribute this to MMP by setting the pool failure mode to panic.\r\n\r\nI was able to easily reproduce using the Lustre backed zfs setup (VM has hostid set and 2 vCPUs, pool has MMP enabled) using the following:\r\n```\r\nm:~# export FSTYPE=zfs\r\nm:~# bash $LUSTRE/tests/llmount.sh\r\n...\r\nm:~# cat /sys/module/zfs/parameters/zfs_multihost_interval \r\n1000\r\nm:~# echo 100 > /sys/module/zfs/parameters/zfs_multihost_interval # set mmp interval to 100ms\r\nm:~# chrt -f 20 dd if=/dev/zero of=/dev/null &\r\nm:~# chrt -f 20 dd if=/dev/zero of=/dev/null &\r\n```\r\n\r\nI think we should probably keep the message from `zio_suspend()` as is but add a suitable message to `mmp_thread()` before calling `zio_suspend()`.", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7045/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/51d1b58ef3467c3a9711c65458f93063dd17354f", "message": "Emit an error message before MMP suspends pool\n\nIn mmp_thread(), emit an MMP specific error message before calling\r\nzio_suspend() so that the administrator will understand why the pool\r\nis being suspended.\r\n\r\nReviewed-by: Olaf Faaland <faaland1@llnl.gov>\r\nReviewed-by: Giuseppe Di Natale <dinatale2@llnl.gov>\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: John L. Hammond <john.hammond@intel.com>\r\nCloses #7048"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "samuelbernardo": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7042", "title": "BUG: soft lockup - CPU# stuck for 22s! [z_wr_iss]", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Gentoo\r\nDistribution Version    | -\r\nLinux Kernel                 | 4.14.12\r\nArchitecture                 | x86_64\r\nZFS Version                  | 0.7.5\r\nSPL Version                  | 0.7.5\r\n\r\n\r\n### Describe the problem you're observing\r\n\r\nzfs thread lock after some intensive IO. It allows to continue to access data, but all writes won't be commited to disk, since reboot needs ctrl+shift+sysreq reisub. It remains locked after trying soft reboot, and the only solution is a forced reboot with sysreq.\r\nThe zfs lock is registered systematically after some intensive IO on each OS reboot.\r\n\r\n### Describe how to reproduce the problem\r\n\r\nThis is the configuration of zfs volume that has the deadlock (using deduplication and lz4 compression):\r\n\r\nNAME   SIZE  ALLOC   FREE  EXPANDSZ   FRAG    CAP  DEDUP  HEALTH  ALTROOT\r\nzfs  21.8T  5.69T  16.1T         -     6%    26%  1.07x  ONLINE  -\r\n  raidz1  10.9T  2.85T  8.03T         -     6%    26%\r\n    ata-TOSHIBA_DT01ACA300_Z5RS6H0KS      -      -      -         -      -      -\r\n    ata-TOSHIBA_HDWD130_678KR5JAS      -      -      -         -      -      -\r\n    ata-TOSHIBA_DT01ACA300_16QUEEEKS      -      -      -         -      -      -\r\n    ata-TOSHIBA_HDWD130_678KPYLAS      -      -      -         -      -      -\r\n  raidz1  10.9T  2.85T  8.03T         -     6%    26%\r\n    ata-TOSHIBA_HDWD130_678KTDUAS      -      -      -         -      -      -\r\n    ata-TOSHIBA_DT01ACA300_16QUDE3KS      -      -      -         -      -      -\r\n    ata-WDC_WD40EZRX-75SPEB0_WD-WCC4E2YAA98J-part6      -      -      -         -      -      -\r\n    ata-TOSHIBA_HDWD130_678KPP7AS      -      -      -         -      -      -\r\ncache      -      -      -         -      -      -\r\n  sdc   699G  79.7M   699G         -     0%     0%\r\n  sde   699G  78.2M   699G         -     0%     0%\r\n\r\n  pool: zfs\r\n state: ONLINE\r\n  scan: resilvered 75.5G in 0h38m with 0 errors on Mon Oct 16 03:45:53 2017\r\nconfig:\r\n        NAME                                                STATE     READ WRITE CKSUM\r\n        zfs                                                 ONLINE       0     0     0\r\n          raidz1-0                                          ONLINE       0     0     0\r\n            ata-TOSHIBA_DT01ACA300_Z5RS6H0KS                ONLINE       0     0     0\r\n            ata-TOSHIBA_HDWD130_678KR5JAS                   ONLINE       0     0     0\r\n            ata-TOSHIBA_DT01ACA300_16QUEEEKS                ONLINE       0     0     0\r\n            ata-TOSHIBA_HDWD130_678KPYLAS                   ONLINE       0     0     0\r\n          raidz1-1                                          ONLINE       0     0     0\r\n            ata-TOSHIBA_HDWD130_678KTDUAS                   ONLINE       0     0     0\r\n            ata-TOSHIBA_DT01ACA300_16QUDE3KS                ONLINE       0     0     0\r\n            ata-WDC_WD40EZRX-75SPEB0_WD-WCC4E2YAA98J-part6  ONLINE       0     0     0\r\n            ata-TOSHIBA_HDWD130_678KPP7AS                   ONLINE       0     0     0\r\n        cache\r\n          sdc                                               ONLINE       0     0     0\r\n          sde                                               ONLINE       0     0     0\r\n\r\ncapacity  |   operations  |   bandwidth  |  total_wait   |  disk_wait  |  syncq_wait  |  asyncq_wait | scrub\r\n\r\npool |  alloc |  free |  read | write |  read | write |  read | write |  read | write  | read | write |  read | write |  wait \r\n  --- |   --- |   --- |   --- |  --- |   --- |  --- |   --- |  --- |   --- |  ---  |  --- |  --- |   --- |  --- |   --- \r\nzfs     |    5.69T | 16.1T  |   81 |   109 |  500K |  950K |   4us  |  1us  |  4us | 543ns | 187ns  |  2ns  |  1us |   1us | 723ns\r\n\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n```\r\nJan 10 21:57:11 x99 kernel: INFO: rcu_sched detected expedited stalls on CPUs/tasks: { 9-... } 218109 jiffies s: 401 root: 0x200/.\r\nJan 10 21:57:11 x99 kernel: blocking rcu_node structures:\r\nJan 10 21:57:11 x99 kernel: Task dump for CPU 9:\r\nJan 10 21:57:11 x99 kernel: z_wr_iss        R  running task    12256   749      2 0x80000008\r\nJan 10 21:57:11 x99 kernel: Call Trace:\r\nJan 10 21:57:11 x99 kernel:  ? arc_buf_info+0xcc7/0xf80 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? mutex_lock+0x9/0x30\r\nJan 10 21:57:11 x99 kernel:  ? dbuf_rele_and_unlock+0x4cb/0x540 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? mutex_lock+0x9/0x30\r\nJan 10 21:57:11 x99 kernel:  ? mutex_lock+0x9/0x30\r\nJan 10 21:57:11 x99 kernel:  ? zio_worst_error+0x60f/0x1250 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? zio_wait+0x113/0x160 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? dbuf_read+0x617/0xd80 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? __kmalloc_node+0x27d/0x290\r\nJan 10 21:57:11 x99 kernel:  ? spl_kmem_zalloc+0x85/0x150 [spl]\r\nJan 10 21:57:11 x99 kernel:  ? zap_leaf_lookup+0x6d/0x130 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? fzap_length+0x48/0x90 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? zap_name_alloc_uint64+0x50/0x60 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? zap_length_uint64+0x74/0x230 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? ddt_walk+0x31b/0x450 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? ddt_lookup+0xb4/0x190 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? zio_checksum_compute+0x15d/0x2a0 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? spl_kmem_cache_alloc+0x5b/0xb10 [spl]\r\nJan 10 21:57:11 x99 kernel:  ? __kmalloc_node+0x27d/0x290\r\nJan 10 21:57:11 x99 kernel:  ? spl_kmem_alloc+0x8e/0x160 [spl]\r\nJan 10 21:57:11 x99 kernel:  ? spl_kmem_alloc+0x8e/0x160 [spl]\r\nJan 10 21:57:11 x99 kernel:  ? zio_flush+0x867/0xde0 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? zio_push_transform+0x662/0xbe0 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? zio_execute+0x7c/0x430 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? taskq_dispatch_delay+0x51f/0x950 [spl]\r\nJan 10 21:57:11 x99 kernel:  ? wake_up_q+0x70/0x70\r\nJan 10 21:57:11 x99 kernel:  ? zio_interrupt+0x1030/0x1030 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? kthread+0xf7/0x130\r\nJan 10 21:57:11 x99 kernel:  ? taskq_dispatch_delay+0x2c0/0x950 [spl]\r\nJan 10 21:57:11 x99 kernel:  ? kthread_create_on_node+0x40/0x40\r\nJan 10 21:57:11 x99 kernel:  ? do_group_exit+0x35/0xa0\r\nJan 10 21:57:11 x99 kernel:  ? ret_from_fork+0x1f/0x30\r\nJan 10 21:57:13 x99 kernel: watchdog: BUG: soft lockup - CPU#9 stuck for 22s! [z_wr_iss:749]\r\nJan 10 21:57:13 x99 kernel: Modules linked in: nvidia_uvm(PO) zfs(PO) zunicode(PO) zavl(PO) icp(PO) zcommon(PO) znvpair(PO) spl(O) nv>\r\nJan 10 21:57:13 x99 kernel: CPU: 9 PID: 749 Comm: z_wr_iss Tainted: P        W  O L  4.14.12-gentoox99 #1\r\nJan 10 21:57:13 x99 kernel: Hardware name: ASUS All Series/X99-S, BIOS 3402 08/18/2016\r\nJan 10 21:57:13 x99 kernel: task: ffff880fef778e00 task.stack: ffffc9000a2dc000\r\nJan 10 21:57:13 x99 kernel: RIP: 0010:zap_leaf_lookup+0x92/0x130 [zfs]\r\nJan 10 21:57:13 x99 kernel: RSP: 0018:ffffc9000a2dfa40 EFLAGS: 00000213 ORIG_RAX: ffffffffffffff10\r\nJan 10 21:57:13 x99 kernel: RAX: 0000000000000000 RBX: ffff880d59b78130 RCX: 0000000000000007\r\nJan 10 21:57:13 x99 kernel: RDX: 000000000000000c RSI: ffff880d59b78000 RDI: 5d7f96b690640000\r\nJan 10 21:57:13 x99 kernel: RBP: ffffc9000a2dfa88 R08: 00000000002ebfcb R09: ffff880de2c53800\r\nJan 10 21:57:13 x99 kernel: R10: ffff880de2c53800 R11: ffff880fe497a000 R12: ffff880de2c53800\r\nJan 10 21:57:13 x99 kernel: R13: ffff880c575f3600 R14: ffff880d59b78132 R15: 0000000000000001\r\nJan 10 21:57:13 x99 kernel: FS:  0000000000000000(0000) GS:ffff880fff440000(0000) knlGS:0000000000000000\r\nJan 10 21:57:13 x99 kernel: CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\r\nJan 10 21:57:13 x99 kernel: CR2: 00007f767108b850 CR3: 0000000004823006 CR4: 00000000001606e0\r\nJan 10 21:57:13 x99 kernel: Call Trace:\r\nJan 10 21:57:13 x99 kernel:  fzap_length+0x48/0x90 [zfs]\r\nJan 10 21:57:13 x99 kernel:  ? zap_name_alloc_uint64+0x50/0x60 [zfs]\r\nJan 10 21:57:13 x99 kernel:  zap_length_uint64+0x74/0x230 [zfs]\r\nJan 10 21:57:13 x99 kernel:  ddt_walk+0x31b/0x450 [zfs]\r\nJan 10 21:57:13 x99 kernel:  ddt_lookup+0xb4/0x190 [zfs]\r\nJan 10 21:57:13 x99 kernel:  ? zio_checksum_compute+0x15d/0x2a0 [zfs]\r\nJan 10 21:57:13 x99 kernel:  ? spl_kmem_cache_alloc+0x5b/0xb10 [spl]\r\nJan 10 21:57:13 x99 kernel:  ? __kmalloc_node+0x27d/0x290\r\nJan 10 21:57:13 x99 kernel:  ? spl_kmem_alloc+0x8e/0x160 [spl]\r\nJan 10 21:57:13 x99 kernel:  ? spl_kmem_alloc+0x8e/0x160 [spl]\r\nJan 10 21:57:13 x99 kernel:  zio_flush+0x867/0xde0 [zfs]\r\nJan 10 21:57:13 x99 kernel:  ? zio_push_transform+0x662/0xbe0 [zfs]\r\nJan 10 21:57:13 x99 kernel:  zio_execute+0x7c/0x430 [zfs]\r\nJan 10 21:57:13 x99 kernel:  taskq_dispatch_delay+0x51f/0x950 [spl]\r\nJan 10 21:57:13 x99 kernel:  ? wake_up_q+0x70/0x70\r\nJan 10 21:57:13 x99 kernel:  ? zio_interrupt+0x1030/0x1030 [zfs]\r\nJan 10 21:57:13 x99 kernel:  kthread+0xf7/0x130\r\nJan 10 21:57:13 x99 kernel:  ? taskq_dispatch_delay+0x2c0/0x950 [spl]\r\nJan 10 21:57:13 x99 kernel:  ? kthread_create_on_node+0x40/0x40\r\nJan 10 21:57:13 x99 kernel:  ? do_group_exit+0x35/0xa0\r\nJan 10 21:57:13 x99 kernel:  ret_from_fork+0x1f/0x30\r\nJan 10 21:57:13 x99 kernel: Code: eb 29 0f b7 43 02 4c 8d 73 02 66 83 f8 ff 74 7f 49 8b 8c 24 d8 00 00 00 41 8b 94 24 d0 00 00 00 49 >\r\nJan 10 21:57:18 x99 systemd[1]: Received SIGINT.\r\n```", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7042/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ltz3317": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7038", "title": "zfs sync hang ", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       |  centos 7.2 \uff0csync hang\r\nDistribution Version    | \r\nLinux Kernel                 | 3.10.0-327.13.1.el7.x86_64 \r\nArchitecture                 | \r\nZFS Version                  | v0.7.5-1\r\nSPL Version                  |  v0.7.5-1\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\nsync hang \uff0cmysql hang\uff0ckworker cpu 100\r\n### Describe how to reproduce the problem\r\nhigh frequency  create/destroy/clone\r\n### Include any warning/errors/backtraces from the system logs\r\ndmsg:\r\n[  189.990968] Adjusting tsc more than 11% (8039035 vs 7759471)\r\n[ 2522.644734] INFO: task mysqld:6608 blocked for more than 120 seconds.\r\n[ 2522.644790] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2522.644854] mysqld          D 0000000000000000     0  6608   5602 0x00000000\r\n[ 2522.644860]  ffff880feb913da0 0000000000000086 ffff881006eac500 ffff880feb913fd8\r\n[ 2522.644865]  ffff880feb913fd8 ffff880feb913fd8 ffff881006eac500 ffff880fffc8a180\r\n[ 2522.644869]  ffff880fffc8a000 ffff880fffc8a188 ffff880fffc8a028 0000000000000000\r\n[ 2522.644873] Call Trace:\r\n[ 2522.644882]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2522.644906]  [<ffffffffa04744d5>] cv_wait_common+0x125/0x150 [spl]\r\n[ 2522.644911]  [<ffffffff810a6ae0>] ? wake_up_atomic_t+0x30/0x30\r\n[ 2522.644922]  [<ffffffffa0474515>] __cv_wait+0x15/0x20 [spl]\r\n[ 2522.644995]  [<ffffffffa062bd7b>] zil_commit.part.12+0x8b/0x830 [zfs]\r\n[ 2522.645006]  [<ffffffffa046d037>] ? spl_kmem_alloc+0xc7/0x170 [spl]\r\n[ 2522.645017]  [<ffffffffa0475cb4>] ? tsd_set+0x324/0x500 [spl]\r\n[ 2522.645022]  [<ffffffff81639082>] ? mutex_lock+0x12/0x2f\r\n[ 2522.645075]  [<ffffffffa062c537>] zil_commit+0x17/0x20 [zfs]\r\n[ 2522.645128]  [<ffffffffa0621a27>] zfs_fsync+0x77/0xf0 [zfs]\r\n[ 2522.645179]  [<ffffffffa0639665>] zpl_fsync+0x65/0x90 [zfs]\r\n[ 2522.645186]  [<ffffffff8120fa45>] do_fsync+0x65/0xa0\r\n[ 2522.645191]  [<ffffffff8120fd10>] SyS_fsync+0x10/0x20\r\n[ 2522.645196]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2522.645202] INFO: task mysqld:7514 blocked for more than 120 seconds.\r\n[ 2522.645245] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2522.645296] mysqld          D ffff880fb554bda0     0  7514   5602 0x00000000\r\n[ 2522.645299]  ffff880fb554bd30 0000000000000086 ffff880ff4c8f300 ffff880fb554bfd8\r\n[ 2522.645303]  ffff880fb554bfd8 ffff880fb554bfd8 ffff880ff4c8f300 ffff880fb554bdb0\r\n[ 2522.645307]  ffff88107ff8dec0 0000000000000002 ffffffff811f9420 ffff880fb554bda0\r\n[ 2522.645312] Call Trace:\r\n[ 2522.645316]  [<ffffffff811f9420>] ? unlock_two_nondirectories+0x60/0x60\r\n[ 2522.645321]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2522.645324]  [<ffffffff811f942e>] inode_wait+0xe/0x20\r\n[ 2522.645328]  [<ffffffff81638cc0>] __wait_on_bit+0x60/0x90\r\n[ 2522.645335]  [<ffffffff812083bf>] __inode_wait_for_writeback+0xaf/0xf0\r\n[ 2522.645339]  [<ffffffff810a6b60>] ? wake_atomic_t_function+0x40/0x40\r\n[ 2522.645345]  [<ffffffff8120b996>] inode_wait_for_writeback+0x26/0x40\r\n[ 2522.645348]  [<ffffffff811fa135>] evict+0x95/0x170\r\n[ 2522.645351]  [<ffffffff811fa985>] iput+0xf5/0x180\r\n[ 2522.645357]  [<ffffffff811ef41e>] do_unlinkat+0x1ae/0x2b0\r\n[ 2522.645362]  [<ffffffff811e3fe1>] ? SyS_readlinkat+0xd1/0x140\r\n[ 2522.645367]  [<ffffffff811f0426>] SyS_unlink+0x16/0x20\r\n[ 2522.645371]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2522.645402] INFO: task sync:2653 blocked for more than 120 seconds.\r\n[ 2522.645443] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2522.645494] sync            D ffffffff8120f8c0     0  2653   1455 0x00000000\r\n[ 2522.645498]  ffff880ffedd7d50 0000000000000082 ffff880f01449700 ffff880ffedd7fd8\r\n[ 2522.645502]  ffff880ffedd7fd8 ffff880ffedd7fd8 ffff880f01449700 ffff880ffedd7e80\r\n[ 2522.645506]  ffff880ffedd7e88 7fffffffffffffff ffff880f01449700 ffffffff8120f8c0\r\n[ 2522.645509] Call Trace:\r\n[ 2522.645515]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2522.645519]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2522.645523]  [<ffffffff81638b39>] schedule_timeout+0x209/0x2d0\r\n[ 2522.645527]  [<ffffffff8109b426>] ? __queue_work+0x136/0x320\r\n[ 2522.645530]  [<ffffffff8109b6da>] ? __queue_delayed_work+0xaa/0x1a0\r\n[ 2522.645534]  [<ffffffff8109ba41>] ? try_to_grab_pending+0xb1/0x160\r\n[ 2522.645538]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2522.645543]  [<ffffffff8163b216>] wait_for_completion+0x116/0x170\r\n[ 2522.645548]  [<ffffffff810b8c30>] ? wake_up_state+0x20/0x20\r\n[ 2522.645552]  [<ffffffff81208987>] sync_inodes_sb+0xb7/0x1e0\r\n[ 2522.645557]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2522.645561]  [<ffffffff8120f8d9>] sync_inodes_one_sb+0x19/0x20\r\n[ 2522.645565]  [<ffffffff811e2182>] iterate_supers+0xb2/0x110\r\n[ 2522.645570]  [<ffffffff8120fb94>] sys_sync+0x44/0xb0\r\n[ 2522.645575]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2642.739175] INFO: task mysqld:6608 blocked for more than 120 seconds.\r\n[ 2642.739228] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2642.739284] mysqld          D 0000000000000000     0  6608   5602 0x00000000\r\n[ 2642.739290]  ffff880feb913da0 0000000000000086 ffff881006eac500 ffff880feb913fd8\r\n[ 2642.739296]  ffff880feb913fd8 ffff880feb913fd8 ffff881006eac500 ffff880fffc8a180\r\n[ 2642.739300]  ffff880fffc8a000 ffff880fffc8a188 ffff880fffc8a028 0000000000000000\r\n[ 2642.739305] Call Trace:\r\n[ 2642.739315]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2642.739340]  [<ffffffffa04744d5>] cv_wait_common+0x125/0x150 [spl]\r\n[ 2642.739345]  [<ffffffff810a6ae0>] ? wake_up_atomic_t+0x30/0x30\r\n[ 2642.739357]  [<ffffffffa0474515>] __cv_wait+0x15/0x20 [spl]\r\n[ 2642.739434]  [<ffffffffa062bd7b>] zil_commit.part.12+0x8b/0x830 [zfs]\r\n[ 2642.739447]  [<ffffffffa046d037>] ? spl_kmem_alloc+0xc7/0x170 [spl]\r\n[ 2642.739460]  [<ffffffffa0475cb4>] ? tsd_set+0x324/0x500 [spl]\r\n[ 2642.739466]  [<ffffffff81639082>] ? mutex_lock+0x12/0x2f\r\n[ 2642.739526]  [<ffffffffa062c537>] zil_commit+0x17/0x20 [zfs]\r\n[ 2642.739587]  [<ffffffffa0621a27>] zfs_fsync+0x77/0xf0 [zfs]\r\n[ 2642.739647]  [<ffffffffa0639665>] zpl_fsync+0x65/0x90 [zfs]\r\n[ 2642.739654]  [<ffffffff8120fa45>] do_fsync+0x65/0xa0\r\n[ 2642.739659]  [<ffffffff8120fd10>] SyS_fsync+0x10/0x20\r\n[ 2642.739665]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2642.739670] INFO: task mysqld:7514 blocked for more than 120 seconds.\r\n[ 2642.739727] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2642.739793] mysqld          D ffff880fb554bda0     0  7514   5602 0x00000000\r\n[ 2642.739798]  ffff880fb554bd30 0000000000000086 ffff880ff4c8f300 ffff880fb554bfd8\r\n[ 2642.739803]  ffff880fb554bfd8 ffff880fb554bfd8 ffff880ff4c8f300 ffff880fb554bdb0\r\n[ 2642.739808]  ffff88107ff8dec0 0000000000000002 ffffffff811f9420 ffff880fb554bda0\r\n[ 2642.739812] Call Trace:\r\n[ 2642.739818]  [<ffffffff811f9420>] ? unlock_two_nondirectories+0x60/0x60\r\n[ 2642.739823]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2642.739826]  [<ffffffff811f942e>] inode_wait+0xe/0x20\r\n[ 2642.739831]  [<ffffffff81638cc0>] __wait_on_bit+0x60/0x90\r\n[ 2642.739839]  [<ffffffff812083bf>] __inode_wait_for_writeback+0xaf/0xf0\r\n[ 2642.739843]  [<ffffffff810a6b60>] ? wake_atomic_t_function+0x40/0x40\r\n[ 2642.739850]  [<ffffffff8120b996>] inode_wait_for_writeback+0x26/0x40\r\n[ 2642.739854]  [<ffffffff811fa135>] evict+0x95/0x170\r\n[ 2642.739857]  [<ffffffff811fa985>] iput+0xf5/0x180\r\n[ 2642.739862]  [<ffffffff811ef41e>] do_unlinkat+0x1ae/0x2b0\r\n[ 2642.739868]  [<ffffffff811e3fe1>] ? SyS_readlinkat+0xd1/0x140\r\n[ 2642.739873]  [<ffffffff811f0426>] SyS_unlink+0x16/0x20\r\n[ 2642.739878]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2642.739897] INFO: task sync:2653 blocked for more than 120 seconds.\r\n[ 2642.739951] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2642.740017] sync            D ffffffff8120f8c0     0  2653   1455 0x00000000\r\n[ 2642.740021]  ffff880ffedd7d50 0000000000000082 ffff880f01449700 ffff880ffedd7fd8\r\n[ 2642.740026]  ffff880ffedd7fd8 ffff880ffedd7fd8 ffff880f01449700 ffff880ffedd7e80\r\n[ 2642.740031]  ffff880ffedd7e88 7fffffffffffffff ffff880f01449700 ffffffff8120f8c0\r\n[ 2642.740036] Call Trace:\r\n[ 2642.740042]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2642.740047]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2642.740051]  [<ffffffff81638b39>] schedule_timeout+0x209/0x2d0\r\n[ 2642.740056]  [<ffffffff8109b426>] ? __queue_work+0x136/0x320\r\n[ 2642.740060]  [<ffffffff8109b6da>] ? __queue_delayed_work+0xaa/0x1a0\r\n[ 2642.740064]  [<ffffffff8109ba41>] ? try_to_grab_pending+0xb1/0x160\r\n[ 2642.740069]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2642.740093]  [<ffffffff8163b216>] wait_for_completion+0x116/0x170\r\n[ 2642.740100]  [<ffffffff810b8c30>] ? wake_up_state+0x20/0x20\r\n[ 2642.740105]  [<ffffffff81208987>] sync_inodes_sb+0xb7/0x1e0\r\n[ 2642.740110]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2642.740116]  [<ffffffff8120f8d9>] sync_inodes_one_sb+0x19/0x20\r\n[ 2642.740121]  [<ffffffff811e2182>] iterate_supers+0xb2/0x110\r\n[ 2642.740127]  [<ffffffff8120fb94>] sys_sync+0x44/0xb0\r\n[ 2642.740134]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2762.834495] INFO: task mysqld:6608 blocked for more than 120 seconds.\r\n[ 2762.834547] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2762.834604] mysqld          D 0000000000000000     0  6608   5602 0x00000000\r\n[ 2762.834609]  ffff880feb913da0 0000000000000086 ffff881006eac500 ffff880feb913fd8\r\n[ 2762.834615]  ffff880feb913fd8 ffff880feb913fd8 ffff881006eac500 ffff880fffc8a180\r\n[ 2762.834619]  ffff880fffc8a000 ffff880fffc8a188 ffff880fffc8a028 0000000000000000\r\n[ 2762.834624] Call Trace:\r\n[ 2762.834634]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2762.834659]  [<ffffffffa04744d5>] cv_wait_common+0x125/0x150 [spl]\r\n[ 2762.834665]  [<ffffffff810a6ae0>] ? wake_up_atomic_t+0x30/0x30\r\n[ 2762.834677]  [<ffffffffa0474515>] __cv_wait+0x15/0x20 [spl]\r\n[ 2762.834748]  [<ffffffffa062bd7b>] zil_commit.part.12+0x8b/0x830 [zfs]\r\n[ 2762.834761]  [<ffffffffa046d037>] ? spl_kmem_alloc+0xc7/0x170 [spl]\r\n[ 2762.834774]  [<ffffffffa0475cb4>] ? tsd_set+0x324/0x500 [spl]\r\n[ 2762.834779]  [<ffffffff81639082>] ? mutex_lock+0x12/0x2f\r\n[ 2762.834843]  [<ffffffffa062c537>] zil_commit+0x17/0x20 [zfs]\r\n[ 2762.834908]  [<ffffffffa0621a27>] zfs_fsync+0x77/0xf0 [zfs]\r\n[ 2762.834971]  [<ffffffffa0639665>] zpl_fsync+0x65/0x90 [zfs]\r\n[ 2762.834978]  [<ffffffff8120fa45>] do_fsync+0x65/0xa0\r\n[ 2762.834983]  [<ffffffff8120fd10>] SyS_fsync+0x10/0x20\r\n[ 2762.834989]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2762.834994] INFO: task mysqld:7514 blocked for more than 120 seconds.\r\n[ 2762.835051] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2762.835118] mysqld          D ffff880fb554bda0     0  7514   5602 0x00000000\r\n[ 2762.835122]  ffff880fb554bd30 0000000000000086 ffff880ff4c8f300 ffff880fb554bfd8\r\n[ 2762.835127]  ffff880fb554bfd8 ffff880fb554bfd8 ffff880ff4c8f300 ffff880fb554bdb0\r\n[ 2762.835132]  ffff88107ff8dec0 0000000000000002 ffffffff811f9420 ffff880fb554bda0\r\n[ 2762.835137] Call Trace:\r\n[ 2762.835143]  [<ffffffff811f9420>] ? unlock_two_nondirectories+0x60/0x60\r\n[ 2762.835148]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2762.835151]  [<ffffffff811f942e>] inode_wait+0xe/0x20\r\n[ 2762.835156]  [<ffffffff81638cc0>] __wait_on_bit+0x60/0x90\r\n[ 2762.835164]  [<ffffffff812083bf>] __inode_wait_for_writeback+0xaf/0xf0\r\n[ 2762.835168]  [<ffffffff810a6b60>] ? wake_atomic_t_function+0x40/0x40\r\n[ 2762.835175]  [<ffffffff8120b996>] inode_wait_for_writeback+0x26/0x40\r\n[ 2762.835179]  [<ffffffff811fa135>] evict+0x95/0x170\r\n[ 2762.835183]  [<ffffffff811fa985>] iput+0xf5/0x180\r\n[ 2762.835188]  [<ffffffff811ef41e>] do_unlinkat+0x1ae/0x2b0\r\n[ 2762.835195]  [<ffffffff811e3fe1>] ? SyS_readlinkat+0xd1/0x140\r\n[ 2762.835199]  [<ffffffff811f0426>] SyS_unlink+0x16/0x20\r\n[ 2762.835205]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2762.835223] INFO: task sync:2653 blocked for more than 120 seconds.\r\n[ 2762.835277] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2762.835343] sync            D ffffffff8120f8c0     0  2653   1455 0x00000000\r\n[ 2762.835348]  ffff880ffedd7d50 0000000000000082 ffff880f01449700 ffff880ffedd7fd8\r\n[ 2762.835352]  ffff880ffedd7fd8 ffff880ffedd7fd8 ffff880f01449700 ffff880ffedd7e80\r\n[ 2762.835357]  ffff880ffedd7e88 7fffffffffffffff ffff880f01449700 ffffffff8120f8c0\r\n[ 2762.835362] Call Trace:\r\n[ 2762.835369]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2762.835374]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2762.835378]  [<ffffffff81638b39>] schedule_timeout+0x209/0x2d0\r\n[ 2762.835382]  [<ffffffff8109b426>] ? __queue_work+0x136/0x320\r\n[ 2762.835386]  [<ffffffff8109b6da>] ? __queue_delayed_work+0xaa/0x1a0\r\n[ 2762.835390]  [<ffffffff8109ba41>] ? try_to_grab_pending+0xb1/0x160\r\n[ 2762.835396]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2762.835409]  [<ffffffff8163b216>] wait_for_completion+0x116/0x170\r\n[ 2762.835417]  [<ffffffff810b8c30>] ? wake_up_state+0x20/0x20\r\n[ 2762.835422]  [<ffffffff81208987>] sync_inodes_sb+0xb7/0x1e0\r\n[ 2762.835427]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2762.835433]  [<ffffffff8120f8d9>] sync_inodes_one_sb+0x19/0x20\r\n[ 2762.835438]  [<ffffffff811e2182>] iterate_supers+0xb2/0x110\r\n[ 2762.835443]  [<ffffffff8120fb94>] sys_sync+0x44/0xb0\r\n[ 2762.835451]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2882.929813] INFO: task mysqld:6608 blocked for more than 120 seconds.\r\n[ 2882.929861] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2882.929913] mysqld          D 0000000000000000     0  6608   5602 0x00000000\r\n[ 2882.929919]  ffff880feb913da0 0000000000000086 ffff881006eac500 ffff880feb913fd8\r\n[ 2882.929924]  ffff880feb913fd8 ffff880feb913fd8 ffff881006eac500 ffff880fffc8a180\r\n[ 2882.929928]  ffff880fffc8a000 ffff880fffc8a188 ffff880fffc8a028 0000000000000000\r\n[ 2882.929932] Call Trace:\r\n[ 2882.929942]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2882.929967]  [<ffffffffa04744d5>] cv_wait_common+0x125/0x150 [spl]\r\n[ 2882.929972]  [<ffffffff810a6ae0>] ? wake_up_atomic_t+0x30/0x30\r\n[ 2882.929983]  [<ffffffffa0474515>] __cv_wait+0x15/0x20 [spl]\r\n[ 2882.930049]  [<ffffffffa062bd7b>] zil_commit.part.12+0x8b/0x830 [zfs]\r\n[ 2882.930059]  [<ffffffffa046d037>] ? spl_kmem_alloc+0xc7/0x170 [spl]\r\n[ 2882.930070]  [<ffffffffa0475cb4>] ? tsd_set+0x324/0x500 [spl]\r\n[ 2882.930075]  [<ffffffff81639082>] ? mutex_lock+0x12/0x2f\r\n[ 2882.930129]  [<ffffffffa062c537>] zil_commit+0x17/0x20 [zfs]\r\n[ 2882.930181]  [<ffffffffa0621a27>] zfs_fsync+0x77/0xf0 [zfs]\r\n[ 2882.930232]  [<ffffffffa0639665>] zpl_fsync+0x65/0x90 [zfs]\r\n[ 2882.930238]  [<ffffffff8120fa45>] do_fsync+0x65/0xa0\r\n[ 2882.930243]  [<ffffffff8120fd10>] SyS_fsync+0x10/0x20\r\n[ 2882.930248]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 4802.367346] perf interrupt took too long (2507 > 2500), lowering kernel.perf_event_max_sample_rate to 50000\r\n\r\nsync process stack:\r\n[<ffffffff81208987>] sync_inodes_sb+0xb7/0x1e0\r\n[<ffffffff8120f8d9>] sync_inodes_one_sb+0x19/0x20\r\n[<ffffffff811e2182>] iterate_supers+0xb2/0x110\r\n[<ffffffff8120fb94>] sys_sync+0x44/0xb0\r\n[<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[<ffffffffffffffff>] 0xffffffffffffffff\r\n\r\nkworker process stack:\r\n cat /proc/3445/stack \r\n[<ffffffffa058feb5>] dmu_zfetch+0x455/0x4f0 [zfs]\r\n[<ffffffffa05711ea>] dbuf_read+0x8ea/0x9f0 [zfs]\r\n[<ffffffffa0591246>] dnode_hold_impl+0xc6/0xc30 [zfs]\r\n[<ffffffffffffffff>] 0xffffffffffffffff\r\n\r\ncat /proc/3445/stack \r\n[<ffffffffffffffff>] 0xffffffffffffffff\r\n[root@ifcos ~]# cat /proc/3445/stack \r\n[<ffffffffa062879c>] zfs_zget+0xfc/0x250 [zfs]\r\n[<ffffffffa0623db7>] zfs_get_data+0x57/0x2d0 [zfs]\r\n[<ffffffffa062c10c>] zil_commit.part.12+0x41c/0x830 [zfs]\r\n[<ffffffffa062c537>] zil_commit+0x17/0x20 [zfs]\r\n[<ffffffffa06394b6>] zpl_writepages+0xd6/0x170 [zfs]\r\n[<ffffffff811759fe>] do_writepages+0x1e/0x40\r\n[<ffffffff812084e0>] __writeback_single_inode+0x40/0x220\r\n[<ffffffff81208f4e>] writeback_sb_inodes+0x25e/0x420\r\n[<ffffffff8120988f>] wb_writeback+0xff/0x2f0\r\n[<ffffffff8120bac5>] bdi_writeback_workfn+0x115/0x460\r\n[<ffffffff8109d5fb>] process_one_work+0x17b/0x470\r\n[<ffffffff8109e3cb>] worker_thread+0x11b/0x400\r\n[<ffffffff810a5aef>] kthread+0xcf/0xe0\r\n[<ffffffff81645e18>] ret_from_fork+0x58/0x90\r\n[<ffffffffffffffff>] 0xffffffffffffffff\r\n\r\n cat /proc/3445/stack \r\n[<ffffffffa058feb5>] dmu_zfetch+0x455/0x4f0 [zfs]\r\n[<ffffffffa0572fd5>] __dbuf_hold_impl+0x135/0x5a0 [zfs]\r\n[<ffffffffffffffff>] 0xffffffffffffffff\r\n\r\n cat /proc/3445/stack \r\n[<ffffffffa056fa69>] dbuf_find+0x1c9/0x1d0 [zfs]\r\n[<ffffffffa0572ee2>] __dbuf_hold_impl+0x42/0x5a0 [zfs]\r\n[<ffffffffffffffff>] 0xffffffffffffffff\r\n\r\n cat /proc/3445/stack \r\n[<ffffffffa058feb5>] dmu_zfetch+0x455/0x4f0 [zfs]\r\n[<ffffffffa0571056>] dbuf_read+0x756/0x9f0 [zfs]\r\n[<ffffffffa0591246>] dnode_hold_impl+0xc6/0xc30 [zfs]\r\n\r\n<!-- \r\n*IMPORTANT* - Please mark logs and text output from terminal commands \r\nor else Github will not display them correctly. \r\nAn example is provided below.\r\n\r\nExample:\r\n```\r\nthis is an example how log text should be marked (wrap it with ```)\r\n```\r\n-->\r\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7038/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "sempervictus": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7035", "title": "Consider adding mitigations for speculative execution related concerns", "body": "GCC should get retpoline support soon, and Intel seems to be proposing kernel code with barriers to speculative execution - https://patchwork.ozlabs.org/cover/856316/. ZFS is already pretty unhappy from KPTI, but since there's a good deal of user controlled data going into it, this might be worth investigating.", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7035/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "abraunegg": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7034", "title": "Missing parameter descriptions in ZFS-Module-Parameters man page", "body": "The following zfs module parameters are missing from the zfs-module-parameters man page (updated 28th Oct 2017) using ZFS 0.7.5:\r\n\r\n* dbuf_cache_hiwater_pct\r\n* dbuf_cache_lowater_pct\r\n* dbuf_cache_max_bytes\r\n* dbuf_cache_max_shift\r\n* dmu_object_alloc_chunk_shift\r\n* send_holes_without_birth_time\r\n* zfs_abd_scatter_enabled\r\n* zfs_abd_scatter_max_order\r\n* zfs_compressed_arc_enabled\r\n* zfs_sync_taskq_batch_pct\r\n\r\nHappy to create a documentation patch for the man pages if someone can send me the a description of what the module parameter is, what the default should be and what valid options are if it is being changed.\r\n\r\nBest regards,\r\n\r\nAlex", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7034/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "rincebrain": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7024", "title": "zfs send -R | zfs recv can fail in the middle due to a snapshot being taken", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Debian\r\nDistribution Version    | 9.3\r\nLinux Kernel                 | 4.9.0-4-amd64\r\nArchitecture                 | amd64\r\nZFS Version                  | 0.7.3-3\r\nSPL Version                  | 0.7.3-1\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing + how to reproduce the problem\r\nWhen doing a long-running `zfs send -R foo/bar/baz@ten | zfs recv -ds newfoo`, an automated utility helpfully took a recursive snapshot on newfoo, and zfs recv abruptly died with `cannot receive incremental stream: kernel modules must be upgraded to receive this stream.` with newfoo/bar/baz having completed snapshots one, ..., seven and throwing that error on attempting to resume.\r\n\r\nI would have expected the in-progress receiving dataset(s) to have remained immutable until the receives were completed, but apparently this isn't the case.\r\n\r\nDestroying the errant snapshot on newfoo/bar/baz allowed the zfs send to proceed like nothing ever happened.\r\n\r\nSince there's already a number of bugs suggesting that this message should be broken out and detailed further (#6547, #6574), this bug is mostly about the fact that nothing is stopping you from shooting yourself in the foot and not being able to discover why without making dramatic leaps or (presumably) reading zfs/dbgmsg.", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7024/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "h1z1": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7015", "title": "Impact of Intel bug (tm) on ZFS", "body": "Maybe the wrong avenue for this but no doubt like others watching the events of the last few days unfold, I've been asked to comment on the impact to ZFS in our environment.   I'm in a rather odd position as I don't really have the hardware to duplicate an entire production silo, running 4.15.x kernel.   I do however know at least 4.14 will bite us as per #6929.  \r\n\r\nHas anyone tested or confirmed what the impact of this will be going forward?  Would rather not duplicate effort if it's already being addressed.\r\n\r\nThanks", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7015/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "sanjeevbagewadi": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7011", "title": "With \"casesensitivity=mixed\" hitting an assert in ZAP code", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | CentOS release 6.8 (Final)\r\n  ---                                  |     --- \r\nDistribution Name       | CentOS\r\nDistribution Version    | 6.8\r\nLinux Kernel                 | 4.4.14-1.el6\r\nArchitecture                 | x86\r\nZFS Version                  | 0.7.1-1\r\nSPL Version                  |  0.7.1-1\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\n\r\nWith casesensitivity=mixed was running the following test :\r\nroot@NTNX-10-5-137-31-A-FSVM:/home/nutanix# cat names.py\r\n#!/usr/bin/python\r\nimport itertools\r\ns=\"abcdefghijklmnopqrstuvwxyz\"\r\nlength = len(s)\r\nnames = map(''.join, itertools.product(*zip(s.upper(), s.lower())))\r\nfor name in names:\r\n    print name\r\n\r\nroot@NTNX-10-5-137-31-A-FSVM:/home/nutanix# ./names.py | while read file\r\n> do\r\n> touch /test/fs2/dir1/$file\r\n> done\r\n\r\nAnd hit the following panic \r\n-- snip --\r\n[    1.068019] VERIFY(!RW_LOCK_HELD(&l->l_rwlock)) failed\r\n[    1.068077] PANIC at zap.c:407:zap_leaf_evict_sync()\r\n[    1.068113] Showing stack for process 67625\r\n[    1.068116] CPU: 0 PID: 67625 Comm: touch Tainted: P           OE   4.4.14-1.el6.nutanix.10272016.x86_64 #1\r\n[    1.068117] Hardware name: Nutanix AHV, BIOS seabios-1.7.5-11.el6 04/01/2014\r\n[    1.068122]  0000000000000000 ffff88015312b2a8 ffffffff81319ae3 0000000000000001\r\n[    1.068125]  0000000100480b8b ffff88015312b2f8 ffffffffa0b5a9c0 ffff88015312b2b8\r\n[    1.068127]  ffffffffa09918c4 ffff88015312b458 ffffffffa0991aeb 0000000000000040\r\n[    1.068129] Call Trace:\r\n[    1.068136]  [<ffffffff81319ae3>] dump_stack+0x67/0x94\r\n[    1.068146]  [<ffffffffa09918c4>] spl_dumpstack+0x44/0x50 [spl]\r\n[    1.068150]  [<ffffffffa0991aeb>] spl_panic+0xcb/0xe0 [spl]\r\n[    1.068153]  [<ffffffff8132a483>] ? __sg_free_table+0x63/0x90\r\n[    1.068157]  [<ffffffff811e447e>] ? kmem_cache_free+0x1ee/0x210\r\n[    1.068160]  [<ffffffffa098d477>] ? spl_kmem_cache_free+0x117/0x140 [spl]\r\n[    1.068200]  [<ffffffffa0a46ecc>] ? arc_hdr_destroy+0x17c/0x1d0 [zfs]\r\n[    1.068231]  [<ffffffffa0acf457>] zap_leaf_evict_sync+0x57/0x60 [zfs]\r\n[    1.068248]  [<ffffffffa0a4d575>] dbuf_evict_user+0x45/0x70 [zfs]\r\n[    1.068265]  [<ffffffffa0a4f95f>] dbuf_destroy+0x4f/0x330 [zfs]\r\n[    1.068282]  [<ffffffffa0a4f561>] dbuf_rele_and_unlock+0x221/0x3e0 [zfs]\r\n[    1.068313]  [<ffffffffa0ad514f>] ? zap_lockdir+0x7f/0xa0 [zfs]\r\n[    1.068344]  [<ffffffffa0ad15e6>] ? zap_grow_ptrtbl+0x186/0x1a0 [zfs]\r\n[    1.068361]  [<ffffffffa0a4f900>] dbuf_rele+0x40/0x50 [zfs]\r\n[    1.068394]  [<ffffffffa0a4fd1e>] dmu_buf_rele+0xe/0x10 [zfs]\r\n[    1.068427]  [<ffffffffa0acf3dd>] zap_put_leaf+0x3d/0x60 [zfs]\r\n[    1.068460]  [<ffffffffa0ad16c7>] zap_put_leaf_maybe_grow_ptrtbl+0xc7/0x130 [zfs]\r\n[    1.068492]  [<ffffffffa0ad1be8>] fzap_add_cd+0xd8/0x130 [zfs]\r\n[    1.068541]  [<ffffffffa0ad4ce4>] mzap_upgrade+0x194/0x210 [zfs]\r\n[    1.068593]  [<ffffffffa0ad4fba>] zap_lockdir_impl+0x25a/0x370 [zfs]\r\n[    1.068628]  [<ffffffffa0ad514f>] zap_lockdir+0x7f/0xa0 [zfs]\r\n[    1.068664]  [<ffffffffa0ad695b>] zap_add+0x5b/0xa0 [zfs]\r\n[    1.068668]  [<ffffffff810ca871>] ? __raw_callee_save___pv_queued_spin_unlock+0x11/0x20\r\n[    1.068703]  [<ffffffffa0adfcbf>] zfs_link_create+0x37f/0x520 [zfs]\r\n[    1.068761]  [<ffffffffa0b00b2a>] zfs_create+0x62a/0x810 [zfs]\r\n[    1.068764]  [<ffffffff811e76f6>] ? __kmalloc_node+0x1f6/0x2b0\r\n[    1.068798]  [<ffffffffa0b19bf2>] zpl_create+0xb2/0x160 [zfs]\r\n[    1.068802]  [<ffffffff81210424>] vfs_create+0xd4/0x100\r\n[    1.068804]  [<ffffffff8120dc4d>] ? lookup_real+0x1d/0x60\r\n[    1.068806]  [<ffffffff812111e3>] lookup_open+0x173/0x1a0\r\n[    1.068808]  [<ffffffff812138d9>] do_last+0x299/0x760\r\n[    1.068811]  [<ffffffff812056d7>] ? get_empty_filp+0xd7/0x1c0\r\n[    1.068813]  [<ffffffff81213e1c>] path_openat+0x7c/0x140\r\n[    1.068832]  [<ffffffff811b53c2>] ? __pte_alloc+0xe2/0x190\r\n[    1.068834]  [<ffffffff81213f65>] do_filp_open+0x85/0xe0\r\n[    1.068836]  [<ffffffff8120eade>] ? getname_flags+0xce/0x1f0\r\n[    1.068838]  [<ffffffff8120311a>] do_sys_open+0x11a/0x220\r\n[    1.068842]  [<ffffffff81003513>] ? syscall_trace_enter_phase1+0x133/0x150\r\n[    1.068844]  [<ffffffff8120325e>] SyS_open+0x1e/0x20\r\n[    1.068850]  [<ffffffff816cf76e>] entry_SYSCALL_64_fastpath+0x12/0x71\r\n-- snip --\r\n\r\n### Describe how to reproduce the problem\r\n\r\nThe following are the steps\\:\r\n- Create zfs dataset with casesensitivity=mixed\r\n- Run the above listed code.\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n<!-- \r\n*IMPORTANT* - Please mark logs and text output from terminal commands \r\nor else Github will not display them correctly. \r\nAn example is provided below.\r\n\r\nExample:\r\n```\r\nthis is an example how log text should be marked (wrap it with ```)\r\n```\r\n-->", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7011/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/7054", "title": "Handle zap_add() failures in \"casesensitivity=mixed\" mode.", "body": "With \"casesensitivity=mixed\", zap_add() could fail when the number of\r\nfiles/directories with the same name (varying in case) exceed the\r\ncapacity of the leaf node of a Fatzap. This results in a ASSERT()\r\nfailure as zfs_link_create() does not expect zap_add() to fail. The fix\r\nis to handle these failures and rollback the transactions.\r\n\r\nSigned-off-by: Sanjeev Bagewadi <sanjeev.bagewadi@gmail.com>\r\n\r\n<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\nFor a dataset with \"casesensitivity=mixed\", when a large number of files/directories\r\nwith same name (varying only in case e.g: ABCD, ABCd, ABcD and so on) are created\r\nzap_add() could fail. With mixed mode zap_add() normalises the names before the hash\r\nis computed. And all the names would generate the same hash and land in the same leaf.\r\nWhen the number of entries exceed the capacity of the leaf-block, zap_add() tries to split\r\nthe leaf-block which fails as well and zap_add() fails. This trips an ASSERT in zfs_link_create()\r\nas it does not expect zap_add() to fail.\r\n\r\nThe fix does the following :\r\n- fzap_add_cd() : Handle the case when zap_expand_leaf() fails with ENOSPC and bailout\r\n   without calling zap_put_leaf_maybe_grow_ptrtbl(). \r\n- zap_add_impl() : When adding to a micro-zap check if the total number of entries\r\n  with colliding/same hash value can fit into fatzap-leaf-block. This is important because, if/when\r\n  the microzap needs to be upgraded to fatzap, all the entries with the same hash would need to\r\n  fit into the same leaf-block (16K). If the number of such entries donot fit fail the zap_add().\r\n  \r\n   The routine mze_canfit_fzap_leaf() today assumes the MZAP_NAME_LEN for every entry.\r\n   This is erring on the safer side but, ends up accommodating lesser number (127) of entries\r\n    with same hash value in microzap. We could find out the size of name of every mze and that\r\n    would be accurate. But, it is expensive to compute the length every time. Alternatively, we\r\n    could compute the length of each entry and cache it. I felt that the amount of code needed\r\n    for this is not worth the gain. I am open to changing it if necessary.\r\n\r\n- zfs_link_create() : Move the call to zap_add() to the beginning and in case of a failure\r\n  return. This ensures that we can bailout easily before making any other modifications to\r\n  the parent-zap or the child-dnode. Keeps the code simpler.\r\n- ZPL interfaces (zfs_create(), zfs_mkdir(), zfs_symlink()) : Handle the failure of zfs_link_create()\r\n  and rollback the operation.\r\n\r\nWith these changes a call to create a file could fail with ENOSPC. Not the best error value.\r\nBut, this is the closest I found. Any alternate suggestions are welcome.\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\nWith \"casesensitivity=mixed\" it is easy to panic the node with a simple test case\r\nas described in https://github.com/zfsonlinux/zfs/issues/7011\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\nThe following tests were run : \r\n- zfs-testsuite\r\n- ztest\r\n- Unit-test described in the #7011 \r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [x] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "woffs": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7003", "title": "autoreplace = on, but spare not automatically activated on drive error", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Debian\r\nDistribution Version    | Stretch (9)\r\nLinux Kernel                 | 4.9.51\r\nArchitecture                 | x86_64\r\nZFS Version                  | 0.7.3\r\nSPL Version                  | 0.7.3\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\n \r\nA disk was failing, zed reported errors ...\r\n\r\n```\r\nZFS has detected that a device was removed.\r\n\r\n impact: Fault tolerance of the pool may be compromised.\r\n    eid: 71656\r\n  class: statechange\r\n  state: REMOVED\r\n   host: inferno\r\n   time: 2017-12-29 19:57:19+0100\r\n  vpath: /dev/disk/by-vdev/E2-part1\r\n  vguid: 0x8F23CA44FDEBE82C\r\n   pool: 0x83BBC476EFE065A2\r\n```\r\n\r\n```\r\nThe number of I/O errors associated with a ZFS device exceeded\r\nacceptable levels. ZFS has marked the device as faulted.\r\n\r\n impact: Fault tolerance of the pool may be compromised.\r\n    eid: 71662\r\n  class: statechange\r\n  state: FAULTED\r\n   host: inferno\r\n   time: 2017-12-29 19:57:19+0100\r\n  vpath: /dev/disk/by-vdev/E2-part1\r\n  vguid: 0x8F23CA44FDEBE82C\r\n   pool: 0x83BBC476EFE065A2\r\n```\r\n\r\n... but the spare was not activated automatically, although the autoreplace property was set to `on`.\r\n\r\n```\r\n        inferno# zpool status\r\n  [...]\r\n                pool: torx\r\n         state: DEGRADED\r\n        status: One or more devices are faulted in response to persistent errors.\r\n                Sufficient replicas exist for the pool to continue functioning in a\r\n                degraded state.\r\n        action: Replace the faulted device, or use 'zpool clear' to mark the device\r\n                repaired.\r\n                scan: scrub repaired 0B in 188h32m with 0 errors on Sun Dec 17 20:56:54 2017\r\n        config:\r\n\r\n                NAME        STATE     READ WRITE CKSUM\r\n                torx        DEGRADED     0     0     0\r\n                        raidz2-0  DEGRADED     0     0     0\r\n                                E0      ONLINE       0     0     0\r\n                                E1      ONLINE       0     0     0\r\n                                E2      FAULTED      0     0     0  too many errors\r\n                                E3      ONLINE       0     0     0\r\n                                E4      ONLINE       0     0     0\r\n                                E5      ONLINE       0     0     0\r\n                                E6      ONLINE       0     0     0\r\n                                E7      ONLINE       0     0     0\r\n                                E8      ONLINE       0     0     0\r\n                                E9      ONLINE       0     0     0\r\n                spares\r\n                        EA        AVAIL\r\n\r\n        errors: No known data errors\r\n```\r\n\r\nAfter manually issuing `zpool replace torx E2 EA` the resilver to the spare started.\r\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7003/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "krichter722": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7002", "title": "\"VERIFY3(range_tree_space(rt) == space) failed\" after I/O freeze", "body": "### System information\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Ubuntu\r\nDistribution Version    | 17.10\r\nLinux Kernel                 | 4.13.0-21-generic\r\nArchitecture                 | amd64\r\nZFS Version                  | 0.7.0-227_g823d48bfb\r\nSPL Version                  | 0.7.0-22_gc9821f1c\r\n\r\n### Describe the problem you're observing\r\nMy pool consisting of 1 HDD vdev and 1 SSD cache and 1 SSD log device experienced an I/O freeze under heavy load including heavy dedup action (parallel checkout and building of Firefox on docker images) where all commands doing I/O on the pool switched to uninterruptible state and no I/O occured anymore according to `iotop`.\r\n\r\nAfter starting the machine again I'm no longer able to import the pool because the `zpool import` command never returns and after a few seconds of reading a few 100 MB the I/O stops and the stack below is printed in `dmesg`.\r\n\r\nA readonly import is possible. `zfs set mountpoint=none data/docker` fails due to `internal error: out of memory` immediately without any noticable memory issues.\r\n\r\n### Describe how to reproduce the problem\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\nThe I/O freeze was caused by\r\n\r\n```\r\n[27969.280956] VERIFY3(range_tree_space(rt) == space) failed (6922371072 == 6922383360)\r\n[27969.280960] PANIC at space_map.c:127:space_map_load()\r\n[27969.280961] Showing stack for process 13639\r\n[27969.280963] CPU: 5 PID: 13639 Comm: z_wr_iss Tainted: P        W  OE   4.13.0-21-generic #24-Ubuntu\r\n[27969.280964] Hardware name: LENOVO 20221/INVALID, BIOS 71CN51WW(V1.21) 07/12/2013\r\n[27969.280964] Call Trace:\r\n[27969.280970]  dump_stack+0x63/0x8b\r\n[27969.280979]  spl_dumpstack+0x42/0x50 [spl]\r\n[27969.280982]  spl_panic+0xc8/0x110 [spl]\r\n[27969.280985]  ? kmem_cache_free+0x197/0x1c0\r\n[27969.280988]  ? avl_add+0x65/0xb0 [zavl]\r\n[27969.281027]  ? rt_avl_add+0x11/0x20 [zfs]\r\n[27969.281054]  ? range_tree_add_impl+0x2f5/0x440 [zfs]\r\n[27969.281078]  ? dnode_rele+0x39/0x40 [zfs]\r\n[27969.281108]  space_map_load+0x470/0x4f0 [zfs]\r\n[27969.281109]  ? avl_nearest+0x2b/0x30 [zavl]\r\n[27969.281136]  metaslab_load+0x36/0xf0 [zfs]\r\n[27969.281162]  metaslab_activate+0x93/0xc0 [zfs]\r\n[27969.281186]  metaslab_alloc+0x4b9/0x1170 [zfs]\r\n[27969.281217]  zio_dva_allocate+0xac/0x630 [zfs]\r\n[27969.281245]  ? zio_execute+0x8a/0xf0 [zfs]\r\n[27969.281274]  ? vdev_config_sync+0x180/0x180 [zfs]\r\n[27969.281301]  ? vdev_mirror_io_start+0xa4/0x180 [zfs]\r\n[27969.281305]  ? tsd_hash_search.isra.3+0x47/0xa0 [spl]\r\n[27969.281308]  ? tsd_get_by_thread+0x2e/0x40 [spl]\r\n[27969.281311]  ? taskq_member+0x18/0x30 [spl]\r\n[27969.281340]  zio_execute+0x8a/0xf0 [zfs]\r\n[27969.281343]  taskq_thread+0x2aa/0x4d0 [spl]\r\n[27969.281345]  ? wake_up_q+0x80/0x80\r\n[27969.281373]  ? zio_reexecute+0x3e0/0x3e0 [zfs]\r\n[27969.281375]  kthread+0x125/0x140\r\n[27969.281378]  ? taskq_thread_should_stop+0x70/0x70 [spl]\r\n[27969.281379]  ? kthread_create_on_node+0x70/0x70\r\n[27969.281382]  ret_from_fork+0x25/0x30\r\n```\r\nwhich I captured before having to shutdown the machine with the power button. After every reboot the import fails due to\r\n\r\n```\r\n[  274.685568]  dump_stack+0x63/0x8b\r\n[  274.685575]  spl_dumpstack+0x42/0x50 [spl]\r\n[  274.685578]  spl_panic+0xc8/0x110 [spl]\r\n[  274.685581]  ? kmem_cache_free+0x197/0x1c0\r\n[  274.685583]  ? avl_add+0x65/0xb0 [zavl]\r\n[  274.685619]  ? rt_avl_add+0x11/0x20 [zfs]\r\n[  274.685645]  ? range_tree_add_impl+0x2f5/0x440 [zfs]\r\n[  274.685667]  ? dnode_rele+0x39/0x40 [zfs]\r\n[  274.685694]  space_map_load+0x470/0x4f0 [zfs]\r\n[  274.685720]  metaslab_load+0x36/0xf0 [zfs]\r\n[  274.685743]  metaslab_activate+0x93/0xc0 [zfs]\r\n[  274.685766]  metaslab_alloc+0x4b9/0x1170 [zfs]\r\n[  274.685794]  zio_dva_allocate+0xac/0x630 [zfs]\r\n[  274.685795]  ? mutex_lock+0x12/0x40\r\n[  274.685799]  ? tsd_hash_search.isra.3+0x47/0xa0 [spl]\r\n[  274.685802]  ? tsd_get_by_thread+0x2e/0x40 [spl]\r\n[  274.685805]  ? taskq_member+0x18/0x30 [spl]\r\n[  274.685832]  zio_execute+0x8a/0xf0 [zfs]\r\n[  274.685835]  taskq_thread+0x2aa/0x4d0 [spl]\r\n[  274.685837]  ? wake_up_q+0x80/0x80\r\n[  274.685864]  ? zio_reexecute+0x3e0/0x3e0 [zfs]\r\n[  274.685865]  kthread+0x125/0x140\r\n[  274.685869]  ? taskq_thread_should_stop+0x70/0x70 [spl]\r\n[  274.685870]  ? kthread_create_on_node+0x70/0x70\r\n[  274.685871]  ret_from_fork+0x25/0x30\r\n```\r\nalso after a successful readonly import.", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7002/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "redzhang1990": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6995", "title": "Can ZFS support numa binding?", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Redhat\r\nDistribution Version    | 7.4\r\nLinux Kernel                 | 4.11.0\r\nArchitecture                 | ARM\r\nZFS Version                  | 0.7.1\r\nSPL Version                  | 0.7.1\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\nCan the ZFS support or willing support numa binding?\r\n### Describe how to reproduce the problem\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n<!-- \r\n*IMPORTANT* - Please mark logs and text output from terminal commands \r\nor else Github will not display them correctly. \r\nAn example is provided below.\r\n\r\nExample:\r\n```\r\n```\r\n-->\r\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6995/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "fejesjoco": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6994", "title": "Documentation of ACLs should be fixed", "body": "There are issues in the manpage of zfs(8).\r\n\r\naclinherit talks about ACEs, acltype talks about ACLs, this is inconsistent.\r\n\r\naclinherit doesn't mention what kind of ACEs it's talking about. Since neither regular file permission bits not POSIX ACLs have write_acl/write_owner, this must be NFSv4. So that should be mentioned here explicitly.\r\n\r\nacltype has two values. Again this doesn't say what it's talking about and one can only guess. Does \"off\" turn off both NFSv4 and POSIX ACLs, or just POSIX? Does \"posixacl\" enable both NFSv4 and POSIX, or only POSIX? I can even read it in a way that I can either have POSIX ACLs or no ACLs, which would mean NFSv4 ACLs are not even supported under Linux.\r\n\r\nThe source code has many mentions of an aclmode property but this is not documented anywhere.\r\n\r\nSince the document talks about multiple ACL types, it might be worth mentioning if regular file permission bits work as usual or not (this is especially interesting across dataset mount boundaries).\r\n\r\nIf you can confirm these points, I can volunteer to send a PR.", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6994/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "dechamps": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6988", "title": "zil_itx_needcopy_bytes kstat counter is corrupted", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Debian\r\nDistribution Version    | Unstable\r\nLinux Kernel                 | 4.13.0-1-amd64\r\nArchitecture                 | amd64\r\nZFS Version                  | 0.7.3-3\r\nSPL Version                  | 0.7.3-1\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\n\r\n```\r\n$ cat /proc/spl/kstat/zfs/zil\r\n15 1 0x01 13 624 31503034653 382758011634377\r\nname                            type data\r\nzil_commit_count                4    197902\r\nzil_commit_writer_count         4    197884\r\nzil_itx_count                   4    611431070\r\nzil_itx_indirect_count          4    0\r\nzil_itx_indirect_bytes          4    0\r\nzil_itx_copied_count            4    0\r\nzil_itx_copied_bytes            4    0\r\nzil_itx_needcopy_count          4    611266365\r\nzil_itx_needcopy_bytes          4    18446744072731425348\r\nzil_itx_metaslab_normal_count   4    0\r\nzil_itx_metaslab_normal_bytes   4    0\r\nzil_itx_metaslab_slog_count     4    1169526\r\nzil_itx_metaslab_slog_bytes     4    140983216376\r\n```\r\n\r\nThe `zil_itx_needcopy_bytes` counter is blatantly wrong - I'm pretty sure I did not write 16 exabytes of data in that pool :) Its value is quite close to `UINT64_MAX`, which suggests some kind of overflow or memory corruption.\r\n\r\n### Describe how to reproduce the problem\r\n\r\nNot sure. However I can tell that it started after I did a system upgrade, which included the following version changes:\r\n\r\n- Kernel: 4.12 \u2192 4.13\r\n- SPL: 0.6.5 \u2192 0.7.3\r\n- ZFS: 0.6.5 \u2192 0.7.3\r\n\r\nFor this reason I suspect this might be a regression introduced between SPL/ZFS 0.6.5 and SPL/ZFS 0.7.3.\r\n\r\nThis issue might seem benign, but in my case it's really not because it prevents [Prometheus Node exporter](https://github.com/prometheus/node_exporter) from exporting ZFS metrics correctly. Here's the log message from the node exporter in an attempt to make this issue easier to search for:\r\n\r\n```\r\ntime=\"2017-12-20T22:32:39Z\" level=error msg=\"ERROR: zfs collector failed after 0.000693s: could not parse expected integer value for \\\"kstat.zfs.misc.zil.zil_itx_needcopy_bytes\\\"\" source=\"node_exporter.go:95\"\r\n```", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6988/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374490", "body": "Hmmm\u2026 in fact this line is supposed to be in pull request #384. Seems like I seriously screwed up while doing the merges: all my pull requests show the same commits. What a mess\u2026 git is new to me, I guess this was bound to happen. There should be only one commit in this pull request: 90e1b2108f3b8fd3d2b92bdaa4775fe2321cffa3, so if you're just interested in ZVOL synchronicity, you should check it out. I'm not sure how to fix this, I guess I'll have to recreate the pull requests.\n\nFYI, in the context of #384, this comment means that maybe the discard operation should be added to the log. This is not very important since losing discard operations cannot result in data corruption.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374490/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374498", "body": "That's what I did, basically; the problem is, when updating my master branch from upstream I guessed it would be a good idea to also update individual pull request branches from my master branch. Alas, it was a very bad idea, because my master branch add commits from all my pull requests, so by merging master into each pull request, I merged all commits from all pull requests into each pull request, hence the mess. In the future I'll just let my pull requests alone when I'm done with them.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374498/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374511", "body": "I never commited anything to my master branch, just merges. I wrote the pull request's code into the appropriate pull request branches, as I should. The issue is, I was merging master into my pull requests without realizing what I was doing. The solution is to stop doing that. I just emailed Brian so that we decide what to do about the already messed up pull requests.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374511/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}, "ScaMar": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6985", "title": "\"space map refcount mismatch\" on never used zpool after reboot", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       |  Ubuntu\r\nDistribution Version    |  LTS 16.04.03\r\nLinux Kernel                 |  4.4.0-104-generic\r\nArchitecture                 |  x86_64\r\nZFS Version                  |  0.6.5.6\r\nSPL Version                  |  0.6.5.6\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\n\r\nHi all,\r\non my live zpool i've found the \"space map refcount mismatch\" (error? warning?).\r\nBecause the pool wasn't too big, i've copied data on an external storage, so i've destroyes the zpool then i've recreated it.\r\nI've execute \"zdb <pool>\" and it was ok. After the first reboot (no data were copied/created on zpool), i've executed \"zdb <pool>\" again and i've found the message \"space map refcount mismatch\".\r\n\r\nI've destroyed - recreated the pool several times, always i got the \"space map refcount mismatch\".\r\nEach time before reboot i've tried something like \"zfs unmount <pool>\".\r\nI think the message is related to the first zpool.cache creation.\r\nAfter i've deleted the zpool.cache, the error was not present after the reboot.\r\n\r\nSo my problem are these lines in the zdb output:\r\n```\r\nspace map refcount mismatch: expected 11 != actual 5\r\n```\r\n\r\n### Describe how to reproduce the problem\r\nInstall Ubuntu 16.04. Update it. Create a zpool. Reboot.\r\n\r\n### Questions, considerations, any suggestions?\r\nAbout such issue, i have some questions:\r\n\r\n1) Is it something i need to worry about?\r\n2) Is there a way to recalculate/rebuild space map?\r\n\r\nThere are similar issues about such message someone wrote \"It is a problem in claiming empty space\", some other wrote \"This situation may lead to data corruption\", \"Ignore it if the delta beetwen refcount and space is fixed (if not?)\".\r\nMay we have a clear/human about the consequencies of this error / warning?\r\n\r\nThe only think i know, and sincerily i don't understand a single line (my fault, i'm not a coder), this is the line of code where the counts are compared:\r\n```\r\nstatic int\r\nverify_spacemap_refcounts(spa_t *spa)\r\n{\r\n\tuint64_t expected_refcount = 0;\r\n\tuint64_t actual_refcount;\r\n\r\n\t(void) feature_get_refcount(spa,\r\n\t    &spa_feature_table[SPA_FEATURE_SPACEMAP_HISTOGRAM],\r\n\t    &expected_refcount);\r\n\tactual_refcount = get_dtl_refcount(spa->spa_root_vdev);\r\n\tactual_refcount += get_metaslab_refcount(spa->spa_root_vdev);\r\n\r\n\tif (expected_refcount != actual_refcount) {\r\n\t\t(void) printf(\"space map refcount mismatch: expected %lld != \"\r\n\t\t    \"actual %lld\\n\",\r\n\t\t    (longlong_t)expected_refcount,\r\n\t\t    (longlong_t)actual_refcount);\r\n\t\treturn (2);\r\n\t}\r\n\treturn (0);\r\n}\r\n```\r\nPlease let me know if i must worry about this, so i can evaluate other ways to achieve my personal storage:\r\n1) linux with btrfs\r\n2) OpenIndiana/FreeBSD with ZFS\r\n3) Old but stable md / lvm / xfs (i will risk the cosmic ray bitrotter...)\r\n\r\nThank you,\r\nMarco\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n<!-- \r\n*IMPORTANT* - Please mark logs and text output from terminal commands \r\nor else Github will not display them correctly. \r\nAn example is provided below.\r\n\r\nExample:\r\n```\r\nthis is an example how log text should be marked (wrap it with ```)\r\n```\r\n-->\r\n\r\n\r\n[zdbout.newcreated.txt](https://github.com/zfsonlinux/zfs/files/1571863/zdbout.newcreated.txt)\r\n[zdbout.firstreboot.txt](https://github.com/zfsonlinux/zfs/files/1571864/zdbout.firstreboot.txt)\r\n```\r\nHistory for 'magazzino':\r\n2017-12-19.13:28:20 zpool create magazzino mirror /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K0KA3UYK /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K7NF5E20\r\n2017-12-19.13:28:21 zpool add magazzino mirror /dev/disk/by-id/ata-WDC_WD30EFRX-68EUZN0_WD-WCC4N7UUHR2X /dev/disk/by-id/ata-WDC_WD30EFRX-68EUZN0_WD-WCC4N3CHVS8X\r\n2017-12-19.13:28:22 zpool add magazzino cache /dev/disk/by-id/ata-KINGSTON_SUV400S37120G_50026B77720127CB-part5 /dev/disk/by-id/ata-KINGSTON_SUV400S37120G_50026B776B0175F0-part5\r\n2017-12-19.13:28:22 zpool add magazzino log mirror /dev/disk/by-id/ata-KINGSTON_SUV400S37120G_50026B77720127CB-part6 /dev/disk/by-id/ata-KINGSTON_SUV400S37120G_50026B776B0175F0-part6\r\n2017-12-19.13:28:22 zfs create magazzino/video\r\n2017-12-19.13:28:22 zfs create magazzino/foto\r\n2017-12-19.13:28:23 zfs create magazzino/owncloud\r\n2017-12-19.13:28:29 zpool scrub magazzino\r\n```\r\n--> deleted /etc/zfs/zpool.cache\r\n--> reboot\r\n```\r\n2017-12-19.13:31:24 zpool import -d /dev/disk/by-id -aN\r\n```\r\n--> new reboot withouth deleting zpool.cache\r\n```\r\n2017-12-19.13:37:03 zpool import -c /etc/zfs/zpool.cache -aN\r\n```\r\n--> another reboot withouth deleting zpool.cache\r\n```\r\n2017-12-19.13:41:01 zpool import -c /etc/zfs/zpool.cache -aN\r\n```\r\n\r\n\r\n\r\n\r\n\r\n\r\n ", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6985/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "samis": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6984", "title": "zpool property 'freeing' partially stuck", "body": "### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Gentoo\r\nDistribution Version    | Profile 17.0\r\nLinux Kernel                 | 4.14.5-gentoo\r\nArchitecture                 | X86_64\r\nZFS Version                  | 0.7.0-211_g4e9b1569\r\nSPL Version                  | 0.7.0-21_ged19bcc\r\n\r\n\r\n### Describe the problem you're observing\r\nI recently decided to clean up and delete two unused sparse zvols. After this, the freeing property increased as expected and did initially decrease. However, it's almost 24 hours (and two reboots) later and the property is still reporting the exact same value. \r\n\r\nAs a test, I filled a zvol with 1G of /dev/urandom and then destroyed it. The property increased from it's original value of 14353956864 to 14605664256 but shortly afterwards the data was freed and the value was back to 14353956864. This is similar to #5808 but both the scenario and the behaviour appear to be different, as neither zvol was ever used for NFS purposes.\r\n### Describe how to reproduce the problem\r\nI have not yet reproduced this beyond the above test. I can't be certain that the freeing value was correct before, but the timing seems right for this issue.\r\n### Include any warning/errors/backtraces from the system logs\r\nSo far there have been no warnings, errors or backtraces created as a result of this problem. \r\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6984/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "kithrup": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/43cb30b3ce6ee3c3041276c93594ae61e7daaf86", "message": "OpenZFS 8959 - Add notifications when a scrub is paused or resumed\n\nAuthored by: Sean Eric Fagan <sef@ixsystems.com>\nReviewed by: Alek Pinchuk <pinchuk.alek@gmail.com>\nReviewed by: Matthew Ahrens <mahrens@delphix.com>\nReviewed-by: George Melikov <mail@gmelikov.ru>\nReviewed-by: Tony Hutter <hutter2@llnl.gov>\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\nApproved by: Gordon Ross <gwr@nexenta.com>\nPorted-by: Giuseppe Di Natale <dinatale2@llnl.gov>\n\nPorting Notes:\n- Brought #defines in eventdefs.h in line with ZFS on Linux format.\n- Updated zfs-events.5 with the new events.\n\nOpenZFS-issue: https://www.illumos.org/issues/8959\nOpenZFS-commit: https://github.com/openzfs/openzfs/commit/c862b93eea\nCloses #7049"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "DeHackEd": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/d658b2caa95726c13d99123874910cdedc7ce866", "message": "Remove l2arc_nocompress from zfs-module-parameters(5)\n\nParameter was removed in d3c2ae1c0806\r\n(OpenZFS 6950 - ARC should cache compressed data)\r\n\r\nReviewed by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: DHE <git@dehacked.net>\r\nCloses #7043"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/460f239e6999195dbcf9b8443c029f07765b21e9", "message": "Fix -fsanitize=address memory leak\n\nkmem_alloc(0, ...) in userspace returns a leakable pointer.\n\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\nSigned-off-by: DHE <git@dehacked.net>\nIssue #6941"}], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6673", "title": "Fail importing if cached config has wrong number of vdev children", "body": "During import compare the labels' configs with the import config\r\nand fail if the labels indicate more vdevs than the cached config\r\n\r\nSigned-off-by: DHE <git@dehacked.net>\r\nFixes #6671\r\n\r\n### Description\r\nWhen the zpool.cache says `vdev_children=X` but the pool actually has `vdev_children=Y` where `X<Y`, blkptr errors will occur during the import process. We detect this specific case and refuse imports from this cache file.\r\n\r\n### Motivation and Context\r\nSee #6671\r\n\r\n### How Has This Been Tested?\r\n`ztest` only\r\n\r\n### Types of changes\r\n- [X] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n- [X] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [ ] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [X] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "prometheanfire": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/c10cdcb55f81ea773486161b31bc91bb7b58b4c8", "message": "Fix copy-builtin to work with ASAN patch\n\nCommit fed90353 didn't fully update the copy-builtin script\r\nas needed to perform in-kernel builds.  Add the missing\r\noptions and flags.\r\n\r\nReviewed by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: Matthew Thode <mthode@mthode.org>\r\nCloses #7033 \r\nCloses #7037"}], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/7008", "title": "DNM: make zfs-mount service work with encryption", "body": "", "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/7004", "title": "Run zfs load-key if needed in dracut", "body": "'zfs load-key -a' will only be called if needed.  If a dataset not\r\nneeded for boot does not have it's key loaded (home directories for\r\nexample) boot can still continue.", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "yuripv": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/6df9f8ebd73c05da627144bcc3823e6fe980cd75", "message": "OpenZFS 8899 - zpool list property documentation doesn't match actual behaviour\n\nAuthored by: Yuri Pankov <yuri.pankov@nexenta.com>\nReviewed by: Alexander Pyhalov <alp@rsu.ru>\nReviewed-by: George Melikov <mail@gmelikov.ru>\nApproved by: Dan McDonald <danmcd@joyent.com>\nPorted-by: Brian Behlendorf <behlendorf1@llnl.gov>\n\nOpenZFS-issue: https://www.illumos.org/issues/8899\nOpenZFS-commit: https://github.com/openzfs/openzfs/commit/b0e142e57d\nCloses #7032"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/bcb1a8a25e4ee9a94478378710de53b45a9b1517", "message": "OpenZFS 8898 - creating fs with checksum=skein on the boot pools fails ungracefully\n\nAuthored by: Yuri Pankov <yuri.pankov@nexenta.com>\nReviewed by: Toomas Soome <tsoome@me.com>\nReviewed by: Andy Stormont <astormont@racktopsystems.com>\nReviewed-by: George Melikov <mail@gmelikov.ru>\nApproved by: Dan McDonald <danmcd@joyent.com>\nPorted-by: Brian Behlendorf <behlendorf1@llnl.gov>\n\nOpenZFS-issue: https://www.illumos.org/issues/8898\nOpenZFS-commit: https://github.com/openzfs/openzfs/commit/9fa2266d9a\nCloses #7031"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/8198c57b21d5e503f7e72221aa714aaabb2079cc", "message": "OpenZFS 8897 - zpool online -e fails assertion when run on non-leaf vdevs\n\nAuthored by: Yuri Pankov <yuri.pankov@nexenta.com>\nReviewed by: Toomas Soome <tsoome@me.com>\nReviewed by: Igor Kozhukhov <igor@dilos.org>\nReviewed-by: George Melikov <mail@gmelikov.ru>\nApproved by: Dan McDonald <danmcd@joyent.com>\nPorted-by: Brian Behlendorf <behlendorf1@llnl.gov>\n\nOpenZFS-issue: https://www.illumos.org/issues/8897\nOpenZFS-commit: https://github.com/openzfs/openzfs/commit/9a551dd645\nCloses #7030"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "avg-I": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/6a2185660d000c99b14556c7eb1108c5609faf41", "message": "OpenZFS 8930 - zfs_zinactive: do not remove the node if the filesystem is readonly\n\nAuthored by: Andriy Gapon <avg@FreeBSD.org>\nReviewed by: Matthew Ahrens <mahrens@delphix.com>\nReviewed-by: George Melikov <mail@gmelikov.ru>\nApproved by: Gordon Ross <gwr@nexenta.com>\nPorted-by: Brian Behlendorf <behlendorf1@llnl.gov>\n\nOpenZFS-issue: https://www.illumos.org/issues/8930\nOpenZFS-commit: https://github.com/openzfs/openzfs/commit/93c618e0f4\nCloses #7029"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ryao": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/1d53657bf561564162e2ad6449f80fa0140f1dd6", "message": "Fix incompatibility with Reiser4 patched kernels\n\nIn ZFSOnLinux, our sources and build system are self contained such that\r\nwe do not need to make changes to the Linux kernel sources. Reiser4 on\r\nthe other hand exists solely as a kernel tree patch and opts to make\r\nchanges to the kernel rather than adapt to it. After Linux 4.1 made a\r\nVFS change that replaced new_sync_read with do_sync_read, Reiser4's\r\nmaintainer decided to modify the kernel VFS to export the old function.\r\nThis caused our autotools check to misidentify the kernel API as\r\npredating Linux 4.1 on kernels that have been patched with Reiser4\r\nsupport, which breaks our build.\r\n\r\nReiser4 really should be patched to stop doing this, but lets modify our\r\ncheck to be more strict to help the affected users of both filesystems.\r\n\r\nAlso, we were not checking the types of arguments and return value of\r\nnew_sync_read() and new_sync_write() . Lets fix that too.\r\n\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nReviewed-by: Giuseppe Di Natale <dinatale2@llnl.gov>\r\nReviewed-by: George Melikov <mail@gmelikov.ru>\r\nSigned-off-by: Richard Yao <ryao@gentoo.org>\r\nCloses #6241 \r\nCloses #7021"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "nwf": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/cba6fc61a2898395c47380a0c2303f19842a2ff0", "message": "Revert raidz_map and _col structure types\n\nAs part of the refactoring of ab9f4b0b824ab4cc64a4fa382c037f4154de12d6,\r\nseveral uint64_t-s and uint8_t-s were changed to other types.  This\r\ncaused ZoL github issue #6981, an overflow of a size_t on a 32-bit ARM\r\nmachine.  In absense of any strong motivation for the type changes, this\r\nsimply puts them back, modulo the changes accumulated for ABD.\r\n\r\nCompile-tested on amd64 and run-tested on armhf.\r\n\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nReviewed-by: Gvozden Neskovic <neskovic@gmail.com>\r\nSigned-off-by: Nathaniel Wesley Filardo <nwf@cs.jhu.edu>\r\nCloses #6981 \r\nCloses #7023"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/8b20a9f996b90abe439ce14303fc440f26390e38", "message": "zhack: fix getopt return type\n\nThis fixes zhack's command processing on ARM.  On ARM char\r\nis unsigned, and so, in promotion to an int, it will never\r\ncompare equal to -1.\r\n\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: Nathaniel Wesley Filardo <nwf@cs.jhu.edu>\r\nCloses #7016"}], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6209", "title": "[RFC] new zscrub command for offline scrubs in userland", "body": "### Description\r\n\r\nThis PR adds a \"zhack scrub\" subcommand which, in user-land, finds and scrubs a pool.  This has proven useful for experimenting with the scan logic (especially the in-order-scrub patches) without having to reload the kernel module and seems like it may be useful to others.\r\n\r\nAt this point, it is not yet ready to merge -- there are no tests, no docs, &c... but I am curious for anyone's commentary and/or suggestions. :)\r\n\r\n### How Has This Been Tested?\r\n\r\nLimited testing against both files and actual block-device-backed pools.  Scrubs and resilvers appear to work just fine.\r\n\r\n### Types of changes\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [ ] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "gamanakis": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/be54a13c3e7db423ffdb3f7983d4dd1141cc94a0", "message": "Fix percentage styling in zfs-module-parameters.5\n\nReplace \"percent\" with \"%\", add bold to default values.\r\n\r\nReviewed-by: bunder2015 <omfgbunder@gmail.com>\r\nReviewed-by: George Melikov <mail@gmelikov.ru>\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: George Amanakis <gamanakis@gmail.com>\r\nCloses #7018"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "loli10K": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/390d679acdfa6a2498280a4dcd33b7600ace27ce", "message": "Fix 'zpool add' handling of nested interior VDEVs\n\nWhen replacing a faulted device which was previously handled by a spare\r\nmultiple levels of nested interior VDEVs will be present in the pool\r\nconfiguration; the following example illustrates one of the possible\r\nsituations:\r\n\r\n   NAME                          STATE     READ WRITE CKSUM\r\n   testpool                      DEGRADED     0     0     0\r\n     raidz1-0                    DEGRADED     0     0     0\r\n       spare-0                   DEGRADED     0     0     0\r\n         replacing-0             DEGRADED     0     0     0\r\n           /var/tmp/fault-dev    UNAVAIL      0     0     0  cannot open\r\n           /var/tmp/replace-dev  ONLINE       0     0     0\r\n         /var/tmp/spare-dev1     ONLINE       0     0     0\r\n       /var/tmp/safe-dev         ONLINE       0     0     0\r\n   spares\r\n     /var/tmp/spare-dev1         INUSE     currently in use\r\n\r\nThis is safe and allowed, but get_replication() needs to handle this\r\nsituation gracefully to let zpool add new devices to the pool.\r\n\r\nReviewed-by: George Melikov <mail@gmelikov.ru>\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: loli10K <ezomori.nozomu@gmail.com>\r\nCloses #6678 \r\nCloses #6996"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/c4ba46deade0a14d089228a56a5d0aa0ffd5fadd", "message": "Handle invalid options in arc_summary\n\nIf an invalid option is provided to arc_summary.py we handle any error\r\nthrown from the getopt Python module and print the usage help message.\r\n\r\nReviewed-by: George Melikov <mail@gmelikov.ru>\r\nReviewed-by: Giuseppe Di Natale <dinatale2@llnl.gov>\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: loli10K <ezomori.nozomu@gmail.com>\r\nCloses #6983"}], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/7058", "title": "Fix Debian packaging on ARMv7/ARM64", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\n\r\nWhen building packages on Debian-based systems specify the target architecture used by `alien` to convert .rpm packages into .deb: this avoids detecting an incorrect value which results in the following errors:\r\n\r\n```\r\n<package>.aarch64.rpm is for architecture aarch64 ; the package cannot be built on this system\r\n<package>.armv7l.rpm is for architecture armel ; the package cannot be built on this system\r\n```\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\nFix https://github.com/zfsonlinux/zfs/issues/7046\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\nTested on a local aarch64 and armhf debootstrapped rootfs\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "prakashsurya": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/2fe61a7ecc507d031451c21b3077fae549b58ec3", "message": "OpenZFS 8909 - 8585 can cause a use-after-free kernel panic\n\nAuthored by: Prakash Surya <prakash.surya@delphix.com>\nReviewed by: John Kennedy <jwk404@gmail.com>\nReviewed by: Matthew Ahrens <mahrens@delphix.com>\nReviewed by: George Wilson <george.wilson@delphix.com>\nReviewed by: Brad Lewis <brad.lewis@delphix.com>\nReviewed by: Igor Kozhukhov <igor@dilos.org>\nReviewed by: Brian Behlendorf <behlendorf1@llnl.gov>\nApproved by: Robert Mustacchi <rm@joyent.com>\nPorted-by: Prakash Surya <prakash.surya@delphix.com>\n\nPROBLEM\n=======\n\nThere's a race condition that exists if `zil_free_lwb` races with either\n`zil_commit_waiter_timeout` and/or `zil_lwb_flush_vdevs_done`.\n\nHere's an example panic due to this bug:\n\n    > ::status\n    debugging crash dump vmcore.0 (64-bit) from ip-10-110-205-40\n    operating system: 5.11 dlpx-5.2.2.0_2017-12-04-17-28-32b6ba51fb (i86pc)\n    image uuid: 4af0edfb-e58e-6ed8-cafc-d3e9167c7513\n    panic message:\n    BAD TRAP: type=e (#pf Page fault) rp=ffffff0010555970 addr=60 occurred in module \"zfs\" due to a NULL pointer dereference\n    dump content: kernel pages only\n\n    > $c\n    zio_shrink+0x12()\n    zil_lwb_write_issue+0x30d(ffffff03dcd15cc0, ffffff03e0730e20)\n    zil_commit_waiter_timeout+0xa2(ffffff03dcd15cc0, ffffff03d97ffcf8)\n    zil_commit_waiter+0xf3(ffffff03dcd15cc0, ffffff03d97ffcf8)\n    zil_commit+0x80(ffffff03dcd15cc0, 9a9)\n    zfs_write+0xc34(ffffff03dc38b140, ffffff0010555e60, 40, ffffff03e00fb758, 0)\n    fop_write+0x5b(ffffff03dc38b140, ffffff0010555e60, 40, ffffff03e00fb758, 0)\n    write+0x250(42, fffffd7ff4832000, 2000)\n    sys_syscall+0x177()\n\nIf there's an outstanding lwb that's in `zil_commit_waiter_timeout`\nwaiting to timeout, waiting on it's waiter's CV, we must be sure not to\ncall `zil_free_lwb`. If we end up calling `zil_free_lwb`, then that LWB\nmay be freed and can result in a use-after-free situation where the\nstale lwb pointer stored in the `zil_commit_waiter_t` structure of the\nthread waiting on the waiter's CV is used.\n\nA similar situation can occur if an lwb is issued to disk, and thus in\nthe `LWB_STATE_ISSUED` state, and `zil_free_lwb` is called while the\ndisk is servicing that lwb. In this situation, the lwb will be freed by\n`zil_free_lwb`, which will result in a use-after-free situation when the\nlwb's zio completes, and `zil_lwb_flush_vdevs_done` is called.\n\nThis race condition is prevented in `zil_close` by calling `zil_commit`\nbefore `zil_free_lwb` is called, which will ensure all outstanding (i.e.\nall lwb's in the `LWB_STATE_OPEN` and/or `LWB_STATE_ISSUED` states)\nreach the `LWB_STATE_DONE` state before the lwb's are freed\n(`zil_commit` will not return untill all the lwb's are\n`LWB_STATE_DONE`).\n\nFurther, this race condition is prevented in `zil_sync` by only calling\n`zil_free_lwb` for lwb's that do not have their `lwb_buf` pointer set.\nAll lwb's not in the `LWB_STATE_DONE` state will have a non-null value\nfor this pointer; the pointer is only cleared in\n`zil_lwb_flush_vdevs_done`, at which point the lwb's state will be\nchanged to `LWB_STATE_DONE`.\n\nThis race *is* present in `zil_suspend`, leading to this bug.\n\nAt first glance, it would appear as though this would not be true\nbecause `zil_suspend` will call `zil_commit`, just like `zil_close`, but\nthe problem is that `zil_suspend` will set the zilog's `zl_suspend`\nfield prior to calling `zil_commit`. Further, in `zil_commit`, if\n`zl_suspend` is set, `zil_commit` will take a special branch of logic\nand use `txg_wait_synced` instead of performing the normal `zil_commit`\nlogic.\n\nThis call to `txg_wait_synced` might be good enough for the data to\nreach disk safely before it returns, but it does not ensure that all\noutstanding lwb's reach the `LWB_STATE_DONE` state before it returns.\nThis is because, if there's an lwb \"stuck\" in\n`zil_commit_waiter_timeout`, waiting for it's lwb to timeout, it will\nmaintain a non-null value for it's `lwb_buf` field and thus `zil_sync`\nwill not free that lwb. Thus, even though the lwb's data is already on\ndisk, the lwb will be left lingering, waiting on the CV, and will\neventually timeout and be issued to disk even though the write is\nunnecessary.\n\nSo, after `zil_commit` is called from `zil_suspend`, we incorrectly\nassume that there are not outstanding lwb's, and proceed to free all\nlwb's found on the zilog's lwb list. As a result, we free the lwb that\nwill later be used `zil_commit_waiter_timeout`.\n\nSOLUTION\n========\n\nThe solution to this, is to ensure all outstanding lwb's complete before\ncalling `zil_free_lwb` via `zil_destroy` in `zil_suspend`. This patch\naccomplishes this goal by forcing the normal `zil_commit` logic when\ncalled from `zil_sync`.\n\nNow, `zil_suspend` will call `zil_commit_impl` which will always use the\nnormal logic of waiting/issuing lwb's to disk before it returns. As a\nresult, any lwb's outstanding when `zil_commit_impl` is called will be\nguaranteed to reach the `LWB_STATE_DONE` state by the time it returns.\n\nFurther, no new lwb's will be created via `zil_commit` since the zilog's\n`zl_suspend` flag will be set. This will force all new callers of\n`zil_commit` to use `txg_wait_synced` instead of creating and issuing\nnew lwb's.\n\nThus, all lwb's left on the zilog's lwb list when `zil_destroy` is\ncalled will be in the `LWB_STATE_DONE` state, and we'll avoid this race\ncondition.\n\nOpenZFS-issue: https://www.illumos.org/issues/8909\nOpenZFS-commit: https://github.com/openzfs/openzfs/commit/ece62b6f8d\nCloses #6940"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "lidongyang": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/823d48bfb182137c53b9432498f1f0564eaa8bfc", "message": "Call commit callbacks from the tail of the list\n\nOur zfs backed Lustre MDT had soft lockups while under heavy metadata\r\nworkloads while handling transaction callbacks from osd_zfs.\r\n\r\nThe problem is zfs is not taking advantage of the fast path in\r\nLustre's trans callback handling, where Lustre will skip the calls\r\nto ptlrpc_commit_replies() when it already saw a higher transaction\r\nnumber.\r\n\r\nThis patch corrects this, it also has a positive impact on metadata\r\nperformance on Lustre with osd_zfs, plus some cleanup in the headers.\r\n\r\nA similar issue for ext4/ldiskfs is described on:\r\nhttps://jira.hpdd.intel.com/browse/LU-6527\r\n\r\nReviewed-by: Olaf Faaland <faaland1@llnl.gov>\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: Li Dongyang <dongyang.li@anu.edu.au>\r\nCloses #6986"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "tcaputi": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/44b61ea506212c287333e03d2cf8933216810800", "message": "Remove empty files accidentally added by a8b2e306 \n\nThis patch simply removes 2 empty files that were accidentally\r\nadded a part of the scrub priority patch.\r\n\r\nReviewed-by: George Melikov <mail@gmelikov.ru>\r\nReviewed-by: Giuseppe Di Natale <dinatale2@llnl.gov>\r\nSigned-off-by: Tom Caputi <tcaputi@datto.com>\r\nCloses #6990"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/a8b2e30685c9214ccfd0181977540e080340df4e", "message": "Support re-prioritizing asynchronous prefetches\n\nWhen sequential scrubs were merged, all calls to arc_read()\r\n(including prefetch IOs) were given ZIO_PRIORITY_ASYNC_READ.\r\nUnfortunately, this behaves badly with an existing issue where\r\nprefetch IOs cannot be re-prioritized after the issue. The\r\nresult is that synchronous reads end up in the same vdev_queue\r\nas the scrub IOs and can have (in some workloads) multiple\r\nseconds of latency.\r\n\r\nThis patch incorporates 2 changes. The first ensures that all\r\nscrub IOs are given ZIO_PRIORITY_SCRUB to allow the vdev_queue\r\ncode to differentiate between these I/Os and user prefetches.\r\nSecond, this patch introduces zio_change_priority() to provide\r\nthe missing capability to upgrade a zio's priority.\r\n\r\nReviewed by: George Wilson <george.wilson@delphix.com>\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: Tom Caputi <tcaputi@datto.com>\r\nCloses #6921 \r\nCloses #6926"}], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6864", "title": "Encryption and Raw Send Stability Improvements", "body": "The current on-disk format for encrypted datasets protects\r\nnot only the encrypted and authenticated blocks, but also\r\nthe order and interpretation of these blocks. In order to\r\nmake this work while maintaining the ability to do raw sends\r\nthe indirect bps maintain a secure checksum of all the MACs\r\nin the block below it, along with a few other fields that\r\ndetermine how the data is interpretted.\r\n\r\nUnfortunately, the current on-disk format erroniously\r\nincludes some fields which are not portable and thus cannot\r\nsupport raw sends. It is also not possible to easily work\r\naround this issue due to a separate and much smaller bug\r\nwhich causes indirect blocks for encrypted dnodes to not\r\nbe compressed, which conflicts with the previous bug. In\r\naddition, raw send streams do not currently include\r\ndn_maxblkid which is needed in order to ensure that we are\r\ncorrectly maintaining the portable objset MAC.\r\n\r\nThis patch zero's out the offending fields when computing the\r\nbp MAC (as they should have been) and registers an errata for\r\nthe on-disk format bug. We detect the errata by adding a\r\n\"version\" field to newly created DSL Crypto Keys. We allow\r\ndatasets without a version (version 0) to only be mounted for\r\nread so that they can easily be migrated. We also now include\r\ndn_maxblkid in raw send streams to ensure the MAC can be\r\nmaintained correctly.\r\n\r\nNote that this fix has not yet been finalized and should not be used until it is tested, reviewed, and merged unless you are ok with losing your data.\r\n\r\nSigned-off-by: Tom Caputi <tcaputi@datto.com>\r\n\r\n### How Has This Been Tested?\r\nI have added a new test for raw sends that essentially stresses as many edge cases as I could think of. In addition, I have manually tested that the recovery process laid out in https://github.com/zfsonlinux/zfsonlinux.github.com/pull/35 works as advertised, and that both old and new datasets function predictably.\r\n\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [x] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [x] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "tesujimath": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/993669a7bf17a26843630c547999be0b27483497", "message": "vdev_id: new slot type ses\n\nThis extends vdev_id to support a new slot type, ses, for SCSI Enclosure\r\nServices.  With slot type ses, the disk slot numbers are determined by\r\nusing the device slot number reported by sg_ses for the device with\r\nmatching SAS address, found by querying all available enclosures.\r\n\r\nThis is primarily of use on systems with a deficient driver omitting\r\nsupport for bay_identifier in /sys/devices.  In my testing, I found that\r\nthe existing slot types of port and id were not stable across disk\r\nreplacement, so an alternative was required.\r\n\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: Simon Guest <simon.guest@tesujimath.org>\r\nCloses #6956"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "dinatale2": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/89a66a0457cd392ab8c6ad6d9c138fedaa425067", "message": "Handle broken pipes in arc_summary\n\nUsing a command similar to 'arc_summary.py | head' causes\r\na broken pipe exception. Gracefully exit in the case of a\r\nbroken pipe in arc_summary.py.\r\n\r\nReviewed-by: Richard Elling <Richard.Elling@RichardElling.com>\r\nReviewed-by: loli10K <ezomori.nozomu@gmail.com>\r\nSigned-off-by: Giuseppe Di Natale <dinatale2@llnl.gov>\r\nCloses #6965 \r\nCloses #6969"}], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6906", "title": "Add dbuf hash and dbuf cache kstats", "body": "### Description\r\n<!--- Describe your changes in detail -->\r\nIntroduce kstats about the dbuf hash and dbuf cache\r\nto make it easier to inspect state. This should help\r\nwith debugging and understanding of these portions\r\nof the codebase.\r\n\r\nCorrect format of dbuf kstat file.\r\n\r\nIntroduce a dbc column to dbufs kstat to indicate if\r\na dbuf is in the dbuf cache.\r\n\r\nIntroduce field filtering in the dbufstat python script.\r\n\r\nI will also be introducing some basic test cases to test the new dbufstats kstat and other basic scenarios.\r\n\r\n<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\nGain a better understanding how dbufs are cached and provide another useful tool for users/developer.\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\nLocally on a VM.\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [x] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6294", "title": "Enforce request limits on zvols", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\nCurrently, zvols do not handle heavy random IO\r\nworkloads. zvols should limit the number of outstanding\r\nin-flight IO requests. This should improve performance.\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n#6127 \r\n#6278 \r\n\r\n### How Has This Been Tested?\r\nBuilds on my VM. Buildbot will help me test. Hoping to test on hardware soon.\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [x] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "MEMBER"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "avw1987": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/7055", "title": "Update README.initramfs.markdown", "body": "Fixed a typo\r\n\r\n<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [x] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [ ] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [ ] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "tonyhutter": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/7051", "title": "zfs-0.7.6 patchset", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\nTest 0.7.6 patchset in buildbot\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [ ] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [ ] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "MEMBER"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "sckobras": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/7007", "title": "Allow to limit zed's syslog chattiness", "body": "### Description\r\n\r\nSome usage patterns like send/recv of replication streams can\r\nproduce a large number of events. In such a case, the current\r\nall-syslog.sh zedlet will hold up to its name, and flood the\r\nlogs with mostly redundant information. To mitigate this\r\nsituation, this changeset introduces two new variables\r\nZED_SYSLOG_SUBCLASS_INCLUDE and ZED_SYSLOG_SUBCLASS_EXCLUDE\r\nto zed.rc that give more control over which event classes end\r\nup in the syslog.\r\n\r\nSigned-off-by: Daniel Kobras <d.kobras@science-computing.de>\r\nCloses: #6886\r\n\r\n### Motivation and Context\r\nIt seems that each time a dataset that also uses =zfs-auto-snapshot= is replicated, a =history_event= for the =com.sun:auto-snapshot-desc= property in each snapshot is logged. This easily spams the logs with thousands of redundant, and rather useless messages as described in #6886, so adding a facility to trim down the noise without disabling the syslog feature altogether seems to be in order.\r\n\r\n### How Has This Been Tested?\r\nTested on EL7.4 with ZoL 0.7.2.\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [x] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "aerusso": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6974", "title": "fstab integration", "body": "Generate a tracked, updateable section in /etc/fstab for zfs filesystems\r\n\r\n### Description\r\nA contrib script fstab-generator is implemented that creates a trackable section in /etc/fstab (or another user-specified file) with fstab syntax reflecting the zfs mount and canmount parameters.\r\n\r\n### Motivation and Context\r\nWhile #4943 implements a per-pool granular import, the user will still \"need to add an entry like this in fstab:\r\n\r\n```rpool/home /home zfs rw,defaults,x-systemd.requires=zpool@rpool.service```\r\n\r\nThis script performs precisely that mechanical task, allowing for filesystem dependencies to be correctly identified, and mounted in time to guarantee their availability. A monolithic import of all zfs filesystems is not required to have system files on native zfs mountpoints. \r\n\r\nMoreover, by including this information in /etc/fstab, tools can fail appropriately if essential mountpoints are unavailable. This helps address the common annoyance where zfs fails to mount an important system directory, files then get placed on the zfs mountpoint, and then zfs will fail to mount on the subsequent boot (because overlay=off) even though the underlying problem was corrected. \r\n\r\n#### Why not a systemd-generator?\r\nBesides the obvious lack of integration for users without systemd, other tools may rely on /etc/fstab to determine what filesystems are present on a system. This approach immediately achieves integration with those tools--e.g., for analogous dependency tracking for other init systems that may develop in the future. Additionally, systemd generators may change syntax in the future, but they will have to remain compatible with /etc/fstab.\r\n\r\n### How Has This Been Tested?\r\nI'm running with the output of this script on a machine that has several `/var/` directories, and `/tmp` with purely zfs mountpoints.\r\n\r\n### RFC\r\nThis is a work in progress.\r\n1. Should this be converted to fstab-generator.in, and use `%sbindir%`, etc?\r\n2. Should this name be changed? Should this be installed elsewhere?\r\n3. How could/should this be integrated with the rest of the tools?\r\n4. Is there some reason `mount -ozfsutil` is ill-advised for zfs filesystems?\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6964", "title": "Use zfs-import.target in contrib/dracut", "body": "### Description\r\nThe new zfs-import.target should be used in place of the zfs-import-*.service units in `contrib/dracut`.\r\n\r\n### Motivation and Context\r\nPR #6764 added `zfs-import.target` to simplify dependency on pool importing. #6822 did some cleanup. The recent #6955 (re: #6953) added RPM support for enabling this units. That bug report has prompted me to grep the code base for zfs-import. The last remaining code section to be updated is under `control/dracut/90zfs`.\r\n\r\nThis PR is  a **work in progress**. I don't think dracut users are exposed to any bug presently, because `sysroot.mount` is still ordered `After=zfs-import-*.service`\r\n\r\nTwo files are affected:\r\n1. `zfs-generator.sh.in` is straightforwardly modified to order `sysroot.mount` `After=zfs-import.target` (instead of each `zfs-import-*.service`). \r\n2. `module-setup.sh.in` is also modified. **I need input, because I don't know how precisely dracut works.** `zfs-import.target` (and each `zfs-import-*.service`) is `dracut_install`-ed (and *unconditionally* `mark_hostonly`-ed). Do we need to build a `zfs-import.target.wants` directory with `zfs-import-*.service` links? Or will that be inherited from the host system?\r\n\r\n### How Has This Been Tested?\r\nThis has NOT been tested. This is a place to centralize discussion about these changes.\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [x] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "dweeezil": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6900", "title": "OpenZFS 7614 - zfs device evacuation/removal", "body": "### Description\r\n<!--- Describe your changes in detail -->\r\nThis project allows top-level vdevs to be removed from the storage pool\r\nwith \"zpool remove\", reducing the total amount of storage in the pool.\r\nThis operation copies all allocated regions of the device to be removed\r\nonto other devices, recording the mapping from old to new location.\r\nAfter the removal is complete, read and free operations to the removed\r\n(now \"indirect\") vdev must be remapped and performed at the new location\r\non disk.  The indirect mapping table is kept in memory whenever the pool\r\nis loaded, so there is minimal performance overhead when doing\r\noperations on the indirect vdev.\r\n\r\nThe size of the in-memory mapping table will be reduced when its entries\r\nbecome \"obsolete\" because they are no longer used by any block pointers\r\nin the pool.  An entry becomes obsolete when all the blocks that use it\r\nare freed.  An entry can also become obsolete when all the snapshots\r\nthat reference it are deleted, and the block pointers that reference it\r\nhave been \"remapped\" in all filesystems/zvols (and clones).  Whenever an\r\nindirect block is written, all the block pointers in it will be\r\n\"remapped\" to their new (concrete) locations if possible.  This process\r\ncan be accelerated by using the \"zfs remap\" command to proactively\r\nrewrite all indirect blocks that reference indirect (removed) vdevs.\r\n\r\nNote that when a device is removed, we do not verify the checksum of the\r\ndata that is copied.  This makes the process much faster, but if it were\r\nused on redundant vdevs (i.e. mirror or raidz vdevs), it would be\r\npossible to copy the wrong data, when we have the correct data on e.g.\r\nthe other side of the mirror.  Therefore, mirror and raidz devices can\r\nnot be removed.\r\n\r\n### Motivation and Context\r\nSee above.\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\n### How Has This Been Tested?\r\nAdditions to the test suite in functional/removal.\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "MEMBER"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "scotws": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6892", "title": "Add Python 3 rewrite of arc_summary.py (#6873)", "body": "### Description\r\n\r\nAdd new Python 3 script `arc_summary3.py` as a complete rewrite of `arc_summary.py` to display basic information on the ARC status and various other parameters. This is provided in addition - not as a replacement - to the existing `arc_summary.py` tool. See #6873 for a discussion of the reasoning behind adding a new version of this tool while keeping a legacy version as well.\r\n\r\nNew options:\r\n\r\n        -g/--graph    - Display crude graphic representation of ARC status and quit\r\n        -r/--raw      - Print all available information as minimally formatted list and quit\r\n        -s/--section  - Print a single section. This supersedes -p/--page, which is kept for\r\n                        backwards use but marked as DEPRECIATED\r\n\r\nAdds new sections with information on the ZIL and SPL. \r\n\r\nWe now notify the user if sections L2ARC and VDEV are skipped instead of failing silently; note VDEV caching is currently disabled and slated for possible removal (see source code). Adds information on the ZFS and SPL versions to the header.\r\n\r\nThe **-s/--section** option is intended to replace the page number system, which required the user to remember which page number was of interest. The -p/--page options are still supported, but marked as DEPRECIATED. Current legal sections are `arc archits dmu l2arc spl tunables vdev zil`. It should be easier now to add and modify sections.\r\n\r\nThe **-r/--raw** option is intended to work with other tools such as `grep`. It respects the -a/-d options (alternate output format / descriptions included) where possible. \r\n\r\nThe output of the **-g/--graph** option is intended to give a quick, rough overview as a visual orientation. An example (Ubuntu 16.04 LTS x86_64 with 24 GB RAM, 8 GB ARC max, ZFS stock version 0.6.5.9-2 with `/home` as ZFS mirror pool immediately after starting _Civilization VI_ on Steam on otherwise quiet machine): \r\n```\r\n        ARC: 3.0 GiB (37.5 %)  MFU: 610.5 MiB  MRU: 2.3 GiB\r\n    +----------------------------------------------------------+\r\n    |FFFFRRRRRRRRRRRRRRRRR                                     |\r\n    +----------------------------------------------------------+\r\n```\r\n`F` is for MFU, `R` for MRU, and `O` is used for \"other\" if necessary (not present in this example). \r\n\r\n`arc_summary3.py` was developed for Python 3.5. This follows the version of Python currently installed in Ubuntu 16.04 LTS. Few systems will have Python 3.6 installed yet.\r\n\r\n### Known issues\r\n\r\nThe new script is based on the same internal logic as the original, so any error or issue present there will probably show up here as well. For instance, the number of anonymous hits can be negative the way it is calculated in both scripts; they both simply hide any negative value.\r\n\r\nThis script will probably make a bunch of test suites unhappy where Python 3 is not included. There is no experience with this script under extreme conditions (for example ARC throttling).\r\n\r\n### How Has This Been Tested?\r\n\r\nThere is a unittest script `test_arc_summary3.py` at https://gist.github.com/scotws/aaf5d9c9317081e249b664a371ec4907\r\nMost testing was done in-tree, comparing the output to that of the current `arc_summary.py` version.\r\n\r\nThe L2ARC section has **not seen any real-world use** because I do not have access to a L2ARC device on my machine.\r\n\r\n### Other \r\n\r\nSwitching to Python 3 results in a noticeably smaller file size despite the addition of several new features. Output of `wc` for both scripts:\r\n```\r\n    837    2586   28021 arc_summary3.py\r\n   1020    2593   35538 arc_summary.py\r\n```\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [ ] I have read the **CONTRIBUTING** document.\r\n- [x] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "Blub": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6865", "title": "user namespace bugfixes and features", "body": "This series can be seen as 4 separate \"chunks\":\r\n\r\nChunk 1: setgid mode bugfix & regression test:\r\n* Patch 1 fixes the main issue.\r\n* Patch 2 adds a helper for running user namespace tests. Currently uses a fixed\r\n  user id range. (I saw no reason for anything more complex than that.)\r\n* Patch 3 adds a regression test for the issue fixed in patch 1.\r\n\r\nChunk 2: mounting from user namespaces (RFC):\r\n* Patch 4 is an RFC useful for when a user can have a mount namespace (usually\r\n  in combination with user namespaces. Eg. giving `zfs allow`ing create+mount\r\n  permissions to a container.\r\n* Patch 5 is necessary when including the third chunk but is otherwise there\r\n  since it made writing the test case of patch 6 more convenient.\r\n* Patch 6 tests create+mount permissions with user namespaces.\r\n\r\nChunk 3: mapping user ids when using zfs allow from within user namespaces.\r\n* Patch 7 causes `ZFS_IOC_GET_FSACL` and `ZFS_IOC_SET_FSACL` to perform user id\r\n  mapping (as well as checking!) on the sent/received data. Otherwise root in a\r\n  user namespace would not be able to run `zfs allow` with the user IDs as seen\r\n  from within its namespace, but would have to perform the mapping to real IDs.\r\n  This is also what easily enables users to create allow entries for user IDs\r\n  which do not exist in the host namespace's `/etc/passwd` and therefore would\r\n  show up empty and indistinguishable to the host (making patch 5 a\r\n  requirement).\r\n\r\nChunk 4: change the 'unallow' check:\r\n* Patch 8 allows users who have CAP_SYS_ADMIN in the current namespace (iow.\r\n  root in containers) to remove permissions of others if they're also allowed\r\n  to add the permission.\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements. (at least according to `make checkstyle`)\r\n- [ ] I have updated the documentation accordingly. (not yet)\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [x] I have added tests to cover my changes.\r\n- [x] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ironMann": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6568", "title": "[wip][test] Prefetch dmu", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\nRun testers\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [ ] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [ ] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6107", "title": "LOCK tracking: disable tracking of ARC and dbuf hashmap locks (16384 mutexes)", "body": "Test for zfsonlinux/spl#587\r\n\r\nRequires-spl: refs/pull/587/head\r\n\r\n### Description\r\nDisable tracking of per-bucket locks.\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [ ] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "MEMBER"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "don-brady": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6558", "title": "OpenZFS 7431 - ZFS Channel Programs", "body": "Authored by: Chris Williamson <chris.williamson@delphix.com>\r\nReviewed by: Matthew Ahrens <mahrens@delphix.com>\r\nReviewed by: George Wilson <george.wilson@delphix.com>\r\nReviewed by: John Kennedy <john.kennedy@delphix.com>\r\nReviewed by: Dan Kimmel <dan.kimmel@delphix.com>\r\nApproved by: Garrett D'Amore <garrett@damore.org>\r\nPorted-by: Don Brady <don.brady@delphix.com>\r\nPorted-by: John Kennedy <john.kennedy@delphix.com>\r\n\r\nOpenZFS-issue: https://www.illumos.org/issues/7431\r\nOpenZFS-commit: https://github.com/openzfs/openzfs/commit/dfc11533\r\n\r\nPorting Notes:\r\n* The CLI long option arguments for '-t' and '-m' don't parse on linux\r\n* Switched from kmem_alloc to vmem_alloc in zcp_lua_alloc\r\n* Lua implementation is built as its own module (zlua.ko)\r\n* Lua headers consumed directly by zfs code moved to 'include/sys/lua/'\r\n* There is no native setjmp/longjump available in stock Linux kernel.  Brought over implementation from illumos and FreeBSD\r\n* The get_temporary_prop() was adapted due to VFS platform differences\r\n* Use of in-lining functions in lua parser code to reduce stack usage per nested C call\r\n\r\n### How Has This Been Tested?\r\n#### Manual tests\r\n- running basic get-props channel programs from CLI\r\n- exercised the zfs property get CLI with the envr *ZFS_PROP_DEBUG=1* set\r\n#### Automated tests\r\n- ztest runs that exercise the new ZCP destroy snapshots path\r\n- new ZTS channel_program functional tests\r\n\r\n### Types of changes\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [x] I have added tests to cover my changes.\r\n- [x] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "MEMBER"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "dong-liuliu": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6546", "title": "Use Multi-buffer sha256 support from SPL", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\nLet sha256 checksum using multi-buffer api if it is exported by SPL\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n Using multi-buffer type, performance of sha256 will be increased 2~7 times.\r\nNow a patch for multi-buffer sha256 facility in kernel space is implemented and submitted to SPL.\r\nIts userspace facility and sha512 parts will be following up after this patch is reviewed and commented.\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\nRun FIO sequential write test, on Intel Xeon server (Haswell E5-2699 v3, 18 core), with 6x SSD :\r\n\r\nSha256 | CPU-sys% | BW(MB/s)\r\n-- | -- | --\r\nmulti-buffer version | 27 | 1859\r\nicp version | 71 | 1876\r\n\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [x] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ahrens": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6536", "title": "diff and bookmark enhancements", "body": "\r\n<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\nThis PR includes 3 related features that work well together:\r\n\r\n`zfs diff -a` shows which specific blocks were modified\r\n\r\n`zfs diff` from a bookmark (but it can't show renamed files)\r\n\r\n`zfs bookmark` from a filesystem, creating a bookmark which represents current point in time.  Not useful for `zfs send`, but can be used with `zfs diff`.\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\nThis makes `zfs diff` useful in more situations.  For example, to find which blocks in a database or VDI file were changed.\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n\r\nManual testing only at this point.  I'd like to add test cases to the test suite, but there aren't any tests for \"zfs diff\" at all, so it seems strange to add tests for just the new functionality I'm adding.  I'm open to input on what should be required for this PR.\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [x] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ofaaland": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6479", "title": "Merge SPL into ZFS [WIP]", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\nMerge the SPL into ZFS to eliminate the extra work required when SPL code must change due to kernel or distro changes, and to simplify the build process.\r\n\r\nWork In Progress.\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [x] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [ ] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "Nasf-Fan": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6290", "title": "Project Quota on ZFS", "body": "Project quota is a new ZFS system space/object usage accounting\r\nand enforcement mechanism. Similar as user/group quota, project\r\nquota is another dimension of system quota. It bases on the new\r\nobject attribute - project ID.\r\n\r\nProject ID is a numerical value to indicate to which project an\r\nobject belongs. An object only can belong to one project though\r\nyou (the object owner or privileged user) can change the object\r\nproject ID that can be set/modified via 'chattr -p' explicitly,\r\nor inherited from its parent object when created if such parent\r\nhas the project inherit flag (via 'chattr +P').\r\n\r\nBy accounting the spaces/objects belong to the same project, we\r\ncan know how many spaces/objects used by the project. And if we\r\nset the upper limit then we can control the spaces/objects that\r\nare consumed by such project. It is useful when multiple groups\r\nand users cooperate for the same project, or when an user/group\r\nneeds to participate in multiple projects.\r\n\r\nSupport the following commands and functionalities:\r\n\r\nzfs set projectquota@project\r\nzfs set projectobjquota@project\r\n\r\nzfs get projectquota@project\r\nzfs get projectobjquota@project\r\nzfs get projectused@project\r\nzfs get projectobjused@project\r\n\r\nzfs projectspace\r\n\r\nzfs allow projectquota\r\nzfs allow projectobjquota\r\nzfs allow projectused\r\nzfs allow projectobjused\r\n\r\nzfs unallow projectquota\r\nzfs unallow projectobjquota\r\nzfs unallow projectused\r\nzfs unallow projectobjused\r\n\r\nchattr +/-P\r\nchattr -p project_id\r\nlsattr -p\r\n\r\nSigned-off-by: Fan Yong <fan.yong@intel.com>\r\nChange-Id: Ib4f0544602e03fb61fd46a849d7ba51a6005693c\r\n\r\n<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [x] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "tuxoko": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6277", "title": "[WIP] Add pool prop `partition` to disable auto partition", "body": "### Description\r\n\r\nzfsonlinux always partition disk when it detects the device given is a\r\nwhole disk. This legacy behavior from Illumos, however, has no apparent\r\nbenefit on Linux, but has some down sides besides confusion. E.g.\r\nautoexpand, switching to dm device requires partprobe.\r\n\r\nWe add a pool property `partition` to be set during pool create. It\r\ncurrently has two values, legacy and raw. When setting it to legacy, it\r\nwill behave as it did. When setiing it to raw, it will always use the\r\ndevice as is without partitioning even if it's a whole disk.\r\n\r\nThis property applies to all commands that add disks to pool, so zpool\r\nadd/attach/replace will partition or not partition based on the property\r\non the target pool.\r\n    \r\nA pool without this property will be treated as legacy. Newly created\r\npool will by default have partition=legacy.\r\n\r\nSigned-off-by: Chunwei Chen <david.chen@osnexus.com>\r\n\r\n### Note\r\n\r\nI use PROP_ONETIME for the property, but it seems that this is not enforced at all, so you can still modify it after the fact. But you shouldn't change it after the fact, as it would cause device name appending wrong.", "author_association": "MEMBER"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "inkdot7": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6078", "title": "Metadata classes wip no accounting", "body": "Please ignore this PR.\r\nI just want to see how the metadata allocation classes behave if the special accounting is removed.  (Which would allow the small-block-size limit to be changed after creation more easily.)\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "n1kl": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/5929", "title": "Quality of service for ZFS + improvement through compression", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\nAs part of my master thesis at University of Hamburg I have targeted to improve ZFS through compression. Now I would like to share my 3 feature branches with the community.\r\n\r\n1. lz4fast #5927 \r\n2. autocompression #5928 \r\n3. qos (current)\r\n### Description\r\n<!--- Describe your changes in detail -->\r\nThis patch adds quality of service to ZFS datasets.\r\nzfs set compression=qos-[10,20,30,40,50,+50*n,1000]\r\nThe chosen value sets the throughput in MB/s.\r\nLow values will result in better compression ratio but less throughput.\r\n\r\n### Motivation1\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\nQuality of service is an important aspect in dealing with limited resources.\r\nAt the moment the user can control storage requirement by choosing a compression algorithm like gzip for high compression. Depending on the hardware and the current CPU load the performance might be either poor or well.\r\nBy using the qos compression feature the desired write throughput can be chosen to meet the requirement for the application.\r\nThe qos algorithm keeps track of the compression speed and chooses either lz4 or gzip-[1-9] to speed up / slow down while compressing data. \r\n\r\n<!--- ### How Has This Been Tested? -->\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n### Benchmark1\r\n\r\nCopy file from Tempfs to ZFS into 1 Dataset:\r\n\r\nName | MB/s\t| Ratio\r\n ---   \t|  --- \t| ---\r\ngzip9\t| 11\t| 0.37\r\nqos10\t| 10\t| 0.38\r\nqos20\t| 22\t| 0.41\r\nqos30\t| 35\t| 0.45\r\nqos40\t| 45\t| 0.48\r\nqos50\t| 55\t| 0.50\r\nlz4\t| 71\t| 0.57\r\noff\t| 62\t| 1\r\n\r\n\r\n### Motivation2\r\n\r\nTransactiongroups in ZFS cause simultaneous writes into multiple datasets to wait for each other to complete. The slowest dataset is the limitation to the overall performance.\r\nThe qos feature can prevent this through dataset prioritisation.\r\nThe maximum bandwidth is limited by the disk throughput. Every dataset can request a part of this bandwidth by setting the qos property value.\r\nData can now be organised into low priority datasets with low quality of service requirements (but high compression, see Motivation1) and high priority to which also all non qos datasets belong.\r\nAll inheriting datasets and their parent share the same requested bandwidth. If the value of an inheriting dataset (lower hierarchy) is explicitly changed from \"inherit\" to \"qos\" then this dataset will request its own bandwidth.\r\n\r\n\r\n### Benchmark2\r\n\r\nCopy 2 files from Tempfs to ZFS into 2 Datasets:\r\n\r\nName     \t\t\t|MB/s\t|MB/s\t|Ratio\t|Ratio\t| Comment\r\n--- | --- | --- | --- | --- | ---\r\nqos10/qos10 - qos10/qos10_2\t|5\t|5\t|0.47\t|0.49\t|use of inheritance\r\nqos10 - qos10/qos10\t\t|5\t|5\t|0.49\t|0.47\t|use of inheritance\r\nqos10 - qos10_2\t\t\t|11\t|10\t|0.46\t|0.48\t| \r\nqos10/qos10 - qos10/qos10x\t|11\t|9\t|0.48\t|0.46\t|qos-10 explicit <br>set on qos10x\r\nqos10/qos20 - qos10\t\t|20\t|9\t|0.49\t|0.43\t| \r\nqos30 - qos10\t\t\t|29\t|9\t|0.52\t|0.40\t| \r\nqos40 - qos10\t\t\t|44\t|10\t|0.54\t|0.40\t| \r\nqos50 - qos10\t\t\t|51\t|9\t|0.53\t|0.40\t| \r\nlz4 - qos10\t\t\t|71\t|9\t|0.57\t|0.39\t| lz4 has high priority\r\noff - qos10\t\t\t|62\t|8\t|1\t|0.38\t| \r\ngzip9 - qos10\t\t\t|13\t|5\t|0.37\t|0.39\t| \r\nlz4 - gzip9\t\t\t|10\t|10\t|0.57\t|0.37\t|  lz4 waiting for gzip\r\n\r\n\r\n### Benchmark3\r\n\r\nCopy 2 files from Tempfs to ZFS into 1 Datasets:\r\n\r\nName     \t\t\t|MB/s\t|MB/s\t|Ratio\r\n--- | --- | --- | --- \r\nqos10 - qos10 |\t5\t|5|\t0,38\r\noff - off|\t22|\t22|\t1\r\nlz4 - lz4|\t30|\t27|\t0,57\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n\r\n#### Branch overlapping changes (feature, compress values)\r\nThe patch has read-only backward compatibility by using the new introduced SPA_FEATURE_COMPRESS_QOS feature. The feature activation procedure is equivalent to my other code branches.\r\nRegarding the limited namespace of BP_GET_COMPRESS() (128 values), the\r\nzio_compress enum's first part is for block pointer & dataset values, the second part for dataset values only. Or should I make use of a new property? This is an alternative suggestion to #3908.\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/5928", "title": "auto compression", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\nAs part of my master thesis at University of Hamburg I have targeted to improve ZFS through compression. Now I would like to share my 3 feature branches with the community.\r\n\r\n1. lz4fast #5927 \r\n2. autocompression (current)\r\n3. qos #5929 \r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\nThis patch adds auto as ZFS compression type.\r\nzfs set compression=auto\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\nWhich compression algorithm is best for high throughput? The answer to this depends on the type of hardware in use.\r\nIf compression takes long then the disk remains idle. If compression is faster than the writing speed of the disk then the CPU remains idle as compression and writing to the disk happens in parallel.\r\nAuto compression tries to keep both as busy as possible.\r\nThe disk load is observed through the vdev queue. If the queue is empty a fast compression algorithm like lz4 with low compression rates is used and if the queue is full then gzip-[1-9] can require more CPU time for higher compression rates.\r\nThe already existing zio_dva_throttle might conflict with the concept described above. Therefore it is recommended to deactivate zio_dva_throttle.\r\n\r\n<!--- ### How Has This Been Tested? -->\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n### Benchmark\r\n\r\nCopy file from Tempfs to ZFS\r\n\r\n\r\n8 Cores:\r\n\r\nName\t|Ratio\t|MB/s\r\n---\t|---\t|---\r\nauto\t|0.44  \t|245\r\ngzip-1\t|0.43  \t|255\r\nlz4\t|0.58  \t|195\r\noff\t|1 \t|99\r\n\r\n\r\n1 Core:\r\n\r\nName\t|Ratio\t|MB/s\r\n---\t|---\t|---\r\nauto\t|0.56 \t|151\r\ngzip-1\t|0.43\t|51\r\nlz4\t|0.58\t|179\r\noff\t|1\t|99\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n\r\n#### Branch overlapping changes (feature, compress values)\r\n\r\nThe patch is has read-only backward compatibility by using the new introduced SPA_FEATURE_COMPRESS_AUTO feature. The feature activation procedure is equivalent to my other code branches.\r\nRegarding the limited namespace of BP_GET_COMPRESS() (128 values), the\r\nzio_compress enum's first part is for block pointer & dataset values, the second part for dataset values only. This is an alternative suggestion to #3908.\r\n\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/5927", "title": "lz4fast compression", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\nAs part of my master thesis at University of Hamburg I have targeted to improve ZFS through compression. Now I would like to share my 3 feature branches with the community.\r\n\r\n1. lz4fast (current)\r\n2. autocompression #5928 \r\n3. qos #5929 \r\n\r\nThis patch updates the lz4 *1 code to version 1.7.3 to make use of lz4 fast compression.\r\nThe lz4 code is based on a seperate project for updating lz4 inside the linux kernel.\r\nThere a few changes were made for an clean implementation and to improve speed that are currently in review *2.\r\n\r\n*1: [https://github.com/lz4/lz4](https://github.com/lz4/lz4)\r\n*2: [https://patchwork.kernel.org/patch/9574745/](https://patchwork.kernel.org/patch/9574745/)\r\n\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\nLZ4-fast capability is now available.\r\nzfs set compression=lz4fast-[1-20,30,+10*n,100]\r\nHigher values result in improved compression speed and less ratio.\r\n\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\nLz4 fast trades in compression ratio for speed. This gives us more flexibility in environments with either low computational power or fast and many SSDs/HDDs where the lz4 is the limiting factor.\r\nAutocompression and qos can also be improved by adding lz4fast algorithms.\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\nChecksums were made to proof full compatibility between the old and new lz4 compressed files.\r\n\r\n#### Benchmark\r\n\r\nCopy file from Tempfs to ZFS (ZFS also in Tempfs for high disk throughput simulation).\r\n\r\n\r\nName         |Ratio   |MB/s\r\n---          |---     |---\r\nlz4          |0.58    |228\r\nlz4fast-2    |0.62    |249\r\nlz4fast-3    |0.65    |266\r\nlz4fast-4    |0.68    |282\r\nlz4fast-5    |0.71    |298\r\nlz4fast-7    |0.76    |329\r\nlz4fast-10   |0.80    |370\r\nlz4fast-20   |0.97    |469\r\nlz4fast-30   |0.98    |546\r\nlz4fast-50   |0.98    |634\r\nlz4fast-100  |0.99    |690\r\noff          |1       |744\r\n\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n\r\n#### Branch overlapping changes (feature, compress values)\r\n\r\nThe patch has read-only backward compatibility by using the new SPA_FEATURE_LZ4FAST_COMPRESS feature. The feature activation procedure is equivalent to my other code branches.\r\nRegarding the limited namespace of BP_GET_COMPRESS() (128 values), the\r\nzio_compress enum's first part is for block pointer & dataset values, the second part for dataset values only. Or should I make use of a new property? This is an alternative suggestion to #3908.\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ghost": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1276681", "body": "Has this issue been resolved? I'm having the same problem on OpenSolaris with ZFS. The zpool-rpool process is writing on average at 400MB/h on an idle system. I can't seem to find an answer anywhere on the net.\n\nThanks for your help.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1276681/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1277385", "body": "A quick DTrace on what the zpool-rpool process is doing reveals the following kernel function calls, accompanied by the number of times they have been called (the sampling lasted about a minute). Does this mean anything to you?\n\n``` DTrace\nrootnex`rootnex_coredma_allochdl          1\nrootnex`rootnex_dma_allochdl            1\nscsi`scsi_transport                     1\nzfs`buf_hash                            1\nzfs`arc_write_done                      1\nzfs`dbuf_find                           1\nzfs`dbuf_dirty                          1\nzfs`metaslab_ndf_alloc                  1\nzfs`spa_writeable                       1\nzfs`space_map_load                      1\nzfs`vdev_queue_deadline_compare          1\nzfs`vdev_queue_offset_compare           1\nzfs`vdev_queue_io                       1\nzfs`zio_buf_free                        1\nzfs`zio_remove_child                    1\nzfs`zio_destroy                         1\nzfs`zio_vdev_io_done                    1\nzfs`zrl_add                             1\nahci`ahci_check_ctl_handle              1\nsata`sata_scsi_start                    1\nsata`sata_txlt_write                    1\nsd`sdstrategy                           1\nsd`sd_core_iostart                      1\nsd`sd_initpkt_for_buf                   1\nsd`sd_start_cmds                        1\nunix`sep_save                           1\nunix`splr                               1\nunix`tsc_gethrtime                      1\nunix`tsc_scalehrtime                    1\nunix`bcopy                              1\nunix`gdt_update_usegd                   1\nunix`lock_set                           1\nunix`cmt_balance                        1\nunix`swtch                              1\nunix`disp_ratify                        1\nunix`default_lock_backoff               1\nunix`lock_set_spin                      1\ngenunix`avl_walk                        1\ngenunix`avl_rotation                    1\ngenunix`cv_broadcast                    1\ngenunix`ddi_fm_acc_err_get              1\ngenunix`disp_lock_enter                 1\ngenunix`thread_lock                     1\ngenunix`ldi_strategy                    1\ngenunix`copy_pattern                    1\ngenunix`kmem_zalloc                     1\ngenunix`list_create                     1\ngenunix`list_remove                     1\ngenunix`ddi_get_soft_state              1\ngenunix`restorectx                      1\nzfs`buf_hash_insert                     2\nzfs`dnode_diduse_space                  2\nzfs`zio_push_transform                  2\nzfs`zio_walk_parents                    2\nzfs`zio_done                            2\nzfs`zio_checksum_compute                2\nzfs`vdev_disk_io_start                  2\nsha2`SHA256TransformBlocks              2\nsd`sd_mapblockaddr_iostart              2\nsd`sd_add_buf_to_waitq                  2\nsd`ddi_xbuf_qstrategy                   2\nsd`xbuf_iostart                         2\nunix`rw_enter                           2\nunix`disp                               2\nunix`atomic_add_64_nv                   2\ngenunix`avl_remove                      2\ngenunix`avl_numnodes                    2\ngenunix`lbolt_event_driven              2\ngenunix`ddi_fm_dma_err_get              2\ngenunix`kmem_cache_free                 2\ngenunix`memcpy                          2\ngenunix`cpu_update_pct                  2\ngenunix`ndi_fmc_insert                  2\ngenunix`taskq_thread_wait               2\nzfs`arc_write_ready                     3\nzfs`metaslab_alloc_dva                  3\nzfs`vdev_accessible                     3\nzfs`zio_wait_for_children               3\nzfs`zio_notify_parent                   3\nzfs`zio_vdev_io_start                   3\nsd`sd_setup_rw_pkt                      3\nunix`mutex_owner_running                3\nunix`rw_exit                            3\nunix`mutex_vector_enter                 3\nunix`vsnprintf                          3\ngenunix`avl_last                        3\nzfs`space_map_remove                    4\nzfs`zio_execute                         4\nsd`sdinfo                               4\nunix`mutex_exit                         4\nzfs`metaslab_group_alloc                5\nzfs`vdev_queue_io_to_issue              5\nunix`bzero                              5\nunix`disp_getwork                       5\ngenunix`avl_insert                      5\nunix`0xfffffffffb85                     6\nunix`tsc_read                           6\ngenunix`kmem_cache_alloc                6\nunix`do_splx                            7\nzfs`space_map_seg_compare               9\nzfs`metaslab_segsize_compare           10\ngenunix`avl_find                       10\nunix`default_lock_delay                11\nzfs`fletcher_4_native                  12\nunix`mutex_enter                       16\nunix`mutex_delay_default               54\nzfs`lzjb_compress                     151\n```\n\nWe can see that the most called function is by far lzjb_compress. Again, DTrace reveals that all the kernel stacks that lead to lzjb_compress pass through the function zio_write_bp_init, which I assume is the guilty function behind all these writes...\n\nDoes this all mean anything to you?\n\nEdit:  kernel stacks\n\n``` DTrace\n              zfs`zio_compress_data+0x8e\n              zfs`zio_write_bp_init+0x216\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              genunix`taskq_thread+0x248\n              unix`thread_start+0x8\n                1\n\n              zfs`zio_compress_data+0x8e\n              zfs`zio_write_bp_init+0x216\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              genunix`taskq_thread+0x248\n              unix`thread_start+0x8\n                1\n\n              zfs`zio_compress_data+0x8e\n              zfs`zio_write_bp_init+0x216\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n                2\n\n              zfs`zio_compress_data+0x8e\n              zfs`zio_write_bp_init+0x216\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              genunix`taskq_thread+0x248\n              unix`thread_start+0x8\n                5\n\n              zfs`zio_compress_data+0x8e\n              zfs`zio_write_bp_init+0x216\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              genunix`taskq_thread+0x248\n              unix`thread_start+0x8\n                6\n\n              zfs`zio_compress_data+0x8e\n              zfs`zio_write_bp_init+0x216\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              genunix`taskq_thread+0x248\n              unix`thread_start+0x8\n               13\n\n              zfs`zio_compress_data+0x8e\n              zfs`zio_write_bp_init+0x216\n              zfs`zio_execute+0x8d\n              genunix`taskq_thread+0x248\n              unix`thread_start+0x8\n               31\n```\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1277385/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1281342", "body": "Here is a list processes which called the write system call on my system, accompanied by the filenames and the total number of bytes written to the files (sampled during one minute):\n\n```\ndtrace -n 'syscall::*write:entry {@[execname, fds[arg0].fi_pathname] = sum (arg2);}'\ndtrace: description 'syscall::*write:entry ' matched 2 probes\n^C\n\n  dtrace                                              /dev/pts/1                                                        1\n  sshd                                                /devices/pseudo/clone@0:ptm                                       1\n  sshd                                                <unknown>                                                        52\n  rsfcli                                              <unknown>                                                       105\n  basename                                            <unknown>                                                       164\n  hostname                                            <unknown>                                                       304\n  syslogd                                             /devices/pseudo/sysmsg@0:sysmsg                                 320\n  awk                                                 <unknown>                                                       331\n  zfs                                                 /devices/pseudo/mm@0:null                                       370\n  java                                                /var/opt/nest/config/site/scheduledjobs/emailnotifications/Notification_ERROR.xml              433\n  java                                                /var/opt/nest/config/site/scheduledjobs/emailnotifications/Notification_WARNING.xml              437\n  java                                                /var/opt/nest/config/site/scheduledjobs/configurationreplications/SiteConfigReplication.xml              511\n  grep                                                <unknown>                                                       725\n  cron                                                /var/cron/log                                                   976\n  java                                                /var/opt/nest/config/site/scheduledjobs/snapshots/Snapshot2290924711711069275.xml             1014\n  java                                                /var/opt/nest/config/site/scheduledjobs/snapshots/Snapshot12337134254217831034.xml             1020\n  java                                                /var/opt/nest/config/site/scheduledjobs/snapshots/Snapshot17476938304947820872.xml             1020\n  java                                                /var/opt/nest/config/site/scheduledjobs/asyncreplications/AsyncReplication13100962750907134551.xml             1056\n  java                                                /var/opt/nest/config/site/scheduledjobs/asyncreplications/AsyncReplication13881922923541859328.xml             1056\n  ksh                                                 <unknown>                                                      1096\n  fcinfo                                              <unknown>                                                      1152\n  zpool                                               <unknown>                                                      1452\n  ksh                                                 /tmp/sf0l.2ol                                                  1650\n  ksh                                                 /tmp/sf0p.gnd                                                  1650\n  ksh                                                 /tmp/sf10.jmu                                                  1650\n  ksh                                                 /tmp/sf1g.3nv                                                  1650\n  ksh                                                 /tmp/sf1i.jvb                                                  1650\n  ksh                                                 /tmp/sf24.5eq                                                  1650\n  ksh                                                 /tmp/sf2f.jop                                                  1650\n  ksh                                                 /tmp/sf3b.beh                                                  1650\n  ksh                                                 /tmp/sf10.ujs                                                  3000\n  ksh                                                 /tmp/sf19.9c4                                                  3000\n  ksh                                                 /tmp/sf2a.o3i                                                  3000\n  ksh                                                 /tmp/sf2p.8d0                                                  3000\n  ksh                                                 /tmp/sf3k.j08                                                  3000\n  svcprop                                             <unknown>                                                      3140\n  format                                              <unknown>                                                      3644\n  sed                                                 <unknown>                                                      3704\n  fmd                                                 /var/fm/fmd/infolog_hival                                      4480\n  nscd                                                <unknown>                                                      5268\n  zfs                                                 <unknown>                                                      5778\n  init                                                /etc/svc/volatile/init-next.state                              9064\n  iostat                                              <unknown>                                                      9102\n  svccfg                                              <unknown>                                                      9801\n  fmtopo                                              <unknown>                                                    429332\n```\n\nIn contrast, for the same duration, here is the list of actual disk writes that were initiated, again accompanied by the filenames and number of bytes.\n\n```\ndtrace -n 'io:::start /args[0]->b_flags & B_WRITE/ {@[execname, args[2]->fi_pathname]=sum(args[0]->b_bcount);}'\ndtrace: description 'io:::start ' matched 6 probes\n^C\n\n  sched                                               /var/opt/nest/config/site/scheduledjobs/configurationreplications/SiteConfigReplication.xml             4096\n  sched                                               /var/opt/nest/config/site/scheduledjobs/emailnotifications/Notification_ERROR.xml             4096\n  sched                                               /var/opt/nest/config/site/scheduledjobs/emailnotifications/Notification_WARNING.xml             4096\n  sched                                               /var/opt/nest/config/site/scheduledjobs/asyncreplications/AsyncReplication13100962750907134551.xml             8192\n  sched                                               /var/opt/nest/config/site/scheduledjobs/asyncreplications/AsyncReplication13881922923541859328.xml             8192\n  sched                                               /var/opt/nest/config/site/scheduledjobs/snapshots/Snapshot12337134254217831034.xml             8192\n  sched                                               /var/opt/nest/config/site/scheduledjobs/snapshots/Snapshot17476938304947820872.xml             8192\n  sched                                               /var/opt/nest/config/site/scheduledjobs/snapshots/Snapshot2290924711711069275.xml             8192\n  zpool-rpool                                         <none>                                                     10463232\n```\n\nThe total number of bytes written to the disk by zpool-rpool alone is much higher than the total of bytes for which the write system call was used. Doesn't that mean that zpool-rpool is acting on its own?\n\nEdit: The two dtrace commands were run in parallel.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1281342/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1283961", "body": "Hmmm it's too bad there isn't a moderately easy way of knowing where all this I/O activity comes from. I tried disabling fmtopo (which is the biggest write-system-call writer) and still, zpool-rpool's io activity didn't seem to lower as significantly as it should have.\n\nAnyway, thanks for your input. I'll post if I find a solution to this on my side.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1283961/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/7731553", "body": "hmm. why not to do it in that way: let O_DIRECT always return true? does it metter that ZFS copies everything in to the ARC cache? let fake a bit an OS. It shouldn't hurt so much.... oh, and that is just my freak idea\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/7731553/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1873708", "body": "Hi - Not sure what's going on here as I don't know much regarding the programming/debugging of zfs but I seems to experience that issue, that is with or without rsync. I never had to read much files on my system as I use zfs for backups storage, however I just had to restore things from the zfs pool and it crashed after a while.. rebooted.. crashed after a while..\n\nHere is the error I found in dmesg/syslog : http://pastebin.com/jMTCNEFy\n\nIf there is anything I can do to help, as far as testings, don't hesitate to let me know.\n\nThanks,\n\nedit: using git from 2011-08-22 on debian squeeze\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1873708/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/2064709", "body": "Alphalead : I think your trick allowed my rsync session to last longer but after a while it crashed again unfortunately\n\nMessage from syslogd@stor01 at Sep 11 12:18:11 ...\n kernel:[1714241.981661] Oops: 0002 [#1] SMP\n\nMessage from syslogd@stor01 at Sep 11 12:18:11 ...\n kernel:[1714241.981673] last sysfs file: /sys/module/mbcache/initstate\n\nMessage from syslogd@stor01 at Sep 11 12:18:11 ...\n kernel:[1714241.982056] Stack:\n\nMessage from syslogd@stor01 at Sep 11 12:18:11 ...\n kernel:[1714241.982133] Call Trace:\n\nMessage from syslogd@stor01 at Sep 11 12:18:11 ...\n kernel:[1714241.982206] Code: 49 8b 14 04 48 c1 e2 03 e8 83 88 ff ff 85 c0 75 10 48 8d 54 24 70 48 89 de 44 89 ef e8 5b f3 ff ff 48 8b 54 24 50 be d0 00 00 00 <48> c7 02 00 00 00 00 48 8b 54 24 48 48 8b 7c 24 70 e8 7d f6 ff\n\nMessage from syslogd@stor01 at Sep 11 12:18:11 ...\n kernel:[1714241.982346] CR2: 0000000000000000\n\nedit: version used is latest commit (2708f716c0)\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/2064709/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/2006354", "body": "I can confirm that his bug does **not exist** in zfs-fuse for linux. \n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/2006354/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/2352510", "body": "Gunnar Beutner was able to come up with a patch for this. I tested it on my development device and so far it works exactly as intended. We're doing some more testing later this week; at this point I would consider this ready for official evaluation so that it can be committed and this bug closed. I will post back here if we encounter any problems while we are testing this patch.\n\nhttps://gunnar-beutner.de/files/0001-Fixed-invalid-resource-re-use-in-file_find.patch\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/2352510/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/2811567", "body": "zfs-fuse:\n\n<pre>\ndd if=/dev/zero of=/tank/xxx/test.io bs=1024k count=1000\n1000+0 records in\n1000+0 records out\n1048576000 bytes (1.0 GB) copied, 8.48609 s, 124 MB/s\n</pre>\n\nubuntu-zfs:\n\n<pre>\ndd if=/dev/zero of=/tank/xxx/test.io bs=1024k count=1000\n1000+0 records in\n1000+0 records out\n1048576000 bytes (1.0 GB) copied, 114.533 s, 9.2 MB/s\n</pre>\n\nOk, i try recreate pool under ubuntu-zfs\n\n<pre>\n# zpool offline tank sdc\n# zpool detach tank sdc\n# zpool create -f test sdc\n# zpool status test\n  pool: test\n state: ONLINE\n scan: none requested\nconfig:\n\n        NAME        STATE     READ WRITE CKSUM\n        test        ONLINE       0     0     0\n          sdc       ONLINE       0     0     0\n\nerrors: No known data errors\n# zfs create test/xxx\n# dd if=/dev/zero of=/test/xxx/test.io bs=1024k count=1000\n1000+0 records in\n1000+0 records out\n1048576000 bytes (1.0 GB) copied, 53.5897 s, 19.6 MB/s\n</pre>\n\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/2811567/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/3299069", "body": "behlendorf, probably, i had bad results because i was try to use 32 bit OS.\nFresh install ferdora 16 32 bit was the same, but zfs on fedora 16 (x64) shows performance near to raw device.\nThanks.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/3299069/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/11986018", "body": "Please fix this, a year later it is still not working. Rudd-O has an open pull request, can it be pulled into te main branche?\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/11986018/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/3399837", "body": "Pretty much this is how I went about setting up everything.\n\nMy platform is Ubuntu 10.04.3 x86 (also used x64) running as a VMware VM on my laptop (as test).\n\nI downloaded the source and compiled as per the instructions on the ZFS on linux website.\n\nThen I compiled the Linux iSCSI target core backports from linux-iscsi.org. I also compiled the lio-utils and targetcli (the management tools).\n\nAfter I installed the deb packages of everything (iscsi target and ZFS) I created my zpool called (tank) and my zfs vol (fish). Because it was a test I just used the names from the website because it did not matter.\n\nThe command I use were the following;\n\nparted /dev/sdb\nmklabel gpt\nquit\n\nparted /dev/sdc\nmklabel gpt\nquit\n\nzpool create tank mirror /dev/sdb /dev/sdc\n\nzfs create tank/fish -V 18G\n\nAfter that was done I dropped into the targetcli tool and tried to add a block device to the /backstores/iblock section. The targetcli emulates a file system, kind of reminds me of /proc or /sys. When I execute the command \"create disk0 /dev/zd0\" it returns and error to me saying the chosen device is not a valid \"TYPE_DISK\". I am not sure though if \"TYPE_DISK\" is something internal to the target or if it is a Linux thing.\n\nThe only way I could use ZFS with the target was to format the ZFS vol with something like ext4 and then create an image file with dd then use the file_io feature of the target. But the is not only complicated but completely undermines the entire point of using ZFS.\n\nWhen I mentioned that the ZFS vols have no vendor information I was referring to what I see when I run \"parted -l\" and look at /dev/zd0. When compared to the VMware disks there is information about who made the disk or anything, not even faked information just to fill the space. I will add an output when I have a chance.\n\nIf you need anymore info let me know.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/3399837/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/3442037", "body": "I get the code from there git repo. git://risingtidesystems.com/\n\nThe only slightly annoying thing is you have to build several packages before you can build the targetcli tool.\n\nBut everything you need is there.\n\nYou need to build the tools in an similar order to this;\n1. lio-utils\n2. configshell\n3. rtslib\n4. targetcli\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/3442037/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/3707762", "body": "I have small update to announce based on my reported issue, I may have a source of the problem.\n\nI believe the error \"Not TYPE_DISK\" is a problem with the iSCSI target drivers and may have nothing to do with ZFS.\n\nThe reason for the error I hypothoize is because ZFS is not listing it ZVOLs in /dev/disk which is most likely where the iSCSI target is look for them and that would sort of explain the error, because it is say that the ZVOL is not a type of device found is /dev/disk. \n\nSo unless something changes with the iSCSI target drivers before the \"final\" release with kernel v3.4 then ZFS just may have sit out on that one.\n\nI will \"try\" to report the issue to the devs of the iSCSI target but I have not heard anything since before Christmas when I last attempted.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/3707762/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/5439790", "body": "Experiencing the same issues with 2.6.32-41 on 10.04 (AMD X2-555 proc in an ASUS M4A88T MB, 16GB ecc).  No apparent problems with 2.6.32-40.  Sorry for lack of trace info, may have time this weekend.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/5439790/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/5441206", "body": "Correction, 12GB.  Might as well mention this:\nJust did a quick check and BIOS version was latest but release date appeared inconsistent.  So updated BIOS anyway, disabled legacy USB, and booted 2x4GB with just channel A (matched pair).  Checked dmesg and errata message is still there.   There's a sleeping zfs mount -a process (configured automount) and any zpool/zfs commands in a shell hang.  FWIW.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/5441206/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/7986088", "body": "I've installed Fedora 17 to a test System with ZFS due to @Rudd-O  \n+1 to this\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/7986088/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/20962527", "body": "Allow me to shed some light on this.\n\nLet's consider an old-school nfs4 export using a native Linux filesystem, one share called 'pmr':\n\n``` /etc/fstab\n/dev/groups/pmr /storage/pmr      xfs    inode64,logdev=/dev/ssdcache/pmr,logbufs=8  1 2\n/storage/pmr    /exports/pmr      none   rw,bind         0 0\n```\n\n``` /etc/exports\n/exports     [nfs4 export root settings]\n/exports/pmr [per-share settings]\n```\n\nWhen the system is booting, the xfs filesystem will be mounted first, followed by a bind mount from /storage/pmr to /exports/pmr. The latter then is exported via /etc/exports using nfs4 and we're all happy.\n\nNow consider a zfs-based scenario.\n\nSince there are no zfs entries in fstab, it becomes:\n\n``` /etc/fstab\n/storage/pmr    /exports/pmr      none   rw,bind         0 0\n```\n\nWhen the system boots, a bind-type mount will be created from /storage/pmr to /exports/pmr which is effectively mounting the underlying filesystem (most likely / ) to the bind point and exporting that. The clients will see the contents of an empty directory as the exporter uses the / bind mount. On the server, the confused administrator will see the actual zfs and will scratch their head.\n\nI don't think this is a bug in zfs rather a race condition between the distribution's native localfs init script and zfs. Perhaps localfs should depend on zfs and not the other way around.\n\nAlternatively, the zfs service should parse some file that will tell it how the binds go and bind after mounting the zfs filesystem. Perhaps a file in /etc/zfs/ like 'binds' would work.\n\nPersonally (sysadmin cap on) /etc/zfs/binds would work for me (together with a bit of parsing in /etc/init.d/zfs) as it's sufficiently low-tech and doesn't require changes in the actual zfs stack.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/20962527/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/20965023", "body": "Proposed patch (only lsb script, others are most likely derivative):\n\n``` patch\n--- etc/init.d/zfs.lsb.in.orig  2013-07-15 12:47:20.055257882 +0100\n+++ etc/init.d/zfs.lsb.in       2013-07-15 12:49:44.732137370 +0100\n@@ -29,6 +29,7 @@\n ZFS=\"@sbindir@/zfs\"\n ZPOOL=\"@sbindir@/zpool\"\n ZPOOL_CACHE=\"@sysconfdir@/zfs/zpool.cache\"\n+ZFS_NFS4_BINDS=\"@sysconfdir@/zfs/binds\"\n\n # Source zfs configuration.\n [ -r '/etc/default/zfs' ] &&  . /etc/default/zfs\n@@ -78,6 +79,26 @@\n                log_end_msg $?\n        fi\n\n+        # Create (optional) binds to the NFS4 export tree\n+        if [ -e \"$ZFS_NFS4_BINDS\" ] ; then\n+                log_begin_msg \"Binding NFS4 mounts\"\n+                sed -e \"s/#.*//\" -e \"/^$/d\" $ZFS_NFS4_BINDS | while read LINE\n+                do\n+                        MODE=\"`echo $LINE | awk '{print $1}'`\"\n+                        SRC=\"`echo $LINE | awk '{print $2}'`\"\n+                        DEST=\"`echo $LINE | awk '{print $3}'`\"\n+                        case $MODE in\n+                                bind)   MOUNTPOINT=\"`zfs get mountpoint $SRC | grep \"$SRC\" | awk '{print $3}'`\"\n+                                        mount -o $MODE $MOUNTPOINT $DEST\n+                                        log_end_msg $?\n+                                        ;;\n+                                *)      echo \"Unknown bind mode ($MODE) in $ZFS_NFS4_BINDS. Aborting.\"\n+                                        exit 4\n+                                        ;;\n+                        esac\n+                done\n+        fi\n+\n        touch \"$LOCKFILE\"\n }\n\n@@ -85,6 +106,25 @@\n {\n        [ ! -f \"$LOCKFILE\" ] && return 3\n\n+       if [ -e \"$ZFS_NFS4_BINDS\" ] ; then\n+                log_begin_msg \"Detaching NFS4 binds\"\n+                sed -e \"s/#.*//\" -e \"/^$/d\" $ZFS_NFS4_BINDS | while read LINE\n+                do\n+                        MODE=\"`echo $LINE | awk '{print $1}'`\"\n+                        SRC=\"`echo $LINE | awk '{print $2}'`\"\n+                        DEST=\"`echo $LINE | awk '{print $3}'`\"\n+                        case $MODE in\n+                                bind)   MOUNTPOINT=\"`zfs get mountpoint $SRC | grep \"$SRC\" | awk '{print $3}'`\"\n+                                        umount $DEST\n+                                        log_end_msg $?\n+                                        ;;\n+                                *)      echo \"Unknown bind mode ($MODE) in $ZFS_NFS4_BINDS. Aborting.\"\n+                                        exit 4\n+                                        ;;\n+                        esac\n+                done\n+        fi\n+\n        log_begin_msg \"Unmounting ZFS filesystems\"\n        \"$ZFS\" umount -a\n        log_end_msg $?\n```\n\n$MODE may look redundant but perhaps could be kept for future expansion, maybe there could be other bind types.\n\nThe /etc/zfs/binds file would look like this:\n\n``` /etc/zfs/binds\n#    zpool[/dataset]        mountpoint\nbind storage/pmr            /exports/pmr\n```\n\nOf course the distribution source would only contain the first line. I believe this is consistent with other files in /etc/zfs.\n\nCheers,\ngrok\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/20965023/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/45432317", "body": "@FransUrbo `/etc/rc.local` does not exist and is not called in all distributions. Even more, `systemd` based distributions (good luck finding one without it these days) won't have it by definition.\n\nAre you suggesting that instead of editing a config file (present, documented) you would rather ask everyone to roll their own code, manually create bind mounts? That doesn't sound like a sane systems management practice.\n\nWhen ZoL filesystem needs to be exported over NFS4, a bind mount must be created. No standard mechanism in GNU/Linux will allow for it if the filesystem is not present in `/etc/fstab`. Since it's ZFS that's 'special', I will argue that it is its own responsibility to provide the functionality required for other parts of the system to continue to function.\n\nIf you don't like my solution, that's fine, please provide a better one or show where exactly am I incorrect. Saying something is 'hackish' and then suggesting that sysadmins 'sort it out in rc.local' isn't constructive.\n\nRegards,\njz\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/45432317/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/45433327", "body": "@FransUrbo \n\nWhat use is a filesystem that cannot be exported over network?\n\nNFS4 exports are different from NFS3 exports. There is a certain, established standard of creating them in GNU/Linux, there exists a well documented process that is different from Solaris-isms still present in ZoL.\n\nI wasn't aware `zfs set sharenfs=on` is able to produce NFS4 mounts. Could you please quote options required to make that happen? How do you define the mount tree? This is different from NFS3.\n\nWhat bugs in other software are you referring to? Exporting NFS4 works perfectly fine in GNU/Linux. Since ZoL provides PV, VG and LV management as well as filesystem mount points in a way that is abstracted from the current device paradigm on Linux, certain steps need to be taken to make those two work together.\n\nWhile you are free to disagree, I still haven't seen a patch that solves the problem. GNU/Linux nfs-kernel-server (and this is ZFS on _Linux_) requires mount points bound into a central exports tree. Since binding is done early (and you can't make the `zfs` init script depend on `$localfs`) ZoL needs to catch up. \n\nNFS4 provides capabilities like idmapd (how would you propose to integrate `zfs set sharenfs` with starting `idmapd`, are there hooks for that? How do I call them?), caching, subtree checks, consistent filesystem IDs and performance improvements over NFS3.\n\nThe logical way to do it (and I have consulted this with a number of Linux Sysadmins before presenting it here) is for the init script to have a mechanism to create the required bound mounts to the exports tree. The section in the init script is self-contained, fails safe (no action if the config file isn't present) and does introduce required compatibility with the host operating system. In one file that is owned by the ZFS package.\n\nIf you continue to disagree, please produce a patch that solves the issue for NFS4 and ZoL or provide a way of exporting NFS4, including all the required export options like the following excerpt from a production environment:\n\n``` /etc/exports\n/exports     172.5.125.0/24(ro,async,wdelay,insecure,root_squash,no_subtree_check,fsid=0)\n/exports     172.5.124.0/25(ro,async,wdelay,insecure,root_squash,no_subtree_check,fsid=0)\n/exports/pmr 172.5.125.0/24(rw,async,wdelay,root_squash,no_subtree_check)\n/exports/pmr 172.5.124.0/25(rw,sync,wdelay,no_root_squash,no_subtree_check)\n```\n\nPlease understand, `rc.local` is the last resort, it isn't available on all distributions, some don't even have an equivalent script and requiring systems administrators to manually do those steps is error-prone. Perhaps one can do it on their home computer but hardly in an enterprise environment where consistency and sustainability is key.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/45433327/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/45434151", "body": "@FransUrbo \n\nThe issue #1029 you referred me to is highlighting the problem I've solved; no way to correctly set up NFS4 shares using Solaris-isms under Linux.\n\n> > Could you please quote options required to make that happen?\n> \n> I did. You need to slow down and read what's given to you.\n\nUnless you meant the four dots at the end of `zfs set sharenfs=on`, I must have missed it.\n\nI'm not going to continue this conversation with you as it's no longer productive.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/45434151/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/73043264", "body": ":+1: \n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/73043264/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/10101505", "body": "oh, how embarrassing.. adding autogen.sh to my weekly routine. Thanks!\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/10101505/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/13097318", "body": "Hey, so while apt-get update automatically chooses 3.6.0-23-virtual for the chroot , I should rather install 3.6.0-29-generic which is the same as the hosts?  Gotcha.\nJust worth noting that i've followed the HOW TO step-by-step and that a virtual kernel (different from the hosts) gets installed by default when installing ubuntu-minimal in a chroot environment.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/13097318/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/13114557", "body": "Thanks for the replies, No objections behlendorf. \nCheers\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/13114557/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/17124603", "body": "http://zfsonlinux.org/faq.html#WhyShouldIUseA64BitSystem\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/17124603/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/39197997", "body": "Some testing on SLES11 SP3 (obs build instance):\n\nThe `path_lookup()` is also triggered on SLES' 3.0.101 kernel so it looks like a proper autoconf check is required.\n\n@Milan-Benes:\n\nSince `spl_kern_path_parent` macro can expand to either `path_lookup(path, LOOKUP_PARENT, nd)`, `kern_path_parent_fn(path, nd)` or `kern_path_parent(path, nd)`, a _quick and very, very dirty_ fix would be to manually patch and build if you're desperate for the functionality. \n\nNote that the `kern_` functions use 2 arguments and not 3 so (I'm going to hell for this!) the middle one needs to go.\n\nSo after applying https://github.com/zfsonlinux/zfs/pull/1655 to 0.6.2 you can try something like this:\n\n``` patch\n--- module/zfs/zfs_ctldir.c.orig        2014-04-01 12:48:37.756605773 +0100\n+++ module/zfs/zfs_ctldir.c     2014-04-01 12:50:58.674195921 +0100\n@@ -997,8 +997,8 @@\n                goto out_path_buff;\n        }\n\n-       error = path_lookup(path_buff, LOOKUP_FOLLOW | LOOKUP_DIRECTORY, &nd);\n-       if (!error)\n+       error = kern_path_parent(path_buff, &nd);\n+       if (!error)\n                path_put(&nd.path);\n\n out_path_buff:\n```\n\nIt builds but **be warned**, may eat your gerbil.\n\n**Edit:** \n\n```\nZFS: snapshot home/tank@auto_daily-2014-03-27-1600 auto mounted at /home/tank/.zfs/snapshot/auto_daily-2014-03-27-1600 unexpectedly unmounted\n```\n\nAnd a nice NULL pointer:\n\n```\nApr  1 13:32:24 hematus kernel: [   83.305579] ZFS: snapshot home/tank@auto_daily-2014-03-27-1600 auto mounted at /home/tank/.zfs/snapshot/auto_daily-2014-03-27-1600 unexpectedly unmounted\nApr  1 13:35:00 hematus kernel: [  239.301971] BUG: unable to handle kernel NULL pointer dereference at 0000000000000020\nApr  1 13:35:00 hematus kernel: [  239.301978] IP: [<ffffffffa065e3a6>] zfsctl_lookup_snapshot_path+0x1a6/0x2c0 [zfs]\nApr  1 13:35:00 hematus kernel: [  239.302022] PGD 0\nApr  1 13:35:00 hematus kernel: [  239.302024] Oops: 0000 [#1] SMP\nApr  1 13:35:00 hematus kernel: [  239.302027] CPU 10\nApr  1 13:35:00 hematus kernel: [  239.302028] Modules linked in: md5 nfsd autofs4 binfmt_misc edd nfs lockd fscache auth_rpcgss nfs_acl sunrpc mpt3sas mpt2sas scsi_transport_sas raid_class mptctl mptbase bonding mperf microcode ext3 jbd mbcache loop flashcache(FN) pciehp zfs(PFN) zcommon(PFN) znvpair(PFN) zavl(PFN) zunicode(PFN) spl(FN) ipv6 ipv6_lib zlib_deflate ixgbe joydev usbhid hid igb usb_storage dca ptp dcdbas(X) pcspkr shpchp pci_hotplug sr_mod mei ses iTCO_wdt cdrom enclosure iTCO_vendor_support button wmi acpi_power_meter rtc_cmos pps_core acpi_pad sg mdio xfs dm_mirror dm_region_hash dm_log linear ehci_hcd usbcore usb_common sd_mod crc_t10dif processor thermal_sys hwmon scsi_dh_rdac scsi_dh_hp_sw scsi_dh_emc scsi_dh_alua scsi_dh dm_snapshot dm_mod ahci libahci libata megaraid_sas scsi_mod\nApr  1 13:35:00 hematus kernel: [  239.302072] Supported: No, Proprietary and Unsupported modules are loaded\nApr  1 13:35:00 hematus kernel: [  239.302074]\nApr  1 13:35:00 hematus kernel: [  239.302076] Pid: 7433, comm: nfsd Tainted: PF          NX 3.0.101-0.15-default #1 Dell Inc. PowerEdge R720/0X3D66\nApr  1 13:35:00 hematus kernel: [  239.302080] RIP: 0010:[<ffffffffa065e3a6>]  [<ffffffffa065e3a6>] zfsctl_lookup_snapshot_path+0x1a6/0x2c0 [zfs]\nApr  1 13:35:00 hematus kernel: [  239.302099] RSP: 0018:ffff8817dbee99e0  EFLAGS: 00010246\nApr  1 13:35:00 hematus kernel: [  239.302100] RAX: 0000000000000000 RBX: ffff8817f116c000 RCX: 0000000000000020\nApr  1 13:35:00 hematus kernel: [  239.302102] RDX: ffff8817f116e4c8 RSI: 0000000000001000 RDI: ffff8817dbee9ab0\nApr  1 13:35:00 hematus kernel: [  239.302104] RBP: 0000000000000da2 R08: e848000000000000 R09: 1200000000000000\nApr  1 13:35:00 hematus kernel: [  239.302106] R10: 0000000000000000 R11: ffffffff8120f630 R12: ffff8817dbee9b60\nApr  1 13:35:00 hematus kernel: [  239.302108] R13: ffff8817f116e4c8 R14: ffff8817f116c000 R15: 0000000000000006\nApr  1 13:35:00 hematus kernel: [  239.302110] FS:  0000000000000000(0000) GS:ffff88187faa0000(0000) knlGS:0000000000000000\nApr  1 13:35:00 hematus kernel: [  239.302112] CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b\nApr  1 13:35:00 hematus kernel: [  239.302114] CR2: 0000000000000020 CR3: 0000000001a09000 CR4: 00000000001407e0\nApr  1 13:35:00 hematus kernel: [  239.302116] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000\nApr  1 13:35:00 hematus kernel: [  239.302118] DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400\nApr  1 13:35:00 hematus kernel: [  239.302120] Process nfsd (pid: 7433, threadinfo ffff8817dbee8000, task ffff8817dbee6380)\nApr  1 13:35:00 hematus kernel: [  239.302122] Stack:\nApr  1 13:35:00 hematus kernel: [  239.302123]  0000000000011800 ffff8817dbee9c44 ffff88187f429a00 0000000000000da2\nApr  1 13:35:00 hematus kernel: [  239.302129]  ffff8817dbee9bd8 0000000000000004 0000000000000004 00000000000000a8\nApr  1 13:35:00 hematus kernel: [  239.302133]  00000000000000a8 ffffffff81145a8e ffff8817f420d400 ffff8817f1656800\nApr  1 13:35:00 hematus kernel: [  239.302137] Call Trace:\nApr  1 13:35:00 hematus kernel: [  239.302221]  [<ffffffffa065e52b>] zfsctl_lookup_objset+0x6b/0x90 [zfs]\nApr  1 13:35:00 hematus kernel: [  239.302284]  [<ffffffffa0672241>] zfs_vget+0xf1/0x350 [zfs]\nApr  1 13:35:00 hematus kernel: [  239.302356]  [<ffffffffa068edf1>] zpl_fh_to_dentry+0x41/0x60 [zfs]\nApr  1 13:35:00 hematus kernel: [  239.302420]  [<ffffffff811d69df>] exportfs_decode_fh+0x6f/0x290\nApr  1 13:35:00 hematus kernel: [  239.302429]  [<ffffffffa086198d>] nfsd_set_fh_dentry+0x17d/0x380 [nfsd]\nApr  1 13:35:00 hematus kernel: [  239.302440]  [<ffffffffa0861d6b>] fh_verify+0x1db/0x2b0 [nfsd]\nApr  1 13:35:00 hematus kernel: [  239.302448]  [<ffffffffa0870b41>] nfsd4_proc_compound+0x341/0x520 [nfsd]\nApr  1 13:35:00 hematus kernel: [  239.302463]  [<ffffffffa085e381>] nfsd_dispatch+0xb1/0x250 [nfsd]\nApr  1 13:35:00 hematus kernel: [  239.302474]  [<ffffffffa07826a3>] svc_process_common+0x333/0x620 [sunrpc]\nApr  1 13:35:00 hematus kernel: [  239.302488]  [<ffffffffa0782ce1>] svc_process+0x101/0x160 [sunrpc]\nApr  1 13:35:00 hematus kernel: [  239.302500]  [<ffffffffa085eb3d>] nfsd+0xcd/0x150 [nfsd]\nApr  1 13:35:00 hematus kernel: [  239.302505]  [<ffffffff81082966>] kthread+0x96/0xa0\nApr  1 13:35:00 hematus kernel: [  239.302511]  [<ffffffff81469ee4>] kernel_thread_helper+0x4/0x10\nApr  1 13:35:00 hematus kernel: [  239.302514] Code: 00 00 00 00 00 48 8b 87 c8 34 00 00 4c 8d af c8 24 00 00 48 8d bc 24 d0 00 00 00 be 00 10 00 00 4c 89 ea 48 89 84 24 d0 00 00 00\nApr  1 13:35:00 hematus kernel: <48>[  239.302527]  8b 40 20 48 89 84 24 d8 00 00 00 e8 49 fd ff ff 85 c0 0f 84\nApr  1 13:35:00 hematus kernel: [  239.302533] RIP  [<ffffffffa065e3a6>] zfsctl_lookup_snapshot_path+0x1a6/0x2c0 [zfs]\nApr  1 13:35:00 hematus kernel: [  239.302551]  RSP <ffff8817dbee99e0>\nApr  1 13:35:00 hematus kernel: [  239.302552] CR2: 0000000000000020\nApr  1 13:35:00 hematus kernel: [  239.302554] ---[ end trace c16be50e3596fc64 ]---\n```\n\nSo yeah, doesn't work just yet.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/39197997/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/39320535", "body": "@andrey-ve \n\nI grepped `/usr/src/linux/include` on a current SLES11 SP3 (and do bear in mind SuSE patches their kernels heavily so the 3.0.101 has interfaces probably similar to 3.6 vanilla) shows no 'HAVE_MOUNT_*' strings.\n\nThe only thing in the region of that was:\n\n```\n$ grep -Ri MOUNT_NODEV *\nlinux/fs.h:extern struct dentry *mount_nodev(struct file_system_type *fs_type,\n```\n\nit's defined as:\n\n``` h\nextern struct dentry *mount_nodev(struct file_system_type *fs_type,\n        int flags, void *data,\n        int (*fill_super)(struct super_block *, void *, int));\n```\n\nThere's also:\n\n``` h\n#define MNT_NODEV       0x02\n```\n\nin `linux/mount.h`.\n\nJust in case, I've put the src.rpm for the stock SLES11 SP3 kernel source at https://anorien.csc.warwick.ac.uk/kernel-source-3.0.76-0.11.1.x86_64.rpm - it will produce the /usr/src/linux used for building on SLES. \n\nHope this helps anyway, don't hesitate to ask if you need more information.\n(edit: updated rpm url)\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/39320535/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "JakeWharton": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/147018", "body": "These two lines should have four spaces before them so they are rendered like this:\n\n```\n$ ./configure\n$ make pkg\n```\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/147018/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "review_comments": []}, "rdylina": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/194382", "body": "Would it not be better to treat this somewhat like a security issue by blacklisting all known devices that are definitely not available to be used as block devices? Somehow seems safer to me.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/194382/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "review_comments": []}, "fajarnugraha": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/282697", "body": "Brian, cmd/zvol_id/Makefile.am is missing. Could you please upload it? Thanks.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/282697/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/282698", "body": "Sorry, I mean cmd/zvol_id/Makefile.in\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/282698/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/282796", "body": "Create another branch, then copy previous comments manually?\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/282796/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/283041", "body": "Copying previous note from email:\n\n<pre>\nfrom    : behlendorf <noreply@github.com>\ndate    : Fri, Feb 25, 2011 at 3:36 AM\nsubject : Re: [GitHub] Use udev to create /dev/zvol/[dataset_name] links [behlendorf/zfs feaf4b2]\n</pre>\n\n- Removed Makefile-sample, with the full integration in the build system it isn't needed.\n- Added all autogen.sh products (Makefile.in, configure) using the following versions of the utils.  Using the same versions of the tools minimizes how much change there is in the autogen products and makes it easier to review.\n  \n  autoconf (GNU Autoconf) 2.63\n  automake (GNU automake) 1.11.1\n  ltmain.sh (GNU libtool) 2.2.6b\n- Added the CDDL header to zvol_id_main.c, including correctly attributing the source.\n- Minor stray whitespace cleanup.\n- Update kmem_free() in zvol_remove_minors() to match  kmem_zalloc()'s use of MAXNAMELEN.  If we fail to do the the memory account code will flag this is a memory leak.  It's critical to ensure you alloc/free both use the same size for the buffer.\n- Add <sys/stat.h> header in zvol_id_main.c, without it my build was failing on RHEL6.\n\nhttps://github.com/behlendorf/zfs/commit/feaf4b287322d6123336f139049686114f6c6ee8#commitcomment-282533\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/283041/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "review_comments": []}, "nedbass": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/333338", "body": "Mixing tabs and spaces here\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/333338/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/333382", "body": "Done.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/333382/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/334541", "body": "Darn, missed this misaligned fi!  Oh well, I'll commit a new fix\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/334541/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/409893", "body": "Yay for killing abominable code!  Not sure if dbuf_hold_impl() is in the same call path, but \nfc5bb51f08a6c91ff9ad3559d0266eeeab0b1f61 employs the same hack to reduce its stack.\nYou may want to check if it can now be safely reverted as well.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/409893/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/413647", "body": "Opened Issue #263 to track this.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/413647/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}], "review_comments": []}, "Rudd-O": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/333340", "body": "## Fix it in your tree, pullrequest, then I will commit later on. \n\nSent from my Android phone with K-9 Mail. Please excuse my brevity.\n\nnedbass reply@reply.github.com wrote:\n\nMixing tabs and spaces here -- Reply to this email directly or view it on GitHub: https://github.com/behlendorf/zfs/commit/6583dcacdcca2aad7eaec51f31797a3533845099#commitcomment-333338\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/333340/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "review_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11071", "body": "don't hardcode the paths, please.  otherwise it will fail depending on where the utilities are installed.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11071/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11072", "body": "we sync.  we expect no unmounting to happen here since it either will fail if core file systems are mounted and have files open, or successfully unmount the file systems only to make the later initscripts crap out horribly because core file systems are not available anymore.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11072/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11073", "body": "show better status here\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11073/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11251", "body": "what should I do with these two lines?  Remove them?\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11251/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11252", "body": "should I re-add this file?\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11252/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11289", "body": "I will add this right now.\n\nEl Wednesday, March 23, 2011, behlendorf escribi\u00f3:\n\n> > @@ -1,6 +0,0 @@\n> > \n> > ## -Stub file for 'make dist' distdir rule.\n> > \n> > -This file is directly referenced by ../Makefile.am as a source\n> > -file and thus will be expected by 'make dist'.  To avoid this\n> \n> This file should be readded exactly for the reasons mentioned in the file.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11289/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11290", "body": "The file has been re-added as of commit 9549dd1 and pushed too.\n\nNow onto the next revision.\n\nEl Wednesday, March 23, 2011, behlendorf escribi\u00f3:\n\n> > @@ -1,6 +0,0 @@\n> > \n> > ## -Stub file for 'make dist' distdir rule.\n> > \n> > -This file is directly referenced by ../Makefile.am as a source\n> > -file and thus will be expected by 'make dist'.  To avoid this\n> \n> This file should be readded exactly for the reasons mentioned in the file.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11290/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11291", "body": "Commit 5469b88, just pushed, removes those by simply cherry-picking your own \ncommit on top of the merge.\n\nEl Wednesday, March 23, 2011, behlendorf escribi\u00f3:\n\n> > @@ -204,6 +204,8 @@ const struct super_operations zpl_super_operations =\n> > {\n> > \n> > ```\n> > .put_super  = zpl_put_super,\n> > .write_super    = NULL,\n> > .sync_fs    = zpl_sync_fs,\n> > ```\n> > -   .freeze_fs  = NULL,\n> \n> Yes, please remove them.  They are currently unused hooks and they cause\n> compile errors on older platforms.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11291/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11294", "body": "File removed.  Commit pushed.  Let me refresh the page to see how the merge \ndiff will look like.  You should do the same.\n\nEl Wednesday, March 23, 2011, behlendorf escribi\u00f3:\n\n> > @@ -0,0 +1,59 @@\n> > +put the dracut/90zfs directory in /usr/share/dracut/modules.d (or\n> > symlink it)\n> \n> A version of this file was already added to the dracut subdirectory.  If\n> you want to make changes/rewrite it that's fine but let's just keep one\n> copy of it around with the other dracut code.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11294/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}, "baryluk": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/383541", "body": "$ mkfs.ext3 /dev/zd0\n$ resize2fs /dev/zd0\n\nI hope you mean\n$ mkfs.ext3 /dev/tank/zd0\n$ resize2fs /dev/tank/zd0\n\nHaving full volume path as well pool name under dev is crucial to prevent conflicts. I would even like to have it under /dev/zvols/tank/zd0, to not conflict with default devices. Consider doing zpool create sda /dev/sda, zfs create -V 10g sda/sda. Horrible.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/383541/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/383556", "body": "See https://github.com/behlendorf/zfs/issues/152#issuecomment-1162158 for some more discussion.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/383556/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/383557", "body": "Probably releated to https://github.com/behlendorf/zfs/commit/4c0d8e50b99b4f3b4a9b7bc67ac7fc4e406f5755\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/383557/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/383767", "body": "Hmm. For me, more natural and more reliable will be to do this in opposite direction. Create device node in from start /dev/zvol/pool/dataset and then create symlink /dev/zd\\* (this actually can be skipped, as is in most practical cases useless beyond eventually symlinking to it from somewhere) and in /dev/disk/by-*/xxx pointing to /dev/zvol/pool/dataset. Is there any reasons or limitations of other tools (kernel, udev, sysfs?, creating DOS partitions on zvols? etc) that you want to put devices directly in the /dev/ directory? It is not necessary to put them there directly. \n\nPS. Hmm. I just checked open-iscsi, and do the same as you. First create /dev/sdX, and then symlink it into /dev/disk/by-path/ip-X.X.X.X:PP-iscsi-iqn-XYZ by udev. So you are right. IMHO it is remenescent of archaic structure of /dev/ directory. Not best possible and easy way, but looks to be standard in Linux. Neverthless /dev/zd\\* shouldn't be used anyway in such tools like fstab, mount, fdisk, fsck, mkfs.*, etc., as this names are unstable, for example doing zfs create -V 10g tank/zd1, will still create /dev/zd0 (at least if this was first volume create/mounted after reboot right?), and symlink in /dev/zvol/tank/zd1 -> ../../zd0. It is pretty confusing. This is the reason why I was somehow against it.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/383767/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "review_comments": []}, "dajhorn": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/461576", "body": "Kernel parameters are subject to decimal/octal/hexadecimal interpretation, so this example should be `spl_hostid=0x00bab10c`.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/461576/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/545339", "body": "zfsonlinux/zfs#370\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/545339/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/545340", "body": "zfsonlinux/zfs#370\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/545340/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/545341", "body": "zfsonlinux/zfs#370\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/545341/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/545343", "body": "zfsonlinux/zfs#370\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/545343/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}], "review_comments": []}, "kylef": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/511969", "body": "I didn't think about that.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/511969/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "review_comments": []}, "rlaager": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374212", "body": "What do you mean by this?\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374212/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374494", "body": "I've found this approach works best: Start from a checkout of upstream trunk. Then `git branch TOPIC; git checkout TOPIC`. Make your changes and commit. Push that branch to github. Repeat as necessary for the other features, starting from a checkout of upstream trunk each time. Then, do a pull request for each branch.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374494/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374507", "body": "The easiest solution is probably to leave your master tracking upstream master (i.e. you should not commit anything to master). Use a separate branch to combine your topic branches.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374507/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354255", "body": "domain should be 256 (255 + NUL). As a result, the other fields might need changing. I haven't looked closely.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354255/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354257", "body": "Is \"EPOH\" supposed to be \"epoch\"?\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354257/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354259", "body": "This should be checked for NUL-termination correctness.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354259/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354260", "body": "This should be checked for NUL-termination correctness.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354260/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354264", "body": "This should probably const char *.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354264/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354267", "body": "By \"EOL\", you probably meant \"NUL\"?\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354267/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354268", "body": "Like in the SMB patch, this usage of a function named file_is_executable() is really confusing.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354268/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354271", "body": "You're just blindly returning OK here. Should something be done?\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354271/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354272", "body": "What should this function do? Maybe I or someone can help flesh it out.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354272/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354276", "body": "You shouldn't be calling strlen() in a loop like this. This should be rewritten more like this (untested):\n\n```\nfor (c = line ; *c ; c++) {\n    if (*c == '\\r' || *c == '\\n') {\n      c = '\\0';\n      break;\n    }\n}\n```\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354276/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354281", "body": "The code inside this should be indented another level. (Is Github hiding that in the diff, maybe? I didn't check.)\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354281/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354285", "body": "What's the purpose of this check? I don't understand why /dev/zvol is hardcoded.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354285/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}}, "2": {"danielkza": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7059", "title": "Scrub gets stuck, becomes unstoppable and locks up user processes in uninterruptible sleep", "body": "Type                    | Version/Name\r\n---                     | ---\r\nDistribution Name       | Fedora\r\nDistribution Version    | 27\r\nLinux Kernel            | 4.14.13\r\nArchitecture            | x86_64\r\nZFS Version             | 0.7.5\r\nSPL Version             | 0.7.5\r\n\r\n### Describe the problem you're observing\r\n\r\nAfter a routine scrub starting on the background, some programs seem stuck in uninterruptible IO due to ZFS. Attempting\r\nto pause or stop the scrub does not work - the `zpool` command hangs and also becomes unkillable.\r\n\r\nHere is the `/proc/PID/stack` of the stuck `zpool`:\r\n\r\n```\r\n[<ffffffffc11f1c23>] cv_wait_common+0x113/0x130 [spl]\r\n[<ffffffffc11f1c55>] __cv_wait+0x15/0x20 [spl]\r\n[<ffffffffc182972d>] txg_wait_synced+0xdd/0x120 [zfs]\r\n[<ffffffffc1801f36>] dsl_sync_task+0x176/0x260 [zfs]\r\n[<ffffffffc180041e>] dsl_scrub_set_pause_resume+0x3e/0x40 [zfs]\r\n[<ffffffffc181e511>] spa_scrub_pause_resume+0x31/0x60 [zfs]\r\n[<ffffffffc1858f85>] zfs_ioc_pool_scan+0xb5/0xc0 [zfs]\r\n[<ffffffffc18592d6>] zfsdev_ioctl+0x1d6/0x600 [zfs]\r\n[<ffffffff9429f575>] do_vfs_ioctl+0xa5/0x610\r\n[<ffffffff9429fb59>] SyS_ioctl+0x79/0x90\r\n[<ffffffff94a0008d>] entry_SYSCALL_64_fastpath+0x20/0x83\r\n```\r\n\r\nAnd of one of the stuck user processes:\r\n\r\n```\r\n[<ffffffff940d7746>] io_schedule+0x16/0x40\r\n[<ffffffffc11f1bb9>] cv_wait_common+0xa9/0x130 [spl]\r\n[<ffffffffc11f1c98>] __cv_wait_io+0x18/0x20 [spl]\r\n[<ffffffffc187f7f2>] zio_wait+0xf2/0x1b0 [zfs]\r\n[<ffffffffc17c38d3>] dbuf_read+0x6e3/0x910 [zfs]\r\n[<ffffffffc17c5c19>] __dbuf_hold_impl+0x549/0x600 [zfs]\r\n[<ffffffffc17c5d71>] dbuf_hold_impl+0xa1/0xd0 [zfs]\r\n[<ffffffffc17c5e33>] dbuf_hold+0x33/0x60 [zfs]\r\n[<ffffffffc17cf1cd>] dmu_buf_hold_noread+0x8d/0x100 [zfs]\r\n[<ffffffffc17cf26f>] dmu_buf_hold+0x2f/0x80 [zfs]\r\n[<ffffffffc1845a5e>] zap_lockdir+0x4e/0xb0 [zfs]\r\n[<ffffffffc1845c3a>] zap_cursor_retrieve+0x17a/0x2e0 [zfs]\r\n[<ffffffffc1869abc>] zfs_readdir+0x13c/0x460 [zfs]\r\n[<ffffffffc1886911>] zpl_iterate+0x51/0x80 [zfs]\r\n[<ffffffff9429fce0>] iterate_dir+0x170/0x1a0\r\n[<ffffffff942a046a>] SyS_getdents+0xaa/0x140\r\n[<ffffffff94a0008d>] entry_SYSCALL_64_fastpath+0x20/0x83\r\n[<ffffffffffffffff>] 0xffffffffffffffff\r\n```\r\n\r\nHere is the affected pool status:\r\n\r\n```\r\n  pool: daniel-pc-media\r\n state: ONLINE\r\n  scan: scrub in progress since Thu Jan 18 03:29:02 2018\r\n    102G scanned out of 2,45T at 2,60M/s, 263h46m to go\r\n    0B repaired, 4,06% done\r\nconfig:\r\n\r\n    NAME                                 STATE     READ WRITE CKSUM\r\n    daniel-pc-media                      ONLINE       0     0     0\r\n      mirror-0                           ONLINE       0     0     0\r\n        ata-ST4000DM000-1F2168_Z301QGEZ  ONLINE       0     0     0\r\n        ata-ST4000DM000-1F2168_Z301QGCM  ONLINE       0     0     0\r\n```\r\n\r\nThere seems to be no progress actually being made, as none of the counters advance (other than the expected ETA).\r\n\r\n### Describe how to reproduce the problem\r\n\r\nNot able to so far. I can provide more observations of the running system if it doesn't force me to restart by\r\nbecoming unstable/unusable.\r\n\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n\r\nNothing of interest or related to ZFS is present in the kernel logs.\r\nThe problem *might* have been triggered by suspending and resuming the computer, but I was not monitoring the scrub before that, so I can't be sure.\r\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7059/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "makhomed": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7057", "title": "tasks txg_sync and zfs blocked for more than 120 seconds", "body": "### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       |  CentOS Linux\r\nDistribution Version    | 7.4.1708\r\nLinux Kernel                 |  3.10.0-693.11.6.el7\r\nArchitecture                 | x86_64\r\nZFS Version                  | 0.7.5-1\r\nSPL Version                  | 0.7.5-1\r\n\r\nZFS installed from zfs-kmod repo, ```baseurl=http://download.zfsonlinux.org/epel/7.4/kmod/$basearch/```\r\n\r\n### Describe the problem you're observing\r\n\r\nMessages in /var/log/messages about blocked tasks.\r\n\r\n### Describe how to reproduce the problem\r\n\r\nSorry, but I do not found way how to reproduce this bug.\r\nMay be stack trace will help to find root cause of this bug?\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n```\r\n\r\nJan 17 17:26:45 kvm-hardware-node kernel: INFO: task txg_sync:10906 blocked for more than 120 seconds.\r\nJan 17 17:26:45 kvm-hardware-node kernel: \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\nJan 17 17:26:45 kvm-hardware-node kernel: txg_sync        D ffff883f6a256eb0     0 10906      2 0x00000000\r\nJan 17 17:26:45 kvm-hardware-node kernel: Call Trace:\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04ddf57>] ? taskq_dispatch_ent+0x57/0x170 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff816ab6d9>] schedule+0x29/0x70\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff816a90e9>] schedule_timeout+0x239/0x2c0\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc07ba30f>] ? zio_taskq_dispatch+0x8f/0xa0 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc07ba352>] ? zio_issue_async+0x12/0x20 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc07bebcc>] ? zio_nowait+0xbc/0x150 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff816aac5d>] io_schedule_timeout+0xad/0x130\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff810b31a6>] ? prepare_to_wait_exclusive+0x56/0x90\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff816aacf8>] io_schedule+0x18/0x20\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04e24a2>] cv_wait_common+0xb2/0x150 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff810b34b0>] ? wake_up_atomic_t+0x30/0x30\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04e2598>] __cv_wait_io+0x18/0x20 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc07be49b>] zio_wait+0x10b/0x1b0 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc07346cf>] dsl_pool_sync+0xbf/0x440 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc07527c7>] spa_sync+0x437/0xdf0 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff810c6452>] ? default_wake_function+0x12/0x20\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff810bf074>] ? __wake_up+0x44/0x50\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0766a91>] txg_sync_thread+0x301/0x510 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0766790>] ? txg_fini+0x2a0/0x2a0 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04dcfa1>] thread_generic_wrapper+0x71/0x80 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04dcf30>] ? __thread_exit+0x20/0x20 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff810b252f>] kthread+0xcf/0xe0\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff810b2460>] ? insert_kthread_work+0x40/0x40\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff816b8798>] ret_from_fork+0x58/0x90\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff810b2460>] ? insert_kthread_work+0x40/0x40\r\nJan 17 17:26:45 kvm-hardware-node kernel: INFO: task zfs:21118 blocked for more than 120 seconds.\r\nJan 17 17:26:45 kvm-hardware-node kernel: \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\nJan 17 17:26:45 kvm-hardware-node kernel: zfs             D ffff883f79a38000     0 21118   8250 0x00000080\r\nJan 17 17:26:45 kvm-hardware-node kernel: Call Trace:\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff816ab6d9>] schedule+0x29/0x70\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04e2515>] cv_wait_common+0x125/0x150 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff810b34b0>] ? wake_up_atomic_t+0x30/0x30\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04e2555>] __cv_wait+0x15/0x20 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0765a2f>] txg_wait_synced+0xef/0x140 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0727d50>] ? dsl_dataset_snapshot_check_impl+0x210/0x210 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc073d017>] dsl_sync_task+0x177/0x270 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc07289d0>] ? dsl_dataset_snapshot_sync_impl+0x760/0x760 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0727d50>] ? dsl_dataset_snapshot_check_impl+0x210/0x210 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc07289d0>] ? dsl_dataset_snapshot_sync_impl+0x760/0x760 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0728dc3>] dsl_dataset_snapshot+0x133/0x2e0 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0479157>] ? nvlist_remove_all+0x77/0xd0 [znvpair]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0479655>] ? nvlist_add_common.part.51+0x325/0x430 [znvpair]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff811df99c>] ? __kmalloc_node+0x5c/0x2b0\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04db31d>] ? spl_kmem_alloc_impl+0xcd/0x170 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04db31d>] ? spl_kmem_alloc_impl+0xcd/0x170 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04db31d>] ? spl_kmem_alloc_impl+0xcd/0x170 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0479fc2>] ? nvlist_lookup_common.part.71+0xa2/0xb0 [znvpair]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0796868>] zfs_ioc_snapshot+0x348/0x3b0 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0798606>] zfsdev_ioctl+0x1d6/0x650 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff8121710d>] do_vfs_ioctl+0x33d/0x540\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff816b3801>] ? __do_page_fault+0x171/0x450\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff812173b1>] SyS_ioctl+0xa1/0xc0\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff816b89fd>] system_call_fastpath+0x16/0x1b\r\n```", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7057/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "beren12": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7056", "title": "Improve snapshot listing error message", "body": "### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Debian\r\nDistribution Version    | 9\r\nLinux Kernel                 | 4.13.13-1~bpo9+1\r\nArchitecture                 | x64\r\nZFS Version                  | 0.7.4\r\nSPL Version                  | 0.7.4\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\nlisting snapshots for a single dataset fails unless -r is used, but this is not mentioned in the error message. -r is not needed to list all snapshots, so it can be a confusing behavior.\r\n\r\n### Describe how to reproduce the problem\r\n\r\n```\r\nzfs list -t snap rpool\r\n```\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n\r\n```\r\nzfs list -t snap rpool\r\ncannot open 'rpool': missing '@' delimiter in snapshot name\r\n```\r\n\r\nCould we amend the error message to also give a hint? Or possibly be consistent and list all snapshots without -r, just as giving no dataset does? Bookmarks might also need the same edit, ike here:\r\n\r\n```diff\r\n--- lib/libzfs/libzfs_dataset.c\t2018-01-17 10:07:12.178817043 -0500\r\n+++ lib/libzfs/libzfs_dataset.c.new\t2018-01-17 10:06:47.307290884 -0500\r\n@@ -175,7 +175,7 @@\r\n \tif (type == ZFS_TYPE_SNAPSHOT && strchr(path, '@') == NULL) {\r\n \t\tif (hdl != NULL)\r\n \t\t\tzfs_error_aux(hdl, dgettext(TEXT_DOMAIN,\r\n-\t\t\t    \"missing '@' delimiter in snapshot name\"));\r\n+\t\t\t    \"missing '@' delimiter in snapshot name, did you mean to use -r?\"));\r\n \t\treturn (0);\r\n \t}\r\n```", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7056/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "behlendorf": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7052", "title": "zfs load-key double free", "body": "### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | CentOS\r\nDistribution Version    | 7\r\nLinux Kernel                 | 3.10.0-693.11.6.1\r\nArchitecture                 | x86_64\r\nZFS Version                  | zfs-0.7.0-246-gd658b2c\r\nSPL Version                  | master\r\n\r\n### Describe the problem you're observing\r\n\r\nWhen zfs is built with `--enable-debug --enable-debuginfo` and an incorrect passphrase is provided to `zfs load-key` followed by an empty one a \"double free or leak\" is reported.  Observed during manual testing.\r\n\r\n### Describe how to reproduce the problem\r\n\r\nAt build time `--enable-debug --enable-debuginfo`, then,\r\n\r\n```sh\r\n$ truncate -s 512M /var/tmp/vdev\r\n$ zpool create tank /var/tmp/vdev\r\n$ zfs create -o encryption=on -o keyformat=passphrase tank/fs\r\nEnter passphrase: password\r\nRe-enter passphrase: password\r\n$ zfs unload-key -a\r\n```\r\n\r\nReload the key giving the wrong password first \"password1\" which is correctly rejected.  Then just hit enter when prompted again.\r\n\r\n```sh\r\n$ zfs load-key -a\r\nEnter passphrase for 'tank/fs': password1\r\nKey load error: Incorrect key provided for 'tank/fs'.\r\nEnter passphrase for 'tank/fs': <empty>\r\nKey load error: Passphrase too short (min 8).\r\n*** Error in `cmd/zfs/.libs/lt-zfs': double free or corruption (fasttop): 0x000000000061f150 ***\r\n======= Backtrace: =========\r\n/lib64/libc.so.6(+0x7c619)[0x2aaaacc65619]\r\nlib/libzfs/.libs/libzfs.so.2(zfs_crypto_load_key+0xf3)[0x2aaaab109023]\r\ncmd/zfs/.libs/lt-zfs[0x406557]\r\ncmd/zfs/.libs/lt-zfs[0x405d41]\r\ncmd/zfs/.libs/lt-zfs[0x408298]\r\ncmd/zfs/.libs/lt-zfs[0x4051ef]\r\n/lib64/libc.so.6(__libc_start_main+0xf5)[0x2aaaacc0ac05]\r\ncmd/zfs/.libs/lt-zfs[0x405318]\r\n...\r\n```", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7052/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7026", "title": "Test case history_004_pos", "body": "### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | all\r\nDistribution Version    | all\r\nLinux Kernel                 | all\r\nArchitecture                 | all\r\nZFS Version                  | zfs-0.7.0-230-gb02beca\r\nSPL Version                  | 0.7\r\n\r\n### Describe the problem you're observing\r\n\r\nRarely observed failure of history_004_pos during automated testing.\r\n\r\n### Describe how to reproduce the problem\r\n\r\nReproducible by the buildbot.\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n\r\n\r\nhttp://build.zfsonlinux.org/builders/Amazon%202%20x86_64%20Release%20%28TEST%29/builds/105/\r\n\r\n```\r\nTest: /usr/share/zfs/zfs-tests/tests/functional/history/history_004_pos (run as root) [00:04] [FAIL]\r\n02:51:58.52 ASSERTION: 'zpool history' can cope with simultaneous commands.\r\n02:52:01.35 umount: testpool/clone3: mountpoint not found\r\n02:52:01.35 cannot unmount 'testpool/clone3': umount failed\r\n02:52:01.55 cannot create 'testpool/clone3': dataset already exists\r\n02:52:01.62 cannot promote 'testpool/clone3': not a cloned filesystem\r\n02:52:01.66 cannot destroy 'testpool/testfs3': filesystem has children\r\n02:52:01.66 use '-r' to destroy the following datasets:\r\n02:52:01.66 testpool/testfs3@snap\r\n02:52:01.81 cannot create 'testpool/testfs3': dataset already exists\r\n02:52:01.92 cannot create snapshot 'testpool/testfs3@snap': dataset already exists\r\n02:52:02.69 The entries count error: entry_count=297  orig_count = 103\r\n02:52:02.69 NOTE: Performing test-fail callback (/usr/share/zfs/zfs-tests/callbacks/zfs_dbgmsg.ksh)\r\n```", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7026/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/3da3488e6339ff2dc5c7f3da8c8a0c552d018d68", "message": "Fix shellcheck v0.4.6 warnings\n\nResolve new warnings reported after upgrading to shellcheck\r\nversion 0.4.6.  This patch contains no functional changes.\r\n\r\n* egrep is non-standard and deprecated. Use grep -E instead. [SC2196]\r\n* Check exit code directly with e.g. 'if mycmd;', not indirectly\r\n  with $?.  [SC2181]  Suppressed.\r\n\r\nReviewed-by: George Melikov <mail@gmelikov.ru>\r\nReviewed-by: Giuseppe Di Natale <dinatale2@llnl.gov>\r\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nCloses #7040"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/e1a0850c3570ae53df5779bc656f17b98b86f160", "message": "Force ztest to always use /dev/urandom\n\nFor ztest, which is solely for testing, using a pseudo random\r\nis entirely reasonable.  Using /dev/urandom ensures the system\r\nentropy pool doesn't get depleted thus stalling the testing.\r\nThis is a particular problem when testing in VMs.\r\n\r\nReviewed-by: Tim Chase <tim@chase2k.com>\r\nReviewed by: Thomas Caputi <tcaputi@datto.com>\r\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nCloses #7017 \r\nCloses #7036"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/fed90353d799acbc5e81b0dfadc6d649b0f2e8b5", "message": "Support -fsanitize=address with --enable-asan\n\nWhen --enable-asan is provided to configure then build all user\r\nspace components with fsanitize=address.  For kernel support\r\nuse the Linux KASAN feature instead.\r\n\r\nhttps://github.com/google/sanitizers/wiki/AddressSanitizer\r\n\r\nWhen using gcc version 4.8 any test case which intentionally\r\ngenerates a core dump will fail when using --enable-asan.\r\nThe default behavior is to disable core dumps and only newer\r\nversions allow this behavior to be controled at run time with\r\nthe ASAN_OPTIONS environment variable.\r\n\r\nAdditionally, this patch includes some build system cleanup.\r\n\r\n* Rules.am updated to set the minimum AM_CFLAGS, AM_CPPFLAGS,\r\n  and AM_LDFLAGS.  Any additional flags should be added on a\r\n  per-Makefile basic.  The --enable-debug and --enable-asan\r\n  options apply to all user space binaries and libraries.\r\n\r\n* Compiler checks consolidated in always-compiler-options.m4\r\n  and renamed for consistency.\r\n\r\n* -fstack-check compiler flag was removed, this functionality\r\n  is provided by asan when configured with --enable-asan.\r\n\r\n* Split DEBUG_CFLAGS in to DEBUG_CFLAGS, DEBUG_CPPFLAGS, and\r\n  DEBUG_LDFLAGS.\r\n\r\n* Moved default kernel build flags in to module/Makefile.in and\r\n  split in to ZFS_MODULE_CFLAGS and ZFS_MODULE_CPPFLAGS.  These\r\n  flags are set with the standard ccflags-y kbuild mechanism.\r\n\r\n* -Wframe-larger-than checks applied only to binaries or\r\n  libraries which include source files which are built in\r\n  both user space and kernel space.  This restriction is\r\n  relaxed for user space only utilities.\r\n\r\n* -Wno-unused-but-set-variable applied only to libzfs and\r\n  libzpool.  The remaining warnings are the result of an\r\n  ASSERT using a variable when is always declared.\r\n\r\n* -D_POSIX_PTHREAD_SEMANTICS and -D__EXTENSIONS__ dropped\r\n  because they are Solaris specific and thus not needed.\r\n\r\n* Ensure $GDB is defined as gdb by default in zloop.sh.\r\n\r\nSigned-off-by: DHE <git@dehacked.net>\r\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nCloses #7027"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/7e7f5132779a04da0070cf6e6ffd8e9b5f7692de", "message": "Disable history_004_pos\n\nOccasionally observed failure of history_004_pos due to the test\r\ncase not being 100% reliable.  In order to prevent false positives\r\ndisable this test case until it can be made reliable.\r\n\r\nReviewed-by: George Melikov <mail@gmelikov.ru>\r\nReviewed-by: Giuseppe Di Natale <dinatale2@llnl.gov>\r\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nIssue #7026 \r\nCloses #7028"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/bfe27ace0de64838d50ff351396423a481de6c84", "message": "Fix unused variable warnings\n\nResolved unused variable warnings observed after restricting\n-Wno-unused-but-set-variable to only libzfs and libzpool.\n\nReviewed-by: DHE <git@dehacked.net>\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\nCloses #6941"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/06401e42221d2f5130065caf70f8276ba4d19acd", "message": "Fix ztest_verify_dnode_bt() test case\n\nIn ztest_verify_dnode_bt the ztest_object_lock must be held in\norder to safely verify the unused bonus space.\n\nReviewed-by: DHE <git@dehacked.net>\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\nCloses #6941"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/b02becaa00aef3d25b30588bf49affbf1e9a84a4", "message": "Reduce codecov PR comments\n\nAttempt to reduce the number of comments posted by codecov\r\nto PR requests.  Based on the codecov documenation setting\r\n\"require_changes=yes\" and \"behavior=once\" should result in\r\na single comment under most circumstances.\r\n\r\nhttps://docs.codecov.io/v4.3.6/docs/pull-request-comments\r\n\r\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nIssue #7022 \r\nCloses #7025"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/0873bb6337452e3e028e40f5dad945b30deab185", "message": "Fix ARC hit rate\n\nWhen the compressed ARC feature was added in commit d3c2ae1\r\nthe method of reference counting in the ARC was modified.  As\r\npart of this accounting change the arc_buf_add_ref() function\r\nwas removed entirely.\r\n\r\nThis would have be fine but the arc_buf_add_ref() function\r\nserved a second undocumented purpose of updating the ARC access\r\ninformation when taking a hold on a dbuf.  Without this logic\r\nin place a cached dbuf would not migrate its associated\r\narc_buf_hdr_t to the MFU list.  This would negatively impact\r\nthe ARC hit rate, particularly on systems with a small ARC.\r\n\r\nThis change reinstates the missing call to arc_access() from\r\ndbuf_hold() by implementing a new arc_buf_access() function.\r\n\r\nReviewed-by: Giuseppe Di Natale <dinatale2@llnl.gov>\r\nReviewed-by: Tony Hutter <hutter2@llnl.gov>\r\nReviewed-by: Tim Chase <tim@chase2k.com>\r\nReviewed by: George Wilson <george.wilson@delphix.com>\r\nReviewed-by: George Melikov <mail@gmelikov.ru>\r\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nCloses #6171 \r\nCloses #6852 \r\nCloses #6989"}], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6999", "title": "Extend deadman logic", "body": "### Description\r\n\r\nThe intent of this patch is extend the existing deadman code such that it's flexible enough to be used by both ztest and on production systems.  The proposed changes include:\r\n\r\n* Added a new `zfs_deadman_failmode` module option which is used to dynamically control the behavior of the deadman.  It's loosely modeled after, but independant from, the pool failmode property.  It can be set to wait, continue, or panic.\r\n\r\n    * wait     - Wait for the \"hung\" I/O (default)\r\n    * continue - Attempt to recover from a \"hung\" I/O\r\n    * panic    - Panic the system\r\n\r\n* Added a new `zfs_deadman_ziotime_ms` module option which is analogous to zfs_deadman_synctime_ms` except instead of applying to a pool TXG sync it applies to zio_wait().  A   default value of 300s is used to define a \"hung\" zio.\r\n\r\n* The ztest deadman thread has been re-enabled by default, aligned with the upstream OpenZFS code, and then extended to terminate the process when it takes significantly longer to complete than expected.\r\n\r\n* The -G option was added to ztest to print the internal debug log when a fatal error is encountered.  This same option was previously added to zdb in commit fa603f82.  Update zloop.sh to unconditionally pass -G to obtain additional debugging.\r\n\r\n* The FM_EREPORT_ZFS_DELAY event which was previously posted when the deadman detect a \"hung\" pool has been replaced by a new dedicated FM_EREPORT_ZFS_DEADMAN event.\r\n\r\n* The proposed recovery logic attempts to restart a \"hung\"  zio by calling zio_interrupt() on any outstanding leaf zios.  We may want to further restrict this to zios in either the  ZIO_STAGE_VDEV_IO_START or ZIO_STAGE_VDEV_IO_DONE stages.  Calling zio_interrupt() is expected to only be useful for cases when an IO has been submitted to the physical device\r\n  but for some reasonable the completion callback hasn't been called by the lower layers.  This shouldn't be possible but  has been observed and may be caused by kernel/driver bugs.\r\n\r\n* The 'zfs_deadman_synctime_ms' default value was reduced from 1000s to 600s.\r\n\r\n* Depending on how ztest fails there may be no cache file to move.  This should not be considered fatal, collect the logs which are available and carry on.\r\n\r\n### Motivation and Context\r\n\r\nAdd some of the needed infrastructure to make it possible to root cause `ztest` \"hangs\" observed during automated testing.  With this change applied at least basic debugging information will be collected for any \"hangs\".  This change can be further augmented with improvements to the debugging infrastructure.\r\n\r\nIssue #6901.\r\n\r\n### How Has This Been Tested?\r\n\r\nLocally by running `zloop.sh` in-tree for approximated 4 days.  Over this time period the deadman behaved as expected and properly terminated `ztest` when it appeared to be hung.  Further analysis of the debug logs and cores obtained is still needed.  The expectation is they will provide some statistical insight in the most often observed failures.\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [x] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [x] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "OWNER"}], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/147559", "body": "Thanks, I hadn't noticed the rendering issue.  Fixed by commit bbf3a3575c0b5795d3e4ddc27523258dc61ffa88.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/147559/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/195492", "body": "I'm not particularly happy with all this grubbing around in /dev/ either for 'zpool import', but for the moment I view it as a short term solution.  The longer term solution, which is well under way, is to be tightly integrated with libblkid.  There has been a patch submitted upstream and accepted by the maintainers to correctly identify a disk which belongs to a zfs pool.  Once a version of libblkid with this change filters back in to the distributions we can simply consult libblkid for the list of zfs devices and avoid checking /dev/.  In fact all the code on the zfs side is already in place for this.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/195492/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/282533", "body": "- Removed Makefile-sample, with the full integration in the build system it isn't needed.\n- Added all autogen.sh products (Makefile.in, configure) using the following versions of the utils.  Using the same versions of the tools minimizes how much change there is in the autogen products and makes it easier to review.\n  \n  autoconf (GNU Autoconf) 2.63\n  automake (GNU automake) 1.11.1\n  ltmain.sh (GNU libtool) 2.2.6b\n- Added the CDDL header to zvol_id_main.c, including correctly attributing the source.\n- Minor stray whitespace cleanup.\n- Update kmem_free() in zvol_remove_minors() to match  kmem_zalloc()'s use of MAXNAMELEN.  If we fail to do the the memory account code will flag this is a memory leak.  It's critical to ensure you alloc/free both use the same size for the buffer.\n- Add <sys/stat.h> header in zvol_id_main.c, without it my build was failing on RHEL6.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/282533/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/282739", "body": "Sorry!  I've force updated my branch to include the Makefile.in... in and the process obliterated the previous review comments.  We need to figure out how to handle this best, I'd really like to be landing one nice concise commit to fix an issue.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/282739/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/383680", "body": "The zvol will be created with unique /dev/zdN names and then the /dev/zvol/pool/dataset links are created with udev rules.  This is exactly how normal block devices work such as /dev/sda with /dev/disk/by-_/_ links created with udev.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/383680/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/384675", "body": "This behavior is forced by the Linux kernel.  The special device files created under /dev/\\* has certain limitations including a maximum name length and certain reserved characters.  To avoid these limitations the standard solution is to create simple unique names at the top level /dev/\\* and symlink them with udev.  That's why all persistent storage devices work this way.  As you say you should never use these top level devices because their names may change.  This is equally true for /dev/sda, /dev/hda, and /dev/zd1.  The above comment is the code was simply an example test case and does not show a real usage scenario.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/384675/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/409945", "body": "I'm pretty sure dbuf_hold_impl() is called in other contexts.  I've love to revert this too but it's going to take more convincing that this is safe...  but that's for pointing it out, I'd actually forgotten about this particular hack!\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/409945/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/512022", "body": "I didn't either at the time or I would have added it to the original patch.  I only noticed later when it annoyed me.  :)\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/512022/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}], "review_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11254", "body": "This file should be readded exactly for the reasons mentioned in the file.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11254/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11255", "body": "Yes, please remove them.  They are currently unused hooks and they cause compile errors on older platforms.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11255/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11259", "body": "A version of this file was already added to the dracut subdirectory.  If you want to make changes/rewrite it that's fine but let's just keep one copy of it around with the other dracut code.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11259/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}]}, "wphilips": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7050", "title": "zfs-dracut boot failure with out of date zpool.cache - zfs_force not working", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       |  Fedora \r\nDistribution Version    |  26 \r\nLinux Kernel                 |  any (e.g., 4.14.6-200.fc26.x86_64)\r\nArchitecture                 |  x86_64\r\nZFS Version                  |   v0.7.5-1\r\nSPL Version                  |  v0.7.5-1\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\nI have several systems with root and boot on zfs. The systems boot with grub initramfs \r\nis generated by dracut with zfs-dracut-0.7.5-1.fc26.x86_64\r\n\r\nThe problem occurs whenever significant changes are made to the zpools attached to the\r\nsystem, or even when adding empty disks.  Very often, dracut enters the emergency shell\r\nbecause it cannot import the pools based on the zpool.cache file. Even adding zfs_force \r\nas a kernel option does not work. E.g., I tried:\r\n\r\nlinux16 /boot/@/vmlinuz-4.14.13-200.fc26.x86_64 root=zfs:ssd/fc26 boot=ssd ro rd_NO_PLYMOUTH audit=0 zfs_force=1\r\n\r\n\r\nThe reason seems to be that the zpoool.cache file does not reflect the current (changed) configuration of the system. It is not clear why zfs.force  or zfs_force does not work.\r\n\r\n\r\nHere are 2 use cases:\r\n\r\n1. to defragment  the pool on which the zfs root is installed, I attach a new disk, create a new\r\nzpool on it, copy all the data, remove the old disk, reboot and change some grub parameters so\r\nthat it boots the new bool. Before the reboot, zpool.cache refers to the old pool on the old disk.\r\nRunning 'dracut -f ...' will therefore copy the \"old\" zpool.cache into initamfs. After boot, the disks\r\nhave changed and this zpool.cache is outdated. \r\n\r\n2. in a system with 3 rpools, I remove one of the disks which contains a non-essential \r\nrpool (after exporting it). I then add two new empty disks. The system boots into the dracut \r\nshell even though the root pool has not changed. The now missing, but non-essential pool\r\nprevents a normal boot.\r\n\r\n\r\nIt is possible to somewhat prevent these problems by removing zpool.cache, then running\r\ndracut and then rebooting. In this case, often dracut still enters the emergency shell claiming\r\nthat the pool(s) are in use in another system, but by force importing them in the dracut shell\r\nand rebooting it is possible to boot the system. Then it is possible to recreate zpool.cache, \r\nand rerun dracut to create a working system. Alternatively, one can continue to use the initramfs\r\nwith the missing zpool.cache.\r\n\r\nIt is probably also possible to create a zpool.cache file for the future new configuration, but it probably \r\ninvolves deleting the current one and it is easy to make a mistake.\r\n\r\nIn any case, make a simple mistake or  forget to take these  \"preventive\" measures \r\nand you end up with a system which will always enter the dracut emergency shell with \r\nno way to recover (except if you have e.g., a usb boot disk with zfs at hand. Even then\r\nit is really hard to recover).\r\n\r\nIn the good old days it also use to be  possible to fix problems in the dracut shell and then continue to boot. These days, systemd prevents this from working (probably related to the message \"transaction is destructive\")\r\n\r\nWhile fixing the zfs_force option would help, adding a configuration option to dracut to never \r\ncreate zfs.cache and/or adding a kernel command line option to ignore zpool.cache might \r\nalso help.\r\n \r\n\r\nPS. Even better would be to fix dracut or systemd so that a boot can continue after fixing problems \r\nin dracut. For instance, in the emergency shell you would remove the zpool.cache file and \r\nthen type some command to continue boot. However, that is probably a more general (non zfsonlinux)\r\nissue.\r\n\r\n\r\n\r\n\r\n\r\n\r\n### Describe how to reproduce the problem\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n<!-- \r\n*IMPORTANT* - Please mark logs and text output from terminal commands \r\nor else Github will not display them correctly. \r\nAn example is provided below.\r\n\r\nExample:\r\n```\r\nthis is an example how log text should be marked (wrap it with ```)\r\n```\r\n-->\r\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7050/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "Menion2k": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7046", "title": "aarch64 and arm64 mismatch", "body": "Hello\r\nIt seems that there is a problem handling the ARCH on arm64 targets\r\nFrom the BUILD detection I see that the ARCH is set to aarch64. The compilation is ok, but aarch64 is not a DEB or RPM architecture, because it is defined as \"arm64\"\r\nThe result is that the make deb fails with the error:\r\n\r\n> spl-0.7.5-1.aarch64.rpm is for architecture aarch64 ; the package cannot be built on this system\r\n\r\nI guess that somewhere in the Makefile the BUILD system architecture shall be converted to a valid package architecture\r\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7046/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "jhammond-intel": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7045", "title": "pool suspension due to delayed MMP writes needs a better error message", "body": "### System information\r\nDistribution Name       | *\r\nDistribution Version    | *\r\nLinux Kernel                 | * \r\nArchitecture                 | *\r\nZFS Version                  | 0.7.5\r\nSPL Version                  | 0.7.5\r\n\r\nThis is related to Lustre issue https://jira.hpdd.intel.com/browse/LU-9845.\r\n\r\nWhen an MMP thread suspends a pool because \"no MMP write has succeeded in over mmp_interval * mmp_fail_intervals nanoseconds\" the only message we see on the console is \"WARNING: Pool 'blahblah' has encountered an uncorrectable I/O failure and has been suspended.\" This is not really informative enough and probably a bit misleading. We encountered these mysteriously suspended pool in our test clusters and were only able to attribute this to MMP by setting the pool failure mode to panic.\r\n\r\nI was able to easily reproduce using the Lustre backed zfs setup (VM has hostid set and 2 vCPUs, pool has MMP enabled) using the following:\r\n```\r\nm:~# export FSTYPE=zfs\r\nm:~# bash $LUSTRE/tests/llmount.sh\r\n...\r\nm:~# cat /sys/module/zfs/parameters/zfs_multihost_interval \r\n1000\r\nm:~# echo 100 > /sys/module/zfs/parameters/zfs_multihost_interval # set mmp interval to 100ms\r\nm:~# chrt -f 20 dd if=/dev/zero of=/dev/null &\r\nm:~# chrt -f 20 dd if=/dev/zero of=/dev/null &\r\n```\r\n\r\nI think we should probably keep the message from `zio_suspend()` as is but add a suitable message to `mmp_thread()` before calling `zio_suspend()`.", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7045/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/51d1b58ef3467c3a9711c65458f93063dd17354f", "message": "Emit an error message before MMP suspends pool\n\nIn mmp_thread(), emit an MMP specific error message before calling\r\nzio_suspend() so that the administrator will understand why the pool\r\nis being suspended.\r\n\r\nReviewed-by: Olaf Faaland <faaland1@llnl.gov>\r\nReviewed-by: Giuseppe Di Natale <dinatale2@llnl.gov>\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: John L. Hammond <john.hammond@intel.com>\r\nCloses #7048"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "samuelbernardo": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7042", "title": "BUG: soft lockup - CPU# stuck for 22s! [z_wr_iss]", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Gentoo\r\nDistribution Version    | -\r\nLinux Kernel                 | 4.14.12\r\nArchitecture                 | x86_64\r\nZFS Version                  | 0.7.5\r\nSPL Version                  | 0.7.5\r\n\r\n\r\n### Describe the problem you're observing\r\n\r\nzfs thread lock after some intensive IO. It allows to continue to access data, but all writes won't be commited to disk, since reboot needs ctrl+shift+sysreq reisub. It remains locked after trying soft reboot, and the only solution is a forced reboot with sysreq.\r\nThe zfs lock is registered systematically after some intensive IO on each OS reboot.\r\n\r\n### Describe how to reproduce the problem\r\n\r\nThis is the configuration of zfs volume that has the deadlock (using deduplication and lz4 compression):\r\n\r\nNAME   SIZE  ALLOC   FREE  EXPANDSZ   FRAG    CAP  DEDUP  HEALTH  ALTROOT\r\nzfs  21.8T  5.69T  16.1T         -     6%    26%  1.07x  ONLINE  -\r\n  raidz1  10.9T  2.85T  8.03T         -     6%    26%\r\n    ata-TOSHIBA_DT01ACA300_Z5RS6H0KS      -      -      -         -      -      -\r\n    ata-TOSHIBA_HDWD130_678KR5JAS      -      -      -         -      -      -\r\n    ata-TOSHIBA_DT01ACA300_16QUEEEKS      -      -      -         -      -      -\r\n    ata-TOSHIBA_HDWD130_678KPYLAS      -      -      -         -      -      -\r\n  raidz1  10.9T  2.85T  8.03T         -     6%    26%\r\n    ata-TOSHIBA_HDWD130_678KTDUAS      -      -      -         -      -      -\r\n    ata-TOSHIBA_DT01ACA300_16QUDE3KS      -      -      -         -      -      -\r\n    ata-WDC_WD40EZRX-75SPEB0_WD-WCC4E2YAA98J-part6      -      -      -         -      -      -\r\n    ata-TOSHIBA_HDWD130_678KPP7AS      -      -      -         -      -      -\r\ncache      -      -      -         -      -      -\r\n  sdc   699G  79.7M   699G         -     0%     0%\r\n  sde   699G  78.2M   699G         -     0%     0%\r\n\r\n  pool: zfs\r\n state: ONLINE\r\n  scan: resilvered 75.5G in 0h38m with 0 errors on Mon Oct 16 03:45:53 2017\r\nconfig:\r\n        NAME                                                STATE     READ WRITE CKSUM\r\n        zfs                                                 ONLINE       0     0     0\r\n          raidz1-0                                          ONLINE       0     0     0\r\n            ata-TOSHIBA_DT01ACA300_Z5RS6H0KS                ONLINE       0     0     0\r\n            ata-TOSHIBA_HDWD130_678KR5JAS                   ONLINE       0     0     0\r\n            ata-TOSHIBA_DT01ACA300_16QUEEEKS                ONLINE       0     0     0\r\n            ata-TOSHIBA_HDWD130_678KPYLAS                   ONLINE       0     0     0\r\n          raidz1-1                                          ONLINE       0     0     0\r\n            ata-TOSHIBA_HDWD130_678KTDUAS                   ONLINE       0     0     0\r\n            ata-TOSHIBA_DT01ACA300_16QUDE3KS                ONLINE       0     0     0\r\n            ata-WDC_WD40EZRX-75SPEB0_WD-WCC4E2YAA98J-part6  ONLINE       0     0     0\r\n            ata-TOSHIBA_HDWD130_678KPP7AS                   ONLINE       0     0     0\r\n        cache\r\n          sdc                                               ONLINE       0     0     0\r\n          sde                                               ONLINE       0     0     0\r\n\r\ncapacity  |   operations  |   bandwidth  |  total_wait   |  disk_wait  |  syncq_wait  |  asyncq_wait | scrub\r\n\r\npool |  alloc |  free |  read | write |  read | write |  read | write |  read | write  | read | write |  read | write |  wait \r\n  --- |   --- |   --- |   --- |  --- |   --- |  --- |   --- |  --- |   --- |  ---  |  --- |  --- |   --- |  --- |   --- \r\nzfs     |    5.69T | 16.1T  |   81 |   109 |  500K |  950K |   4us  |  1us  |  4us | 543ns | 187ns  |  2ns  |  1us |   1us | 723ns\r\n\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n```\r\nJan 10 21:57:11 x99 kernel: INFO: rcu_sched detected expedited stalls on CPUs/tasks: { 9-... } 218109 jiffies s: 401 root: 0x200/.\r\nJan 10 21:57:11 x99 kernel: blocking rcu_node structures:\r\nJan 10 21:57:11 x99 kernel: Task dump for CPU 9:\r\nJan 10 21:57:11 x99 kernel: z_wr_iss        R  running task    12256   749      2 0x80000008\r\nJan 10 21:57:11 x99 kernel: Call Trace:\r\nJan 10 21:57:11 x99 kernel:  ? arc_buf_info+0xcc7/0xf80 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? mutex_lock+0x9/0x30\r\nJan 10 21:57:11 x99 kernel:  ? dbuf_rele_and_unlock+0x4cb/0x540 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? mutex_lock+0x9/0x30\r\nJan 10 21:57:11 x99 kernel:  ? mutex_lock+0x9/0x30\r\nJan 10 21:57:11 x99 kernel:  ? zio_worst_error+0x60f/0x1250 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? zio_wait+0x113/0x160 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? dbuf_read+0x617/0xd80 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? __kmalloc_node+0x27d/0x290\r\nJan 10 21:57:11 x99 kernel:  ? spl_kmem_zalloc+0x85/0x150 [spl]\r\nJan 10 21:57:11 x99 kernel:  ? zap_leaf_lookup+0x6d/0x130 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? fzap_length+0x48/0x90 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? zap_name_alloc_uint64+0x50/0x60 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? zap_length_uint64+0x74/0x230 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? ddt_walk+0x31b/0x450 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? ddt_lookup+0xb4/0x190 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? zio_checksum_compute+0x15d/0x2a0 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? spl_kmem_cache_alloc+0x5b/0xb10 [spl]\r\nJan 10 21:57:11 x99 kernel:  ? __kmalloc_node+0x27d/0x290\r\nJan 10 21:57:11 x99 kernel:  ? spl_kmem_alloc+0x8e/0x160 [spl]\r\nJan 10 21:57:11 x99 kernel:  ? spl_kmem_alloc+0x8e/0x160 [spl]\r\nJan 10 21:57:11 x99 kernel:  ? zio_flush+0x867/0xde0 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? zio_push_transform+0x662/0xbe0 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? zio_execute+0x7c/0x430 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? taskq_dispatch_delay+0x51f/0x950 [spl]\r\nJan 10 21:57:11 x99 kernel:  ? wake_up_q+0x70/0x70\r\nJan 10 21:57:11 x99 kernel:  ? zio_interrupt+0x1030/0x1030 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? kthread+0xf7/0x130\r\nJan 10 21:57:11 x99 kernel:  ? taskq_dispatch_delay+0x2c0/0x950 [spl]\r\nJan 10 21:57:11 x99 kernel:  ? kthread_create_on_node+0x40/0x40\r\nJan 10 21:57:11 x99 kernel:  ? do_group_exit+0x35/0xa0\r\nJan 10 21:57:11 x99 kernel:  ? ret_from_fork+0x1f/0x30\r\nJan 10 21:57:13 x99 kernel: watchdog: BUG: soft lockup - CPU#9 stuck for 22s! [z_wr_iss:749]\r\nJan 10 21:57:13 x99 kernel: Modules linked in: nvidia_uvm(PO) zfs(PO) zunicode(PO) zavl(PO) icp(PO) zcommon(PO) znvpair(PO) spl(O) nv>\r\nJan 10 21:57:13 x99 kernel: CPU: 9 PID: 749 Comm: z_wr_iss Tainted: P        W  O L  4.14.12-gentoox99 #1\r\nJan 10 21:57:13 x99 kernel: Hardware name: ASUS All Series/X99-S, BIOS 3402 08/18/2016\r\nJan 10 21:57:13 x99 kernel: task: ffff880fef778e00 task.stack: ffffc9000a2dc000\r\nJan 10 21:57:13 x99 kernel: RIP: 0010:zap_leaf_lookup+0x92/0x130 [zfs]\r\nJan 10 21:57:13 x99 kernel: RSP: 0018:ffffc9000a2dfa40 EFLAGS: 00000213 ORIG_RAX: ffffffffffffff10\r\nJan 10 21:57:13 x99 kernel: RAX: 0000000000000000 RBX: ffff880d59b78130 RCX: 0000000000000007\r\nJan 10 21:57:13 x99 kernel: RDX: 000000000000000c RSI: ffff880d59b78000 RDI: 5d7f96b690640000\r\nJan 10 21:57:13 x99 kernel: RBP: ffffc9000a2dfa88 R08: 00000000002ebfcb R09: ffff880de2c53800\r\nJan 10 21:57:13 x99 kernel: R10: ffff880de2c53800 R11: ffff880fe497a000 R12: ffff880de2c53800\r\nJan 10 21:57:13 x99 kernel: R13: ffff880c575f3600 R14: ffff880d59b78132 R15: 0000000000000001\r\nJan 10 21:57:13 x99 kernel: FS:  0000000000000000(0000) GS:ffff880fff440000(0000) knlGS:0000000000000000\r\nJan 10 21:57:13 x99 kernel: CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\r\nJan 10 21:57:13 x99 kernel: CR2: 00007f767108b850 CR3: 0000000004823006 CR4: 00000000001606e0\r\nJan 10 21:57:13 x99 kernel: Call Trace:\r\nJan 10 21:57:13 x99 kernel:  fzap_length+0x48/0x90 [zfs]\r\nJan 10 21:57:13 x99 kernel:  ? zap_name_alloc_uint64+0x50/0x60 [zfs]\r\nJan 10 21:57:13 x99 kernel:  zap_length_uint64+0x74/0x230 [zfs]\r\nJan 10 21:57:13 x99 kernel:  ddt_walk+0x31b/0x450 [zfs]\r\nJan 10 21:57:13 x99 kernel:  ddt_lookup+0xb4/0x190 [zfs]\r\nJan 10 21:57:13 x99 kernel:  ? zio_checksum_compute+0x15d/0x2a0 [zfs]\r\nJan 10 21:57:13 x99 kernel:  ? spl_kmem_cache_alloc+0x5b/0xb10 [spl]\r\nJan 10 21:57:13 x99 kernel:  ? __kmalloc_node+0x27d/0x290\r\nJan 10 21:57:13 x99 kernel:  ? spl_kmem_alloc+0x8e/0x160 [spl]\r\nJan 10 21:57:13 x99 kernel:  ? spl_kmem_alloc+0x8e/0x160 [spl]\r\nJan 10 21:57:13 x99 kernel:  zio_flush+0x867/0xde0 [zfs]\r\nJan 10 21:57:13 x99 kernel:  ? zio_push_transform+0x662/0xbe0 [zfs]\r\nJan 10 21:57:13 x99 kernel:  zio_execute+0x7c/0x430 [zfs]\r\nJan 10 21:57:13 x99 kernel:  taskq_dispatch_delay+0x51f/0x950 [spl]\r\nJan 10 21:57:13 x99 kernel:  ? wake_up_q+0x70/0x70\r\nJan 10 21:57:13 x99 kernel:  ? zio_interrupt+0x1030/0x1030 [zfs]\r\nJan 10 21:57:13 x99 kernel:  kthread+0xf7/0x130\r\nJan 10 21:57:13 x99 kernel:  ? taskq_dispatch_delay+0x2c0/0x950 [spl]\r\nJan 10 21:57:13 x99 kernel:  ? kthread_create_on_node+0x40/0x40\r\nJan 10 21:57:13 x99 kernel:  ? do_group_exit+0x35/0xa0\r\nJan 10 21:57:13 x99 kernel:  ret_from_fork+0x1f/0x30\r\nJan 10 21:57:13 x99 kernel: Code: eb 29 0f b7 43 02 4c 8d 73 02 66 83 f8 ff 74 7f 49 8b 8c 24 d8 00 00 00 41 8b 94 24 d0 00 00 00 49 >\r\nJan 10 21:57:18 x99 systemd[1]: Received SIGINT.\r\n```", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7042/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ltz3317": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7038", "title": "zfs sync hang ", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       |  centos 7.2 \uff0csync hang\r\nDistribution Version    | \r\nLinux Kernel                 | 3.10.0-327.13.1.el7.x86_64 \r\nArchitecture                 | \r\nZFS Version                  | v0.7.5-1\r\nSPL Version                  |  v0.7.5-1\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\nsync hang \uff0cmysql hang\uff0ckworker cpu 100\r\n### Describe how to reproduce the problem\r\nhigh frequency  create/destroy/clone\r\n### Include any warning/errors/backtraces from the system logs\r\ndmsg:\r\n[  189.990968] Adjusting tsc more than 11% (8039035 vs 7759471)\r\n[ 2522.644734] INFO: task mysqld:6608 blocked for more than 120 seconds.\r\n[ 2522.644790] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2522.644854] mysqld          D 0000000000000000     0  6608   5602 0x00000000\r\n[ 2522.644860]  ffff880feb913da0 0000000000000086 ffff881006eac500 ffff880feb913fd8\r\n[ 2522.644865]  ffff880feb913fd8 ffff880feb913fd8 ffff881006eac500 ffff880fffc8a180\r\n[ 2522.644869]  ffff880fffc8a000 ffff880fffc8a188 ffff880fffc8a028 0000000000000000\r\n[ 2522.644873] Call Trace:\r\n[ 2522.644882]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2522.644906]  [<ffffffffa04744d5>] cv_wait_common+0x125/0x150 [spl]\r\n[ 2522.644911]  [<ffffffff810a6ae0>] ? wake_up_atomic_t+0x30/0x30\r\n[ 2522.644922]  [<ffffffffa0474515>] __cv_wait+0x15/0x20 [spl]\r\n[ 2522.644995]  [<ffffffffa062bd7b>] zil_commit.part.12+0x8b/0x830 [zfs]\r\n[ 2522.645006]  [<ffffffffa046d037>] ? spl_kmem_alloc+0xc7/0x170 [spl]\r\n[ 2522.645017]  [<ffffffffa0475cb4>] ? tsd_set+0x324/0x500 [spl]\r\n[ 2522.645022]  [<ffffffff81639082>] ? mutex_lock+0x12/0x2f\r\n[ 2522.645075]  [<ffffffffa062c537>] zil_commit+0x17/0x20 [zfs]\r\n[ 2522.645128]  [<ffffffffa0621a27>] zfs_fsync+0x77/0xf0 [zfs]\r\n[ 2522.645179]  [<ffffffffa0639665>] zpl_fsync+0x65/0x90 [zfs]\r\n[ 2522.645186]  [<ffffffff8120fa45>] do_fsync+0x65/0xa0\r\n[ 2522.645191]  [<ffffffff8120fd10>] SyS_fsync+0x10/0x20\r\n[ 2522.645196]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2522.645202] INFO: task mysqld:7514 blocked for more than 120 seconds.\r\n[ 2522.645245] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2522.645296] mysqld          D ffff880fb554bda0     0  7514   5602 0x00000000\r\n[ 2522.645299]  ffff880fb554bd30 0000000000000086 ffff880ff4c8f300 ffff880fb554bfd8\r\n[ 2522.645303]  ffff880fb554bfd8 ffff880fb554bfd8 ffff880ff4c8f300 ffff880fb554bdb0\r\n[ 2522.645307]  ffff88107ff8dec0 0000000000000002 ffffffff811f9420 ffff880fb554bda0\r\n[ 2522.645312] Call Trace:\r\n[ 2522.645316]  [<ffffffff811f9420>] ? unlock_two_nondirectories+0x60/0x60\r\n[ 2522.645321]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2522.645324]  [<ffffffff811f942e>] inode_wait+0xe/0x20\r\n[ 2522.645328]  [<ffffffff81638cc0>] __wait_on_bit+0x60/0x90\r\n[ 2522.645335]  [<ffffffff812083bf>] __inode_wait_for_writeback+0xaf/0xf0\r\n[ 2522.645339]  [<ffffffff810a6b60>] ? wake_atomic_t_function+0x40/0x40\r\n[ 2522.645345]  [<ffffffff8120b996>] inode_wait_for_writeback+0x26/0x40\r\n[ 2522.645348]  [<ffffffff811fa135>] evict+0x95/0x170\r\n[ 2522.645351]  [<ffffffff811fa985>] iput+0xf5/0x180\r\n[ 2522.645357]  [<ffffffff811ef41e>] do_unlinkat+0x1ae/0x2b0\r\n[ 2522.645362]  [<ffffffff811e3fe1>] ? SyS_readlinkat+0xd1/0x140\r\n[ 2522.645367]  [<ffffffff811f0426>] SyS_unlink+0x16/0x20\r\n[ 2522.645371]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2522.645402] INFO: task sync:2653 blocked for more than 120 seconds.\r\n[ 2522.645443] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2522.645494] sync            D ffffffff8120f8c0     0  2653   1455 0x00000000\r\n[ 2522.645498]  ffff880ffedd7d50 0000000000000082 ffff880f01449700 ffff880ffedd7fd8\r\n[ 2522.645502]  ffff880ffedd7fd8 ffff880ffedd7fd8 ffff880f01449700 ffff880ffedd7e80\r\n[ 2522.645506]  ffff880ffedd7e88 7fffffffffffffff ffff880f01449700 ffffffff8120f8c0\r\n[ 2522.645509] Call Trace:\r\n[ 2522.645515]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2522.645519]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2522.645523]  [<ffffffff81638b39>] schedule_timeout+0x209/0x2d0\r\n[ 2522.645527]  [<ffffffff8109b426>] ? __queue_work+0x136/0x320\r\n[ 2522.645530]  [<ffffffff8109b6da>] ? __queue_delayed_work+0xaa/0x1a0\r\n[ 2522.645534]  [<ffffffff8109ba41>] ? try_to_grab_pending+0xb1/0x160\r\n[ 2522.645538]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2522.645543]  [<ffffffff8163b216>] wait_for_completion+0x116/0x170\r\n[ 2522.645548]  [<ffffffff810b8c30>] ? wake_up_state+0x20/0x20\r\n[ 2522.645552]  [<ffffffff81208987>] sync_inodes_sb+0xb7/0x1e0\r\n[ 2522.645557]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2522.645561]  [<ffffffff8120f8d9>] sync_inodes_one_sb+0x19/0x20\r\n[ 2522.645565]  [<ffffffff811e2182>] iterate_supers+0xb2/0x110\r\n[ 2522.645570]  [<ffffffff8120fb94>] sys_sync+0x44/0xb0\r\n[ 2522.645575]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2642.739175] INFO: task mysqld:6608 blocked for more than 120 seconds.\r\n[ 2642.739228] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2642.739284] mysqld          D 0000000000000000     0  6608   5602 0x00000000\r\n[ 2642.739290]  ffff880feb913da0 0000000000000086 ffff881006eac500 ffff880feb913fd8\r\n[ 2642.739296]  ffff880feb913fd8 ffff880feb913fd8 ffff881006eac500 ffff880fffc8a180\r\n[ 2642.739300]  ffff880fffc8a000 ffff880fffc8a188 ffff880fffc8a028 0000000000000000\r\n[ 2642.739305] Call Trace:\r\n[ 2642.739315]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2642.739340]  [<ffffffffa04744d5>] cv_wait_common+0x125/0x150 [spl]\r\n[ 2642.739345]  [<ffffffff810a6ae0>] ? wake_up_atomic_t+0x30/0x30\r\n[ 2642.739357]  [<ffffffffa0474515>] __cv_wait+0x15/0x20 [spl]\r\n[ 2642.739434]  [<ffffffffa062bd7b>] zil_commit.part.12+0x8b/0x830 [zfs]\r\n[ 2642.739447]  [<ffffffffa046d037>] ? spl_kmem_alloc+0xc7/0x170 [spl]\r\n[ 2642.739460]  [<ffffffffa0475cb4>] ? tsd_set+0x324/0x500 [spl]\r\n[ 2642.739466]  [<ffffffff81639082>] ? mutex_lock+0x12/0x2f\r\n[ 2642.739526]  [<ffffffffa062c537>] zil_commit+0x17/0x20 [zfs]\r\n[ 2642.739587]  [<ffffffffa0621a27>] zfs_fsync+0x77/0xf0 [zfs]\r\n[ 2642.739647]  [<ffffffffa0639665>] zpl_fsync+0x65/0x90 [zfs]\r\n[ 2642.739654]  [<ffffffff8120fa45>] do_fsync+0x65/0xa0\r\n[ 2642.739659]  [<ffffffff8120fd10>] SyS_fsync+0x10/0x20\r\n[ 2642.739665]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2642.739670] INFO: task mysqld:7514 blocked for more than 120 seconds.\r\n[ 2642.739727] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2642.739793] mysqld          D ffff880fb554bda0     0  7514   5602 0x00000000\r\n[ 2642.739798]  ffff880fb554bd30 0000000000000086 ffff880ff4c8f300 ffff880fb554bfd8\r\n[ 2642.739803]  ffff880fb554bfd8 ffff880fb554bfd8 ffff880ff4c8f300 ffff880fb554bdb0\r\n[ 2642.739808]  ffff88107ff8dec0 0000000000000002 ffffffff811f9420 ffff880fb554bda0\r\n[ 2642.739812] Call Trace:\r\n[ 2642.739818]  [<ffffffff811f9420>] ? unlock_two_nondirectories+0x60/0x60\r\n[ 2642.739823]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2642.739826]  [<ffffffff811f942e>] inode_wait+0xe/0x20\r\n[ 2642.739831]  [<ffffffff81638cc0>] __wait_on_bit+0x60/0x90\r\n[ 2642.739839]  [<ffffffff812083bf>] __inode_wait_for_writeback+0xaf/0xf0\r\n[ 2642.739843]  [<ffffffff810a6b60>] ? wake_atomic_t_function+0x40/0x40\r\n[ 2642.739850]  [<ffffffff8120b996>] inode_wait_for_writeback+0x26/0x40\r\n[ 2642.739854]  [<ffffffff811fa135>] evict+0x95/0x170\r\n[ 2642.739857]  [<ffffffff811fa985>] iput+0xf5/0x180\r\n[ 2642.739862]  [<ffffffff811ef41e>] do_unlinkat+0x1ae/0x2b0\r\n[ 2642.739868]  [<ffffffff811e3fe1>] ? SyS_readlinkat+0xd1/0x140\r\n[ 2642.739873]  [<ffffffff811f0426>] SyS_unlink+0x16/0x20\r\n[ 2642.739878]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2642.739897] INFO: task sync:2653 blocked for more than 120 seconds.\r\n[ 2642.739951] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2642.740017] sync            D ffffffff8120f8c0     0  2653   1455 0x00000000\r\n[ 2642.740021]  ffff880ffedd7d50 0000000000000082 ffff880f01449700 ffff880ffedd7fd8\r\n[ 2642.740026]  ffff880ffedd7fd8 ffff880ffedd7fd8 ffff880f01449700 ffff880ffedd7e80\r\n[ 2642.740031]  ffff880ffedd7e88 7fffffffffffffff ffff880f01449700 ffffffff8120f8c0\r\n[ 2642.740036] Call Trace:\r\n[ 2642.740042]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2642.740047]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2642.740051]  [<ffffffff81638b39>] schedule_timeout+0x209/0x2d0\r\n[ 2642.740056]  [<ffffffff8109b426>] ? __queue_work+0x136/0x320\r\n[ 2642.740060]  [<ffffffff8109b6da>] ? __queue_delayed_work+0xaa/0x1a0\r\n[ 2642.740064]  [<ffffffff8109ba41>] ? try_to_grab_pending+0xb1/0x160\r\n[ 2642.740069]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2642.740093]  [<ffffffff8163b216>] wait_for_completion+0x116/0x170\r\n[ 2642.740100]  [<ffffffff810b8c30>] ? wake_up_state+0x20/0x20\r\n[ 2642.740105]  [<ffffffff81208987>] sync_inodes_sb+0xb7/0x1e0\r\n[ 2642.740110]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2642.740116]  [<ffffffff8120f8d9>] sync_inodes_one_sb+0x19/0x20\r\n[ 2642.740121]  [<ffffffff811e2182>] iterate_supers+0xb2/0x110\r\n[ 2642.740127]  [<ffffffff8120fb94>] sys_sync+0x44/0xb0\r\n[ 2642.740134]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2762.834495] INFO: task mysqld:6608 blocked for more than 120 seconds.\r\n[ 2762.834547] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2762.834604] mysqld          D 0000000000000000     0  6608   5602 0x00000000\r\n[ 2762.834609]  ffff880feb913da0 0000000000000086 ffff881006eac500 ffff880feb913fd8\r\n[ 2762.834615]  ffff880feb913fd8 ffff880feb913fd8 ffff881006eac500 ffff880fffc8a180\r\n[ 2762.834619]  ffff880fffc8a000 ffff880fffc8a188 ffff880fffc8a028 0000000000000000\r\n[ 2762.834624] Call Trace:\r\n[ 2762.834634]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2762.834659]  [<ffffffffa04744d5>] cv_wait_common+0x125/0x150 [spl]\r\n[ 2762.834665]  [<ffffffff810a6ae0>] ? wake_up_atomic_t+0x30/0x30\r\n[ 2762.834677]  [<ffffffffa0474515>] __cv_wait+0x15/0x20 [spl]\r\n[ 2762.834748]  [<ffffffffa062bd7b>] zil_commit.part.12+0x8b/0x830 [zfs]\r\n[ 2762.834761]  [<ffffffffa046d037>] ? spl_kmem_alloc+0xc7/0x170 [spl]\r\n[ 2762.834774]  [<ffffffffa0475cb4>] ? tsd_set+0x324/0x500 [spl]\r\n[ 2762.834779]  [<ffffffff81639082>] ? mutex_lock+0x12/0x2f\r\n[ 2762.834843]  [<ffffffffa062c537>] zil_commit+0x17/0x20 [zfs]\r\n[ 2762.834908]  [<ffffffffa0621a27>] zfs_fsync+0x77/0xf0 [zfs]\r\n[ 2762.834971]  [<ffffffffa0639665>] zpl_fsync+0x65/0x90 [zfs]\r\n[ 2762.834978]  [<ffffffff8120fa45>] do_fsync+0x65/0xa0\r\n[ 2762.834983]  [<ffffffff8120fd10>] SyS_fsync+0x10/0x20\r\n[ 2762.834989]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2762.834994] INFO: task mysqld:7514 blocked for more than 120 seconds.\r\n[ 2762.835051] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2762.835118] mysqld          D ffff880fb554bda0     0  7514   5602 0x00000000\r\n[ 2762.835122]  ffff880fb554bd30 0000000000000086 ffff880ff4c8f300 ffff880fb554bfd8\r\n[ 2762.835127]  ffff880fb554bfd8 ffff880fb554bfd8 ffff880ff4c8f300 ffff880fb554bdb0\r\n[ 2762.835132]  ffff88107ff8dec0 0000000000000002 ffffffff811f9420 ffff880fb554bda0\r\n[ 2762.835137] Call Trace:\r\n[ 2762.835143]  [<ffffffff811f9420>] ? unlock_two_nondirectories+0x60/0x60\r\n[ 2762.835148]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2762.835151]  [<ffffffff811f942e>] inode_wait+0xe/0x20\r\n[ 2762.835156]  [<ffffffff81638cc0>] __wait_on_bit+0x60/0x90\r\n[ 2762.835164]  [<ffffffff812083bf>] __inode_wait_for_writeback+0xaf/0xf0\r\n[ 2762.835168]  [<ffffffff810a6b60>] ? wake_atomic_t_function+0x40/0x40\r\n[ 2762.835175]  [<ffffffff8120b996>] inode_wait_for_writeback+0x26/0x40\r\n[ 2762.835179]  [<ffffffff811fa135>] evict+0x95/0x170\r\n[ 2762.835183]  [<ffffffff811fa985>] iput+0xf5/0x180\r\n[ 2762.835188]  [<ffffffff811ef41e>] do_unlinkat+0x1ae/0x2b0\r\n[ 2762.835195]  [<ffffffff811e3fe1>] ? SyS_readlinkat+0xd1/0x140\r\n[ 2762.835199]  [<ffffffff811f0426>] SyS_unlink+0x16/0x20\r\n[ 2762.835205]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2762.835223] INFO: task sync:2653 blocked for more than 120 seconds.\r\n[ 2762.835277] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2762.835343] sync            D ffffffff8120f8c0     0  2653   1455 0x00000000\r\n[ 2762.835348]  ffff880ffedd7d50 0000000000000082 ffff880f01449700 ffff880ffedd7fd8\r\n[ 2762.835352]  ffff880ffedd7fd8 ffff880ffedd7fd8 ffff880f01449700 ffff880ffedd7e80\r\n[ 2762.835357]  ffff880ffedd7e88 7fffffffffffffff ffff880f01449700 ffffffff8120f8c0\r\n[ 2762.835362] Call Trace:\r\n[ 2762.835369]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2762.835374]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2762.835378]  [<ffffffff81638b39>] schedule_timeout+0x209/0x2d0\r\n[ 2762.835382]  [<ffffffff8109b426>] ? __queue_work+0x136/0x320\r\n[ 2762.835386]  [<ffffffff8109b6da>] ? __queue_delayed_work+0xaa/0x1a0\r\n[ 2762.835390]  [<ffffffff8109ba41>] ? try_to_grab_pending+0xb1/0x160\r\n[ 2762.835396]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2762.835409]  [<ffffffff8163b216>] wait_for_completion+0x116/0x170\r\n[ 2762.835417]  [<ffffffff810b8c30>] ? wake_up_state+0x20/0x20\r\n[ 2762.835422]  [<ffffffff81208987>] sync_inodes_sb+0xb7/0x1e0\r\n[ 2762.835427]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2762.835433]  [<ffffffff8120f8d9>] sync_inodes_one_sb+0x19/0x20\r\n[ 2762.835438]  [<ffffffff811e2182>] iterate_supers+0xb2/0x110\r\n[ 2762.835443]  [<ffffffff8120fb94>] sys_sync+0x44/0xb0\r\n[ 2762.835451]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2882.929813] INFO: task mysqld:6608 blocked for more than 120 seconds.\r\n[ 2882.929861] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2882.929913] mysqld          D 0000000000000000     0  6608   5602 0x00000000\r\n[ 2882.929919]  ffff880feb913da0 0000000000000086 ffff881006eac500 ffff880feb913fd8\r\n[ 2882.929924]  ffff880feb913fd8 ffff880feb913fd8 ffff881006eac500 ffff880fffc8a180\r\n[ 2882.929928]  ffff880fffc8a000 ffff880fffc8a188 ffff880fffc8a028 0000000000000000\r\n[ 2882.929932] Call Trace:\r\n[ 2882.929942]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2882.929967]  [<ffffffffa04744d5>] cv_wait_common+0x125/0x150 [spl]\r\n[ 2882.929972]  [<ffffffff810a6ae0>] ? wake_up_atomic_t+0x30/0x30\r\n[ 2882.929983]  [<ffffffffa0474515>] __cv_wait+0x15/0x20 [spl]\r\n[ 2882.930049]  [<ffffffffa062bd7b>] zil_commit.part.12+0x8b/0x830 [zfs]\r\n[ 2882.930059]  [<ffffffffa046d037>] ? spl_kmem_alloc+0xc7/0x170 [spl]\r\n[ 2882.930070]  [<ffffffffa0475cb4>] ? tsd_set+0x324/0x500 [spl]\r\n[ 2882.930075]  [<ffffffff81639082>] ? mutex_lock+0x12/0x2f\r\n[ 2882.930129]  [<ffffffffa062c537>] zil_commit+0x17/0x20 [zfs]\r\n[ 2882.930181]  [<ffffffffa0621a27>] zfs_fsync+0x77/0xf0 [zfs]\r\n[ 2882.930232]  [<ffffffffa0639665>] zpl_fsync+0x65/0x90 [zfs]\r\n[ 2882.930238]  [<ffffffff8120fa45>] do_fsync+0x65/0xa0\r\n[ 2882.930243]  [<ffffffff8120fd10>] SyS_fsync+0x10/0x20\r\n[ 2882.930248]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 4802.367346] perf interrupt took too long (2507 > 2500), lowering kernel.perf_event_max_sample_rate to 50000\r\n\r\nsync process stack:\r\n[<ffffffff81208987>] sync_inodes_sb+0xb7/0x1e0\r\n[<ffffffff8120f8d9>] sync_inodes_one_sb+0x19/0x20\r\n[<ffffffff811e2182>] iterate_supers+0xb2/0x110\r\n[<ffffffff8120fb94>] sys_sync+0x44/0xb0\r\n[<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[<ffffffffffffffff>] 0xffffffffffffffff\r\n\r\nkworker process stack:\r\n cat /proc/3445/stack \r\n[<ffffffffa058feb5>] dmu_zfetch+0x455/0x4f0 [zfs]\r\n[<ffffffffa05711ea>] dbuf_read+0x8ea/0x9f0 [zfs]\r\n[<ffffffffa0591246>] dnode_hold_impl+0xc6/0xc30 [zfs]\r\n[<ffffffffffffffff>] 0xffffffffffffffff\r\n\r\ncat /proc/3445/stack \r\n[<ffffffffffffffff>] 0xffffffffffffffff\r\n[root@ifcos ~]# cat /proc/3445/stack \r\n[<ffffffffa062879c>] zfs_zget+0xfc/0x250 [zfs]\r\n[<ffffffffa0623db7>] zfs_get_data+0x57/0x2d0 [zfs]\r\n[<ffffffffa062c10c>] zil_commit.part.12+0x41c/0x830 [zfs]\r\n[<ffffffffa062c537>] zil_commit+0x17/0x20 [zfs]\r\n[<ffffffffa06394b6>] zpl_writepages+0xd6/0x170 [zfs]\r\n[<ffffffff811759fe>] do_writepages+0x1e/0x40\r\n[<ffffffff812084e0>] __writeback_single_inode+0x40/0x220\r\n[<ffffffff81208f4e>] writeback_sb_inodes+0x25e/0x420\r\n[<ffffffff8120988f>] wb_writeback+0xff/0x2f0\r\n[<ffffffff8120bac5>] bdi_writeback_workfn+0x115/0x460\r\n[<ffffffff8109d5fb>] process_one_work+0x17b/0x470\r\n[<ffffffff8109e3cb>] worker_thread+0x11b/0x400\r\n[<ffffffff810a5aef>] kthread+0xcf/0xe0\r\n[<ffffffff81645e18>] ret_from_fork+0x58/0x90\r\n[<ffffffffffffffff>] 0xffffffffffffffff\r\n\r\n cat /proc/3445/stack \r\n[<ffffffffa058feb5>] dmu_zfetch+0x455/0x4f0 [zfs]\r\n[<ffffffffa0572fd5>] __dbuf_hold_impl+0x135/0x5a0 [zfs]\r\n[<ffffffffffffffff>] 0xffffffffffffffff\r\n\r\n cat /proc/3445/stack \r\n[<ffffffffa056fa69>] dbuf_find+0x1c9/0x1d0 [zfs]\r\n[<ffffffffa0572ee2>] __dbuf_hold_impl+0x42/0x5a0 [zfs]\r\n[<ffffffffffffffff>] 0xffffffffffffffff\r\n\r\n cat /proc/3445/stack \r\n[<ffffffffa058feb5>] dmu_zfetch+0x455/0x4f0 [zfs]\r\n[<ffffffffa0571056>] dbuf_read+0x756/0x9f0 [zfs]\r\n[<ffffffffa0591246>] dnode_hold_impl+0xc6/0xc30 [zfs]\r\n\r\n<!-- \r\n*IMPORTANT* - Please mark logs and text output from terminal commands \r\nor else Github will not display them correctly. \r\nAn example is provided below.\r\n\r\nExample:\r\n```\r\nthis is an example how log text should be marked (wrap it with ```)\r\n```\r\n-->\r\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7038/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "sempervictus": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7035", "title": "Consider adding mitigations for speculative execution related concerns", "body": "GCC should get retpoline support soon, and Intel seems to be proposing kernel code with barriers to speculative execution - https://patchwork.ozlabs.org/cover/856316/. ZFS is already pretty unhappy from KPTI, but since there's a good deal of user controlled data going into it, this might be worth investigating.", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7035/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "abraunegg": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7034", "title": "Missing parameter descriptions in ZFS-Module-Parameters man page", "body": "The following zfs module parameters are missing from the zfs-module-parameters man page (updated 28th Oct 2017) using ZFS 0.7.5:\r\n\r\n* dbuf_cache_hiwater_pct\r\n* dbuf_cache_lowater_pct\r\n* dbuf_cache_max_bytes\r\n* dbuf_cache_max_shift\r\n* dmu_object_alloc_chunk_shift\r\n* send_holes_without_birth_time\r\n* zfs_abd_scatter_enabled\r\n* zfs_abd_scatter_max_order\r\n* zfs_compressed_arc_enabled\r\n* zfs_sync_taskq_batch_pct\r\n\r\nHappy to create a documentation patch for the man pages if someone can send me the a description of what the module parameter is, what the default should be and what valid options are if it is being changed.\r\n\r\nBest regards,\r\n\r\nAlex", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7034/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "rincebrain": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7024", "title": "zfs send -R | zfs recv can fail in the middle due to a snapshot being taken", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Debian\r\nDistribution Version    | 9.3\r\nLinux Kernel                 | 4.9.0-4-amd64\r\nArchitecture                 | amd64\r\nZFS Version                  | 0.7.3-3\r\nSPL Version                  | 0.7.3-1\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing + how to reproduce the problem\r\nWhen doing a long-running `zfs send -R foo/bar/baz@ten | zfs recv -ds newfoo`, an automated utility helpfully took a recursive snapshot on newfoo, and zfs recv abruptly died with `cannot receive incremental stream: kernel modules must be upgraded to receive this stream.` with newfoo/bar/baz having completed snapshots one, ..., seven and throwing that error on attempting to resume.\r\n\r\nI would have expected the in-progress receiving dataset(s) to have remained immutable until the receives were completed, but apparently this isn't the case.\r\n\r\nDestroying the errant snapshot on newfoo/bar/baz allowed the zfs send to proceed like nothing ever happened.\r\n\r\nSince there's already a number of bugs suggesting that this message should be broken out and detailed further (#6547, #6574), this bug is mostly about the fact that nothing is stopping you from shooting yourself in the foot and not being able to discover why without making dramatic leaps or (presumably) reading zfs/dbgmsg.", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7024/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "h1z1": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7015", "title": "Impact of Intel bug (tm) on ZFS", "body": "Maybe the wrong avenue for this but no doubt like others watching the events of the last few days unfold, I've been asked to comment on the impact to ZFS in our environment.   I'm in a rather odd position as I don't really have the hardware to duplicate an entire production silo, running 4.15.x kernel.   I do however know at least 4.14 will bite us as per #6929.  \r\n\r\nHas anyone tested or confirmed what the impact of this will be going forward?  Would rather not duplicate effort if it's already being addressed.\r\n\r\nThanks", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7015/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "sanjeevbagewadi": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7011", "title": "With \"casesensitivity=mixed\" hitting an assert in ZAP code", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | CentOS release 6.8 (Final)\r\n  ---                                  |     --- \r\nDistribution Name       | CentOS\r\nDistribution Version    | 6.8\r\nLinux Kernel                 | 4.4.14-1.el6\r\nArchitecture                 | x86\r\nZFS Version                  | 0.7.1-1\r\nSPL Version                  |  0.7.1-1\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\n\r\nWith casesensitivity=mixed was running the following test :\r\nroot@NTNX-10-5-137-31-A-FSVM:/home/nutanix# cat names.py\r\n#!/usr/bin/python\r\nimport itertools\r\ns=\"abcdefghijklmnopqrstuvwxyz\"\r\nlength = len(s)\r\nnames = map(''.join, itertools.product(*zip(s.upper(), s.lower())))\r\nfor name in names:\r\n    print name\r\n\r\nroot@NTNX-10-5-137-31-A-FSVM:/home/nutanix# ./names.py | while read file\r\n> do\r\n> touch /test/fs2/dir1/$file\r\n> done\r\n\r\nAnd hit the following panic \r\n-- snip --\r\n[    1.068019] VERIFY(!RW_LOCK_HELD(&l->l_rwlock)) failed\r\n[    1.068077] PANIC at zap.c:407:zap_leaf_evict_sync()\r\n[    1.068113] Showing stack for process 67625\r\n[    1.068116] CPU: 0 PID: 67625 Comm: touch Tainted: P           OE   4.4.14-1.el6.nutanix.10272016.x86_64 #1\r\n[    1.068117] Hardware name: Nutanix AHV, BIOS seabios-1.7.5-11.el6 04/01/2014\r\n[    1.068122]  0000000000000000 ffff88015312b2a8 ffffffff81319ae3 0000000000000001\r\n[    1.068125]  0000000100480b8b ffff88015312b2f8 ffffffffa0b5a9c0 ffff88015312b2b8\r\n[    1.068127]  ffffffffa09918c4 ffff88015312b458 ffffffffa0991aeb 0000000000000040\r\n[    1.068129] Call Trace:\r\n[    1.068136]  [<ffffffff81319ae3>] dump_stack+0x67/0x94\r\n[    1.068146]  [<ffffffffa09918c4>] spl_dumpstack+0x44/0x50 [spl]\r\n[    1.068150]  [<ffffffffa0991aeb>] spl_panic+0xcb/0xe0 [spl]\r\n[    1.068153]  [<ffffffff8132a483>] ? __sg_free_table+0x63/0x90\r\n[    1.068157]  [<ffffffff811e447e>] ? kmem_cache_free+0x1ee/0x210\r\n[    1.068160]  [<ffffffffa098d477>] ? spl_kmem_cache_free+0x117/0x140 [spl]\r\n[    1.068200]  [<ffffffffa0a46ecc>] ? arc_hdr_destroy+0x17c/0x1d0 [zfs]\r\n[    1.068231]  [<ffffffffa0acf457>] zap_leaf_evict_sync+0x57/0x60 [zfs]\r\n[    1.068248]  [<ffffffffa0a4d575>] dbuf_evict_user+0x45/0x70 [zfs]\r\n[    1.068265]  [<ffffffffa0a4f95f>] dbuf_destroy+0x4f/0x330 [zfs]\r\n[    1.068282]  [<ffffffffa0a4f561>] dbuf_rele_and_unlock+0x221/0x3e0 [zfs]\r\n[    1.068313]  [<ffffffffa0ad514f>] ? zap_lockdir+0x7f/0xa0 [zfs]\r\n[    1.068344]  [<ffffffffa0ad15e6>] ? zap_grow_ptrtbl+0x186/0x1a0 [zfs]\r\n[    1.068361]  [<ffffffffa0a4f900>] dbuf_rele+0x40/0x50 [zfs]\r\n[    1.068394]  [<ffffffffa0a4fd1e>] dmu_buf_rele+0xe/0x10 [zfs]\r\n[    1.068427]  [<ffffffffa0acf3dd>] zap_put_leaf+0x3d/0x60 [zfs]\r\n[    1.068460]  [<ffffffffa0ad16c7>] zap_put_leaf_maybe_grow_ptrtbl+0xc7/0x130 [zfs]\r\n[    1.068492]  [<ffffffffa0ad1be8>] fzap_add_cd+0xd8/0x130 [zfs]\r\n[    1.068541]  [<ffffffffa0ad4ce4>] mzap_upgrade+0x194/0x210 [zfs]\r\n[    1.068593]  [<ffffffffa0ad4fba>] zap_lockdir_impl+0x25a/0x370 [zfs]\r\n[    1.068628]  [<ffffffffa0ad514f>] zap_lockdir+0x7f/0xa0 [zfs]\r\n[    1.068664]  [<ffffffffa0ad695b>] zap_add+0x5b/0xa0 [zfs]\r\n[    1.068668]  [<ffffffff810ca871>] ? __raw_callee_save___pv_queued_spin_unlock+0x11/0x20\r\n[    1.068703]  [<ffffffffa0adfcbf>] zfs_link_create+0x37f/0x520 [zfs]\r\n[    1.068761]  [<ffffffffa0b00b2a>] zfs_create+0x62a/0x810 [zfs]\r\n[    1.068764]  [<ffffffff811e76f6>] ? __kmalloc_node+0x1f6/0x2b0\r\n[    1.068798]  [<ffffffffa0b19bf2>] zpl_create+0xb2/0x160 [zfs]\r\n[    1.068802]  [<ffffffff81210424>] vfs_create+0xd4/0x100\r\n[    1.068804]  [<ffffffff8120dc4d>] ? lookup_real+0x1d/0x60\r\n[    1.068806]  [<ffffffff812111e3>] lookup_open+0x173/0x1a0\r\n[    1.068808]  [<ffffffff812138d9>] do_last+0x299/0x760\r\n[    1.068811]  [<ffffffff812056d7>] ? get_empty_filp+0xd7/0x1c0\r\n[    1.068813]  [<ffffffff81213e1c>] path_openat+0x7c/0x140\r\n[    1.068832]  [<ffffffff811b53c2>] ? __pte_alloc+0xe2/0x190\r\n[    1.068834]  [<ffffffff81213f65>] do_filp_open+0x85/0xe0\r\n[    1.068836]  [<ffffffff8120eade>] ? getname_flags+0xce/0x1f0\r\n[    1.068838]  [<ffffffff8120311a>] do_sys_open+0x11a/0x220\r\n[    1.068842]  [<ffffffff81003513>] ? syscall_trace_enter_phase1+0x133/0x150\r\n[    1.068844]  [<ffffffff8120325e>] SyS_open+0x1e/0x20\r\n[    1.068850]  [<ffffffff816cf76e>] entry_SYSCALL_64_fastpath+0x12/0x71\r\n-- snip --\r\n\r\n### Describe how to reproduce the problem\r\n\r\nThe following are the steps\\:\r\n- Create zfs dataset with casesensitivity=mixed\r\n- Run the above listed code.\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n<!-- \r\n*IMPORTANT* - Please mark logs and text output from terminal commands \r\nor else Github will not display them correctly. \r\nAn example is provided below.\r\n\r\nExample:\r\n```\r\nthis is an example how log text should be marked (wrap it with ```)\r\n```\r\n-->", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7011/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/7054", "title": "Handle zap_add() failures in \"casesensitivity=mixed\" mode.", "body": "With \"casesensitivity=mixed\", zap_add() could fail when the number of\r\nfiles/directories with the same name (varying in case) exceed the\r\ncapacity of the leaf node of a Fatzap. This results in a ASSERT()\r\nfailure as zfs_link_create() does not expect zap_add() to fail. The fix\r\nis to handle these failures and rollback the transactions.\r\n\r\nSigned-off-by: Sanjeev Bagewadi <sanjeev.bagewadi@gmail.com>\r\n\r\n<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\nFor a dataset with \"casesensitivity=mixed\", when a large number of files/directories\r\nwith same name (varying only in case e.g: ABCD, ABCd, ABcD and so on) are created\r\nzap_add() could fail. With mixed mode zap_add() normalises the names before the hash\r\nis computed. And all the names would generate the same hash and land in the same leaf.\r\nWhen the number of entries exceed the capacity of the leaf-block, zap_add() tries to split\r\nthe leaf-block which fails as well and zap_add() fails. This trips an ASSERT in zfs_link_create()\r\nas it does not expect zap_add() to fail.\r\n\r\nThe fix does the following :\r\n- fzap_add_cd() : Handle the case when zap_expand_leaf() fails with ENOSPC and bailout\r\n   without calling zap_put_leaf_maybe_grow_ptrtbl(). \r\n- zap_add_impl() : When adding to a micro-zap check if the total number of entries\r\n  with colliding/same hash value can fit into fatzap-leaf-block. This is important because, if/when\r\n  the microzap needs to be upgraded to fatzap, all the entries with the same hash would need to\r\n  fit into the same leaf-block (16K). If the number of such entries donot fit fail the zap_add().\r\n  \r\n   The routine mze_canfit_fzap_leaf() today assumes the MZAP_NAME_LEN for every entry.\r\n   This is erring on the safer side but, ends up accommodating lesser number (127) of entries\r\n    with same hash value in microzap. We could find out the size of name of every mze and that\r\n    would be accurate. But, it is expensive to compute the length every time. Alternatively, we\r\n    could compute the length of each entry and cache it. I felt that the amount of code needed\r\n    for this is not worth the gain. I am open to changing it if necessary.\r\n\r\n- zfs_link_create() : Move the call to zap_add() to the beginning and in case of a failure\r\n  return. This ensures that we can bailout easily before making any other modifications to\r\n  the parent-zap or the child-dnode. Keeps the code simpler.\r\n- ZPL interfaces (zfs_create(), zfs_mkdir(), zfs_symlink()) : Handle the failure of zfs_link_create()\r\n  and rollback the operation.\r\n\r\nWith these changes a call to create a file could fail with ENOSPC. Not the best error value.\r\nBut, this is the closest I found. Any alternate suggestions are welcome.\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\nWith \"casesensitivity=mixed\" it is easy to panic the node with a simple test case\r\nas described in https://github.com/zfsonlinux/zfs/issues/7011\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\nThe following tests were run : \r\n- zfs-testsuite\r\n- ztest\r\n- Unit-test described in the #7011 \r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [x] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "woffs": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7003", "title": "autoreplace = on, but spare not automatically activated on drive error", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Debian\r\nDistribution Version    | Stretch (9)\r\nLinux Kernel                 | 4.9.51\r\nArchitecture                 | x86_64\r\nZFS Version                  | 0.7.3\r\nSPL Version                  | 0.7.3\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\n \r\nA disk was failing, zed reported errors ...\r\n\r\n```\r\nZFS has detected that a device was removed.\r\n\r\n impact: Fault tolerance of the pool may be compromised.\r\n    eid: 71656\r\n  class: statechange\r\n  state: REMOVED\r\n   host: inferno\r\n   time: 2017-12-29 19:57:19+0100\r\n  vpath: /dev/disk/by-vdev/E2-part1\r\n  vguid: 0x8F23CA44FDEBE82C\r\n   pool: 0x83BBC476EFE065A2\r\n```\r\n\r\n```\r\nThe number of I/O errors associated with a ZFS device exceeded\r\nacceptable levels. ZFS has marked the device as faulted.\r\n\r\n impact: Fault tolerance of the pool may be compromised.\r\n    eid: 71662\r\n  class: statechange\r\n  state: FAULTED\r\n   host: inferno\r\n   time: 2017-12-29 19:57:19+0100\r\n  vpath: /dev/disk/by-vdev/E2-part1\r\n  vguid: 0x8F23CA44FDEBE82C\r\n   pool: 0x83BBC476EFE065A2\r\n```\r\n\r\n... but the spare was not activated automatically, although the autoreplace property was set to `on`.\r\n\r\n```\r\n        inferno# zpool status\r\n  [...]\r\n                pool: torx\r\n         state: DEGRADED\r\n        status: One or more devices are faulted in response to persistent errors.\r\n                Sufficient replicas exist for the pool to continue functioning in a\r\n                degraded state.\r\n        action: Replace the faulted device, or use 'zpool clear' to mark the device\r\n                repaired.\r\n                scan: scrub repaired 0B in 188h32m with 0 errors on Sun Dec 17 20:56:54 2017\r\n        config:\r\n\r\n                NAME        STATE     READ WRITE CKSUM\r\n                torx        DEGRADED     0     0     0\r\n                        raidz2-0  DEGRADED     0     0     0\r\n                                E0      ONLINE       0     0     0\r\n                                E1      ONLINE       0     0     0\r\n                                E2      FAULTED      0     0     0  too many errors\r\n                                E3      ONLINE       0     0     0\r\n                                E4      ONLINE       0     0     0\r\n                                E5      ONLINE       0     0     0\r\n                                E6      ONLINE       0     0     0\r\n                                E7      ONLINE       0     0     0\r\n                                E8      ONLINE       0     0     0\r\n                                E9      ONLINE       0     0     0\r\n                spares\r\n                        EA        AVAIL\r\n\r\n        errors: No known data errors\r\n```\r\n\r\nAfter manually issuing `zpool replace torx E2 EA` the resilver to the spare started.\r\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7003/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "krichter722": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7002", "title": "\"VERIFY3(range_tree_space(rt) == space) failed\" after I/O freeze", "body": "### System information\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Ubuntu\r\nDistribution Version    | 17.10\r\nLinux Kernel                 | 4.13.0-21-generic\r\nArchitecture                 | amd64\r\nZFS Version                  | 0.7.0-227_g823d48bfb\r\nSPL Version                  | 0.7.0-22_gc9821f1c\r\n\r\n### Describe the problem you're observing\r\nMy pool consisting of 1 HDD vdev and 1 SSD cache and 1 SSD log device experienced an I/O freeze under heavy load including heavy dedup action (parallel checkout and building of Firefox on docker images) where all commands doing I/O on the pool switched to uninterruptible state and no I/O occured anymore according to `iotop`.\r\n\r\nAfter starting the machine again I'm no longer able to import the pool because the `zpool import` command never returns and after a few seconds of reading a few 100 MB the I/O stops and the stack below is printed in `dmesg`.\r\n\r\nA readonly import is possible. `zfs set mountpoint=none data/docker` fails due to `internal error: out of memory` immediately without any noticable memory issues.\r\n\r\n### Describe how to reproduce the problem\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\nThe I/O freeze was caused by\r\n\r\n```\r\n[27969.280956] VERIFY3(range_tree_space(rt) == space) failed (6922371072 == 6922383360)\r\n[27969.280960] PANIC at space_map.c:127:space_map_load()\r\n[27969.280961] Showing stack for process 13639\r\n[27969.280963] CPU: 5 PID: 13639 Comm: z_wr_iss Tainted: P        W  OE   4.13.0-21-generic #24-Ubuntu\r\n[27969.280964] Hardware name: LENOVO 20221/INVALID, BIOS 71CN51WW(V1.21) 07/12/2013\r\n[27969.280964] Call Trace:\r\n[27969.280970]  dump_stack+0x63/0x8b\r\n[27969.280979]  spl_dumpstack+0x42/0x50 [spl]\r\n[27969.280982]  spl_panic+0xc8/0x110 [spl]\r\n[27969.280985]  ? kmem_cache_free+0x197/0x1c0\r\n[27969.280988]  ? avl_add+0x65/0xb0 [zavl]\r\n[27969.281027]  ? rt_avl_add+0x11/0x20 [zfs]\r\n[27969.281054]  ? range_tree_add_impl+0x2f5/0x440 [zfs]\r\n[27969.281078]  ? dnode_rele+0x39/0x40 [zfs]\r\n[27969.281108]  space_map_load+0x470/0x4f0 [zfs]\r\n[27969.281109]  ? avl_nearest+0x2b/0x30 [zavl]\r\n[27969.281136]  metaslab_load+0x36/0xf0 [zfs]\r\n[27969.281162]  metaslab_activate+0x93/0xc0 [zfs]\r\n[27969.281186]  metaslab_alloc+0x4b9/0x1170 [zfs]\r\n[27969.281217]  zio_dva_allocate+0xac/0x630 [zfs]\r\n[27969.281245]  ? zio_execute+0x8a/0xf0 [zfs]\r\n[27969.281274]  ? vdev_config_sync+0x180/0x180 [zfs]\r\n[27969.281301]  ? vdev_mirror_io_start+0xa4/0x180 [zfs]\r\n[27969.281305]  ? tsd_hash_search.isra.3+0x47/0xa0 [spl]\r\n[27969.281308]  ? tsd_get_by_thread+0x2e/0x40 [spl]\r\n[27969.281311]  ? taskq_member+0x18/0x30 [spl]\r\n[27969.281340]  zio_execute+0x8a/0xf0 [zfs]\r\n[27969.281343]  taskq_thread+0x2aa/0x4d0 [spl]\r\n[27969.281345]  ? wake_up_q+0x80/0x80\r\n[27969.281373]  ? zio_reexecute+0x3e0/0x3e0 [zfs]\r\n[27969.281375]  kthread+0x125/0x140\r\n[27969.281378]  ? taskq_thread_should_stop+0x70/0x70 [spl]\r\n[27969.281379]  ? kthread_create_on_node+0x70/0x70\r\n[27969.281382]  ret_from_fork+0x25/0x30\r\n```\r\nwhich I captured before having to shutdown the machine with the power button. After every reboot the import fails due to\r\n\r\n```\r\n[  274.685568]  dump_stack+0x63/0x8b\r\n[  274.685575]  spl_dumpstack+0x42/0x50 [spl]\r\n[  274.685578]  spl_panic+0xc8/0x110 [spl]\r\n[  274.685581]  ? kmem_cache_free+0x197/0x1c0\r\n[  274.685583]  ? avl_add+0x65/0xb0 [zavl]\r\n[  274.685619]  ? rt_avl_add+0x11/0x20 [zfs]\r\n[  274.685645]  ? range_tree_add_impl+0x2f5/0x440 [zfs]\r\n[  274.685667]  ? dnode_rele+0x39/0x40 [zfs]\r\n[  274.685694]  space_map_load+0x470/0x4f0 [zfs]\r\n[  274.685720]  metaslab_load+0x36/0xf0 [zfs]\r\n[  274.685743]  metaslab_activate+0x93/0xc0 [zfs]\r\n[  274.685766]  metaslab_alloc+0x4b9/0x1170 [zfs]\r\n[  274.685794]  zio_dva_allocate+0xac/0x630 [zfs]\r\n[  274.685795]  ? mutex_lock+0x12/0x40\r\n[  274.685799]  ? tsd_hash_search.isra.3+0x47/0xa0 [spl]\r\n[  274.685802]  ? tsd_get_by_thread+0x2e/0x40 [spl]\r\n[  274.685805]  ? taskq_member+0x18/0x30 [spl]\r\n[  274.685832]  zio_execute+0x8a/0xf0 [zfs]\r\n[  274.685835]  taskq_thread+0x2aa/0x4d0 [spl]\r\n[  274.685837]  ? wake_up_q+0x80/0x80\r\n[  274.685864]  ? zio_reexecute+0x3e0/0x3e0 [zfs]\r\n[  274.685865]  kthread+0x125/0x140\r\n[  274.685869]  ? taskq_thread_should_stop+0x70/0x70 [spl]\r\n[  274.685870]  ? kthread_create_on_node+0x70/0x70\r\n[  274.685871]  ret_from_fork+0x25/0x30\r\n```\r\nalso after a successful readonly import.", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7002/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "redzhang1990": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6995", "title": "Can ZFS support numa binding?", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Redhat\r\nDistribution Version    | 7.4\r\nLinux Kernel                 | 4.11.0\r\nArchitecture                 | ARM\r\nZFS Version                  | 0.7.1\r\nSPL Version                  | 0.7.1\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\nCan the ZFS support or willing support numa binding?\r\n### Describe how to reproduce the problem\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n<!-- \r\n*IMPORTANT* - Please mark logs and text output from terminal commands \r\nor else Github will not display them correctly. \r\nAn example is provided below.\r\n\r\nExample:\r\n```\r\n```\r\n-->\r\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6995/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "fejesjoco": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6994", "title": "Documentation of ACLs should be fixed", "body": "There are issues in the manpage of zfs(8).\r\n\r\naclinherit talks about ACEs, acltype talks about ACLs, this is inconsistent.\r\n\r\naclinherit doesn't mention what kind of ACEs it's talking about. Since neither regular file permission bits not POSIX ACLs have write_acl/write_owner, this must be NFSv4. So that should be mentioned here explicitly.\r\n\r\nacltype has two values. Again this doesn't say what it's talking about and one can only guess. Does \"off\" turn off both NFSv4 and POSIX ACLs, or just POSIX? Does \"posixacl\" enable both NFSv4 and POSIX, or only POSIX? I can even read it in a way that I can either have POSIX ACLs or no ACLs, which would mean NFSv4 ACLs are not even supported under Linux.\r\n\r\nThe source code has many mentions of an aclmode property but this is not documented anywhere.\r\n\r\nSince the document talks about multiple ACL types, it might be worth mentioning if regular file permission bits work as usual or not (this is especially interesting across dataset mount boundaries).\r\n\r\nIf you can confirm these points, I can volunteer to send a PR.", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6994/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "dechamps": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6988", "title": "zil_itx_needcopy_bytes kstat counter is corrupted", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Debian\r\nDistribution Version    | Unstable\r\nLinux Kernel                 | 4.13.0-1-amd64\r\nArchitecture                 | amd64\r\nZFS Version                  | 0.7.3-3\r\nSPL Version                  | 0.7.3-1\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\n\r\n```\r\n$ cat /proc/spl/kstat/zfs/zil\r\n15 1 0x01 13 624 31503034653 382758011634377\r\nname                            type data\r\nzil_commit_count                4    197902\r\nzil_commit_writer_count         4    197884\r\nzil_itx_count                   4    611431070\r\nzil_itx_indirect_count          4    0\r\nzil_itx_indirect_bytes          4    0\r\nzil_itx_copied_count            4    0\r\nzil_itx_copied_bytes            4    0\r\nzil_itx_needcopy_count          4    611266365\r\nzil_itx_needcopy_bytes          4    18446744072731425348\r\nzil_itx_metaslab_normal_count   4    0\r\nzil_itx_metaslab_normal_bytes   4    0\r\nzil_itx_metaslab_slog_count     4    1169526\r\nzil_itx_metaslab_slog_bytes     4    140983216376\r\n```\r\n\r\nThe `zil_itx_needcopy_bytes` counter is blatantly wrong - I'm pretty sure I did not write 16 exabytes of data in that pool :) Its value is quite close to `UINT64_MAX`, which suggests some kind of overflow or memory corruption.\r\n\r\n### Describe how to reproduce the problem\r\n\r\nNot sure. However I can tell that it started after I did a system upgrade, which included the following version changes:\r\n\r\n- Kernel: 4.12 \u2192 4.13\r\n- SPL: 0.6.5 \u2192 0.7.3\r\n- ZFS: 0.6.5 \u2192 0.7.3\r\n\r\nFor this reason I suspect this might be a regression introduced between SPL/ZFS 0.6.5 and SPL/ZFS 0.7.3.\r\n\r\nThis issue might seem benign, but in my case it's really not because it prevents [Prometheus Node exporter](https://github.com/prometheus/node_exporter) from exporting ZFS metrics correctly. Here's the log message from the node exporter in an attempt to make this issue easier to search for:\r\n\r\n```\r\ntime=\"2017-12-20T22:32:39Z\" level=error msg=\"ERROR: zfs collector failed after 0.000693s: could not parse expected integer value for \\\"kstat.zfs.misc.zil.zil_itx_needcopy_bytes\\\"\" source=\"node_exporter.go:95\"\r\n```", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6988/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374490", "body": "Hmmm\u2026 in fact this line is supposed to be in pull request #384. Seems like I seriously screwed up while doing the merges: all my pull requests show the same commits. What a mess\u2026 git is new to me, I guess this was bound to happen. There should be only one commit in this pull request: 90e1b2108f3b8fd3d2b92bdaa4775fe2321cffa3, so if you're just interested in ZVOL synchronicity, you should check it out. I'm not sure how to fix this, I guess I'll have to recreate the pull requests.\n\nFYI, in the context of #384, this comment means that maybe the discard operation should be added to the log. This is not very important since losing discard operations cannot result in data corruption.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374490/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374498", "body": "That's what I did, basically; the problem is, when updating my master branch from upstream I guessed it would be a good idea to also update individual pull request branches from my master branch. Alas, it was a very bad idea, because my master branch add commits from all my pull requests, so by merging master into each pull request, I merged all commits from all pull requests into each pull request, hence the mess. In the future I'll just let my pull requests alone when I'm done with them.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374498/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374511", "body": "I never commited anything to my master branch, just merges. I wrote the pull request's code into the appropriate pull request branches, as I should. The issue is, I was merging master into my pull requests without realizing what I was doing. The solution is to stop doing that. I just emailed Brian so that we decide what to do about the already messed up pull requests.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374511/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}, "ScaMar": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6985", "title": "\"space map refcount mismatch\" on never used zpool after reboot", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       |  Ubuntu\r\nDistribution Version    |  LTS 16.04.03\r\nLinux Kernel                 |  4.4.0-104-generic\r\nArchitecture                 |  x86_64\r\nZFS Version                  |  0.6.5.6\r\nSPL Version                  |  0.6.5.6\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\n\r\nHi all,\r\non my live zpool i've found the \"space map refcount mismatch\" (error? warning?).\r\nBecause the pool wasn't too big, i've copied data on an external storage, so i've destroyes the zpool then i've recreated it.\r\nI've execute \"zdb <pool>\" and it was ok. After the first reboot (no data were copied/created on zpool), i've executed \"zdb <pool>\" again and i've found the message \"space map refcount mismatch\".\r\n\r\nI've destroyed - recreated the pool several times, always i got the \"space map refcount mismatch\".\r\nEach time before reboot i've tried something like \"zfs unmount <pool>\".\r\nI think the message is related to the first zpool.cache creation.\r\nAfter i've deleted the zpool.cache, the error was not present after the reboot.\r\n\r\nSo my problem are these lines in the zdb output:\r\n```\r\nspace map refcount mismatch: expected 11 != actual 5\r\n```\r\n\r\n### Describe how to reproduce the problem\r\nInstall Ubuntu 16.04. Update it. Create a zpool. Reboot.\r\n\r\n### Questions, considerations, any suggestions?\r\nAbout such issue, i have some questions:\r\n\r\n1) Is it something i need to worry about?\r\n2) Is there a way to recalculate/rebuild space map?\r\n\r\nThere are similar issues about such message someone wrote \"It is a problem in claiming empty space\", some other wrote \"This situation may lead to data corruption\", \"Ignore it if the delta beetwen refcount and space is fixed (if not?)\".\r\nMay we have a clear/human about the consequencies of this error / warning?\r\n\r\nThe only think i know, and sincerily i don't understand a single line (my fault, i'm not a coder), this is the line of code where the counts are compared:\r\n```\r\nstatic int\r\nverify_spacemap_refcounts(spa_t *spa)\r\n{\r\n\tuint64_t expected_refcount = 0;\r\n\tuint64_t actual_refcount;\r\n\r\n\t(void) feature_get_refcount(spa,\r\n\t    &spa_feature_table[SPA_FEATURE_SPACEMAP_HISTOGRAM],\r\n\t    &expected_refcount);\r\n\tactual_refcount = get_dtl_refcount(spa->spa_root_vdev);\r\n\tactual_refcount += get_metaslab_refcount(spa->spa_root_vdev);\r\n\r\n\tif (expected_refcount != actual_refcount) {\r\n\t\t(void) printf(\"space map refcount mismatch: expected %lld != \"\r\n\t\t    \"actual %lld\\n\",\r\n\t\t    (longlong_t)expected_refcount,\r\n\t\t    (longlong_t)actual_refcount);\r\n\t\treturn (2);\r\n\t}\r\n\treturn (0);\r\n}\r\n```\r\nPlease let me know if i must worry about this, so i can evaluate other ways to achieve my personal storage:\r\n1) linux with btrfs\r\n2) OpenIndiana/FreeBSD with ZFS\r\n3) Old but stable md / lvm / xfs (i will risk the cosmic ray bitrotter...)\r\n\r\nThank you,\r\nMarco\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n<!-- \r\n*IMPORTANT* - Please mark logs and text output from terminal commands \r\nor else Github will not display them correctly. \r\nAn example is provided below.\r\n\r\nExample:\r\n```\r\nthis is an example how log text should be marked (wrap it with ```)\r\n```\r\n-->\r\n\r\n\r\n[zdbout.newcreated.txt](https://github.com/zfsonlinux/zfs/files/1571863/zdbout.newcreated.txt)\r\n[zdbout.firstreboot.txt](https://github.com/zfsonlinux/zfs/files/1571864/zdbout.firstreboot.txt)\r\n```\r\nHistory for 'magazzino':\r\n2017-12-19.13:28:20 zpool create magazzino mirror /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K0KA3UYK /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K7NF5E20\r\n2017-12-19.13:28:21 zpool add magazzino mirror /dev/disk/by-id/ata-WDC_WD30EFRX-68EUZN0_WD-WCC4N7UUHR2X /dev/disk/by-id/ata-WDC_WD30EFRX-68EUZN0_WD-WCC4N3CHVS8X\r\n2017-12-19.13:28:22 zpool add magazzino cache /dev/disk/by-id/ata-KINGSTON_SUV400S37120G_50026B77720127CB-part5 /dev/disk/by-id/ata-KINGSTON_SUV400S37120G_50026B776B0175F0-part5\r\n2017-12-19.13:28:22 zpool add magazzino log mirror /dev/disk/by-id/ata-KINGSTON_SUV400S37120G_50026B77720127CB-part6 /dev/disk/by-id/ata-KINGSTON_SUV400S37120G_50026B776B0175F0-part6\r\n2017-12-19.13:28:22 zfs create magazzino/video\r\n2017-12-19.13:28:22 zfs create magazzino/foto\r\n2017-12-19.13:28:23 zfs create magazzino/owncloud\r\n2017-12-19.13:28:29 zpool scrub magazzino\r\n```\r\n--> deleted /etc/zfs/zpool.cache\r\n--> reboot\r\n```\r\n2017-12-19.13:31:24 zpool import -d /dev/disk/by-id -aN\r\n```\r\n--> new reboot withouth deleting zpool.cache\r\n```\r\n2017-12-19.13:37:03 zpool import -c /etc/zfs/zpool.cache -aN\r\n```\r\n--> another reboot withouth deleting zpool.cache\r\n```\r\n2017-12-19.13:41:01 zpool import -c /etc/zfs/zpool.cache -aN\r\n```\r\n\r\n\r\n\r\n\r\n\r\n\r\n ", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6985/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "samis": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6984", "title": "zpool property 'freeing' partially stuck", "body": "### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Gentoo\r\nDistribution Version    | Profile 17.0\r\nLinux Kernel                 | 4.14.5-gentoo\r\nArchitecture                 | X86_64\r\nZFS Version                  | 0.7.0-211_g4e9b1569\r\nSPL Version                  | 0.7.0-21_ged19bcc\r\n\r\n\r\n### Describe the problem you're observing\r\nI recently decided to clean up and delete two unused sparse zvols. After this, the freeing property increased as expected and did initially decrease. However, it's almost 24 hours (and two reboots) later and the property is still reporting the exact same value. \r\n\r\nAs a test, I filled a zvol with 1G of /dev/urandom and then destroyed it. The property increased from it's original value of 14353956864 to 14605664256 but shortly afterwards the data was freed and the value was back to 14353956864. This is similar to #5808 but both the scenario and the behaviour appear to be different, as neither zvol was ever used for NFS purposes.\r\n### Describe how to reproduce the problem\r\nI have not yet reproduced this beyond the above test. I can't be certain that the freeing value was correct before, but the timing seems right for this issue.\r\n### Include any warning/errors/backtraces from the system logs\r\nSo far there have been no warnings, errors or backtraces created as a result of this problem. \r\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6984/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "kithrup": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/43cb30b3ce6ee3c3041276c93594ae61e7daaf86", "message": "OpenZFS 8959 - Add notifications when a scrub is paused or resumed\n\nAuthored by: Sean Eric Fagan <sef@ixsystems.com>\nReviewed by: Alek Pinchuk <pinchuk.alek@gmail.com>\nReviewed by: Matthew Ahrens <mahrens@delphix.com>\nReviewed-by: George Melikov <mail@gmelikov.ru>\nReviewed-by: Tony Hutter <hutter2@llnl.gov>\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\nApproved by: Gordon Ross <gwr@nexenta.com>\nPorted-by: Giuseppe Di Natale <dinatale2@llnl.gov>\n\nPorting Notes:\n- Brought #defines in eventdefs.h in line with ZFS on Linux format.\n- Updated zfs-events.5 with the new events.\n\nOpenZFS-issue: https://www.illumos.org/issues/8959\nOpenZFS-commit: https://github.com/openzfs/openzfs/commit/c862b93eea\nCloses #7049"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "DeHackEd": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/d658b2caa95726c13d99123874910cdedc7ce866", "message": "Remove l2arc_nocompress from zfs-module-parameters(5)\n\nParameter was removed in d3c2ae1c0806\r\n(OpenZFS 6950 - ARC should cache compressed data)\r\n\r\nReviewed by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: DHE <git@dehacked.net>\r\nCloses #7043"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/460f239e6999195dbcf9b8443c029f07765b21e9", "message": "Fix -fsanitize=address memory leak\n\nkmem_alloc(0, ...) in userspace returns a leakable pointer.\n\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\nSigned-off-by: DHE <git@dehacked.net>\nIssue #6941"}], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6673", "title": "Fail importing if cached config has wrong number of vdev children", "body": "During import compare the labels' configs with the import config\r\nand fail if the labels indicate more vdevs than the cached config\r\n\r\nSigned-off-by: DHE <git@dehacked.net>\r\nFixes #6671\r\n\r\n### Description\r\nWhen the zpool.cache says `vdev_children=X` but the pool actually has `vdev_children=Y` where `X<Y`, blkptr errors will occur during the import process. We detect this specific case and refuse imports from this cache file.\r\n\r\n### Motivation and Context\r\nSee #6671\r\n\r\n### How Has This Been Tested?\r\n`ztest` only\r\n\r\n### Types of changes\r\n- [X] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n- [X] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [ ] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [X] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "prometheanfire": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/c10cdcb55f81ea773486161b31bc91bb7b58b4c8", "message": "Fix copy-builtin to work with ASAN patch\n\nCommit fed90353 didn't fully update the copy-builtin script\r\nas needed to perform in-kernel builds.  Add the missing\r\noptions and flags.\r\n\r\nReviewed by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: Matthew Thode <mthode@mthode.org>\r\nCloses #7033 \r\nCloses #7037"}], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/7008", "title": "DNM: make zfs-mount service work with encryption", "body": "", "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/7004", "title": "Run zfs load-key if needed in dracut", "body": "'zfs load-key -a' will only be called if needed.  If a dataset not\r\nneeded for boot does not have it's key loaded (home directories for\r\nexample) boot can still continue.", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "yuripv": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/6df9f8ebd73c05da627144bcc3823e6fe980cd75", "message": "OpenZFS 8899 - zpool list property documentation doesn't match actual behaviour\n\nAuthored by: Yuri Pankov <yuri.pankov@nexenta.com>\nReviewed by: Alexander Pyhalov <alp@rsu.ru>\nReviewed-by: George Melikov <mail@gmelikov.ru>\nApproved by: Dan McDonald <danmcd@joyent.com>\nPorted-by: Brian Behlendorf <behlendorf1@llnl.gov>\n\nOpenZFS-issue: https://www.illumos.org/issues/8899\nOpenZFS-commit: https://github.com/openzfs/openzfs/commit/b0e142e57d\nCloses #7032"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/bcb1a8a25e4ee9a94478378710de53b45a9b1517", "message": "OpenZFS 8898 - creating fs with checksum=skein on the boot pools fails ungracefully\n\nAuthored by: Yuri Pankov <yuri.pankov@nexenta.com>\nReviewed by: Toomas Soome <tsoome@me.com>\nReviewed by: Andy Stormont <astormont@racktopsystems.com>\nReviewed-by: George Melikov <mail@gmelikov.ru>\nApproved by: Dan McDonald <danmcd@joyent.com>\nPorted-by: Brian Behlendorf <behlendorf1@llnl.gov>\n\nOpenZFS-issue: https://www.illumos.org/issues/8898\nOpenZFS-commit: https://github.com/openzfs/openzfs/commit/9fa2266d9a\nCloses #7031"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/8198c57b21d5e503f7e72221aa714aaabb2079cc", "message": "OpenZFS 8897 - zpool online -e fails assertion when run on non-leaf vdevs\n\nAuthored by: Yuri Pankov <yuri.pankov@nexenta.com>\nReviewed by: Toomas Soome <tsoome@me.com>\nReviewed by: Igor Kozhukhov <igor@dilos.org>\nReviewed-by: George Melikov <mail@gmelikov.ru>\nApproved by: Dan McDonald <danmcd@joyent.com>\nPorted-by: Brian Behlendorf <behlendorf1@llnl.gov>\n\nOpenZFS-issue: https://www.illumos.org/issues/8897\nOpenZFS-commit: https://github.com/openzfs/openzfs/commit/9a551dd645\nCloses #7030"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "avg-I": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/6a2185660d000c99b14556c7eb1108c5609faf41", "message": "OpenZFS 8930 - zfs_zinactive: do not remove the node if the filesystem is readonly\n\nAuthored by: Andriy Gapon <avg@FreeBSD.org>\nReviewed by: Matthew Ahrens <mahrens@delphix.com>\nReviewed-by: George Melikov <mail@gmelikov.ru>\nApproved by: Gordon Ross <gwr@nexenta.com>\nPorted-by: Brian Behlendorf <behlendorf1@llnl.gov>\n\nOpenZFS-issue: https://www.illumos.org/issues/8930\nOpenZFS-commit: https://github.com/openzfs/openzfs/commit/93c618e0f4\nCloses #7029"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ryao": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/1d53657bf561564162e2ad6449f80fa0140f1dd6", "message": "Fix incompatibility with Reiser4 patched kernels\n\nIn ZFSOnLinux, our sources and build system are self contained such that\r\nwe do not need to make changes to the Linux kernel sources. Reiser4 on\r\nthe other hand exists solely as a kernel tree patch and opts to make\r\nchanges to the kernel rather than adapt to it. After Linux 4.1 made a\r\nVFS change that replaced new_sync_read with do_sync_read, Reiser4's\r\nmaintainer decided to modify the kernel VFS to export the old function.\r\nThis caused our autotools check to misidentify the kernel API as\r\npredating Linux 4.1 on kernels that have been patched with Reiser4\r\nsupport, which breaks our build.\r\n\r\nReiser4 really should be patched to stop doing this, but lets modify our\r\ncheck to be more strict to help the affected users of both filesystems.\r\n\r\nAlso, we were not checking the types of arguments and return value of\r\nnew_sync_read() and new_sync_write() . Lets fix that too.\r\n\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nReviewed-by: Giuseppe Di Natale <dinatale2@llnl.gov>\r\nReviewed-by: George Melikov <mail@gmelikov.ru>\r\nSigned-off-by: Richard Yao <ryao@gentoo.org>\r\nCloses #6241 \r\nCloses #7021"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "nwf": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/cba6fc61a2898395c47380a0c2303f19842a2ff0", "message": "Revert raidz_map and _col structure types\n\nAs part of the refactoring of ab9f4b0b824ab4cc64a4fa382c037f4154de12d6,\r\nseveral uint64_t-s and uint8_t-s were changed to other types.  This\r\ncaused ZoL github issue #6981, an overflow of a size_t on a 32-bit ARM\r\nmachine.  In absense of any strong motivation for the type changes, this\r\nsimply puts them back, modulo the changes accumulated for ABD.\r\n\r\nCompile-tested on amd64 and run-tested on armhf.\r\n\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nReviewed-by: Gvozden Neskovic <neskovic@gmail.com>\r\nSigned-off-by: Nathaniel Wesley Filardo <nwf@cs.jhu.edu>\r\nCloses #6981 \r\nCloses #7023"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/8b20a9f996b90abe439ce14303fc440f26390e38", "message": "zhack: fix getopt return type\n\nThis fixes zhack's command processing on ARM.  On ARM char\r\nis unsigned, and so, in promotion to an int, it will never\r\ncompare equal to -1.\r\n\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: Nathaniel Wesley Filardo <nwf@cs.jhu.edu>\r\nCloses #7016"}], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6209", "title": "[RFC] new zscrub command for offline scrubs in userland", "body": "### Description\r\n\r\nThis PR adds a \"zhack scrub\" subcommand which, in user-land, finds and scrubs a pool.  This has proven useful for experimenting with the scan logic (especially the in-order-scrub patches) without having to reload the kernel module and seems like it may be useful to others.\r\n\r\nAt this point, it is not yet ready to merge -- there are no tests, no docs, &c... but I am curious for anyone's commentary and/or suggestions. :)\r\n\r\n### How Has This Been Tested?\r\n\r\nLimited testing against both files and actual block-device-backed pools.  Scrubs and resilvers appear to work just fine.\r\n\r\n### Types of changes\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [ ] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "gamanakis": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/be54a13c3e7db423ffdb3f7983d4dd1141cc94a0", "message": "Fix percentage styling in zfs-module-parameters.5\n\nReplace \"percent\" with \"%\", add bold to default values.\r\n\r\nReviewed-by: bunder2015 <omfgbunder@gmail.com>\r\nReviewed-by: George Melikov <mail@gmelikov.ru>\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: George Amanakis <gamanakis@gmail.com>\r\nCloses #7018"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "loli10K": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/390d679acdfa6a2498280a4dcd33b7600ace27ce", "message": "Fix 'zpool add' handling of nested interior VDEVs\n\nWhen replacing a faulted device which was previously handled by a spare\r\nmultiple levels of nested interior VDEVs will be present in the pool\r\nconfiguration; the following example illustrates one of the possible\r\nsituations:\r\n\r\n   NAME                          STATE     READ WRITE CKSUM\r\n   testpool                      DEGRADED     0     0     0\r\n     raidz1-0                    DEGRADED     0     0     0\r\n       spare-0                   DEGRADED     0     0     0\r\n         replacing-0             DEGRADED     0     0     0\r\n           /var/tmp/fault-dev    UNAVAIL      0     0     0  cannot open\r\n           /var/tmp/replace-dev  ONLINE       0     0     0\r\n         /var/tmp/spare-dev1     ONLINE       0     0     0\r\n       /var/tmp/safe-dev         ONLINE       0     0     0\r\n   spares\r\n     /var/tmp/spare-dev1         INUSE     currently in use\r\n\r\nThis is safe and allowed, but get_replication() needs to handle this\r\nsituation gracefully to let zpool add new devices to the pool.\r\n\r\nReviewed-by: George Melikov <mail@gmelikov.ru>\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: loli10K <ezomori.nozomu@gmail.com>\r\nCloses #6678 \r\nCloses #6996"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/c4ba46deade0a14d089228a56a5d0aa0ffd5fadd", "message": "Handle invalid options in arc_summary\n\nIf an invalid option is provided to arc_summary.py we handle any error\r\nthrown from the getopt Python module and print the usage help message.\r\n\r\nReviewed-by: George Melikov <mail@gmelikov.ru>\r\nReviewed-by: Giuseppe Di Natale <dinatale2@llnl.gov>\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: loli10K <ezomori.nozomu@gmail.com>\r\nCloses #6983"}], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/7058", "title": "Fix Debian packaging on ARMv7/ARM64", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\n\r\nWhen building packages on Debian-based systems specify the target architecture used by `alien` to convert .rpm packages into .deb: this avoids detecting an incorrect value which results in the following errors:\r\n\r\n```\r\n<package>.aarch64.rpm is for architecture aarch64 ; the package cannot be built on this system\r\n<package>.armv7l.rpm is for architecture armel ; the package cannot be built on this system\r\n```\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\nFix https://github.com/zfsonlinux/zfs/issues/7046\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\nTested on a local aarch64 and armhf debootstrapped rootfs\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "prakashsurya": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/2fe61a7ecc507d031451c21b3077fae549b58ec3", "message": "OpenZFS 8909 - 8585 can cause a use-after-free kernel panic\n\nAuthored by: Prakash Surya <prakash.surya@delphix.com>\nReviewed by: John Kennedy <jwk404@gmail.com>\nReviewed by: Matthew Ahrens <mahrens@delphix.com>\nReviewed by: George Wilson <george.wilson@delphix.com>\nReviewed by: Brad Lewis <brad.lewis@delphix.com>\nReviewed by: Igor Kozhukhov <igor@dilos.org>\nReviewed by: Brian Behlendorf <behlendorf1@llnl.gov>\nApproved by: Robert Mustacchi <rm@joyent.com>\nPorted-by: Prakash Surya <prakash.surya@delphix.com>\n\nPROBLEM\n=======\n\nThere's a race condition that exists if `zil_free_lwb` races with either\n`zil_commit_waiter_timeout` and/or `zil_lwb_flush_vdevs_done`.\n\nHere's an example panic due to this bug:\n\n    > ::status\n    debugging crash dump vmcore.0 (64-bit) from ip-10-110-205-40\n    operating system: 5.11 dlpx-5.2.2.0_2017-12-04-17-28-32b6ba51fb (i86pc)\n    image uuid: 4af0edfb-e58e-6ed8-cafc-d3e9167c7513\n    panic message:\n    BAD TRAP: type=e (#pf Page fault) rp=ffffff0010555970 addr=60 occurred in module \"zfs\" due to a NULL pointer dereference\n    dump content: kernel pages only\n\n    > $c\n    zio_shrink+0x12()\n    zil_lwb_write_issue+0x30d(ffffff03dcd15cc0, ffffff03e0730e20)\n    zil_commit_waiter_timeout+0xa2(ffffff03dcd15cc0, ffffff03d97ffcf8)\n    zil_commit_waiter+0xf3(ffffff03dcd15cc0, ffffff03d97ffcf8)\n    zil_commit+0x80(ffffff03dcd15cc0, 9a9)\n    zfs_write+0xc34(ffffff03dc38b140, ffffff0010555e60, 40, ffffff03e00fb758, 0)\n    fop_write+0x5b(ffffff03dc38b140, ffffff0010555e60, 40, ffffff03e00fb758, 0)\n    write+0x250(42, fffffd7ff4832000, 2000)\n    sys_syscall+0x177()\n\nIf there's an outstanding lwb that's in `zil_commit_waiter_timeout`\nwaiting to timeout, waiting on it's waiter's CV, we must be sure not to\ncall `zil_free_lwb`. If we end up calling `zil_free_lwb`, then that LWB\nmay be freed and can result in a use-after-free situation where the\nstale lwb pointer stored in the `zil_commit_waiter_t` structure of the\nthread waiting on the waiter's CV is used.\n\nA similar situation can occur if an lwb is issued to disk, and thus in\nthe `LWB_STATE_ISSUED` state, and `zil_free_lwb` is called while the\ndisk is servicing that lwb. In this situation, the lwb will be freed by\n`zil_free_lwb`, which will result in a use-after-free situation when the\nlwb's zio completes, and `zil_lwb_flush_vdevs_done` is called.\n\nThis race condition is prevented in `zil_close` by calling `zil_commit`\nbefore `zil_free_lwb` is called, which will ensure all outstanding (i.e.\nall lwb's in the `LWB_STATE_OPEN` and/or `LWB_STATE_ISSUED` states)\nreach the `LWB_STATE_DONE` state before the lwb's are freed\n(`zil_commit` will not return untill all the lwb's are\n`LWB_STATE_DONE`).\n\nFurther, this race condition is prevented in `zil_sync` by only calling\n`zil_free_lwb` for lwb's that do not have their `lwb_buf` pointer set.\nAll lwb's not in the `LWB_STATE_DONE` state will have a non-null value\nfor this pointer; the pointer is only cleared in\n`zil_lwb_flush_vdevs_done`, at which point the lwb's state will be\nchanged to `LWB_STATE_DONE`.\n\nThis race *is* present in `zil_suspend`, leading to this bug.\n\nAt first glance, it would appear as though this would not be true\nbecause `zil_suspend` will call `zil_commit`, just like `zil_close`, but\nthe problem is that `zil_suspend` will set the zilog's `zl_suspend`\nfield prior to calling `zil_commit`. Further, in `zil_commit`, if\n`zl_suspend` is set, `zil_commit` will take a special branch of logic\nand use `txg_wait_synced` instead of performing the normal `zil_commit`\nlogic.\n\nThis call to `txg_wait_synced` might be good enough for the data to\nreach disk safely before it returns, but it does not ensure that all\noutstanding lwb's reach the `LWB_STATE_DONE` state before it returns.\nThis is because, if there's an lwb \"stuck\" in\n`zil_commit_waiter_timeout`, waiting for it's lwb to timeout, it will\nmaintain a non-null value for it's `lwb_buf` field and thus `zil_sync`\nwill not free that lwb. Thus, even though the lwb's data is already on\ndisk, the lwb will be left lingering, waiting on the CV, and will\neventually timeout and be issued to disk even though the write is\nunnecessary.\n\nSo, after `zil_commit` is called from `zil_suspend`, we incorrectly\nassume that there are not outstanding lwb's, and proceed to free all\nlwb's found on the zilog's lwb list. As a result, we free the lwb that\nwill later be used `zil_commit_waiter_timeout`.\n\nSOLUTION\n========\n\nThe solution to this, is to ensure all outstanding lwb's complete before\ncalling `zil_free_lwb` via `zil_destroy` in `zil_suspend`. This patch\naccomplishes this goal by forcing the normal `zil_commit` logic when\ncalled from `zil_sync`.\n\nNow, `zil_suspend` will call `zil_commit_impl` which will always use the\nnormal logic of waiting/issuing lwb's to disk before it returns. As a\nresult, any lwb's outstanding when `zil_commit_impl` is called will be\nguaranteed to reach the `LWB_STATE_DONE` state by the time it returns.\n\nFurther, no new lwb's will be created via `zil_commit` since the zilog's\n`zl_suspend` flag will be set. This will force all new callers of\n`zil_commit` to use `txg_wait_synced` instead of creating and issuing\nnew lwb's.\n\nThus, all lwb's left on the zilog's lwb list when `zil_destroy` is\ncalled will be in the `LWB_STATE_DONE` state, and we'll avoid this race\ncondition.\n\nOpenZFS-issue: https://www.illumos.org/issues/8909\nOpenZFS-commit: https://github.com/openzfs/openzfs/commit/ece62b6f8d\nCloses #6940"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "lidongyang": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/823d48bfb182137c53b9432498f1f0564eaa8bfc", "message": "Call commit callbacks from the tail of the list\n\nOur zfs backed Lustre MDT had soft lockups while under heavy metadata\r\nworkloads while handling transaction callbacks from osd_zfs.\r\n\r\nThe problem is zfs is not taking advantage of the fast path in\r\nLustre's trans callback handling, where Lustre will skip the calls\r\nto ptlrpc_commit_replies() when it already saw a higher transaction\r\nnumber.\r\n\r\nThis patch corrects this, it also has a positive impact on metadata\r\nperformance on Lustre with osd_zfs, plus some cleanup in the headers.\r\n\r\nA similar issue for ext4/ldiskfs is described on:\r\nhttps://jira.hpdd.intel.com/browse/LU-6527\r\n\r\nReviewed-by: Olaf Faaland <faaland1@llnl.gov>\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: Li Dongyang <dongyang.li@anu.edu.au>\r\nCloses #6986"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "tcaputi": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/44b61ea506212c287333e03d2cf8933216810800", "message": "Remove empty files accidentally added by a8b2e306 \n\nThis patch simply removes 2 empty files that were accidentally\r\nadded a part of the scrub priority patch.\r\n\r\nReviewed-by: George Melikov <mail@gmelikov.ru>\r\nReviewed-by: Giuseppe Di Natale <dinatale2@llnl.gov>\r\nSigned-off-by: Tom Caputi <tcaputi@datto.com>\r\nCloses #6990"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/a8b2e30685c9214ccfd0181977540e080340df4e", "message": "Support re-prioritizing asynchronous prefetches\n\nWhen sequential scrubs were merged, all calls to arc_read()\r\n(including prefetch IOs) were given ZIO_PRIORITY_ASYNC_READ.\r\nUnfortunately, this behaves badly with an existing issue where\r\nprefetch IOs cannot be re-prioritized after the issue. The\r\nresult is that synchronous reads end up in the same vdev_queue\r\nas the scrub IOs and can have (in some workloads) multiple\r\nseconds of latency.\r\n\r\nThis patch incorporates 2 changes. The first ensures that all\r\nscrub IOs are given ZIO_PRIORITY_SCRUB to allow the vdev_queue\r\ncode to differentiate between these I/Os and user prefetches.\r\nSecond, this patch introduces zio_change_priority() to provide\r\nthe missing capability to upgrade a zio's priority.\r\n\r\nReviewed by: George Wilson <george.wilson@delphix.com>\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: Tom Caputi <tcaputi@datto.com>\r\nCloses #6921 \r\nCloses #6926"}], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6864", "title": "Encryption and Raw Send Stability Improvements", "body": "The current on-disk format for encrypted datasets protects\r\nnot only the encrypted and authenticated blocks, but also\r\nthe order and interpretation of these blocks. In order to\r\nmake this work while maintaining the ability to do raw sends\r\nthe indirect bps maintain a secure checksum of all the MACs\r\nin the block below it, along with a few other fields that\r\ndetermine how the data is interpretted.\r\n\r\nUnfortunately, the current on-disk format erroniously\r\nincludes some fields which are not portable and thus cannot\r\nsupport raw sends. It is also not possible to easily work\r\naround this issue due to a separate and much smaller bug\r\nwhich causes indirect blocks for encrypted dnodes to not\r\nbe compressed, which conflicts with the previous bug. In\r\naddition, raw send streams do not currently include\r\ndn_maxblkid which is needed in order to ensure that we are\r\ncorrectly maintaining the portable objset MAC.\r\n\r\nThis patch zero's out the offending fields when computing the\r\nbp MAC (as they should have been) and registers an errata for\r\nthe on-disk format bug. We detect the errata by adding a\r\n\"version\" field to newly created DSL Crypto Keys. We allow\r\ndatasets without a version (version 0) to only be mounted for\r\nread so that they can easily be migrated. We also now include\r\ndn_maxblkid in raw send streams to ensure the MAC can be\r\nmaintained correctly.\r\n\r\nNote that this fix has not yet been finalized and should not be used until it is tested, reviewed, and merged unless you are ok with losing your data.\r\n\r\nSigned-off-by: Tom Caputi <tcaputi@datto.com>\r\n\r\n### How Has This Been Tested?\r\nI have added a new test for raw sends that essentially stresses as many edge cases as I could think of. In addition, I have manually tested that the recovery process laid out in https://github.com/zfsonlinux/zfsonlinux.github.com/pull/35 works as advertised, and that both old and new datasets function predictably.\r\n\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [x] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [x] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "tesujimath": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/993669a7bf17a26843630c547999be0b27483497", "message": "vdev_id: new slot type ses\n\nThis extends vdev_id to support a new slot type, ses, for SCSI Enclosure\r\nServices.  With slot type ses, the disk slot numbers are determined by\r\nusing the device slot number reported by sg_ses for the device with\r\nmatching SAS address, found by querying all available enclosures.\r\n\r\nThis is primarily of use on systems with a deficient driver omitting\r\nsupport for bay_identifier in /sys/devices.  In my testing, I found that\r\nthe existing slot types of port and id were not stable across disk\r\nreplacement, so an alternative was required.\r\n\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: Simon Guest <simon.guest@tesujimath.org>\r\nCloses #6956"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "dinatale2": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/89a66a0457cd392ab8c6ad6d9c138fedaa425067", "message": "Handle broken pipes in arc_summary\n\nUsing a command similar to 'arc_summary.py | head' causes\r\na broken pipe exception. Gracefully exit in the case of a\r\nbroken pipe in arc_summary.py.\r\n\r\nReviewed-by: Richard Elling <Richard.Elling@RichardElling.com>\r\nReviewed-by: loli10K <ezomori.nozomu@gmail.com>\r\nSigned-off-by: Giuseppe Di Natale <dinatale2@llnl.gov>\r\nCloses #6965 \r\nCloses #6969"}], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6906", "title": "Add dbuf hash and dbuf cache kstats", "body": "### Description\r\n<!--- Describe your changes in detail -->\r\nIntroduce kstats about the dbuf hash and dbuf cache\r\nto make it easier to inspect state. This should help\r\nwith debugging and understanding of these portions\r\nof the codebase.\r\n\r\nCorrect format of dbuf kstat file.\r\n\r\nIntroduce a dbc column to dbufs kstat to indicate if\r\na dbuf is in the dbuf cache.\r\n\r\nIntroduce field filtering in the dbufstat python script.\r\n\r\nI will also be introducing some basic test cases to test the new dbufstats kstat and other basic scenarios.\r\n\r\n<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\nGain a better understanding how dbufs are cached and provide another useful tool for users/developer.\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\nLocally on a VM.\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [x] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6294", "title": "Enforce request limits on zvols", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\nCurrently, zvols do not handle heavy random IO\r\nworkloads. zvols should limit the number of outstanding\r\nin-flight IO requests. This should improve performance.\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n#6127 \r\n#6278 \r\n\r\n### How Has This Been Tested?\r\nBuilds on my VM. Buildbot will help me test. Hoping to test on hardware soon.\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [x] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "MEMBER"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "avw1987": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/7055", "title": "Update README.initramfs.markdown", "body": "Fixed a typo\r\n\r\n<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [x] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [ ] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [ ] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "tonyhutter": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/7051", "title": "zfs-0.7.6 patchset", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\nTest 0.7.6 patchset in buildbot\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [ ] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [ ] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "MEMBER"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "sckobras": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/7007", "title": "Allow to limit zed's syslog chattiness", "body": "### Description\r\n\r\nSome usage patterns like send/recv of replication streams can\r\nproduce a large number of events. In such a case, the current\r\nall-syslog.sh zedlet will hold up to its name, and flood the\r\nlogs with mostly redundant information. To mitigate this\r\nsituation, this changeset introduces two new variables\r\nZED_SYSLOG_SUBCLASS_INCLUDE and ZED_SYSLOG_SUBCLASS_EXCLUDE\r\nto zed.rc that give more control over which event classes end\r\nup in the syslog.\r\n\r\nSigned-off-by: Daniel Kobras <d.kobras@science-computing.de>\r\nCloses: #6886\r\n\r\n### Motivation and Context\r\nIt seems that each time a dataset that also uses =zfs-auto-snapshot= is replicated, a =history_event= for the =com.sun:auto-snapshot-desc= property in each snapshot is logged. This easily spams the logs with thousands of redundant, and rather useless messages as described in #6886, so adding a facility to trim down the noise without disabling the syslog feature altogether seems to be in order.\r\n\r\n### How Has This Been Tested?\r\nTested on EL7.4 with ZoL 0.7.2.\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [x] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "aerusso": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6974", "title": "fstab integration", "body": "Generate a tracked, updateable section in /etc/fstab for zfs filesystems\r\n\r\n### Description\r\nA contrib script fstab-generator is implemented that creates a trackable section in /etc/fstab (or another user-specified file) with fstab syntax reflecting the zfs mount and canmount parameters.\r\n\r\n### Motivation and Context\r\nWhile #4943 implements a per-pool granular import, the user will still \"need to add an entry like this in fstab:\r\n\r\n```rpool/home /home zfs rw,defaults,x-systemd.requires=zpool@rpool.service```\r\n\r\nThis script performs precisely that mechanical task, allowing for filesystem dependencies to be correctly identified, and mounted in time to guarantee their availability. A monolithic import of all zfs filesystems is not required to have system files on native zfs mountpoints. \r\n\r\nMoreover, by including this information in /etc/fstab, tools can fail appropriately if essential mountpoints are unavailable. This helps address the common annoyance where zfs fails to mount an important system directory, files then get placed on the zfs mountpoint, and then zfs will fail to mount on the subsequent boot (because overlay=off) even though the underlying problem was corrected. \r\n\r\n#### Why not a systemd-generator?\r\nBesides the obvious lack of integration for users without systemd, other tools may rely on /etc/fstab to determine what filesystems are present on a system. This approach immediately achieves integration with those tools--e.g., for analogous dependency tracking for other init systems that may develop in the future. Additionally, systemd generators may change syntax in the future, but they will have to remain compatible with /etc/fstab.\r\n\r\n### How Has This Been Tested?\r\nI'm running with the output of this script on a machine that has several `/var/` directories, and `/tmp` with purely zfs mountpoints.\r\n\r\n### RFC\r\nThis is a work in progress.\r\n1. Should this be converted to fstab-generator.in, and use `%sbindir%`, etc?\r\n2. Should this name be changed? Should this be installed elsewhere?\r\n3. How could/should this be integrated with the rest of the tools?\r\n4. Is there some reason `mount -ozfsutil` is ill-advised for zfs filesystems?\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6964", "title": "Use zfs-import.target in contrib/dracut", "body": "### Description\r\nThe new zfs-import.target should be used in place of the zfs-import-*.service units in `contrib/dracut`.\r\n\r\n### Motivation and Context\r\nPR #6764 added `zfs-import.target` to simplify dependency on pool importing. #6822 did some cleanup. The recent #6955 (re: #6953) added RPM support for enabling this units. That bug report has prompted me to grep the code base for zfs-import. The last remaining code section to be updated is under `control/dracut/90zfs`.\r\n\r\nThis PR is  a **work in progress**. I don't think dracut users are exposed to any bug presently, because `sysroot.mount` is still ordered `After=zfs-import-*.service`\r\n\r\nTwo files are affected:\r\n1. `zfs-generator.sh.in` is straightforwardly modified to order `sysroot.mount` `After=zfs-import.target` (instead of each `zfs-import-*.service`). \r\n2. `module-setup.sh.in` is also modified. **I need input, because I don't know how precisely dracut works.** `zfs-import.target` (and each `zfs-import-*.service`) is `dracut_install`-ed (and *unconditionally* `mark_hostonly`-ed). Do we need to build a `zfs-import.target.wants` directory with `zfs-import-*.service` links? Or will that be inherited from the host system?\r\n\r\n### How Has This Been Tested?\r\nThis has NOT been tested. This is a place to centralize discussion about these changes.\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [x] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "dweeezil": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6900", "title": "OpenZFS 7614 - zfs device evacuation/removal", "body": "### Description\r\n<!--- Describe your changes in detail -->\r\nThis project allows top-level vdevs to be removed from the storage pool\r\nwith \"zpool remove\", reducing the total amount of storage in the pool.\r\nThis operation copies all allocated regions of the device to be removed\r\nonto other devices, recording the mapping from old to new location.\r\nAfter the removal is complete, read and free operations to the removed\r\n(now \"indirect\") vdev must be remapped and performed at the new location\r\non disk.  The indirect mapping table is kept in memory whenever the pool\r\nis loaded, so there is minimal performance overhead when doing\r\noperations on the indirect vdev.\r\n\r\nThe size of the in-memory mapping table will be reduced when its entries\r\nbecome \"obsolete\" because they are no longer used by any block pointers\r\nin the pool.  An entry becomes obsolete when all the blocks that use it\r\nare freed.  An entry can also become obsolete when all the snapshots\r\nthat reference it are deleted, and the block pointers that reference it\r\nhave been \"remapped\" in all filesystems/zvols (and clones).  Whenever an\r\nindirect block is written, all the block pointers in it will be\r\n\"remapped\" to their new (concrete) locations if possible.  This process\r\ncan be accelerated by using the \"zfs remap\" command to proactively\r\nrewrite all indirect blocks that reference indirect (removed) vdevs.\r\n\r\nNote that when a device is removed, we do not verify the checksum of the\r\ndata that is copied.  This makes the process much faster, but if it were\r\nused on redundant vdevs (i.e. mirror or raidz vdevs), it would be\r\npossible to copy the wrong data, when we have the correct data on e.g.\r\nthe other side of the mirror.  Therefore, mirror and raidz devices can\r\nnot be removed.\r\n\r\n### Motivation and Context\r\nSee above.\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\n### How Has This Been Tested?\r\nAdditions to the test suite in functional/removal.\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "MEMBER"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "scotws": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6892", "title": "Add Python 3 rewrite of arc_summary.py (#6873)", "body": "### Description\r\n\r\nAdd new Python 3 script `arc_summary3.py` as a complete rewrite of `arc_summary.py` to display basic information on the ARC status and various other parameters. This is provided in addition - not as a replacement - to the existing `arc_summary.py` tool. See #6873 for a discussion of the reasoning behind adding a new version of this tool while keeping a legacy version as well.\r\n\r\nNew options:\r\n\r\n        -g/--graph    - Display crude graphic representation of ARC status and quit\r\n        -r/--raw      - Print all available information as minimally formatted list and quit\r\n        -s/--section  - Print a single section. This supersedes -p/--page, which is kept for\r\n                        backwards use but marked as DEPRECIATED\r\n\r\nAdds new sections with information on the ZIL and SPL. \r\n\r\nWe now notify the user if sections L2ARC and VDEV are skipped instead of failing silently; note VDEV caching is currently disabled and slated for possible removal (see source code). Adds information on the ZFS and SPL versions to the header.\r\n\r\nThe **-s/--section** option is intended to replace the page number system, which required the user to remember which page number was of interest. The -p/--page options are still supported, but marked as DEPRECIATED. Current legal sections are `arc archits dmu l2arc spl tunables vdev zil`. It should be easier now to add and modify sections.\r\n\r\nThe **-r/--raw** option is intended to work with other tools such as `grep`. It respects the -a/-d options (alternate output format / descriptions included) where possible. \r\n\r\nThe output of the **-g/--graph** option is intended to give a quick, rough overview as a visual orientation. An example (Ubuntu 16.04 LTS x86_64 with 24 GB RAM, 8 GB ARC max, ZFS stock version 0.6.5.9-2 with `/home` as ZFS mirror pool immediately after starting _Civilization VI_ on Steam on otherwise quiet machine): \r\n```\r\n        ARC: 3.0 GiB (37.5 %)  MFU: 610.5 MiB  MRU: 2.3 GiB\r\n    +----------------------------------------------------------+\r\n    |FFFFRRRRRRRRRRRRRRRRR                                     |\r\n    +----------------------------------------------------------+\r\n```\r\n`F` is for MFU, `R` for MRU, and `O` is used for \"other\" if necessary (not present in this example). \r\n\r\n`arc_summary3.py` was developed for Python 3.5. This follows the version of Python currently installed in Ubuntu 16.04 LTS. Few systems will have Python 3.6 installed yet.\r\n\r\n### Known issues\r\n\r\nThe new script is based on the same internal logic as the original, so any error or issue present there will probably show up here as well. For instance, the number of anonymous hits can be negative the way it is calculated in both scripts; they both simply hide any negative value.\r\n\r\nThis script will probably make a bunch of test suites unhappy where Python 3 is not included. There is no experience with this script under extreme conditions (for example ARC throttling).\r\n\r\n### How Has This Been Tested?\r\n\r\nThere is a unittest script `test_arc_summary3.py` at https://gist.github.com/scotws/aaf5d9c9317081e249b664a371ec4907\r\nMost testing was done in-tree, comparing the output to that of the current `arc_summary.py` version.\r\n\r\nThe L2ARC section has **not seen any real-world use** because I do not have access to a L2ARC device on my machine.\r\n\r\n### Other \r\n\r\nSwitching to Python 3 results in a noticeably smaller file size despite the addition of several new features. Output of `wc` for both scripts:\r\n```\r\n    837    2586   28021 arc_summary3.py\r\n   1020    2593   35538 arc_summary.py\r\n```\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [ ] I have read the **CONTRIBUTING** document.\r\n- [x] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "Blub": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6865", "title": "user namespace bugfixes and features", "body": "This series can be seen as 4 separate \"chunks\":\r\n\r\nChunk 1: setgid mode bugfix & regression test:\r\n* Patch 1 fixes the main issue.\r\n* Patch 2 adds a helper for running user namespace tests. Currently uses a fixed\r\n  user id range. (I saw no reason for anything more complex than that.)\r\n* Patch 3 adds a regression test for the issue fixed in patch 1.\r\n\r\nChunk 2: mounting from user namespaces (RFC):\r\n* Patch 4 is an RFC useful for when a user can have a mount namespace (usually\r\n  in combination with user namespaces. Eg. giving `zfs allow`ing create+mount\r\n  permissions to a container.\r\n* Patch 5 is necessary when including the third chunk but is otherwise there\r\n  since it made writing the test case of patch 6 more convenient.\r\n* Patch 6 tests create+mount permissions with user namespaces.\r\n\r\nChunk 3: mapping user ids when using zfs allow from within user namespaces.\r\n* Patch 7 causes `ZFS_IOC_GET_FSACL` and `ZFS_IOC_SET_FSACL` to perform user id\r\n  mapping (as well as checking!) on the sent/received data. Otherwise root in a\r\n  user namespace would not be able to run `zfs allow` with the user IDs as seen\r\n  from within its namespace, but would have to perform the mapping to real IDs.\r\n  This is also what easily enables users to create allow entries for user IDs\r\n  which do not exist in the host namespace's `/etc/passwd` and therefore would\r\n  show up empty and indistinguishable to the host (making patch 5 a\r\n  requirement).\r\n\r\nChunk 4: change the 'unallow' check:\r\n* Patch 8 allows users who have CAP_SYS_ADMIN in the current namespace (iow.\r\n  root in containers) to remove permissions of others if they're also allowed\r\n  to add the permission.\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements. (at least according to `make checkstyle`)\r\n- [ ] I have updated the documentation accordingly. (not yet)\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [x] I have added tests to cover my changes.\r\n- [x] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ironMann": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6568", "title": "[wip][test] Prefetch dmu", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\nRun testers\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [ ] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [ ] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6107", "title": "LOCK tracking: disable tracking of ARC and dbuf hashmap locks (16384 mutexes)", "body": "Test for zfsonlinux/spl#587\r\n\r\nRequires-spl: refs/pull/587/head\r\n\r\n### Description\r\nDisable tracking of per-bucket locks.\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [ ] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "MEMBER"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "don-brady": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6558", "title": "OpenZFS 7431 - ZFS Channel Programs", "body": "Authored by: Chris Williamson <chris.williamson@delphix.com>\r\nReviewed by: Matthew Ahrens <mahrens@delphix.com>\r\nReviewed by: George Wilson <george.wilson@delphix.com>\r\nReviewed by: John Kennedy <john.kennedy@delphix.com>\r\nReviewed by: Dan Kimmel <dan.kimmel@delphix.com>\r\nApproved by: Garrett D'Amore <garrett@damore.org>\r\nPorted-by: Don Brady <don.brady@delphix.com>\r\nPorted-by: John Kennedy <john.kennedy@delphix.com>\r\n\r\nOpenZFS-issue: https://www.illumos.org/issues/7431\r\nOpenZFS-commit: https://github.com/openzfs/openzfs/commit/dfc11533\r\n\r\nPorting Notes:\r\n* The CLI long option arguments for '-t' and '-m' don't parse on linux\r\n* Switched from kmem_alloc to vmem_alloc in zcp_lua_alloc\r\n* Lua implementation is built as its own module (zlua.ko)\r\n* Lua headers consumed directly by zfs code moved to 'include/sys/lua/'\r\n* There is no native setjmp/longjump available in stock Linux kernel.  Brought over implementation from illumos and FreeBSD\r\n* The get_temporary_prop() was adapted due to VFS platform differences\r\n* Use of in-lining functions in lua parser code to reduce stack usage per nested C call\r\n\r\n### How Has This Been Tested?\r\n#### Manual tests\r\n- running basic get-props channel programs from CLI\r\n- exercised the zfs property get CLI with the envr *ZFS_PROP_DEBUG=1* set\r\n#### Automated tests\r\n- ztest runs that exercise the new ZCP destroy snapshots path\r\n- new ZTS channel_program functional tests\r\n\r\n### Types of changes\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [x] I have added tests to cover my changes.\r\n- [x] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "MEMBER"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "dong-liuliu": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6546", "title": "Use Multi-buffer sha256 support from SPL", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\nLet sha256 checksum using multi-buffer api if it is exported by SPL\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n Using multi-buffer type, performance of sha256 will be increased 2~7 times.\r\nNow a patch for multi-buffer sha256 facility in kernel space is implemented and submitted to SPL.\r\nIts userspace facility and sha512 parts will be following up after this patch is reviewed and commented.\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\nRun FIO sequential write test, on Intel Xeon server (Haswell E5-2699 v3, 18 core), with 6x SSD :\r\n\r\nSha256 | CPU-sys% | BW(MB/s)\r\n-- | -- | --\r\nmulti-buffer version | 27 | 1859\r\nicp version | 71 | 1876\r\n\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [x] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ahrens": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6536", "title": "diff and bookmark enhancements", "body": "\r\n<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\nThis PR includes 3 related features that work well together:\r\n\r\n`zfs diff -a` shows which specific blocks were modified\r\n\r\n`zfs diff` from a bookmark (but it can't show renamed files)\r\n\r\n`zfs bookmark` from a filesystem, creating a bookmark which represents current point in time.  Not useful for `zfs send`, but can be used with `zfs diff`.\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\nThis makes `zfs diff` useful in more situations.  For example, to find which blocks in a database or VDI file were changed.\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n\r\nManual testing only at this point.  I'd like to add test cases to the test suite, but there aren't any tests for \"zfs diff\" at all, so it seems strange to add tests for just the new functionality I'm adding.  I'm open to input on what should be required for this PR.\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [x] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ofaaland": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6479", "title": "Merge SPL into ZFS [WIP]", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\nMerge the SPL into ZFS to eliminate the extra work required when SPL code must change due to kernel or distro changes, and to simplify the build process.\r\n\r\nWork In Progress.\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [x] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [ ] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "Nasf-Fan": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6290", "title": "Project Quota on ZFS", "body": "Project quota is a new ZFS system space/object usage accounting\r\nand enforcement mechanism. Similar as user/group quota, project\r\nquota is another dimension of system quota. It bases on the new\r\nobject attribute - project ID.\r\n\r\nProject ID is a numerical value to indicate to which project an\r\nobject belongs. An object only can belong to one project though\r\nyou (the object owner or privileged user) can change the object\r\nproject ID that can be set/modified via 'chattr -p' explicitly,\r\nor inherited from its parent object when created if such parent\r\nhas the project inherit flag (via 'chattr +P').\r\n\r\nBy accounting the spaces/objects belong to the same project, we\r\ncan know how many spaces/objects used by the project. And if we\r\nset the upper limit then we can control the spaces/objects that\r\nare consumed by such project. It is useful when multiple groups\r\nand users cooperate for the same project, or when an user/group\r\nneeds to participate in multiple projects.\r\n\r\nSupport the following commands and functionalities:\r\n\r\nzfs set projectquota@project\r\nzfs set projectobjquota@project\r\n\r\nzfs get projectquota@project\r\nzfs get projectobjquota@project\r\nzfs get projectused@project\r\nzfs get projectobjused@project\r\n\r\nzfs projectspace\r\n\r\nzfs allow projectquota\r\nzfs allow projectobjquota\r\nzfs allow projectused\r\nzfs allow projectobjused\r\n\r\nzfs unallow projectquota\r\nzfs unallow projectobjquota\r\nzfs unallow projectused\r\nzfs unallow projectobjused\r\n\r\nchattr +/-P\r\nchattr -p project_id\r\nlsattr -p\r\n\r\nSigned-off-by: Fan Yong <fan.yong@intel.com>\r\nChange-Id: Ib4f0544602e03fb61fd46a849d7ba51a6005693c\r\n\r\n<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [x] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "tuxoko": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6277", "title": "[WIP] Add pool prop `partition` to disable auto partition", "body": "### Description\r\n\r\nzfsonlinux always partition disk when it detects the device given is a\r\nwhole disk. This legacy behavior from Illumos, however, has no apparent\r\nbenefit on Linux, but has some down sides besides confusion. E.g.\r\nautoexpand, switching to dm device requires partprobe.\r\n\r\nWe add a pool property `partition` to be set during pool create. It\r\ncurrently has two values, legacy and raw. When setting it to legacy, it\r\nwill behave as it did. When setiing it to raw, it will always use the\r\ndevice as is without partitioning even if it's a whole disk.\r\n\r\nThis property applies to all commands that add disks to pool, so zpool\r\nadd/attach/replace will partition or not partition based on the property\r\non the target pool.\r\n    \r\nA pool without this property will be treated as legacy. Newly created\r\npool will by default have partition=legacy.\r\n\r\nSigned-off-by: Chunwei Chen <david.chen@osnexus.com>\r\n\r\n### Note\r\n\r\nI use PROP_ONETIME for the property, but it seems that this is not enforced at all, so you can still modify it after the fact. But you shouldn't change it after the fact, as it would cause device name appending wrong.", "author_association": "MEMBER"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "inkdot7": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6078", "title": "Metadata classes wip no accounting", "body": "Please ignore this PR.\r\nI just want to see how the metadata allocation classes behave if the special accounting is removed.  (Which would allow the small-block-size limit to be changed after creation more easily.)\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "n1kl": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/5929", "title": "Quality of service for ZFS + improvement through compression", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\nAs part of my master thesis at University of Hamburg I have targeted to improve ZFS through compression. Now I would like to share my 3 feature branches with the community.\r\n\r\n1. lz4fast #5927 \r\n2. autocompression #5928 \r\n3. qos (current)\r\n### Description\r\n<!--- Describe your changes in detail -->\r\nThis patch adds quality of service to ZFS datasets.\r\nzfs set compression=qos-[10,20,30,40,50,+50*n,1000]\r\nThe chosen value sets the throughput in MB/s.\r\nLow values will result in better compression ratio but less throughput.\r\n\r\n### Motivation1\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\nQuality of service is an important aspect in dealing with limited resources.\r\nAt the moment the user can control storage requirement by choosing a compression algorithm like gzip for high compression. Depending on the hardware and the current CPU load the performance might be either poor or well.\r\nBy using the qos compression feature the desired write throughput can be chosen to meet the requirement for the application.\r\nThe qos algorithm keeps track of the compression speed and chooses either lz4 or gzip-[1-9] to speed up / slow down while compressing data. \r\n\r\n<!--- ### How Has This Been Tested? -->\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n### Benchmark1\r\n\r\nCopy file from Tempfs to ZFS into 1 Dataset:\r\n\r\nName | MB/s\t| Ratio\r\n ---   \t|  --- \t| ---\r\ngzip9\t| 11\t| 0.37\r\nqos10\t| 10\t| 0.38\r\nqos20\t| 22\t| 0.41\r\nqos30\t| 35\t| 0.45\r\nqos40\t| 45\t| 0.48\r\nqos50\t| 55\t| 0.50\r\nlz4\t| 71\t| 0.57\r\noff\t| 62\t| 1\r\n\r\n\r\n### Motivation2\r\n\r\nTransactiongroups in ZFS cause simultaneous writes into multiple datasets to wait for each other to complete. The slowest dataset is the limitation to the overall performance.\r\nThe qos feature can prevent this through dataset prioritisation.\r\nThe maximum bandwidth is limited by the disk throughput. Every dataset can request a part of this bandwidth by setting the qos property value.\r\nData can now be organised into low priority datasets with low quality of service requirements (but high compression, see Motivation1) and high priority to which also all non qos datasets belong.\r\nAll inheriting datasets and their parent share the same requested bandwidth. If the value of an inheriting dataset (lower hierarchy) is explicitly changed from \"inherit\" to \"qos\" then this dataset will request its own bandwidth.\r\n\r\n\r\n### Benchmark2\r\n\r\nCopy 2 files from Tempfs to ZFS into 2 Datasets:\r\n\r\nName     \t\t\t|MB/s\t|MB/s\t|Ratio\t|Ratio\t| Comment\r\n--- | --- | --- | --- | --- | ---\r\nqos10/qos10 - qos10/qos10_2\t|5\t|5\t|0.47\t|0.49\t|use of inheritance\r\nqos10 - qos10/qos10\t\t|5\t|5\t|0.49\t|0.47\t|use of inheritance\r\nqos10 - qos10_2\t\t\t|11\t|10\t|0.46\t|0.48\t| \r\nqos10/qos10 - qos10/qos10x\t|11\t|9\t|0.48\t|0.46\t|qos-10 explicit <br>set on qos10x\r\nqos10/qos20 - qos10\t\t|20\t|9\t|0.49\t|0.43\t| \r\nqos30 - qos10\t\t\t|29\t|9\t|0.52\t|0.40\t| \r\nqos40 - qos10\t\t\t|44\t|10\t|0.54\t|0.40\t| \r\nqos50 - qos10\t\t\t|51\t|9\t|0.53\t|0.40\t| \r\nlz4 - qos10\t\t\t|71\t|9\t|0.57\t|0.39\t| lz4 has high priority\r\noff - qos10\t\t\t|62\t|8\t|1\t|0.38\t| \r\ngzip9 - qos10\t\t\t|13\t|5\t|0.37\t|0.39\t| \r\nlz4 - gzip9\t\t\t|10\t|10\t|0.57\t|0.37\t|  lz4 waiting for gzip\r\n\r\n\r\n### Benchmark3\r\n\r\nCopy 2 files from Tempfs to ZFS into 1 Datasets:\r\n\r\nName     \t\t\t|MB/s\t|MB/s\t|Ratio\r\n--- | --- | --- | --- \r\nqos10 - qos10 |\t5\t|5|\t0,38\r\noff - off|\t22|\t22|\t1\r\nlz4 - lz4|\t30|\t27|\t0,57\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n\r\n#### Branch overlapping changes (feature, compress values)\r\nThe patch has read-only backward compatibility by using the new introduced SPA_FEATURE_COMPRESS_QOS feature. The feature activation procedure is equivalent to my other code branches.\r\nRegarding the limited namespace of BP_GET_COMPRESS() (128 values), the\r\nzio_compress enum's first part is for block pointer & dataset values, the second part for dataset values only. Or should I make use of a new property? This is an alternative suggestion to #3908.\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/5928", "title": "auto compression", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\nAs part of my master thesis at University of Hamburg I have targeted to improve ZFS through compression. Now I would like to share my 3 feature branches with the community.\r\n\r\n1. lz4fast #5927 \r\n2. autocompression (current)\r\n3. qos #5929 \r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\nThis patch adds auto as ZFS compression type.\r\nzfs set compression=auto\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\nWhich compression algorithm is best for high throughput? The answer to this depends on the type of hardware in use.\r\nIf compression takes long then the disk remains idle. If compression is faster than the writing speed of the disk then the CPU remains idle as compression and writing to the disk happens in parallel.\r\nAuto compression tries to keep both as busy as possible.\r\nThe disk load is observed through the vdev queue. If the queue is empty a fast compression algorithm like lz4 with low compression rates is used and if the queue is full then gzip-[1-9] can require more CPU time for higher compression rates.\r\nThe already existing zio_dva_throttle might conflict with the concept described above. Therefore it is recommended to deactivate zio_dva_throttle.\r\n\r\n<!--- ### How Has This Been Tested? -->\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n### Benchmark\r\n\r\nCopy file from Tempfs to ZFS\r\n\r\n\r\n8 Cores:\r\n\r\nName\t|Ratio\t|MB/s\r\n---\t|---\t|---\r\nauto\t|0.44  \t|245\r\ngzip-1\t|0.43  \t|255\r\nlz4\t|0.58  \t|195\r\noff\t|1 \t|99\r\n\r\n\r\n1 Core:\r\n\r\nName\t|Ratio\t|MB/s\r\n---\t|---\t|---\r\nauto\t|0.56 \t|151\r\ngzip-1\t|0.43\t|51\r\nlz4\t|0.58\t|179\r\noff\t|1\t|99\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n\r\n#### Branch overlapping changes (feature, compress values)\r\n\r\nThe patch is has read-only backward compatibility by using the new introduced SPA_FEATURE_COMPRESS_AUTO feature. The feature activation procedure is equivalent to my other code branches.\r\nRegarding the limited namespace of BP_GET_COMPRESS() (128 values), the\r\nzio_compress enum's first part is for block pointer & dataset values, the second part for dataset values only. This is an alternative suggestion to #3908.\r\n\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/5927", "title": "lz4fast compression", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\nAs part of my master thesis at University of Hamburg I have targeted to improve ZFS through compression. Now I would like to share my 3 feature branches with the community.\r\n\r\n1. lz4fast (current)\r\n2. autocompression #5928 \r\n3. qos #5929 \r\n\r\nThis patch updates the lz4 *1 code to version 1.7.3 to make use of lz4 fast compression.\r\nThe lz4 code is based on a seperate project for updating lz4 inside the linux kernel.\r\nThere a few changes were made for an clean implementation and to improve speed that are currently in review *2.\r\n\r\n*1: [https://github.com/lz4/lz4](https://github.com/lz4/lz4)\r\n*2: [https://patchwork.kernel.org/patch/9574745/](https://patchwork.kernel.org/patch/9574745/)\r\n\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\nLZ4-fast capability is now available.\r\nzfs set compression=lz4fast-[1-20,30,+10*n,100]\r\nHigher values result in improved compression speed and less ratio.\r\n\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\nLz4 fast trades in compression ratio for speed. This gives us more flexibility in environments with either low computational power or fast and many SSDs/HDDs where the lz4 is the limiting factor.\r\nAutocompression and qos can also be improved by adding lz4fast algorithms.\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\nChecksums were made to proof full compatibility between the old and new lz4 compressed files.\r\n\r\n#### Benchmark\r\n\r\nCopy file from Tempfs to ZFS (ZFS also in Tempfs for high disk throughput simulation).\r\n\r\n\r\nName         |Ratio   |MB/s\r\n---          |---     |---\r\nlz4          |0.58    |228\r\nlz4fast-2    |0.62    |249\r\nlz4fast-3    |0.65    |266\r\nlz4fast-4    |0.68    |282\r\nlz4fast-5    |0.71    |298\r\nlz4fast-7    |0.76    |329\r\nlz4fast-10   |0.80    |370\r\nlz4fast-20   |0.97    |469\r\nlz4fast-30   |0.98    |546\r\nlz4fast-50   |0.98    |634\r\nlz4fast-100  |0.99    |690\r\noff          |1       |744\r\n\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n\r\n#### Branch overlapping changes (feature, compress values)\r\n\r\nThe patch has read-only backward compatibility by using the new SPA_FEATURE_LZ4FAST_COMPRESS feature. The feature activation procedure is equivalent to my other code branches.\r\nRegarding the limited namespace of BP_GET_COMPRESS() (128 values), the\r\nzio_compress enum's first part is for block pointer & dataset values, the second part for dataset values only. Or should I make use of a new property? This is an alternative suggestion to #3908.\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ghost": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1276681", "body": "Has this issue been resolved? I'm having the same problem on OpenSolaris with ZFS. The zpool-rpool process is writing on average at 400MB/h on an idle system. I can't seem to find an answer anywhere on the net.\n\nThanks for your help.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1276681/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1277385", "body": "A quick DTrace on what the zpool-rpool process is doing reveals the following kernel function calls, accompanied by the number of times they have been called (the sampling lasted about a minute). Does this mean anything to you?\n\n``` DTrace\nrootnex`rootnex_coredma_allochdl          1\nrootnex`rootnex_dma_allochdl            1\nscsi`scsi_transport                     1\nzfs`buf_hash                            1\nzfs`arc_write_done                      1\nzfs`dbuf_find                           1\nzfs`dbuf_dirty                          1\nzfs`metaslab_ndf_alloc                  1\nzfs`spa_writeable                       1\nzfs`space_map_load                      1\nzfs`vdev_queue_deadline_compare          1\nzfs`vdev_queue_offset_compare           1\nzfs`vdev_queue_io                       1\nzfs`zio_buf_free                        1\nzfs`zio_remove_child                    1\nzfs`zio_destroy                         1\nzfs`zio_vdev_io_done                    1\nzfs`zrl_add                             1\nahci`ahci_check_ctl_handle              1\nsata`sata_scsi_start                    1\nsata`sata_txlt_write                    1\nsd`sdstrategy                           1\nsd`sd_core_iostart                      1\nsd`sd_initpkt_for_buf                   1\nsd`sd_start_cmds                        1\nunix`sep_save                           1\nunix`splr                               1\nunix`tsc_gethrtime                      1\nunix`tsc_scalehrtime                    1\nunix`bcopy                              1\nunix`gdt_update_usegd                   1\nunix`lock_set                           1\nunix`cmt_balance                        1\nunix`swtch                              1\nunix`disp_ratify                        1\nunix`default_lock_backoff               1\nunix`lock_set_spin                      1\ngenunix`avl_walk                        1\ngenunix`avl_rotation                    1\ngenunix`cv_broadcast                    1\ngenunix`ddi_fm_acc_err_get              1\ngenunix`disp_lock_enter                 1\ngenunix`thread_lock                     1\ngenunix`ldi_strategy                    1\ngenunix`copy_pattern                    1\ngenunix`kmem_zalloc                     1\ngenunix`list_create                     1\ngenunix`list_remove                     1\ngenunix`ddi_get_soft_state              1\ngenunix`restorectx                      1\nzfs`buf_hash_insert                     2\nzfs`dnode_diduse_space                  2\nzfs`zio_push_transform                  2\nzfs`zio_walk_parents                    2\nzfs`zio_done                            2\nzfs`zio_checksum_compute                2\nzfs`vdev_disk_io_start                  2\nsha2`SHA256TransformBlocks              2\nsd`sd_mapblockaddr_iostart              2\nsd`sd_add_buf_to_waitq                  2\nsd`ddi_xbuf_qstrategy                   2\nsd`xbuf_iostart                         2\nunix`rw_enter                           2\nunix`disp                               2\nunix`atomic_add_64_nv                   2\ngenunix`avl_remove                      2\ngenunix`avl_numnodes                    2\ngenunix`lbolt_event_driven              2\ngenunix`ddi_fm_dma_err_get              2\ngenunix`kmem_cache_free                 2\ngenunix`memcpy                          2\ngenunix`cpu_update_pct                  2\ngenunix`ndi_fmc_insert                  2\ngenunix`taskq_thread_wait               2\nzfs`arc_write_ready                     3\nzfs`metaslab_alloc_dva                  3\nzfs`vdev_accessible                     3\nzfs`zio_wait_for_children               3\nzfs`zio_notify_parent                   3\nzfs`zio_vdev_io_start                   3\nsd`sd_setup_rw_pkt                      3\nunix`mutex_owner_running                3\nunix`rw_exit                            3\nunix`mutex_vector_enter                 3\nunix`vsnprintf                          3\ngenunix`avl_last                        3\nzfs`space_map_remove                    4\nzfs`zio_execute                         4\nsd`sdinfo                               4\nunix`mutex_exit                         4\nzfs`metaslab_group_alloc                5\nzfs`vdev_queue_io_to_issue              5\nunix`bzero                              5\nunix`disp_getwork                       5\ngenunix`avl_insert                      5\nunix`0xfffffffffb85                     6\nunix`tsc_read                           6\ngenunix`kmem_cache_alloc                6\nunix`do_splx                            7\nzfs`space_map_seg_compare               9\nzfs`metaslab_segsize_compare           10\ngenunix`avl_find                       10\nunix`default_lock_delay                11\nzfs`fletcher_4_native                  12\nunix`mutex_enter                       16\nunix`mutex_delay_default               54\nzfs`lzjb_compress                     151\n```\n\nWe can see that the most called function is by far lzjb_compress. Again, DTrace reveals that all the kernel stacks that lead to lzjb_compress pass through the function zio_write_bp_init, which I assume is the guilty function behind all these writes...\n\nDoes this all mean anything to you?\n\nEdit:  kernel stacks\n\n``` DTrace\n              zfs`zio_compress_data+0x8e\n              zfs`zio_write_bp_init+0x216\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              genunix`taskq_thread+0x248\n              unix`thread_start+0x8\n                1\n\n              zfs`zio_compress_data+0x8e\n              zfs`zio_write_bp_init+0x216\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              genunix`taskq_thread+0x248\n              unix`thread_start+0x8\n                1\n\n              zfs`zio_compress_data+0x8e\n              zfs`zio_write_bp_init+0x216\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n                2\n\n              zfs`zio_compress_data+0x8e\n              zfs`zio_write_bp_init+0x216\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              genunix`taskq_thread+0x248\n              unix`thread_start+0x8\n                5\n\n              zfs`zio_compress_data+0x8e\n              zfs`zio_write_bp_init+0x216\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              genunix`taskq_thread+0x248\n              unix`thread_start+0x8\n                6\n\n              zfs`zio_compress_data+0x8e\n              zfs`zio_write_bp_init+0x216\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              genunix`taskq_thread+0x248\n              unix`thread_start+0x8\n               13\n\n              zfs`zio_compress_data+0x8e\n              zfs`zio_write_bp_init+0x216\n              zfs`zio_execute+0x8d\n              genunix`taskq_thread+0x248\n              unix`thread_start+0x8\n               31\n```\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1277385/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1281342", "body": "Here is a list processes which called the write system call on my system, accompanied by the filenames and the total number of bytes written to the files (sampled during one minute):\n\n```\ndtrace -n 'syscall::*write:entry {@[execname, fds[arg0].fi_pathname] = sum (arg2);}'\ndtrace: description 'syscall::*write:entry ' matched 2 probes\n^C\n\n  dtrace                                              /dev/pts/1                                                        1\n  sshd                                                /devices/pseudo/clone@0:ptm                                       1\n  sshd                                                <unknown>                                                        52\n  rsfcli                                              <unknown>                                                       105\n  basename                                            <unknown>                                                       164\n  hostname                                            <unknown>                                                       304\n  syslogd                                             /devices/pseudo/sysmsg@0:sysmsg                                 320\n  awk                                                 <unknown>                                                       331\n  zfs                                                 /devices/pseudo/mm@0:null                                       370\n  java                                                /var/opt/nest/config/site/scheduledjobs/emailnotifications/Notification_ERROR.xml              433\n  java                                                /var/opt/nest/config/site/scheduledjobs/emailnotifications/Notification_WARNING.xml              437\n  java                                                /var/opt/nest/config/site/scheduledjobs/configurationreplications/SiteConfigReplication.xml              511\n  grep                                                <unknown>                                                       725\n  cron                                                /var/cron/log                                                   976\n  java                                                /var/opt/nest/config/site/scheduledjobs/snapshots/Snapshot2290924711711069275.xml             1014\n  java                                                /var/opt/nest/config/site/scheduledjobs/snapshots/Snapshot12337134254217831034.xml             1020\n  java                                                /var/opt/nest/config/site/scheduledjobs/snapshots/Snapshot17476938304947820872.xml             1020\n  java                                                /var/opt/nest/config/site/scheduledjobs/asyncreplications/AsyncReplication13100962750907134551.xml             1056\n  java                                                /var/opt/nest/config/site/scheduledjobs/asyncreplications/AsyncReplication13881922923541859328.xml             1056\n  ksh                                                 <unknown>                                                      1096\n  fcinfo                                              <unknown>                                                      1152\n  zpool                                               <unknown>                                                      1452\n  ksh                                                 /tmp/sf0l.2ol                                                  1650\n  ksh                                                 /tmp/sf0p.gnd                                                  1650\n  ksh                                                 /tmp/sf10.jmu                                                  1650\n  ksh                                                 /tmp/sf1g.3nv                                                  1650\n  ksh                                                 /tmp/sf1i.jvb                                                  1650\n  ksh                                                 /tmp/sf24.5eq                                                  1650\n  ksh                                                 /tmp/sf2f.jop                                                  1650\n  ksh                                                 /tmp/sf3b.beh                                                  1650\n  ksh                                                 /tmp/sf10.ujs                                                  3000\n  ksh                                                 /tmp/sf19.9c4                                                  3000\n  ksh                                                 /tmp/sf2a.o3i                                                  3000\n  ksh                                                 /tmp/sf2p.8d0                                                  3000\n  ksh                                                 /tmp/sf3k.j08                                                  3000\n  svcprop                                             <unknown>                                                      3140\n  format                                              <unknown>                                                      3644\n  sed                                                 <unknown>                                                      3704\n  fmd                                                 /var/fm/fmd/infolog_hival                                      4480\n  nscd                                                <unknown>                                                      5268\n  zfs                                                 <unknown>                                                      5778\n  init                                                /etc/svc/volatile/init-next.state                              9064\n  iostat                                              <unknown>                                                      9102\n  svccfg                                              <unknown>                                                      9801\n  fmtopo                                              <unknown>                                                    429332\n```\n\nIn contrast, for the same duration, here is the list of actual disk writes that were initiated, again accompanied by the filenames and number of bytes.\n\n```\ndtrace -n 'io:::start /args[0]->b_flags & B_WRITE/ {@[execname, args[2]->fi_pathname]=sum(args[0]->b_bcount);}'\ndtrace: description 'io:::start ' matched 6 probes\n^C\n\n  sched                                               /var/opt/nest/config/site/scheduledjobs/configurationreplications/SiteConfigReplication.xml             4096\n  sched                                               /var/opt/nest/config/site/scheduledjobs/emailnotifications/Notification_ERROR.xml             4096\n  sched                                               /var/opt/nest/config/site/scheduledjobs/emailnotifications/Notification_WARNING.xml             4096\n  sched                                               /var/opt/nest/config/site/scheduledjobs/asyncreplications/AsyncReplication13100962750907134551.xml             8192\n  sched                                               /var/opt/nest/config/site/scheduledjobs/asyncreplications/AsyncReplication13881922923541859328.xml             8192\n  sched                                               /var/opt/nest/config/site/scheduledjobs/snapshots/Snapshot12337134254217831034.xml             8192\n  sched                                               /var/opt/nest/config/site/scheduledjobs/snapshots/Snapshot17476938304947820872.xml             8192\n  sched                                               /var/opt/nest/config/site/scheduledjobs/snapshots/Snapshot2290924711711069275.xml             8192\n  zpool-rpool                                         <none>                                                     10463232\n```\n\nThe total number of bytes written to the disk by zpool-rpool alone is much higher than the total of bytes for which the write system call was used. Doesn't that mean that zpool-rpool is acting on its own?\n\nEdit: The two dtrace commands were run in parallel.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1281342/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1283961", "body": "Hmmm it's too bad there isn't a moderately easy way of knowing where all this I/O activity comes from. I tried disabling fmtopo (which is the biggest write-system-call writer) and still, zpool-rpool's io activity didn't seem to lower as significantly as it should have.\n\nAnyway, thanks for your input. I'll post if I find a solution to this on my side.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1283961/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/7731553", "body": "hmm. why not to do it in that way: let O_DIRECT always return true? does it metter that ZFS copies everything in to the ARC cache? let fake a bit an OS. It shouldn't hurt so much.... oh, and that is just my freak idea\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/7731553/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1873708", "body": "Hi - Not sure what's going on here as I don't know much regarding the programming/debugging of zfs but I seems to experience that issue, that is with or without rsync. I never had to read much files on my system as I use zfs for backups storage, however I just had to restore things from the zfs pool and it crashed after a while.. rebooted.. crashed after a while..\n\nHere is the error I found in dmesg/syslog : http://pastebin.com/jMTCNEFy\n\nIf there is anything I can do to help, as far as testings, don't hesitate to let me know.\n\nThanks,\n\nedit: using git from 2011-08-22 on debian squeeze\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1873708/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/2064709", "body": "Alphalead : I think your trick allowed my rsync session to last longer but after a while it crashed again unfortunately\n\nMessage from syslogd@stor01 at Sep 11 12:18:11 ...\n kernel:[1714241.981661] Oops: 0002 [#1] SMP\n\nMessage from syslogd@stor01 at Sep 11 12:18:11 ...\n kernel:[1714241.981673] last sysfs file: /sys/module/mbcache/initstate\n\nMessage from syslogd@stor01 at Sep 11 12:18:11 ...\n kernel:[1714241.982056] Stack:\n\nMessage from syslogd@stor01 at Sep 11 12:18:11 ...\n kernel:[1714241.982133] Call Trace:\n\nMessage from syslogd@stor01 at Sep 11 12:18:11 ...\n kernel:[1714241.982206] Code: 49 8b 14 04 48 c1 e2 03 e8 83 88 ff ff 85 c0 75 10 48 8d 54 24 70 48 89 de 44 89 ef e8 5b f3 ff ff 48 8b 54 24 50 be d0 00 00 00 <48> c7 02 00 00 00 00 48 8b 54 24 48 48 8b 7c 24 70 e8 7d f6 ff\n\nMessage from syslogd@stor01 at Sep 11 12:18:11 ...\n kernel:[1714241.982346] CR2: 0000000000000000\n\nedit: version used is latest commit (2708f716c0)\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/2064709/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/2006354", "body": "I can confirm that his bug does **not exist** in zfs-fuse for linux. \n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/2006354/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/2352510", "body": "Gunnar Beutner was able to come up with a patch for this. I tested it on my development device and so far it works exactly as intended. We're doing some more testing later this week; at this point I would consider this ready for official evaluation so that it can be committed and this bug closed. I will post back here if we encounter any problems while we are testing this patch.\n\nhttps://gunnar-beutner.de/files/0001-Fixed-invalid-resource-re-use-in-file_find.patch\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/2352510/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/2811567", "body": "zfs-fuse:\n\n<pre>\ndd if=/dev/zero of=/tank/xxx/test.io bs=1024k count=1000\n1000+0 records in\n1000+0 records out\n1048576000 bytes (1.0 GB) copied, 8.48609 s, 124 MB/s\n</pre>\n\nubuntu-zfs:\n\n<pre>\ndd if=/dev/zero of=/tank/xxx/test.io bs=1024k count=1000\n1000+0 records in\n1000+0 records out\n1048576000 bytes (1.0 GB) copied, 114.533 s, 9.2 MB/s\n</pre>\n\nOk, i try recreate pool under ubuntu-zfs\n\n<pre>\n# zpool offline tank sdc\n# zpool detach tank sdc\n# zpool create -f test sdc\n# zpool status test\n  pool: test\n state: ONLINE\n scan: none requested\nconfig:\n\n        NAME        STATE     READ WRITE CKSUM\n        test        ONLINE       0     0     0\n          sdc       ONLINE       0     0     0\n\nerrors: No known data errors\n# zfs create test/xxx\n# dd if=/dev/zero of=/test/xxx/test.io bs=1024k count=1000\n1000+0 records in\n1000+0 records out\n1048576000 bytes (1.0 GB) copied, 53.5897 s, 19.6 MB/s\n</pre>\n\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/2811567/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/3299069", "body": "behlendorf, probably, i had bad results because i was try to use 32 bit OS.\nFresh install ferdora 16 32 bit was the same, but zfs on fedora 16 (x64) shows performance near to raw device.\nThanks.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/3299069/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/11986018", "body": "Please fix this, a year later it is still not working. Rudd-O has an open pull request, can it be pulled into te main branche?\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/11986018/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/3399837", "body": "Pretty much this is how I went about setting up everything.\n\nMy platform is Ubuntu 10.04.3 x86 (also used x64) running as a VMware VM on my laptop (as test).\n\nI downloaded the source and compiled as per the instructions on the ZFS on linux website.\n\nThen I compiled the Linux iSCSI target core backports from linux-iscsi.org. I also compiled the lio-utils and targetcli (the management tools).\n\nAfter I installed the deb packages of everything (iscsi target and ZFS) I created my zpool called (tank) and my zfs vol (fish). Because it was a test I just used the names from the website because it did not matter.\n\nThe command I use were the following;\n\nparted /dev/sdb\nmklabel gpt\nquit\n\nparted /dev/sdc\nmklabel gpt\nquit\n\nzpool create tank mirror /dev/sdb /dev/sdc\n\nzfs create tank/fish -V 18G\n\nAfter that was done I dropped into the targetcli tool and tried to add a block device to the /backstores/iblock section. The targetcli emulates a file system, kind of reminds me of /proc or /sys. When I execute the command \"create disk0 /dev/zd0\" it returns and error to me saying the chosen device is not a valid \"TYPE_DISK\". I am not sure though if \"TYPE_DISK\" is something internal to the target or if it is a Linux thing.\n\nThe only way I could use ZFS with the target was to format the ZFS vol with something like ext4 and then create an image file with dd then use the file_io feature of the target. But the is not only complicated but completely undermines the entire point of using ZFS.\n\nWhen I mentioned that the ZFS vols have no vendor information I was referring to what I see when I run \"parted -l\" and look at /dev/zd0. When compared to the VMware disks there is information about who made the disk or anything, not even faked information just to fill the space. I will add an output when I have a chance.\n\nIf you need anymore info let me know.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/3399837/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/3442037", "body": "I get the code from there git repo. git://risingtidesystems.com/\n\nThe only slightly annoying thing is you have to build several packages before you can build the targetcli tool.\n\nBut everything you need is there.\n\nYou need to build the tools in an similar order to this;\n1. lio-utils\n2. configshell\n3. rtslib\n4. targetcli\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/3442037/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/3707762", "body": "I have small update to announce based on my reported issue, I may have a source of the problem.\n\nI believe the error \"Not TYPE_DISK\" is a problem with the iSCSI target drivers and may have nothing to do with ZFS.\n\nThe reason for the error I hypothoize is because ZFS is not listing it ZVOLs in /dev/disk which is most likely where the iSCSI target is look for them and that would sort of explain the error, because it is say that the ZVOL is not a type of device found is /dev/disk. \n\nSo unless something changes with the iSCSI target drivers before the \"final\" release with kernel v3.4 then ZFS just may have sit out on that one.\n\nI will \"try\" to report the issue to the devs of the iSCSI target but I have not heard anything since before Christmas when I last attempted.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/3707762/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/5439790", "body": "Experiencing the same issues with 2.6.32-41 on 10.04 (AMD X2-555 proc in an ASUS M4A88T MB, 16GB ecc).  No apparent problems with 2.6.32-40.  Sorry for lack of trace info, may have time this weekend.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/5439790/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/5441206", "body": "Correction, 12GB.  Might as well mention this:\nJust did a quick check and BIOS version was latest but release date appeared inconsistent.  So updated BIOS anyway, disabled legacy USB, and booted 2x4GB with just channel A (matched pair).  Checked dmesg and errata message is still there.   There's a sleeping zfs mount -a process (configured automount) and any zpool/zfs commands in a shell hang.  FWIW.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/5441206/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/7986088", "body": "I've installed Fedora 17 to a test System with ZFS due to @Rudd-O  \n+1 to this\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/7986088/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/20962527", "body": "Allow me to shed some light on this.\n\nLet's consider an old-school nfs4 export using a native Linux filesystem, one share called 'pmr':\n\n``` /etc/fstab\n/dev/groups/pmr /storage/pmr      xfs    inode64,logdev=/dev/ssdcache/pmr,logbufs=8  1 2\n/storage/pmr    /exports/pmr      none   rw,bind         0 0\n```\n\n``` /etc/exports\n/exports     [nfs4 export root settings]\n/exports/pmr [per-share settings]\n```\n\nWhen the system is booting, the xfs filesystem will be mounted first, followed by a bind mount from /storage/pmr to /exports/pmr. The latter then is exported via /etc/exports using nfs4 and we're all happy.\n\nNow consider a zfs-based scenario.\n\nSince there are no zfs entries in fstab, it becomes:\n\n``` /etc/fstab\n/storage/pmr    /exports/pmr      none   rw,bind         0 0\n```\n\nWhen the system boots, a bind-type mount will be created from /storage/pmr to /exports/pmr which is effectively mounting the underlying filesystem (most likely / ) to the bind point and exporting that. The clients will see the contents of an empty directory as the exporter uses the / bind mount. On the server, the confused administrator will see the actual zfs and will scratch their head.\n\nI don't think this is a bug in zfs rather a race condition between the distribution's native localfs init script and zfs. Perhaps localfs should depend on zfs and not the other way around.\n\nAlternatively, the zfs service should parse some file that will tell it how the binds go and bind after mounting the zfs filesystem. Perhaps a file in /etc/zfs/ like 'binds' would work.\n\nPersonally (sysadmin cap on) /etc/zfs/binds would work for me (together with a bit of parsing in /etc/init.d/zfs) as it's sufficiently low-tech and doesn't require changes in the actual zfs stack.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/20962527/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/20965023", "body": "Proposed patch (only lsb script, others are most likely derivative):\n\n``` patch\n--- etc/init.d/zfs.lsb.in.orig  2013-07-15 12:47:20.055257882 +0100\n+++ etc/init.d/zfs.lsb.in       2013-07-15 12:49:44.732137370 +0100\n@@ -29,6 +29,7 @@\n ZFS=\"@sbindir@/zfs\"\n ZPOOL=\"@sbindir@/zpool\"\n ZPOOL_CACHE=\"@sysconfdir@/zfs/zpool.cache\"\n+ZFS_NFS4_BINDS=\"@sysconfdir@/zfs/binds\"\n\n # Source zfs configuration.\n [ -r '/etc/default/zfs' ] &&  . /etc/default/zfs\n@@ -78,6 +79,26 @@\n                log_end_msg $?\n        fi\n\n+        # Create (optional) binds to the NFS4 export tree\n+        if [ -e \"$ZFS_NFS4_BINDS\" ] ; then\n+                log_begin_msg \"Binding NFS4 mounts\"\n+                sed -e \"s/#.*//\" -e \"/^$/d\" $ZFS_NFS4_BINDS | while read LINE\n+                do\n+                        MODE=\"`echo $LINE | awk '{print $1}'`\"\n+                        SRC=\"`echo $LINE | awk '{print $2}'`\"\n+                        DEST=\"`echo $LINE | awk '{print $3}'`\"\n+                        case $MODE in\n+                                bind)   MOUNTPOINT=\"`zfs get mountpoint $SRC | grep \"$SRC\" | awk '{print $3}'`\"\n+                                        mount -o $MODE $MOUNTPOINT $DEST\n+                                        log_end_msg $?\n+                                        ;;\n+                                *)      echo \"Unknown bind mode ($MODE) in $ZFS_NFS4_BINDS. Aborting.\"\n+                                        exit 4\n+                                        ;;\n+                        esac\n+                done\n+        fi\n+\n        touch \"$LOCKFILE\"\n }\n\n@@ -85,6 +106,25 @@\n {\n        [ ! -f \"$LOCKFILE\" ] && return 3\n\n+       if [ -e \"$ZFS_NFS4_BINDS\" ] ; then\n+                log_begin_msg \"Detaching NFS4 binds\"\n+                sed -e \"s/#.*//\" -e \"/^$/d\" $ZFS_NFS4_BINDS | while read LINE\n+                do\n+                        MODE=\"`echo $LINE | awk '{print $1}'`\"\n+                        SRC=\"`echo $LINE | awk '{print $2}'`\"\n+                        DEST=\"`echo $LINE | awk '{print $3}'`\"\n+                        case $MODE in\n+                                bind)   MOUNTPOINT=\"`zfs get mountpoint $SRC | grep \"$SRC\" | awk '{print $3}'`\"\n+                                        umount $DEST\n+                                        log_end_msg $?\n+                                        ;;\n+                                *)      echo \"Unknown bind mode ($MODE) in $ZFS_NFS4_BINDS. Aborting.\"\n+                                        exit 4\n+                                        ;;\n+                        esac\n+                done\n+        fi\n+\n        log_begin_msg \"Unmounting ZFS filesystems\"\n        \"$ZFS\" umount -a\n        log_end_msg $?\n```\n\n$MODE may look redundant but perhaps could be kept for future expansion, maybe there could be other bind types.\n\nThe /etc/zfs/binds file would look like this:\n\n``` /etc/zfs/binds\n#    zpool[/dataset]        mountpoint\nbind storage/pmr            /exports/pmr\n```\n\nOf course the distribution source would only contain the first line. I believe this is consistent with other files in /etc/zfs.\n\nCheers,\ngrok\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/20965023/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/45432317", "body": "@FransUrbo `/etc/rc.local` does not exist and is not called in all distributions. Even more, `systemd` based distributions (good luck finding one without it these days) won't have it by definition.\n\nAre you suggesting that instead of editing a config file (present, documented) you would rather ask everyone to roll their own code, manually create bind mounts? That doesn't sound like a sane systems management practice.\n\nWhen ZoL filesystem needs to be exported over NFS4, a bind mount must be created. No standard mechanism in GNU/Linux will allow for it if the filesystem is not present in `/etc/fstab`. Since it's ZFS that's 'special', I will argue that it is its own responsibility to provide the functionality required for other parts of the system to continue to function.\n\nIf you don't like my solution, that's fine, please provide a better one or show where exactly am I incorrect. Saying something is 'hackish' and then suggesting that sysadmins 'sort it out in rc.local' isn't constructive.\n\nRegards,\njz\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/45432317/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/45433327", "body": "@FransUrbo \n\nWhat use is a filesystem that cannot be exported over network?\n\nNFS4 exports are different from NFS3 exports. There is a certain, established standard of creating them in GNU/Linux, there exists a well documented process that is different from Solaris-isms still present in ZoL.\n\nI wasn't aware `zfs set sharenfs=on` is able to produce NFS4 mounts. Could you please quote options required to make that happen? How do you define the mount tree? This is different from NFS3.\n\nWhat bugs in other software are you referring to? Exporting NFS4 works perfectly fine in GNU/Linux. Since ZoL provides PV, VG and LV management as well as filesystem mount points in a way that is abstracted from the current device paradigm on Linux, certain steps need to be taken to make those two work together.\n\nWhile you are free to disagree, I still haven't seen a patch that solves the problem. GNU/Linux nfs-kernel-server (and this is ZFS on _Linux_) requires mount points bound into a central exports tree. Since binding is done early (and you can't make the `zfs` init script depend on `$localfs`) ZoL needs to catch up. \n\nNFS4 provides capabilities like idmapd (how would you propose to integrate `zfs set sharenfs` with starting `idmapd`, are there hooks for that? How do I call them?), caching, subtree checks, consistent filesystem IDs and performance improvements over NFS3.\n\nThe logical way to do it (and I have consulted this with a number of Linux Sysadmins before presenting it here) is for the init script to have a mechanism to create the required bound mounts to the exports tree. The section in the init script is self-contained, fails safe (no action if the config file isn't present) and does introduce required compatibility with the host operating system. In one file that is owned by the ZFS package.\n\nIf you continue to disagree, please produce a patch that solves the issue for NFS4 and ZoL or provide a way of exporting NFS4, including all the required export options like the following excerpt from a production environment:\n\n``` /etc/exports\n/exports     172.5.125.0/24(ro,async,wdelay,insecure,root_squash,no_subtree_check,fsid=0)\n/exports     172.5.124.0/25(ro,async,wdelay,insecure,root_squash,no_subtree_check,fsid=0)\n/exports/pmr 172.5.125.0/24(rw,async,wdelay,root_squash,no_subtree_check)\n/exports/pmr 172.5.124.0/25(rw,sync,wdelay,no_root_squash,no_subtree_check)\n```\n\nPlease understand, `rc.local` is the last resort, it isn't available on all distributions, some don't even have an equivalent script and requiring systems administrators to manually do those steps is error-prone. Perhaps one can do it on their home computer but hardly in an enterprise environment where consistency and sustainability is key.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/45433327/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/45434151", "body": "@FransUrbo \n\nThe issue #1029 you referred me to is highlighting the problem I've solved; no way to correctly set up NFS4 shares using Solaris-isms under Linux.\n\n> > Could you please quote options required to make that happen?\n> \n> I did. You need to slow down and read what's given to you.\n\nUnless you meant the four dots at the end of `zfs set sharenfs=on`, I must have missed it.\n\nI'm not going to continue this conversation with you as it's no longer productive.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/45434151/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/73043264", "body": ":+1: \n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/73043264/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/10101505", "body": "oh, how embarrassing.. adding autogen.sh to my weekly routine. Thanks!\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/10101505/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/13097318", "body": "Hey, so while apt-get update automatically chooses 3.6.0-23-virtual for the chroot , I should rather install 3.6.0-29-generic which is the same as the hosts?  Gotcha.\nJust worth noting that i've followed the HOW TO step-by-step and that a virtual kernel (different from the hosts) gets installed by default when installing ubuntu-minimal in a chroot environment.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/13097318/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/13114557", "body": "Thanks for the replies, No objections behlendorf. \nCheers\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/13114557/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/17124603", "body": "http://zfsonlinux.org/faq.html#WhyShouldIUseA64BitSystem\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/17124603/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/39197997", "body": "Some testing on SLES11 SP3 (obs build instance):\n\nThe `path_lookup()` is also triggered on SLES' 3.0.101 kernel so it looks like a proper autoconf check is required.\n\n@Milan-Benes:\n\nSince `spl_kern_path_parent` macro can expand to either `path_lookup(path, LOOKUP_PARENT, nd)`, `kern_path_parent_fn(path, nd)` or `kern_path_parent(path, nd)`, a _quick and very, very dirty_ fix would be to manually patch and build if you're desperate for the functionality. \n\nNote that the `kern_` functions use 2 arguments and not 3 so (I'm going to hell for this!) the middle one needs to go.\n\nSo after applying https://github.com/zfsonlinux/zfs/pull/1655 to 0.6.2 you can try something like this:\n\n``` patch\n--- module/zfs/zfs_ctldir.c.orig        2014-04-01 12:48:37.756605773 +0100\n+++ module/zfs/zfs_ctldir.c     2014-04-01 12:50:58.674195921 +0100\n@@ -997,8 +997,8 @@\n                goto out_path_buff;\n        }\n\n-       error = path_lookup(path_buff, LOOKUP_FOLLOW | LOOKUP_DIRECTORY, &nd);\n-       if (!error)\n+       error = kern_path_parent(path_buff, &nd);\n+       if (!error)\n                path_put(&nd.path);\n\n out_path_buff:\n```\n\nIt builds but **be warned**, may eat your gerbil.\n\n**Edit:** \n\n```\nZFS: snapshot home/tank@auto_daily-2014-03-27-1600 auto mounted at /home/tank/.zfs/snapshot/auto_daily-2014-03-27-1600 unexpectedly unmounted\n```\n\nAnd a nice NULL pointer:\n\n```\nApr  1 13:32:24 hematus kernel: [   83.305579] ZFS: snapshot home/tank@auto_daily-2014-03-27-1600 auto mounted at /home/tank/.zfs/snapshot/auto_daily-2014-03-27-1600 unexpectedly unmounted\nApr  1 13:35:00 hematus kernel: [  239.301971] BUG: unable to handle kernel NULL pointer dereference at 0000000000000020\nApr  1 13:35:00 hematus kernel: [  239.301978] IP: [<ffffffffa065e3a6>] zfsctl_lookup_snapshot_path+0x1a6/0x2c0 [zfs]\nApr  1 13:35:00 hematus kernel: [  239.302022] PGD 0\nApr  1 13:35:00 hematus kernel: [  239.302024] Oops: 0000 [#1] SMP\nApr  1 13:35:00 hematus kernel: [  239.302027] CPU 10\nApr  1 13:35:00 hematus kernel: [  239.302028] Modules linked in: md5 nfsd autofs4 binfmt_misc edd nfs lockd fscache auth_rpcgss nfs_acl sunrpc mpt3sas mpt2sas scsi_transport_sas raid_class mptctl mptbase bonding mperf microcode ext3 jbd mbcache loop flashcache(FN) pciehp zfs(PFN) zcommon(PFN) znvpair(PFN) zavl(PFN) zunicode(PFN) spl(FN) ipv6 ipv6_lib zlib_deflate ixgbe joydev usbhid hid igb usb_storage dca ptp dcdbas(X) pcspkr shpchp pci_hotplug sr_mod mei ses iTCO_wdt cdrom enclosure iTCO_vendor_support button wmi acpi_power_meter rtc_cmos pps_core acpi_pad sg mdio xfs dm_mirror dm_region_hash dm_log linear ehci_hcd usbcore usb_common sd_mod crc_t10dif processor thermal_sys hwmon scsi_dh_rdac scsi_dh_hp_sw scsi_dh_emc scsi_dh_alua scsi_dh dm_snapshot dm_mod ahci libahci libata megaraid_sas scsi_mod\nApr  1 13:35:00 hematus kernel: [  239.302072] Supported: No, Proprietary and Unsupported modules are loaded\nApr  1 13:35:00 hematus kernel: [  239.302074]\nApr  1 13:35:00 hematus kernel: [  239.302076] Pid: 7433, comm: nfsd Tainted: PF          NX 3.0.101-0.15-default #1 Dell Inc. PowerEdge R720/0X3D66\nApr  1 13:35:00 hematus kernel: [  239.302080] RIP: 0010:[<ffffffffa065e3a6>]  [<ffffffffa065e3a6>] zfsctl_lookup_snapshot_path+0x1a6/0x2c0 [zfs]\nApr  1 13:35:00 hematus kernel: [  239.302099] RSP: 0018:ffff8817dbee99e0  EFLAGS: 00010246\nApr  1 13:35:00 hematus kernel: [  239.302100] RAX: 0000000000000000 RBX: ffff8817f116c000 RCX: 0000000000000020\nApr  1 13:35:00 hematus kernel: [  239.302102] RDX: ffff8817f116e4c8 RSI: 0000000000001000 RDI: ffff8817dbee9ab0\nApr  1 13:35:00 hematus kernel: [  239.302104] RBP: 0000000000000da2 R08: e848000000000000 R09: 1200000000000000\nApr  1 13:35:00 hematus kernel: [  239.302106] R10: 0000000000000000 R11: ffffffff8120f630 R12: ffff8817dbee9b60\nApr  1 13:35:00 hematus kernel: [  239.302108] R13: ffff8817f116e4c8 R14: ffff8817f116c000 R15: 0000000000000006\nApr  1 13:35:00 hematus kernel: [  239.302110] FS:  0000000000000000(0000) GS:ffff88187faa0000(0000) knlGS:0000000000000000\nApr  1 13:35:00 hematus kernel: [  239.302112] CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b\nApr  1 13:35:00 hematus kernel: [  239.302114] CR2: 0000000000000020 CR3: 0000000001a09000 CR4: 00000000001407e0\nApr  1 13:35:00 hematus kernel: [  239.302116] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000\nApr  1 13:35:00 hematus kernel: [  239.302118] DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400\nApr  1 13:35:00 hematus kernel: [  239.302120] Process nfsd (pid: 7433, threadinfo ffff8817dbee8000, task ffff8817dbee6380)\nApr  1 13:35:00 hematus kernel: [  239.302122] Stack:\nApr  1 13:35:00 hematus kernel: [  239.302123]  0000000000011800 ffff8817dbee9c44 ffff88187f429a00 0000000000000da2\nApr  1 13:35:00 hematus kernel: [  239.302129]  ffff8817dbee9bd8 0000000000000004 0000000000000004 00000000000000a8\nApr  1 13:35:00 hematus kernel: [  239.302133]  00000000000000a8 ffffffff81145a8e ffff8817f420d400 ffff8817f1656800\nApr  1 13:35:00 hematus kernel: [  239.302137] Call Trace:\nApr  1 13:35:00 hematus kernel: [  239.302221]  [<ffffffffa065e52b>] zfsctl_lookup_objset+0x6b/0x90 [zfs]\nApr  1 13:35:00 hematus kernel: [  239.302284]  [<ffffffffa0672241>] zfs_vget+0xf1/0x350 [zfs]\nApr  1 13:35:00 hematus kernel: [  239.302356]  [<ffffffffa068edf1>] zpl_fh_to_dentry+0x41/0x60 [zfs]\nApr  1 13:35:00 hematus kernel: [  239.302420]  [<ffffffff811d69df>] exportfs_decode_fh+0x6f/0x290\nApr  1 13:35:00 hematus kernel: [  239.302429]  [<ffffffffa086198d>] nfsd_set_fh_dentry+0x17d/0x380 [nfsd]\nApr  1 13:35:00 hematus kernel: [  239.302440]  [<ffffffffa0861d6b>] fh_verify+0x1db/0x2b0 [nfsd]\nApr  1 13:35:00 hematus kernel: [  239.302448]  [<ffffffffa0870b41>] nfsd4_proc_compound+0x341/0x520 [nfsd]\nApr  1 13:35:00 hematus kernel: [  239.302463]  [<ffffffffa085e381>] nfsd_dispatch+0xb1/0x250 [nfsd]\nApr  1 13:35:00 hematus kernel: [  239.302474]  [<ffffffffa07826a3>] svc_process_common+0x333/0x620 [sunrpc]\nApr  1 13:35:00 hematus kernel: [  239.302488]  [<ffffffffa0782ce1>] svc_process+0x101/0x160 [sunrpc]\nApr  1 13:35:00 hematus kernel: [  239.302500]  [<ffffffffa085eb3d>] nfsd+0xcd/0x150 [nfsd]\nApr  1 13:35:00 hematus kernel: [  239.302505]  [<ffffffff81082966>] kthread+0x96/0xa0\nApr  1 13:35:00 hematus kernel: [  239.302511]  [<ffffffff81469ee4>] kernel_thread_helper+0x4/0x10\nApr  1 13:35:00 hematus kernel: [  239.302514] Code: 00 00 00 00 00 48 8b 87 c8 34 00 00 4c 8d af c8 24 00 00 48 8d bc 24 d0 00 00 00 be 00 10 00 00 4c 89 ea 48 89 84 24 d0 00 00 00\nApr  1 13:35:00 hematus kernel: <48>[  239.302527]  8b 40 20 48 89 84 24 d8 00 00 00 e8 49 fd ff ff 85 c0 0f 84\nApr  1 13:35:00 hematus kernel: [  239.302533] RIP  [<ffffffffa065e3a6>] zfsctl_lookup_snapshot_path+0x1a6/0x2c0 [zfs]\nApr  1 13:35:00 hematus kernel: [  239.302551]  RSP <ffff8817dbee99e0>\nApr  1 13:35:00 hematus kernel: [  239.302552] CR2: 0000000000000020\nApr  1 13:35:00 hematus kernel: [  239.302554] ---[ end trace c16be50e3596fc64 ]---\n```\n\nSo yeah, doesn't work just yet.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/39197997/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/39320535", "body": "@andrey-ve \n\nI grepped `/usr/src/linux/include` on a current SLES11 SP3 (and do bear in mind SuSE patches their kernels heavily so the 3.0.101 has interfaces probably similar to 3.6 vanilla) shows no 'HAVE_MOUNT_*' strings.\n\nThe only thing in the region of that was:\n\n```\n$ grep -Ri MOUNT_NODEV *\nlinux/fs.h:extern struct dentry *mount_nodev(struct file_system_type *fs_type,\n```\n\nit's defined as:\n\n``` h\nextern struct dentry *mount_nodev(struct file_system_type *fs_type,\n        int flags, void *data,\n        int (*fill_super)(struct super_block *, void *, int));\n```\n\nThere's also:\n\n``` h\n#define MNT_NODEV       0x02\n```\n\nin `linux/mount.h`.\n\nJust in case, I've put the src.rpm for the stock SLES11 SP3 kernel source at https://anorien.csc.warwick.ac.uk/kernel-source-3.0.76-0.11.1.x86_64.rpm - it will produce the /usr/src/linux used for building on SLES. \n\nHope this helps anyway, don't hesitate to ask if you need more information.\n(edit: updated rpm url)\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/39320535/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "JakeWharton": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/147018", "body": "These two lines should have four spaces before them so they are rendered like this:\n\n```\n$ ./configure\n$ make pkg\n```\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/147018/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "review_comments": []}, "rdylina": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/194382", "body": "Would it not be better to treat this somewhat like a security issue by blacklisting all known devices that are definitely not available to be used as block devices? Somehow seems safer to me.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/194382/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "review_comments": []}, "fajarnugraha": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/282697", "body": "Brian, cmd/zvol_id/Makefile.am is missing. Could you please upload it? Thanks.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/282697/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/282698", "body": "Sorry, I mean cmd/zvol_id/Makefile.in\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/282698/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/282796", "body": "Create another branch, then copy previous comments manually?\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/282796/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/283041", "body": "Copying previous note from email:\n\n<pre>\nfrom    : behlendorf <noreply@github.com>\ndate    : Fri, Feb 25, 2011 at 3:36 AM\nsubject : Re: [GitHub] Use udev to create /dev/zvol/[dataset_name] links [behlendorf/zfs feaf4b2]\n</pre>\n\n- Removed Makefile-sample, with the full integration in the build system it isn't needed.\n- Added all autogen.sh products (Makefile.in, configure) using the following versions of the utils.  Using the same versions of the tools minimizes how much change there is in the autogen products and makes it easier to review.\n  \n  autoconf (GNU Autoconf) 2.63\n  automake (GNU automake) 1.11.1\n  ltmain.sh (GNU libtool) 2.2.6b\n- Added the CDDL header to zvol_id_main.c, including correctly attributing the source.\n- Minor stray whitespace cleanup.\n- Update kmem_free() in zvol_remove_minors() to match  kmem_zalloc()'s use of MAXNAMELEN.  If we fail to do the the memory account code will flag this is a memory leak.  It's critical to ensure you alloc/free both use the same size for the buffer.\n- Add <sys/stat.h> header in zvol_id_main.c, without it my build was failing on RHEL6.\n\nhttps://github.com/behlendorf/zfs/commit/feaf4b287322d6123336f139049686114f6c6ee8#commitcomment-282533\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/283041/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "review_comments": []}, "nedbass": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/333338", "body": "Mixing tabs and spaces here\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/333338/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/333382", "body": "Done.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/333382/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/334541", "body": "Darn, missed this misaligned fi!  Oh well, I'll commit a new fix\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/334541/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/409893", "body": "Yay for killing abominable code!  Not sure if dbuf_hold_impl() is in the same call path, but \nfc5bb51f08a6c91ff9ad3559d0266eeeab0b1f61 employs the same hack to reduce its stack.\nYou may want to check if it can now be safely reverted as well.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/409893/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/413647", "body": "Opened Issue #263 to track this.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/413647/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}], "review_comments": []}, "Rudd-O": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/333340", "body": "## Fix it in your tree, pullrequest, then I will commit later on. \n\nSent from my Android phone with K-9 Mail. Please excuse my brevity.\n\nnedbass reply@reply.github.com wrote:\n\nMixing tabs and spaces here -- Reply to this email directly or view it on GitHub: https://github.com/behlendorf/zfs/commit/6583dcacdcca2aad7eaec51f31797a3533845099#commitcomment-333338\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/333340/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "review_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11071", "body": "don't hardcode the paths, please.  otherwise it will fail depending on where the utilities are installed.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11071/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11072", "body": "we sync.  we expect no unmounting to happen here since it either will fail if core file systems are mounted and have files open, or successfully unmount the file systems only to make the later initscripts crap out horribly because core file systems are not available anymore.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11072/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11073", "body": "show better status here\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11073/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11251", "body": "what should I do with these two lines?  Remove them?\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11251/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11252", "body": "should I re-add this file?\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11252/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11289", "body": "I will add this right now.\n\nEl Wednesday, March 23, 2011, behlendorf escribi\u00f3:\n\n> > @@ -1,6 +0,0 @@\n> > \n> > ## -Stub file for 'make dist' distdir rule.\n> > \n> > -This file is directly referenced by ../Makefile.am as a source\n> > -file and thus will be expected by 'make dist'.  To avoid this\n> \n> This file should be readded exactly for the reasons mentioned in the file.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11289/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11290", "body": "The file has been re-added as of commit 9549dd1 and pushed too.\n\nNow onto the next revision.\n\nEl Wednesday, March 23, 2011, behlendorf escribi\u00f3:\n\n> > @@ -1,6 +0,0 @@\n> > \n> > ## -Stub file for 'make dist' distdir rule.\n> > \n> > -This file is directly referenced by ../Makefile.am as a source\n> > -file and thus will be expected by 'make dist'.  To avoid this\n> \n> This file should be readded exactly for the reasons mentioned in the file.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11290/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11291", "body": "Commit 5469b88, just pushed, removes those by simply cherry-picking your own \ncommit on top of the merge.\n\nEl Wednesday, March 23, 2011, behlendorf escribi\u00f3:\n\n> > @@ -204,6 +204,8 @@ const struct super_operations zpl_super_operations =\n> > {\n> > \n> > ```\n> > .put_super  = zpl_put_super,\n> > .write_super    = NULL,\n> > .sync_fs    = zpl_sync_fs,\n> > ```\n> > -   .freeze_fs  = NULL,\n> \n> Yes, please remove them.  They are currently unused hooks and they cause\n> compile errors on older platforms.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11291/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11294", "body": "File removed.  Commit pushed.  Let me refresh the page to see how the merge \ndiff will look like.  You should do the same.\n\nEl Wednesday, March 23, 2011, behlendorf escribi\u00f3:\n\n> > @@ -0,0 +1,59 @@\n> > +put the dracut/90zfs directory in /usr/share/dracut/modules.d (or\n> > symlink it)\n> \n> A version of this file was already added to the dracut subdirectory.  If\n> you want to make changes/rewrite it that's fine but let's just keep one\n> copy of it around with the other dracut code.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11294/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}, "baryluk": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/383541", "body": "$ mkfs.ext3 /dev/zd0\n$ resize2fs /dev/zd0\n\nI hope you mean\n$ mkfs.ext3 /dev/tank/zd0\n$ resize2fs /dev/tank/zd0\n\nHaving full volume path as well pool name under dev is crucial to prevent conflicts. I would even like to have it under /dev/zvols/tank/zd0, to not conflict with default devices. Consider doing zpool create sda /dev/sda, zfs create -V 10g sda/sda. Horrible.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/383541/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/383556", "body": "See https://github.com/behlendorf/zfs/issues/152#issuecomment-1162158 for some more discussion.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/383556/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/383557", "body": "Probably releated to https://github.com/behlendorf/zfs/commit/4c0d8e50b99b4f3b4a9b7bc67ac7fc4e406f5755\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/383557/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/383767", "body": "Hmm. For me, more natural and more reliable will be to do this in opposite direction. Create device node in from start /dev/zvol/pool/dataset and then create symlink /dev/zd\\* (this actually can be skipped, as is in most practical cases useless beyond eventually symlinking to it from somewhere) and in /dev/disk/by-*/xxx pointing to /dev/zvol/pool/dataset. Is there any reasons or limitations of other tools (kernel, udev, sysfs?, creating DOS partitions on zvols? etc) that you want to put devices directly in the /dev/ directory? It is not necessary to put them there directly. \n\nPS. Hmm. I just checked open-iscsi, and do the same as you. First create /dev/sdX, and then symlink it into /dev/disk/by-path/ip-X.X.X.X:PP-iscsi-iqn-XYZ by udev. So you are right. IMHO it is remenescent of archaic structure of /dev/ directory. Not best possible and easy way, but looks to be standard in Linux. Neverthless /dev/zd\\* shouldn't be used anyway in such tools like fstab, mount, fdisk, fsck, mkfs.*, etc., as this names are unstable, for example doing zfs create -V 10g tank/zd1, will still create /dev/zd0 (at least if this was first volume create/mounted after reboot right?), and symlink in /dev/zvol/tank/zd1 -> ../../zd0. It is pretty confusing. This is the reason why I was somehow against it.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/383767/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "review_comments": []}, "dajhorn": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/461576", "body": "Kernel parameters are subject to decimal/octal/hexadecimal interpretation, so this example should be `spl_hostid=0x00bab10c`.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/461576/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/545339", "body": "zfsonlinux/zfs#370\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/545339/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/545340", "body": "zfsonlinux/zfs#370\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/545340/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/545341", "body": "zfsonlinux/zfs#370\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/545341/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/545343", "body": "zfsonlinux/zfs#370\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/545343/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}], "review_comments": []}, "kylef": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/511969", "body": "I didn't think about that.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/511969/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "review_comments": []}, "rlaager": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374212", "body": "What do you mean by this?\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374212/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374494", "body": "I've found this approach works best: Start from a checkout of upstream trunk. Then `git branch TOPIC; git checkout TOPIC`. Make your changes and commit. Push that branch to github. Repeat as necessary for the other features, starting from a checkout of upstream trunk each time. Then, do a pull request for each branch.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374494/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374507", "body": "The easiest solution is probably to leave your master tracking upstream master (i.e. you should not commit anything to master). Use a separate branch to combine your topic branches.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374507/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354255", "body": "domain should be 256 (255 + NUL). As a result, the other fields might need changing. I haven't looked closely.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354255/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354257", "body": "Is \"EPOH\" supposed to be \"epoch\"?\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354257/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354259", "body": "This should be checked for NUL-termination correctness.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354259/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354260", "body": "This should be checked for NUL-termination correctness.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354260/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354264", "body": "This should probably const char *.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354264/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354267", "body": "By \"EOL\", you probably meant \"NUL\"?\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354267/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354268", "body": "Like in the SMB patch, this usage of a function named file_is_executable() is really confusing.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354268/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354271", "body": "You're just blindly returning OK here. Should something be done?\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354271/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354272", "body": "What should this function do? Maybe I or someone can help flesh it out.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354272/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354276", "body": "You shouldn't be calling strlen() in a loop like this. This should be rewritten more like this (untested):\n\n```\nfor (c = line ; *c ; c++) {\n    if (*c == '\\r' || *c == '\\n') {\n      c = '\\0';\n      break;\n    }\n}\n```\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354276/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354281", "body": "The code inside this should be indented another level. (Is Github hiding that in the diff, maybe? I didn't check.)\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354281/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354285", "body": "What's the purpose of this check? I don't understand why /dev/zvol is hardcoded.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354285/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}}, "3": {"danielkza": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7059", "title": "Scrub gets stuck, becomes unstoppable and locks up user processes in uninterruptible sleep", "body": "Type                    | Version/Name\r\n---                     | ---\r\nDistribution Name       | Fedora\r\nDistribution Version    | 27\r\nLinux Kernel            | 4.14.13\r\nArchitecture            | x86_64\r\nZFS Version             | 0.7.5\r\nSPL Version             | 0.7.5\r\n\r\n### Describe the problem you're observing\r\n\r\nAfter a routine scrub starting on the background, some programs seem stuck in uninterruptible IO due to ZFS. Attempting\r\nto pause or stop the scrub does not work - the `zpool` command hangs and also becomes unkillable.\r\n\r\nHere is the `/proc/PID/stack` of the stuck `zpool`:\r\n\r\n```\r\n[<ffffffffc11f1c23>] cv_wait_common+0x113/0x130 [spl]\r\n[<ffffffffc11f1c55>] __cv_wait+0x15/0x20 [spl]\r\n[<ffffffffc182972d>] txg_wait_synced+0xdd/0x120 [zfs]\r\n[<ffffffffc1801f36>] dsl_sync_task+0x176/0x260 [zfs]\r\n[<ffffffffc180041e>] dsl_scrub_set_pause_resume+0x3e/0x40 [zfs]\r\n[<ffffffffc181e511>] spa_scrub_pause_resume+0x31/0x60 [zfs]\r\n[<ffffffffc1858f85>] zfs_ioc_pool_scan+0xb5/0xc0 [zfs]\r\n[<ffffffffc18592d6>] zfsdev_ioctl+0x1d6/0x600 [zfs]\r\n[<ffffffff9429f575>] do_vfs_ioctl+0xa5/0x610\r\n[<ffffffff9429fb59>] SyS_ioctl+0x79/0x90\r\n[<ffffffff94a0008d>] entry_SYSCALL_64_fastpath+0x20/0x83\r\n```\r\n\r\nAnd of one of the stuck user processes:\r\n\r\n```\r\n[<ffffffff940d7746>] io_schedule+0x16/0x40\r\n[<ffffffffc11f1bb9>] cv_wait_common+0xa9/0x130 [spl]\r\n[<ffffffffc11f1c98>] __cv_wait_io+0x18/0x20 [spl]\r\n[<ffffffffc187f7f2>] zio_wait+0xf2/0x1b0 [zfs]\r\n[<ffffffffc17c38d3>] dbuf_read+0x6e3/0x910 [zfs]\r\n[<ffffffffc17c5c19>] __dbuf_hold_impl+0x549/0x600 [zfs]\r\n[<ffffffffc17c5d71>] dbuf_hold_impl+0xa1/0xd0 [zfs]\r\n[<ffffffffc17c5e33>] dbuf_hold+0x33/0x60 [zfs]\r\n[<ffffffffc17cf1cd>] dmu_buf_hold_noread+0x8d/0x100 [zfs]\r\n[<ffffffffc17cf26f>] dmu_buf_hold+0x2f/0x80 [zfs]\r\n[<ffffffffc1845a5e>] zap_lockdir+0x4e/0xb0 [zfs]\r\n[<ffffffffc1845c3a>] zap_cursor_retrieve+0x17a/0x2e0 [zfs]\r\n[<ffffffffc1869abc>] zfs_readdir+0x13c/0x460 [zfs]\r\n[<ffffffffc1886911>] zpl_iterate+0x51/0x80 [zfs]\r\n[<ffffffff9429fce0>] iterate_dir+0x170/0x1a0\r\n[<ffffffff942a046a>] SyS_getdents+0xaa/0x140\r\n[<ffffffff94a0008d>] entry_SYSCALL_64_fastpath+0x20/0x83\r\n[<ffffffffffffffff>] 0xffffffffffffffff\r\n```\r\n\r\nHere is the affected pool status:\r\n\r\n```\r\n  pool: daniel-pc-media\r\n state: ONLINE\r\n  scan: scrub in progress since Thu Jan 18 03:29:02 2018\r\n    102G scanned out of 2,45T at 2,60M/s, 263h46m to go\r\n    0B repaired, 4,06% done\r\nconfig:\r\n\r\n    NAME                                 STATE     READ WRITE CKSUM\r\n    daniel-pc-media                      ONLINE       0     0     0\r\n      mirror-0                           ONLINE       0     0     0\r\n        ata-ST4000DM000-1F2168_Z301QGEZ  ONLINE       0     0     0\r\n        ata-ST4000DM000-1F2168_Z301QGCM  ONLINE       0     0     0\r\n```\r\n\r\nThere seems to be no progress actually being made, as none of the counters advance (other than the expected ETA).\r\n\r\n### Describe how to reproduce the problem\r\n\r\nNot able to so far. I can provide more observations of the running system if it doesn't force me to restart by\r\nbecoming unstable/unusable.\r\n\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n\r\nNothing of interest or related to ZFS is present in the kernel logs.\r\nThe problem *might* have been triggered by suspending and resuming the computer, but I was not monitoring the scrub before that, so I can't be sure.\r\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7059/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "makhomed": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7057", "title": "tasks txg_sync and zfs blocked for more than 120 seconds", "body": "### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       |  CentOS Linux\r\nDistribution Version    | 7.4.1708\r\nLinux Kernel                 |  3.10.0-693.11.6.el7\r\nArchitecture                 | x86_64\r\nZFS Version                  | 0.7.5-1\r\nSPL Version                  | 0.7.5-1\r\n\r\nZFS installed from zfs-kmod repo, ```baseurl=http://download.zfsonlinux.org/epel/7.4/kmod/$basearch/```\r\n\r\n### Describe the problem you're observing\r\n\r\nMessages in /var/log/messages about blocked tasks.\r\n\r\n### Describe how to reproduce the problem\r\n\r\nSorry, but I do not found way how to reproduce this bug.\r\nMay be stack trace will help to find root cause of this bug?\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n```\r\n\r\nJan 17 17:26:45 kvm-hardware-node kernel: INFO: task txg_sync:10906 blocked for more than 120 seconds.\r\nJan 17 17:26:45 kvm-hardware-node kernel: \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\nJan 17 17:26:45 kvm-hardware-node kernel: txg_sync        D ffff883f6a256eb0     0 10906      2 0x00000000\r\nJan 17 17:26:45 kvm-hardware-node kernel: Call Trace:\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04ddf57>] ? taskq_dispatch_ent+0x57/0x170 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff816ab6d9>] schedule+0x29/0x70\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff816a90e9>] schedule_timeout+0x239/0x2c0\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc07ba30f>] ? zio_taskq_dispatch+0x8f/0xa0 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc07ba352>] ? zio_issue_async+0x12/0x20 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc07bebcc>] ? zio_nowait+0xbc/0x150 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff816aac5d>] io_schedule_timeout+0xad/0x130\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff810b31a6>] ? prepare_to_wait_exclusive+0x56/0x90\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff816aacf8>] io_schedule+0x18/0x20\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04e24a2>] cv_wait_common+0xb2/0x150 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff810b34b0>] ? wake_up_atomic_t+0x30/0x30\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04e2598>] __cv_wait_io+0x18/0x20 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc07be49b>] zio_wait+0x10b/0x1b0 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc07346cf>] dsl_pool_sync+0xbf/0x440 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc07527c7>] spa_sync+0x437/0xdf0 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff810c6452>] ? default_wake_function+0x12/0x20\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff810bf074>] ? __wake_up+0x44/0x50\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0766a91>] txg_sync_thread+0x301/0x510 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0766790>] ? txg_fini+0x2a0/0x2a0 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04dcfa1>] thread_generic_wrapper+0x71/0x80 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04dcf30>] ? __thread_exit+0x20/0x20 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff810b252f>] kthread+0xcf/0xe0\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff810b2460>] ? insert_kthread_work+0x40/0x40\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff816b8798>] ret_from_fork+0x58/0x90\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff810b2460>] ? insert_kthread_work+0x40/0x40\r\nJan 17 17:26:45 kvm-hardware-node kernel: INFO: task zfs:21118 blocked for more than 120 seconds.\r\nJan 17 17:26:45 kvm-hardware-node kernel: \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\nJan 17 17:26:45 kvm-hardware-node kernel: zfs             D ffff883f79a38000     0 21118   8250 0x00000080\r\nJan 17 17:26:45 kvm-hardware-node kernel: Call Trace:\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff816ab6d9>] schedule+0x29/0x70\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04e2515>] cv_wait_common+0x125/0x150 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff810b34b0>] ? wake_up_atomic_t+0x30/0x30\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04e2555>] __cv_wait+0x15/0x20 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0765a2f>] txg_wait_synced+0xef/0x140 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0727d50>] ? dsl_dataset_snapshot_check_impl+0x210/0x210 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc073d017>] dsl_sync_task+0x177/0x270 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc07289d0>] ? dsl_dataset_snapshot_sync_impl+0x760/0x760 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0727d50>] ? dsl_dataset_snapshot_check_impl+0x210/0x210 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc07289d0>] ? dsl_dataset_snapshot_sync_impl+0x760/0x760 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0728dc3>] dsl_dataset_snapshot+0x133/0x2e0 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0479157>] ? nvlist_remove_all+0x77/0xd0 [znvpair]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0479655>] ? nvlist_add_common.part.51+0x325/0x430 [znvpair]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff811df99c>] ? __kmalloc_node+0x5c/0x2b0\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04db31d>] ? spl_kmem_alloc_impl+0xcd/0x170 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04db31d>] ? spl_kmem_alloc_impl+0xcd/0x170 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04db31d>] ? spl_kmem_alloc_impl+0xcd/0x170 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0479fc2>] ? nvlist_lookup_common.part.71+0xa2/0xb0 [znvpair]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0796868>] zfs_ioc_snapshot+0x348/0x3b0 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0798606>] zfsdev_ioctl+0x1d6/0x650 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff8121710d>] do_vfs_ioctl+0x33d/0x540\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff816b3801>] ? __do_page_fault+0x171/0x450\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff812173b1>] SyS_ioctl+0xa1/0xc0\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff816b89fd>] system_call_fastpath+0x16/0x1b\r\n```", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7057/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "beren12": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7056", "title": "Improve snapshot listing error message", "body": "### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Debian\r\nDistribution Version    | 9\r\nLinux Kernel                 | 4.13.13-1~bpo9+1\r\nArchitecture                 | x64\r\nZFS Version                  | 0.7.4\r\nSPL Version                  | 0.7.4\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\nlisting snapshots for a single dataset fails unless -r is used, but this is not mentioned in the error message. -r is not needed to list all snapshots, so it can be a confusing behavior.\r\n\r\n### Describe how to reproduce the problem\r\n\r\n```\r\nzfs list -t snap rpool\r\n```\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n\r\n```\r\nzfs list -t snap rpool\r\ncannot open 'rpool': missing '@' delimiter in snapshot name\r\n```\r\n\r\nCould we amend the error message to also give a hint? Or possibly be consistent and list all snapshots without -r, just as giving no dataset does? Bookmarks might also need the same edit, ike here:\r\n\r\n```diff\r\n--- lib/libzfs/libzfs_dataset.c\t2018-01-17 10:07:12.178817043 -0500\r\n+++ lib/libzfs/libzfs_dataset.c.new\t2018-01-17 10:06:47.307290884 -0500\r\n@@ -175,7 +175,7 @@\r\n \tif (type == ZFS_TYPE_SNAPSHOT && strchr(path, '@') == NULL) {\r\n \t\tif (hdl != NULL)\r\n \t\t\tzfs_error_aux(hdl, dgettext(TEXT_DOMAIN,\r\n-\t\t\t    \"missing '@' delimiter in snapshot name\"));\r\n+\t\t\t    \"missing '@' delimiter in snapshot name, did you mean to use -r?\"));\r\n \t\treturn (0);\r\n \t}\r\n```", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7056/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "behlendorf": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7052", "title": "zfs load-key double free", "body": "### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | CentOS\r\nDistribution Version    | 7\r\nLinux Kernel                 | 3.10.0-693.11.6.1\r\nArchitecture                 | x86_64\r\nZFS Version                  | zfs-0.7.0-246-gd658b2c\r\nSPL Version                  | master\r\n\r\n### Describe the problem you're observing\r\n\r\nWhen zfs is built with `--enable-debug --enable-debuginfo` and an incorrect passphrase is provided to `zfs load-key` followed by an empty one a \"double free or leak\" is reported.  Observed during manual testing.\r\n\r\n### Describe how to reproduce the problem\r\n\r\nAt build time `--enable-debug --enable-debuginfo`, then,\r\n\r\n```sh\r\n$ truncate -s 512M /var/tmp/vdev\r\n$ zpool create tank /var/tmp/vdev\r\n$ zfs create -o encryption=on -o keyformat=passphrase tank/fs\r\nEnter passphrase: password\r\nRe-enter passphrase: password\r\n$ zfs unload-key -a\r\n```\r\n\r\nReload the key giving the wrong password first \"password1\" which is correctly rejected.  Then just hit enter when prompted again.\r\n\r\n```sh\r\n$ zfs load-key -a\r\nEnter passphrase for 'tank/fs': password1\r\nKey load error: Incorrect key provided for 'tank/fs'.\r\nEnter passphrase for 'tank/fs': <empty>\r\nKey load error: Passphrase too short (min 8).\r\n*** Error in `cmd/zfs/.libs/lt-zfs': double free or corruption (fasttop): 0x000000000061f150 ***\r\n======= Backtrace: =========\r\n/lib64/libc.so.6(+0x7c619)[0x2aaaacc65619]\r\nlib/libzfs/.libs/libzfs.so.2(zfs_crypto_load_key+0xf3)[0x2aaaab109023]\r\ncmd/zfs/.libs/lt-zfs[0x406557]\r\ncmd/zfs/.libs/lt-zfs[0x405d41]\r\ncmd/zfs/.libs/lt-zfs[0x408298]\r\ncmd/zfs/.libs/lt-zfs[0x4051ef]\r\n/lib64/libc.so.6(__libc_start_main+0xf5)[0x2aaaacc0ac05]\r\ncmd/zfs/.libs/lt-zfs[0x405318]\r\n...\r\n```", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7052/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7026", "title": "Test case history_004_pos", "body": "### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | all\r\nDistribution Version    | all\r\nLinux Kernel                 | all\r\nArchitecture                 | all\r\nZFS Version                  | zfs-0.7.0-230-gb02beca\r\nSPL Version                  | 0.7\r\n\r\n### Describe the problem you're observing\r\n\r\nRarely observed failure of history_004_pos during automated testing.\r\n\r\n### Describe how to reproduce the problem\r\n\r\nReproducible by the buildbot.\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n\r\n\r\nhttp://build.zfsonlinux.org/builders/Amazon%202%20x86_64%20Release%20%28TEST%29/builds/105/\r\n\r\n```\r\nTest: /usr/share/zfs/zfs-tests/tests/functional/history/history_004_pos (run as root) [00:04] [FAIL]\r\n02:51:58.52 ASSERTION: 'zpool history' can cope with simultaneous commands.\r\n02:52:01.35 umount: testpool/clone3: mountpoint not found\r\n02:52:01.35 cannot unmount 'testpool/clone3': umount failed\r\n02:52:01.55 cannot create 'testpool/clone3': dataset already exists\r\n02:52:01.62 cannot promote 'testpool/clone3': not a cloned filesystem\r\n02:52:01.66 cannot destroy 'testpool/testfs3': filesystem has children\r\n02:52:01.66 use '-r' to destroy the following datasets:\r\n02:52:01.66 testpool/testfs3@snap\r\n02:52:01.81 cannot create 'testpool/testfs3': dataset already exists\r\n02:52:01.92 cannot create snapshot 'testpool/testfs3@snap': dataset already exists\r\n02:52:02.69 The entries count error: entry_count=297  orig_count = 103\r\n02:52:02.69 NOTE: Performing test-fail callback (/usr/share/zfs/zfs-tests/callbacks/zfs_dbgmsg.ksh)\r\n```", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7026/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/3da3488e6339ff2dc5c7f3da8c8a0c552d018d68", "message": "Fix shellcheck v0.4.6 warnings\n\nResolve new warnings reported after upgrading to shellcheck\r\nversion 0.4.6.  This patch contains no functional changes.\r\n\r\n* egrep is non-standard and deprecated. Use grep -E instead. [SC2196]\r\n* Check exit code directly with e.g. 'if mycmd;', not indirectly\r\n  with $?.  [SC2181]  Suppressed.\r\n\r\nReviewed-by: George Melikov <mail@gmelikov.ru>\r\nReviewed-by: Giuseppe Di Natale <dinatale2@llnl.gov>\r\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nCloses #7040"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/e1a0850c3570ae53df5779bc656f17b98b86f160", "message": "Force ztest to always use /dev/urandom\n\nFor ztest, which is solely for testing, using a pseudo random\r\nis entirely reasonable.  Using /dev/urandom ensures the system\r\nentropy pool doesn't get depleted thus stalling the testing.\r\nThis is a particular problem when testing in VMs.\r\n\r\nReviewed-by: Tim Chase <tim@chase2k.com>\r\nReviewed by: Thomas Caputi <tcaputi@datto.com>\r\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nCloses #7017 \r\nCloses #7036"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/fed90353d799acbc5e81b0dfadc6d649b0f2e8b5", "message": "Support -fsanitize=address with --enable-asan\n\nWhen --enable-asan is provided to configure then build all user\r\nspace components with fsanitize=address.  For kernel support\r\nuse the Linux KASAN feature instead.\r\n\r\nhttps://github.com/google/sanitizers/wiki/AddressSanitizer\r\n\r\nWhen using gcc version 4.8 any test case which intentionally\r\ngenerates a core dump will fail when using --enable-asan.\r\nThe default behavior is to disable core dumps and only newer\r\nversions allow this behavior to be controled at run time with\r\nthe ASAN_OPTIONS environment variable.\r\n\r\nAdditionally, this patch includes some build system cleanup.\r\n\r\n* Rules.am updated to set the minimum AM_CFLAGS, AM_CPPFLAGS,\r\n  and AM_LDFLAGS.  Any additional flags should be added on a\r\n  per-Makefile basic.  The --enable-debug and --enable-asan\r\n  options apply to all user space binaries and libraries.\r\n\r\n* Compiler checks consolidated in always-compiler-options.m4\r\n  and renamed for consistency.\r\n\r\n* -fstack-check compiler flag was removed, this functionality\r\n  is provided by asan when configured with --enable-asan.\r\n\r\n* Split DEBUG_CFLAGS in to DEBUG_CFLAGS, DEBUG_CPPFLAGS, and\r\n  DEBUG_LDFLAGS.\r\n\r\n* Moved default kernel build flags in to module/Makefile.in and\r\n  split in to ZFS_MODULE_CFLAGS and ZFS_MODULE_CPPFLAGS.  These\r\n  flags are set with the standard ccflags-y kbuild mechanism.\r\n\r\n* -Wframe-larger-than checks applied only to binaries or\r\n  libraries which include source files which are built in\r\n  both user space and kernel space.  This restriction is\r\n  relaxed for user space only utilities.\r\n\r\n* -Wno-unused-but-set-variable applied only to libzfs and\r\n  libzpool.  The remaining warnings are the result of an\r\n  ASSERT using a variable when is always declared.\r\n\r\n* -D_POSIX_PTHREAD_SEMANTICS and -D__EXTENSIONS__ dropped\r\n  because they are Solaris specific and thus not needed.\r\n\r\n* Ensure $GDB is defined as gdb by default in zloop.sh.\r\n\r\nSigned-off-by: DHE <git@dehacked.net>\r\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nCloses #7027"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/7e7f5132779a04da0070cf6e6ffd8e9b5f7692de", "message": "Disable history_004_pos\n\nOccasionally observed failure of history_004_pos due to the test\r\ncase not being 100% reliable.  In order to prevent false positives\r\ndisable this test case until it can be made reliable.\r\n\r\nReviewed-by: George Melikov <mail@gmelikov.ru>\r\nReviewed-by: Giuseppe Di Natale <dinatale2@llnl.gov>\r\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nIssue #7026 \r\nCloses #7028"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/bfe27ace0de64838d50ff351396423a481de6c84", "message": "Fix unused variable warnings\n\nResolved unused variable warnings observed after restricting\n-Wno-unused-but-set-variable to only libzfs and libzpool.\n\nReviewed-by: DHE <git@dehacked.net>\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\nCloses #6941"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/06401e42221d2f5130065caf70f8276ba4d19acd", "message": "Fix ztest_verify_dnode_bt() test case\n\nIn ztest_verify_dnode_bt the ztest_object_lock must be held in\norder to safely verify the unused bonus space.\n\nReviewed-by: DHE <git@dehacked.net>\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\nCloses #6941"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/b02becaa00aef3d25b30588bf49affbf1e9a84a4", "message": "Reduce codecov PR comments\n\nAttempt to reduce the number of comments posted by codecov\r\nto PR requests.  Based on the codecov documenation setting\r\n\"require_changes=yes\" and \"behavior=once\" should result in\r\na single comment under most circumstances.\r\n\r\nhttps://docs.codecov.io/v4.3.6/docs/pull-request-comments\r\n\r\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nIssue #7022 \r\nCloses #7025"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/0873bb6337452e3e028e40f5dad945b30deab185", "message": "Fix ARC hit rate\n\nWhen the compressed ARC feature was added in commit d3c2ae1\r\nthe method of reference counting in the ARC was modified.  As\r\npart of this accounting change the arc_buf_add_ref() function\r\nwas removed entirely.\r\n\r\nThis would have be fine but the arc_buf_add_ref() function\r\nserved a second undocumented purpose of updating the ARC access\r\ninformation when taking a hold on a dbuf.  Without this logic\r\nin place a cached dbuf would not migrate its associated\r\narc_buf_hdr_t to the MFU list.  This would negatively impact\r\nthe ARC hit rate, particularly on systems with a small ARC.\r\n\r\nThis change reinstates the missing call to arc_access() from\r\ndbuf_hold() by implementing a new arc_buf_access() function.\r\n\r\nReviewed-by: Giuseppe Di Natale <dinatale2@llnl.gov>\r\nReviewed-by: Tony Hutter <hutter2@llnl.gov>\r\nReviewed-by: Tim Chase <tim@chase2k.com>\r\nReviewed by: George Wilson <george.wilson@delphix.com>\r\nReviewed-by: George Melikov <mail@gmelikov.ru>\r\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nCloses #6171 \r\nCloses #6852 \r\nCloses #6989"}], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6999", "title": "Extend deadman logic", "body": "### Description\r\n\r\nThe intent of this patch is extend the existing deadman code such that it's flexible enough to be used by both ztest and on production systems.  The proposed changes include:\r\n\r\n* Added a new `zfs_deadman_failmode` module option which is used to dynamically control the behavior of the deadman.  It's loosely modeled after, but independant from, the pool failmode property.  It can be set to wait, continue, or panic.\r\n\r\n    * wait     - Wait for the \"hung\" I/O (default)\r\n    * continue - Attempt to recover from a \"hung\" I/O\r\n    * panic    - Panic the system\r\n\r\n* Added a new `zfs_deadman_ziotime_ms` module option which is analogous to zfs_deadman_synctime_ms` except instead of applying to a pool TXG sync it applies to zio_wait().  A   default value of 300s is used to define a \"hung\" zio.\r\n\r\n* The ztest deadman thread has been re-enabled by default, aligned with the upstream OpenZFS code, and then extended to terminate the process when it takes significantly longer to complete than expected.\r\n\r\n* The -G option was added to ztest to print the internal debug log when a fatal error is encountered.  This same option was previously added to zdb in commit fa603f82.  Update zloop.sh to unconditionally pass -G to obtain additional debugging.\r\n\r\n* The FM_EREPORT_ZFS_DELAY event which was previously posted when the deadman detect a \"hung\" pool has been replaced by a new dedicated FM_EREPORT_ZFS_DEADMAN event.\r\n\r\n* The proposed recovery logic attempts to restart a \"hung\"  zio by calling zio_interrupt() on any outstanding leaf zios.  We may want to further restrict this to zios in either the  ZIO_STAGE_VDEV_IO_START or ZIO_STAGE_VDEV_IO_DONE stages.  Calling zio_interrupt() is expected to only be useful for cases when an IO has been submitted to the physical device\r\n  but for some reasonable the completion callback hasn't been called by the lower layers.  This shouldn't be possible but  has been observed and may be caused by kernel/driver bugs.\r\n\r\n* The 'zfs_deadman_synctime_ms' default value was reduced from 1000s to 600s.\r\n\r\n* Depending on how ztest fails there may be no cache file to move.  This should not be considered fatal, collect the logs which are available and carry on.\r\n\r\n### Motivation and Context\r\n\r\nAdd some of the needed infrastructure to make it possible to root cause `ztest` \"hangs\" observed during automated testing.  With this change applied at least basic debugging information will be collected for any \"hangs\".  This change can be further augmented with improvements to the debugging infrastructure.\r\n\r\nIssue #6901.\r\n\r\n### How Has This Been Tested?\r\n\r\nLocally by running `zloop.sh` in-tree for approximated 4 days.  Over this time period the deadman behaved as expected and properly terminated `ztest` when it appeared to be hung.  Further analysis of the debug logs and cores obtained is still needed.  The expectation is they will provide some statistical insight in the most often observed failures.\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [x] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [x] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "OWNER"}], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/147559", "body": "Thanks, I hadn't noticed the rendering issue.  Fixed by commit bbf3a3575c0b5795d3e4ddc27523258dc61ffa88.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/147559/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/195492", "body": "I'm not particularly happy with all this grubbing around in /dev/ either for 'zpool import', but for the moment I view it as a short term solution.  The longer term solution, which is well under way, is to be tightly integrated with libblkid.  There has been a patch submitted upstream and accepted by the maintainers to correctly identify a disk which belongs to a zfs pool.  Once a version of libblkid with this change filters back in to the distributions we can simply consult libblkid for the list of zfs devices and avoid checking /dev/.  In fact all the code on the zfs side is already in place for this.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/195492/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/282533", "body": "- Removed Makefile-sample, with the full integration in the build system it isn't needed.\n- Added all autogen.sh products (Makefile.in, configure) using the following versions of the utils.  Using the same versions of the tools minimizes how much change there is in the autogen products and makes it easier to review.\n  \n  autoconf (GNU Autoconf) 2.63\n  automake (GNU automake) 1.11.1\n  ltmain.sh (GNU libtool) 2.2.6b\n- Added the CDDL header to zvol_id_main.c, including correctly attributing the source.\n- Minor stray whitespace cleanup.\n- Update kmem_free() in zvol_remove_minors() to match  kmem_zalloc()'s use of MAXNAMELEN.  If we fail to do the the memory account code will flag this is a memory leak.  It's critical to ensure you alloc/free both use the same size for the buffer.\n- Add <sys/stat.h> header in zvol_id_main.c, without it my build was failing on RHEL6.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/282533/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/282739", "body": "Sorry!  I've force updated my branch to include the Makefile.in... in and the process obliterated the previous review comments.  We need to figure out how to handle this best, I'd really like to be landing one nice concise commit to fix an issue.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/282739/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/383680", "body": "The zvol will be created with unique /dev/zdN names and then the /dev/zvol/pool/dataset links are created with udev rules.  This is exactly how normal block devices work such as /dev/sda with /dev/disk/by-_/_ links created with udev.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/383680/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/384675", "body": "This behavior is forced by the Linux kernel.  The special device files created under /dev/\\* has certain limitations including a maximum name length and certain reserved characters.  To avoid these limitations the standard solution is to create simple unique names at the top level /dev/\\* and symlink them with udev.  That's why all persistent storage devices work this way.  As you say you should never use these top level devices because their names may change.  This is equally true for /dev/sda, /dev/hda, and /dev/zd1.  The above comment is the code was simply an example test case and does not show a real usage scenario.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/384675/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/409945", "body": "I'm pretty sure dbuf_hold_impl() is called in other contexts.  I've love to revert this too but it's going to take more convincing that this is safe...  but that's for pointing it out, I'd actually forgotten about this particular hack!\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/409945/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/512022", "body": "I didn't either at the time or I would have added it to the original patch.  I only noticed later when it annoyed me.  :)\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/512022/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}], "review_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11254", "body": "This file should be readded exactly for the reasons mentioned in the file.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11254/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11255", "body": "Yes, please remove them.  They are currently unused hooks and they cause compile errors on older platforms.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11255/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11259", "body": "A version of this file was already added to the dracut subdirectory.  If you want to make changes/rewrite it that's fine but let's just keep one copy of it around with the other dracut code.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11259/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}]}, "wphilips": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7050", "title": "zfs-dracut boot failure with out of date zpool.cache - zfs_force not working", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       |  Fedora \r\nDistribution Version    |  26 \r\nLinux Kernel                 |  any (e.g., 4.14.6-200.fc26.x86_64)\r\nArchitecture                 |  x86_64\r\nZFS Version                  |   v0.7.5-1\r\nSPL Version                  |  v0.7.5-1\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\nI have several systems with root and boot on zfs. The systems boot with grub initramfs \r\nis generated by dracut with zfs-dracut-0.7.5-1.fc26.x86_64\r\n\r\nThe problem occurs whenever significant changes are made to the zpools attached to the\r\nsystem, or even when adding empty disks.  Very often, dracut enters the emergency shell\r\nbecause it cannot import the pools based on the zpool.cache file. Even adding zfs_force \r\nas a kernel option does not work. E.g., I tried:\r\n\r\nlinux16 /boot/@/vmlinuz-4.14.13-200.fc26.x86_64 root=zfs:ssd/fc26 boot=ssd ro rd_NO_PLYMOUTH audit=0 zfs_force=1\r\n\r\n\r\nThe reason seems to be that the zpoool.cache file does not reflect the current (changed) configuration of the system. It is not clear why zfs.force  or zfs_force does not work.\r\n\r\n\r\nHere are 2 use cases:\r\n\r\n1. to defragment  the pool on which the zfs root is installed, I attach a new disk, create a new\r\nzpool on it, copy all the data, remove the old disk, reboot and change some grub parameters so\r\nthat it boots the new bool. Before the reboot, zpool.cache refers to the old pool on the old disk.\r\nRunning 'dracut -f ...' will therefore copy the \"old\" zpool.cache into initamfs. After boot, the disks\r\nhave changed and this zpool.cache is outdated. \r\n\r\n2. in a system with 3 rpools, I remove one of the disks which contains a non-essential \r\nrpool (after exporting it). I then add two new empty disks. The system boots into the dracut \r\nshell even though the root pool has not changed. The now missing, but non-essential pool\r\nprevents a normal boot.\r\n\r\n\r\nIt is possible to somewhat prevent these problems by removing zpool.cache, then running\r\ndracut and then rebooting. In this case, often dracut still enters the emergency shell claiming\r\nthat the pool(s) are in use in another system, but by force importing them in the dracut shell\r\nand rebooting it is possible to boot the system. Then it is possible to recreate zpool.cache, \r\nand rerun dracut to create a working system. Alternatively, one can continue to use the initramfs\r\nwith the missing zpool.cache.\r\n\r\nIt is probably also possible to create a zpool.cache file for the future new configuration, but it probably \r\ninvolves deleting the current one and it is easy to make a mistake.\r\n\r\nIn any case, make a simple mistake or  forget to take these  \"preventive\" measures \r\nand you end up with a system which will always enter the dracut emergency shell with \r\nno way to recover (except if you have e.g., a usb boot disk with zfs at hand. Even then\r\nit is really hard to recover).\r\n\r\nIn the good old days it also use to be  possible to fix problems in the dracut shell and then continue to boot. These days, systemd prevents this from working (probably related to the message \"transaction is destructive\")\r\n\r\nWhile fixing the zfs_force option would help, adding a configuration option to dracut to never \r\ncreate zfs.cache and/or adding a kernel command line option to ignore zpool.cache might \r\nalso help.\r\n \r\n\r\nPS. Even better would be to fix dracut or systemd so that a boot can continue after fixing problems \r\nin dracut. For instance, in the emergency shell you would remove the zpool.cache file and \r\nthen type some command to continue boot. However, that is probably a more general (non zfsonlinux)\r\nissue.\r\n\r\n\r\n\r\n\r\n\r\n\r\n### Describe how to reproduce the problem\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n<!-- \r\n*IMPORTANT* - Please mark logs and text output from terminal commands \r\nor else Github will not display them correctly. \r\nAn example is provided below.\r\n\r\nExample:\r\n```\r\nthis is an example how log text should be marked (wrap it with ```)\r\n```\r\n-->\r\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7050/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "Menion2k": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7046", "title": "aarch64 and arm64 mismatch", "body": "Hello\r\nIt seems that there is a problem handling the ARCH on arm64 targets\r\nFrom the BUILD detection I see that the ARCH is set to aarch64. The compilation is ok, but aarch64 is not a DEB or RPM architecture, because it is defined as \"arm64\"\r\nThe result is that the make deb fails with the error:\r\n\r\n> spl-0.7.5-1.aarch64.rpm is for architecture aarch64 ; the package cannot be built on this system\r\n\r\nI guess that somewhere in the Makefile the BUILD system architecture shall be converted to a valid package architecture\r\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7046/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "jhammond-intel": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7045", "title": "pool suspension due to delayed MMP writes needs a better error message", "body": "### System information\r\nDistribution Name       | *\r\nDistribution Version    | *\r\nLinux Kernel                 | * \r\nArchitecture                 | *\r\nZFS Version                  | 0.7.5\r\nSPL Version                  | 0.7.5\r\n\r\nThis is related to Lustre issue https://jira.hpdd.intel.com/browse/LU-9845.\r\n\r\nWhen an MMP thread suspends a pool because \"no MMP write has succeeded in over mmp_interval * mmp_fail_intervals nanoseconds\" the only message we see on the console is \"WARNING: Pool 'blahblah' has encountered an uncorrectable I/O failure and has been suspended.\" This is not really informative enough and probably a bit misleading. We encountered these mysteriously suspended pool in our test clusters and were only able to attribute this to MMP by setting the pool failure mode to panic.\r\n\r\nI was able to easily reproduce using the Lustre backed zfs setup (VM has hostid set and 2 vCPUs, pool has MMP enabled) using the following:\r\n```\r\nm:~# export FSTYPE=zfs\r\nm:~# bash $LUSTRE/tests/llmount.sh\r\n...\r\nm:~# cat /sys/module/zfs/parameters/zfs_multihost_interval \r\n1000\r\nm:~# echo 100 > /sys/module/zfs/parameters/zfs_multihost_interval # set mmp interval to 100ms\r\nm:~# chrt -f 20 dd if=/dev/zero of=/dev/null &\r\nm:~# chrt -f 20 dd if=/dev/zero of=/dev/null &\r\n```\r\n\r\nI think we should probably keep the message from `zio_suspend()` as is but add a suitable message to `mmp_thread()` before calling `zio_suspend()`.", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7045/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/51d1b58ef3467c3a9711c65458f93063dd17354f", "message": "Emit an error message before MMP suspends pool\n\nIn mmp_thread(), emit an MMP specific error message before calling\r\nzio_suspend() so that the administrator will understand why the pool\r\nis being suspended.\r\n\r\nReviewed-by: Olaf Faaland <faaland1@llnl.gov>\r\nReviewed-by: Giuseppe Di Natale <dinatale2@llnl.gov>\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: John L. Hammond <john.hammond@intel.com>\r\nCloses #7048"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "samuelbernardo": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7042", "title": "BUG: soft lockup - CPU# stuck for 22s! [z_wr_iss]", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Gentoo\r\nDistribution Version    | -\r\nLinux Kernel                 | 4.14.12\r\nArchitecture                 | x86_64\r\nZFS Version                  | 0.7.5\r\nSPL Version                  | 0.7.5\r\n\r\n\r\n### Describe the problem you're observing\r\n\r\nzfs thread lock after some intensive IO. It allows to continue to access data, but all writes won't be commited to disk, since reboot needs ctrl+shift+sysreq reisub. It remains locked after trying soft reboot, and the only solution is a forced reboot with sysreq.\r\nThe zfs lock is registered systematically after some intensive IO on each OS reboot.\r\n\r\n### Describe how to reproduce the problem\r\n\r\nThis is the configuration of zfs volume that has the deadlock (using deduplication and lz4 compression):\r\n\r\nNAME   SIZE  ALLOC   FREE  EXPANDSZ   FRAG    CAP  DEDUP  HEALTH  ALTROOT\r\nzfs  21.8T  5.69T  16.1T         -     6%    26%  1.07x  ONLINE  -\r\n  raidz1  10.9T  2.85T  8.03T         -     6%    26%\r\n    ata-TOSHIBA_DT01ACA300_Z5RS6H0KS      -      -      -         -      -      -\r\n    ata-TOSHIBA_HDWD130_678KR5JAS      -      -      -         -      -      -\r\n    ata-TOSHIBA_DT01ACA300_16QUEEEKS      -      -      -         -      -      -\r\n    ata-TOSHIBA_HDWD130_678KPYLAS      -      -      -         -      -      -\r\n  raidz1  10.9T  2.85T  8.03T         -     6%    26%\r\n    ata-TOSHIBA_HDWD130_678KTDUAS      -      -      -         -      -      -\r\n    ata-TOSHIBA_DT01ACA300_16QUDE3KS      -      -      -         -      -      -\r\n    ata-WDC_WD40EZRX-75SPEB0_WD-WCC4E2YAA98J-part6      -      -      -         -      -      -\r\n    ata-TOSHIBA_HDWD130_678KPP7AS      -      -      -         -      -      -\r\ncache      -      -      -         -      -      -\r\n  sdc   699G  79.7M   699G         -     0%     0%\r\n  sde   699G  78.2M   699G         -     0%     0%\r\n\r\n  pool: zfs\r\n state: ONLINE\r\n  scan: resilvered 75.5G in 0h38m with 0 errors on Mon Oct 16 03:45:53 2017\r\nconfig:\r\n        NAME                                                STATE     READ WRITE CKSUM\r\n        zfs                                                 ONLINE       0     0     0\r\n          raidz1-0                                          ONLINE       0     0     0\r\n            ata-TOSHIBA_DT01ACA300_Z5RS6H0KS                ONLINE       0     0     0\r\n            ata-TOSHIBA_HDWD130_678KR5JAS                   ONLINE       0     0     0\r\n            ata-TOSHIBA_DT01ACA300_16QUEEEKS                ONLINE       0     0     0\r\n            ata-TOSHIBA_HDWD130_678KPYLAS                   ONLINE       0     0     0\r\n          raidz1-1                                          ONLINE       0     0     0\r\n            ata-TOSHIBA_HDWD130_678KTDUAS                   ONLINE       0     0     0\r\n            ata-TOSHIBA_DT01ACA300_16QUDE3KS                ONLINE       0     0     0\r\n            ata-WDC_WD40EZRX-75SPEB0_WD-WCC4E2YAA98J-part6  ONLINE       0     0     0\r\n            ata-TOSHIBA_HDWD130_678KPP7AS                   ONLINE       0     0     0\r\n        cache\r\n          sdc                                               ONLINE       0     0     0\r\n          sde                                               ONLINE       0     0     0\r\n\r\ncapacity  |   operations  |   bandwidth  |  total_wait   |  disk_wait  |  syncq_wait  |  asyncq_wait | scrub\r\n\r\npool |  alloc |  free |  read | write |  read | write |  read | write |  read | write  | read | write |  read | write |  wait \r\n  --- |   --- |   --- |   --- |  --- |   --- |  --- |   --- |  --- |   --- |  ---  |  --- |  --- |   --- |  --- |   --- \r\nzfs     |    5.69T | 16.1T  |   81 |   109 |  500K |  950K |   4us  |  1us  |  4us | 543ns | 187ns  |  2ns  |  1us |   1us | 723ns\r\n\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n```\r\nJan 10 21:57:11 x99 kernel: INFO: rcu_sched detected expedited stalls on CPUs/tasks: { 9-... } 218109 jiffies s: 401 root: 0x200/.\r\nJan 10 21:57:11 x99 kernel: blocking rcu_node structures:\r\nJan 10 21:57:11 x99 kernel: Task dump for CPU 9:\r\nJan 10 21:57:11 x99 kernel: z_wr_iss        R  running task    12256   749      2 0x80000008\r\nJan 10 21:57:11 x99 kernel: Call Trace:\r\nJan 10 21:57:11 x99 kernel:  ? arc_buf_info+0xcc7/0xf80 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? mutex_lock+0x9/0x30\r\nJan 10 21:57:11 x99 kernel:  ? dbuf_rele_and_unlock+0x4cb/0x540 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? mutex_lock+0x9/0x30\r\nJan 10 21:57:11 x99 kernel:  ? mutex_lock+0x9/0x30\r\nJan 10 21:57:11 x99 kernel:  ? zio_worst_error+0x60f/0x1250 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? zio_wait+0x113/0x160 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? dbuf_read+0x617/0xd80 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? __kmalloc_node+0x27d/0x290\r\nJan 10 21:57:11 x99 kernel:  ? spl_kmem_zalloc+0x85/0x150 [spl]\r\nJan 10 21:57:11 x99 kernel:  ? zap_leaf_lookup+0x6d/0x130 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? fzap_length+0x48/0x90 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? zap_name_alloc_uint64+0x50/0x60 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? zap_length_uint64+0x74/0x230 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? ddt_walk+0x31b/0x450 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? ddt_lookup+0xb4/0x190 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? zio_checksum_compute+0x15d/0x2a0 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? spl_kmem_cache_alloc+0x5b/0xb10 [spl]\r\nJan 10 21:57:11 x99 kernel:  ? __kmalloc_node+0x27d/0x290\r\nJan 10 21:57:11 x99 kernel:  ? spl_kmem_alloc+0x8e/0x160 [spl]\r\nJan 10 21:57:11 x99 kernel:  ? spl_kmem_alloc+0x8e/0x160 [spl]\r\nJan 10 21:57:11 x99 kernel:  ? zio_flush+0x867/0xde0 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? zio_push_transform+0x662/0xbe0 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? zio_execute+0x7c/0x430 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? taskq_dispatch_delay+0x51f/0x950 [spl]\r\nJan 10 21:57:11 x99 kernel:  ? wake_up_q+0x70/0x70\r\nJan 10 21:57:11 x99 kernel:  ? zio_interrupt+0x1030/0x1030 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? kthread+0xf7/0x130\r\nJan 10 21:57:11 x99 kernel:  ? taskq_dispatch_delay+0x2c0/0x950 [spl]\r\nJan 10 21:57:11 x99 kernel:  ? kthread_create_on_node+0x40/0x40\r\nJan 10 21:57:11 x99 kernel:  ? do_group_exit+0x35/0xa0\r\nJan 10 21:57:11 x99 kernel:  ? ret_from_fork+0x1f/0x30\r\nJan 10 21:57:13 x99 kernel: watchdog: BUG: soft lockup - CPU#9 stuck for 22s! [z_wr_iss:749]\r\nJan 10 21:57:13 x99 kernel: Modules linked in: nvidia_uvm(PO) zfs(PO) zunicode(PO) zavl(PO) icp(PO) zcommon(PO) znvpair(PO) spl(O) nv>\r\nJan 10 21:57:13 x99 kernel: CPU: 9 PID: 749 Comm: z_wr_iss Tainted: P        W  O L  4.14.12-gentoox99 #1\r\nJan 10 21:57:13 x99 kernel: Hardware name: ASUS All Series/X99-S, BIOS 3402 08/18/2016\r\nJan 10 21:57:13 x99 kernel: task: ffff880fef778e00 task.stack: ffffc9000a2dc000\r\nJan 10 21:57:13 x99 kernel: RIP: 0010:zap_leaf_lookup+0x92/0x130 [zfs]\r\nJan 10 21:57:13 x99 kernel: RSP: 0018:ffffc9000a2dfa40 EFLAGS: 00000213 ORIG_RAX: ffffffffffffff10\r\nJan 10 21:57:13 x99 kernel: RAX: 0000000000000000 RBX: ffff880d59b78130 RCX: 0000000000000007\r\nJan 10 21:57:13 x99 kernel: RDX: 000000000000000c RSI: ffff880d59b78000 RDI: 5d7f96b690640000\r\nJan 10 21:57:13 x99 kernel: RBP: ffffc9000a2dfa88 R08: 00000000002ebfcb R09: ffff880de2c53800\r\nJan 10 21:57:13 x99 kernel: R10: ffff880de2c53800 R11: ffff880fe497a000 R12: ffff880de2c53800\r\nJan 10 21:57:13 x99 kernel: R13: ffff880c575f3600 R14: ffff880d59b78132 R15: 0000000000000001\r\nJan 10 21:57:13 x99 kernel: FS:  0000000000000000(0000) GS:ffff880fff440000(0000) knlGS:0000000000000000\r\nJan 10 21:57:13 x99 kernel: CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\r\nJan 10 21:57:13 x99 kernel: CR2: 00007f767108b850 CR3: 0000000004823006 CR4: 00000000001606e0\r\nJan 10 21:57:13 x99 kernel: Call Trace:\r\nJan 10 21:57:13 x99 kernel:  fzap_length+0x48/0x90 [zfs]\r\nJan 10 21:57:13 x99 kernel:  ? zap_name_alloc_uint64+0x50/0x60 [zfs]\r\nJan 10 21:57:13 x99 kernel:  zap_length_uint64+0x74/0x230 [zfs]\r\nJan 10 21:57:13 x99 kernel:  ddt_walk+0x31b/0x450 [zfs]\r\nJan 10 21:57:13 x99 kernel:  ddt_lookup+0xb4/0x190 [zfs]\r\nJan 10 21:57:13 x99 kernel:  ? zio_checksum_compute+0x15d/0x2a0 [zfs]\r\nJan 10 21:57:13 x99 kernel:  ? spl_kmem_cache_alloc+0x5b/0xb10 [spl]\r\nJan 10 21:57:13 x99 kernel:  ? __kmalloc_node+0x27d/0x290\r\nJan 10 21:57:13 x99 kernel:  ? spl_kmem_alloc+0x8e/0x160 [spl]\r\nJan 10 21:57:13 x99 kernel:  ? spl_kmem_alloc+0x8e/0x160 [spl]\r\nJan 10 21:57:13 x99 kernel:  zio_flush+0x867/0xde0 [zfs]\r\nJan 10 21:57:13 x99 kernel:  ? zio_push_transform+0x662/0xbe0 [zfs]\r\nJan 10 21:57:13 x99 kernel:  zio_execute+0x7c/0x430 [zfs]\r\nJan 10 21:57:13 x99 kernel:  taskq_dispatch_delay+0x51f/0x950 [spl]\r\nJan 10 21:57:13 x99 kernel:  ? wake_up_q+0x70/0x70\r\nJan 10 21:57:13 x99 kernel:  ? zio_interrupt+0x1030/0x1030 [zfs]\r\nJan 10 21:57:13 x99 kernel:  kthread+0xf7/0x130\r\nJan 10 21:57:13 x99 kernel:  ? taskq_dispatch_delay+0x2c0/0x950 [spl]\r\nJan 10 21:57:13 x99 kernel:  ? kthread_create_on_node+0x40/0x40\r\nJan 10 21:57:13 x99 kernel:  ? do_group_exit+0x35/0xa0\r\nJan 10 21:57:13 x99 kernel:  ret_from_fork+0x1f/0x30\r\nJan 10 21:57:13 x99 kernel: Code: eb 29 0f b7 43 02 4c 8d 73 02 66 83 f8 ff 74 7f 49 8b 8c 24 d8 00 00 00 41 8b 94 24 d0 00 00 00 49 >\r\nJan 10 21:57:18 x99 systemd[1]: Received SIGINT.\r\n```", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7042/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ltz3317": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7038", "title": "zfs sync hang ", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       |  centos 7.2 \uff0csync hang\r\nDistribution Version    | \r\nLinux Kernel                 | 3.10.0-327.13.1.el7.x86_64 \r\nArchitecture                 | \r\nZFS Version                  | v0.7.5-1\r\nSPL Version                  |  v0.7.5-1\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\nsync hang \uff0cmysql hang\uff0ckworker cpu 100\r\n### Describe how to reproduce the problem\r\nhigh frequency  create/destroy/clone\r\n### Include any warning/errors/backtraces from the system logs\r\ndmsg:\r\n[  189.990968] Adjusting tsc more than 11% (8039035 vs 7759471)\r\n[ 2522.644734] INFO: task mysqld:6608 blocked for more than 120 seconds.\r\n[ 2522.644790] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2522.644854] mysqld          D 0000000000000000     0  6608   5602 0x00000000\r\n[ 2522.644860]  ffff880feb913da0 0000000000000086 ffff881006eac500 ffff880feb913fd8\r\n[ 2522.644865]  ffff880feb913fd8 ffff880feb913fd8 ffff881006eac500 ffff880fffc8a180\r\n[ 2522.644869]  ffff880fffc8a000 ffff880fffc8a188 ffff880fffc8a028 0000000000000000\r\n[ 2522.644873] Call Trace:\r\n[ 2522.644882]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2522.644906]  [<ffffffffa04744d5>] cv_wait_common+0x125/0x150 [spl]\r\n[ 2522.644911]  [<ffffffff810a6ae0>] ? wake_up_atomic_t+0x30/0x30\r\n[ 2522.644922]  [<ffffffffa0474515>] __cv_wait+0x15/0x20 [spl]\r\n[ 2522.644995]  [<ffffffffa062bd7b>] zil_commit.part.12+0x8b/0x830 [zfs]\r\n[ 2522.645006]  [<ffffffffa046d037>] ? spl_kmem_alloc+0xc7/0x170 [spl]\r\n[ 2522.645017]  [<ffffffffa0475cb4>] ? tsd_set+0x324/0x500 [spl]\r\n[ 2522.645022]  [<ffffffff81639082>] ? mutex_lock+0x12/0x2f\r\n[ 2522.645075]  [<ffffffffa062c537>] zil_commit+0x17/0x20 [zfs]\r\n[ 2522.645128]  [<ffffffffa0621a27>] zfs_fsync+0x77/0xf0 [zfs]\r\n[ 2522.645179]  [<ffffffffa0639665>] zpl_fsync+0x65/0x90 [zfs]\r\n[ 2522.645186]  [<ffffffff8120fa45>] do_fsync+0x65/0xa0\r\n[ 2522.645191]  [<ffffffff8120fd10>] SyS_fsync+0x10/0x20\r\n[ 2522.645196]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2522.645202] INFO: task mysqld:7514 blocked for more than 120 seconds.\r\n[ 2522.645245] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2522.645296] mysqld          D ffff880fb554bda0     0  7514   5602 0x00000000\r\n[ 2522.645299]  ffff880fb554bd30 0000000000000086 ffff880ff4c8f300 ffff880fb554bfd8\r\n[ 2522.645303]  ffff880fb554bfd8 ffff880fb554bfd8 ffff880ff4c8f300 ffff880fb554bdb0\r\n[ 2522.645307]  ffff88107ff8dec0 0000000000000002 ffffffff811f9420 ffff880fb554bda0\r\n[ 2522.645312] Call Trace:\r\n[ 2522.645316]  [<ffffffff811f9420>] ? unlock_two_nondirectories+0x60/0x60\r\n[ 2522.645321]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2522.645324]  [<ffffffff811f942e>] inode_wait+0xe/0x20\r\n[ 2522.645328]  [<ffffffff81638cc0>] __wait_on_bit+0x60/0x90\r\n[ 2522.645335]  [<ffffffff812083bf>] __inode_wait_for_writeback+0xaf/0xf0\r\n[ 2522.645339]  [<ffffffff810a6b60>] ? wake_atomic_t_function+0x40/0x40\r\n[ 2522.645345]  [<ffffffff8120b996>] inode_wait_for_writeback+0x26/0x40\r\n[ 2522.645348]  [<ffffffff811fa135>] evict+0x95/0x170\r\n[ 2522.645351]  [<ffffffff811fa985>] iput+0xf5/0x180\r\n[ 2522.645357]  [<ffffffff811ef41e>] do_unlinkat+0x1ae/0x2b0\r\n[ 2522.645362]  [<ffffffff811e3fe1>] ? SyS_readlinkat+0xd1/0x140\r\n[ 2522.645367]  [<ffffffff811f0426>] SyS_unlink+0x16/0x20\r\n[ 2522.645371]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2522.645402] INFO: task sync:2653 blocked for more than 120 seconds.\r\n[ 2522.645443] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2522.645494] sync            D ffffffff8120f8c0     0  2653   1455 0x00000000\r\n[ 2522.645498]  ffff880ffedd7d50 0000000000000082 ffff880f01449700 ffff880ffedd7fd8\r\n[ 2522.645502]  ffff880ffedd7fd8 ffff880ffedd7fd8 ffff880f01449700 ffff880ffedd7e80\r\n[ 2522.645506]  ffff880ffedd7e88 7fffffffffffffff ffff880f01449700 ffffffff8120f8c0\r\n[ 2522.645509] Call Trace:\r\n[ 2522.645515]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2522.645519]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2522.645523]  [<ffffffff81638b39>] schedule_timeout+0x209/0x2d0\r\n[ 2522.645527]  [<ffffffff8109b426>] ? __queue_work+0x136/0x320\r\n[ 2522.645530]  [<ffffffff8109b6da>] ? __queue_delayed_work+0xaa/0x1a0\r\n[ 2522.645534]  [<ffffffff8109ba41>] ? try_to_grab_pending+0xb1/0x160\r\n[ 2522.645538]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2522.645543]  [<ffffffff8163b216>] wait_for_completion+0x116/0x170\r\n[ 2522.645548]  [<ffffffff810b8c30>] ? wake_up_state+0x20/0x20\r\n[ 2522.645552]  [<ffffffff81208987>] sync_inodes_sb+0xb7/0x1e0\r\n[ 2522.645557]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2522.645561]  [<ffffffff8120f8d9>] sync_inodes_one_sb+0x19/0x20\r\n[ 2522.645565]  [<ffffffff811e2182>] iterate_supers+0xb2/0x110\r\n[ 2522.645570]  [<ffffffff8120fb94>] sys_sync+0x44/0xb0\r\n[ 2522.645575]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2642.739175] INFO: task mysqld:6608 blocked for more than 120 seconds.\r\n[ 2642.739228] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2642.739284] mysqld          D 0000000000000000     0  6608   5602 0x00000000\r\n[ 2642.739290]  ffff880feb913da0 0000000000000086 ffff881006eac500 ffff880feb913fd8\r\n[ 2642.739296]  ffff880feb913fd8 ffff880feb913fd8 ffff881006eac500 ffff880fffc8a180\r\n[ 2642.739300]  ffff880fffc8a000 ffff880fffc8a188 ffff880fffc8a028 0000000000000000\r\n[ 2642.739305] Call Trace:\r\n[ 2642.739315]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2642.739340]  [<ffffffffa04744d5>] cv_wait_common+0x125/0x150 [spl]\r\n[ 2642.739345]  [<ffffffff810a6ae0>] ? wake_up_atomic_t+0x30/0x30\r\n[ 2642.739357]  [<ffffffffa0474515>] __cv_wait+0x15/0x20 [spl]\r\n[ 2642.739434]  [<ffffffffa062bd7b>] zil_commit.part.12+0x8b/0x830 [zfs]\r\n[ 2642.739447]  [<ffffffffa046d037>] ? spl_kmem_alloc+0xc7/0x170 [spl]\r\n[ 2642.739460]  [<ffffffffa0475cb4>] ? tsd_set+0x324/0x500 [spl]\r\n[ 2642.739466]  [<ffffffff81639082>] ? mutex_lock+0x12/0x2f\r\n[ 2642.739526]  [<ffffffffa062c537>] zil_commit+0x17/0x20 [zfs]\r\n[ 2642.739587]  [<ffffffffa0621a27>] zfs_fsync+0x77/0xf0 [zfs]\r\n[ 2642.739647]  [<ffffffffa0639665>] zpl_fsync+0x65/0x90 [zfs]\r\n[ 2642.739654]  [<ffffffff8120fa45>] do_fsync+0x65/0xa0\r\n[ 2642.739659]  [<ffffffff8120fd10>] SyS_fsync+0x10/0x20\r\n[ 2642.739665]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2642.739670] INFO: task mysqld:7514 blocked for more than 120 seconds.\r\n[ 2642.739727] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2642.739793] mysqld          D ffff880fb554bda0     0  7514   5602 0x00000000\r\n[ 2642.739798]  ffff880fb554bd30 0000000000000086 ffff880ff4c8f300 ffff880fb554bfd8\r\n[ 2642.739803]  ffff880fb554bfd8 ffff880fb554bfd8 ffff880ff4c8f300 ffff880fb554bdb0\r\n[ 2642.739808]  ffff88107ff8dec0 0000000000000002 ffffffff811f9420 ffff880fb554bda0\r\n[ 2642.739812] Call Trace:\r\n[ 2642.739818]  [<ffffffff811f9420>] ? unlock_two_nondirectories+0x60/0x60\r\n[ 2642.739823]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2642.739826]  [<ffffffff811f942e>] inode_wait+0xe/0x20\r\n[ 2642.739831]  [<ffffffff81638cc0>] __wait_on_bit+0x60/0x90\r\n[ 2642.739839]  [<ffffffff812083bf>] __inode_wait_for_writeback+0xaf/0xf0\r\n[ 2642.739843]  [<ffffffff810a6b60>] ? wake_atomic_t_function+0x40/0x40\r\n[ 2642.739850]  [<ffffffff8120b996>] inode_wait_for_writeback+0x26/0x40\r\n[ 2642.739854]  [<ffffffff811fa135>] evict+0x95/0x170\r\n[ 2642.739857]  [<ffffffff811fa985>] iput+0xf5/0x180\r\n[ 2642.739862]  [<ffffffff811ef41e>] do_unlinkat+0x1ae/0x2b0\r\n[ 2642.739868]  [<ffffffff811e3fe1>] ? SyS_readlinkat+0xd1/0x140\r\n[ 2642.739873]  [<ffffffff811f0426>] SyS_unlink+0x16/0x20\r\n[ 2642.739878]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2642.739897] INFO: task sync:2653 blocked for more than 120 seconds.\r\n[ 2642.739951] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2642.740017] sync            D ffffffff8120f8c0     0  2653   1455 0x00000000\r\n[ 2642.740021]  ffff880ffedd7d50 0000000000000082 ffff880f01449700 ffff880ffedd7fd8\r\n[ 2642.740026]  ffff880ffedd7fd8 ffff880ffedd7fd8 ffff880f01449700 ffff880ffedd7e80\r\n[ 2642.740031]  ffff880ffedd7e88 7fffffffffffffff ffff880f01449700 ffffffff8120f8c0\r\n[ 2642.740036] Call Trace:\r\n[ 2642.740042]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2642.740047]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2642.740051]  [<ffffffff81638b39>] schedule_timeout+0x209/0x2d0\r\n[ 2642.740056]  [<ffffffff8109b426>] ? __queue_work+0x136/0x320\r\n[ 2642.740060]  [<ffffffff8109b6da>] ? __queue_delayed_work+0xaa/0x1a0\r\n[ 2642.740064]  [<ffffffff8109ba41>] ? try_to_grab_pending+0xb1/0x160\r\n[ 2642.740069]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2642.740093]  [<ffffffff8163b216>] wait_for_completion+0x116/0x170\r\n[ 2642.740100]  [<ffffffff810b8c30>] ? wake_up_state+0x20/0x20\r\n[ 2642.740105]  [<ffffffff81208987>] sync_inodes_sb+0xb7/0x1e0\r\n[ 2642.740110]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2642.740116]  [<ffffffff8120f8d9>] sync_inodes_one_sb+0x19/0x20\r\n[ 2642.740121]  [<ffffffff811e2182>] iterate_supers+0xb2/0x110\r\n[ 2642.740127]  [<ffffffff8120fb94>] sys_sync+0x44/0xb0\r\n[ 2642.740134]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2762.834495] INFO: task mysqld:6608 blocked for more than 120 seconds.\r\n[ 2762.834547] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2762.834604] mysqld          D 0000000000000000     0  6608   5602 0x00000000\r\n[ 2762.834609]  ffff880feb913da0 0000000000000086 ffff881006eac500 ffff880feb913fd8\r\n[ 2762.834615]  ffff880feb913fd8 ffff880feb913fd8 ffff881006eac500 ffff880fffc8a180\r\n[ 2762.834619]  ffff880fffc8a000 ffff880fffc8a188 ffff880fffc8a028 0000000000000000\r\n[ 2762.834624] Call Trace:\r\n[ 2762.834634]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2762.834659]  [<ffffffffa04744d5>] cv_wait_common+0x125/0x150 [spl]\r\n[ 2762.834665]  [<ffffffff810a6ae0>] ? wake_up_atomic_t+0x30/0x30\r\n[ 2762.834677]  [<ffffffffa0474515>] __cv_wait+0x15/0x20 [spl]\r\n[ 2762.834748]  [<ffffffffa062bd7b>] zil_commit.part.12+0x8b/0x830 [zfs]\r\n[ 2762.834761]  [<ffffffffa046d037>] ? spl_kmem_alloc+0xc7/0x170 [spl]\r\n[ 2762.834774]  [<ffffffffa0475cb4>] ? tsd_set+0x324/0x500 [spl]\r\n[ 2762.834779]  [<ffffffff81639082>] ? mutex_lock+0x12/0x2f\r\n[ 2762.834843]  [<ffffffffa062c537>] zil_commit+0x17/0x20 [zfs]\r\n[ 2762.834908]  [<ffffffffa0621a27>] zfs_fsync+0x77/0xf0 [zfs]\r\n[ 2762.834971]  [<ffffffffa0639665>] zpl_fsync+0x65/0x90 [zfs]\r\n[ 2762.834978]  [<ffffffff8120fa45>] do_fsync+0x65/0xa0\r\n[ 2762.834983]  [<ffffffff8120fd10>] SyS_fsync+0x10/0x20\r\n[ 2762.834989]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2762.834994] INFO: task mysqld:7514 blocked for more than 120 seconds.\r\n[ 2762.835051] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2762.835118] mysqld          D ffff880fb554bda0     0  7514   5602 0x00000000\r\n[ 2762.835122]  ffff880fb554bd30 0000000000000086 ffff880ff4c8f300 ffff880fb554bfd8\r\n[ 2762.835127]  ffff880fb554bfd8 ffff880fb554bfd8 ffff880ff4c8f300 ffff880fb554bdb0\r\n[ 2762.835132]  ffff88107ff8dec0 0000000000000002 ffffffff811f9420 ffff880fb554bda0\r\n[ 2762.835137] Call Trace:\r\n[ 2762.835143]  [<ffffffff811f9420>] ? unlock_two_nondirectories+0x60/0x60\r\n[ 2762.835148]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2762.835151]  [<ffffffff811f942e>] inode_wait+0xe/0x20\r\n[ 2762.835156]  [<ffffffff81638cc0>] __wait_on_bit+0x60/0x90\r\n[ 2762.835164]  [<ffffffff812083bf>] __inode_wait_for_writeback+0xaf/0xf0\r\n[ 2762.835168]  [<ffffffff810a6b60>] ? wake_atomic_t_function+0x40/0x40\r\n[ 2762.835175]  [<ffffffff8120b996>] inode_wait_for_writeback+0x26/0x40\r\n[ 2762.835179]  [<ffffffff811fa135>] evict+0x95/0x170\r\n[ 2762.835183]  [<ffffffff811fa985>] iput+0xf5/0x180\r\n[ 2762.835188]  [<ffffffff811ef41e>] do_unlinkat+0x1ae/0x2b0\r\n[ 2762.835195]  [<ffffffff811e3fe1>] ? SyS_readlinkat+0xd1/0x140\r\n[ 2762.835199]  [<ffffffff811f0426>] SyS_unlink+0x16/0x20\r\n[ 2762.835205]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2762.835223] INFO: task sync:2653 blocked for more than 120 seconds.\r\n[ 2762.835277] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2762.835343] sync            D ffffffff8120f8c0     0  2653   1455 0x00000000\r\n[ 2762.835348]  ffff880ffedd7d50 0000000000000082 ffff880f01449700 ffff880ffedd7fd8\r\n[ 2762.835352]  ffff880ffedd7fd8 ffff880ffedd7fd8 ffff880f01449700 ffff880ffedd7e80\r\n[ 2762.835357]  ffff880ffedd7e88 7fffffffffffffff ffff880f01449700 ffffffff8120f8c0\r\n[ 2762.835362] Call Trace:\r\n[ 2762.835369]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2762.835374]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2762.835378]  [<ffffffff81638b39>] schedule_timeout+0x209/0x2d0\r\n[ 2762.835382]  [<ffffffff8109b426>] ? __queue_work+0x136/0x320\r\n[ 2762.835386]  [<ffffffff8109b6da>] ? __queue_delayed_work+0xaa/0x1a0\r\n[ 2762.835390]  [<ffffffff8109ba41>] ? try_to_grab_pending+0xb1/0x160\r\n[ 2762.835396]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2762.835409]  [<ffffffff8163b216>] wait_for_completion+0x116/0x170\r\n[ 2762.835417]  [<ffffffff810b8c30>] ? wake_up_state+0x20/0x20\r\n[ 2762.835422]  [<ffffffff81208987>] sync_inodes_sb+0xb7/0x1e0\r\n[ 2762.835427]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2762.835433]  [<ffffffff8120f8d9>] sync_inodes_one_sb+0x19/0x20\r\n[ 2762.835438]  [<ffffffff811e2182>] iterate_supers+0xb2/0x110\r\n[ 2762.835443]  [<ffffffff8120fb94>] sys_sync+0x44/0xb0\r\n[ 2762.835451]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2882.929813] INFO: task mysqld:6608 blocked for more than 120 seconds.\r\n[ 2882.929861] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2882.929913] mysqld          D 0000000000000000     0  6608   5602 0x00000000\r\n[ 2882.929919]  ffff880feb913da0 0000000000000086 ffff881006eac500 ffff880feb913fd8\r\n[ 2882.929924]  ffff880feb913fd8 ffff880feb913fd8 ffff881006eac500 ffff880fffc8a180\r\n[ 2882.929928]  ffff880fffc8a000 ffff880fffc8a188 ffff880fffc8a028 0000000000000000\r\n[ 2882.929932] Call Trace:\r\n[ 2882.929942]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2882.929967]  [<ffffffffa04744d5>] cv_wait_common+0x125/0x150 [spl]\r\n[ 2882.929972]  [<ffffffff810a6ae0>] ? wake_up_atomic_t+0x30/0x30\r\n[ 2882.929983]  [<ffffffffa0474515>] __cv_wait+0x15/0x20 [spl]\r\n[ 2882.930049]  [<ffffffffa062bd7b>] zil_commit.part.12+0x8b/0x830 [zfs]\r\n[ 2882.930059]  [<ffffffffa046d037>] ? spl_kmem_alloc+0xc7/0x170 [spl]\r\n[ 2882.930070]  [<ffffffffa0475cb4>] ? tsd_set+0x324/0x500 [spl]\r\n[ 2882.930075]  [<ffffffff81639082>] ? mutex_lock+0x12/0x2f\r\n[ 2882.930129]  [<ffffffffa062c537>] zil_commit+0x17/0x20 [zfs]\r\n[ 2882.930181]  [<ffffffffa0621a27>] zfs_fsync+0x77/0xf0 [zfs]\r\n[ 2882.930232]  [<ffffffffa0639665>] zpl_fsync+0x65/0x90 [zfs]\r\n[ 2882.930238]  [<ffffffff8120fa45>] do_fsync+0x65/0xa0\r\n[ 2882.930243]  [<ffffffff8120fd10>] SyS_fsync+0x10/0x20\r\n[ 2882.930248]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 4802.367346] perf interrupt took too long (2507 > 2500), lowering kernel.perf_event_max_sample_rate to 50000\r\n\r\nsync process stack:\r\n[<ffffffff81208987>] sync_inodes_sb+0xb7/0x1e0\r\n[<ffffffff8120f8d9>] sync_inodes_one_sb+0x19/0x20\r\n[<ffffffff811e2182>] iterate_supers+0xb2/0x110\r\n[<ffffffff8120fb94>] sys_sync+0x44/0xb0\r\n[<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[<ffffffffffffffff>] 0xffffffffffffffff\r\n\r\nkworker process stack:\r\n cat /proc/3445/stack \r\n[<ffffffffa058feb5>] dmu_zfetch+0x455/0x4f0 [zfs]\r\n[<ffffffffa05711ea>] dbuf_read+0x8ea/0x9f0 [zfs]\r\n[<ffffffffa0591246>] dnode_hold_impl+0xc6/0xc30 [zfs]\r\n[<ffffffffffffffff>] 0xffffffffffffffff\r\n\r\ncat /proc/3445/stack \r\n[<ffffffffffffffff>] 0xffffffffffffffff\r\n[root@ifcos ~]# cat /proc/3445/stack \r\n[<ffffffffa062879c>] zfs_zget+0xfc/0x250 [zfs]\r\n[<ffffffffa0623db7>] zfs_get_data+0x57/0x2d0 [zfs]\r\n[<ffffffffa062c10c>] zil_commit.part.12+0x41c/0x830 [zfs]\r\n[<ffffffffa062c537>] zil_commit+0x17/0x20 [zfs]\r\n[<ffffffffa06394b6>] zpl_writepages+0xd6/0x170 [zfs]\r\n[<ffffffff811759fe>] do_writepages+0x1e/0x40\r\n[<ffffffff812084e0>] __writeback_single_inode+0x40/0x220\r\n[<ffffffff81208f4e>] writeback_sb_inodes+0x25e/0x420\r\n[<ffffffff8120988f>] wb_writeback+0xff/0x2f0\r\n[<ffffffff8120bac5>] bdi_writeback_workfn+0x115/0x460\r\n[<ffffffff8109d5fb>] process_one_work+0x17b/0x470\r\n[<ffffffff8109e3cb>] worker_thread+0x11b/0x400\r\n[<ffffffff810a5aef>] kthread+0xcf/0xe0\r\n[<ffffffff81645e18>] ret_from_fork+0x58/0x90\r\n[<ffffffffffffffff>] 0xffffffffffffffff\r\n\r\n cat /proc/3445/stack \r\n[<ffffffffa058feb5>] dmu_zfetch+0x455/0x4f0 [zfs]\r\n[<ffffffffa0572fd5>] __dbuf_hold_impl+0x135/0x5a0 [zfs]\r\n[<ffffffffffffffff>] 0xffffffffffffffff\r\n\r\n cat /proc/3445/stack \r\n[<ffffffffa056fa69>] dbuf_find+0x1c9/0x1d0 [zfs]\r\n[<ffffffffa0572ee2>] __dbuf_hold_impl+0x42/0x5a0 [zfs]\r\n[<ffffffffffffffff>] 0xffffffffffffffff\r\n\r\n cat /proc/3445/stack \r\n[<ffffffffa058feb5>] dmu_zfetch+0x455/0x4f0 [zfs]\r\n[<ffffffffa0571056>] dbuf_read+0x756/0x9f0 [zfs]\r\n[<ffffffffa0591246>] dnode_hold_impl+0xc6/0xc30 [zfs]\r\n\r\n<!-- \r\n*IMPORTANT* - Please mark logs and text output from terminal commands \r\nor else Github will not display them correctly. \r\nAn example is provided below.\r\n\r\nExample:\r\n```\r\nthis is an example how log text should be marked (wrap it with ```)\r\n```\r\n-->\r\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7038/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "sempervictus": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7035", "title": "Consider adding mitigations for speculative execution related concerns", "body": "GCC should get retpoline support soon, and Intel seems to be proposing kernel code with barriers to speculative execution - https://patchwork.ozlabs.org/cover/856316/. ZFS is already pretty unhappy from KPTI, but since there's a good deal of user controlled data going into it, this might be worth investigating.", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7035/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "abraunegg": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7034", "title": "Missing parameter descriptions in ZFS-Module-Parameters man page", "body": "The following zfs module parameters are missing from the zfs-module-parameters man page (updated 28th Oct 2017) using ZFS 0.7.5:\r\n\r\n* dbuf_cache_hiwater_pct\r\n* dbuf_cache_lowater_pct\r\n* dbuf_cache_max_bytes\r\n* dbuf_cache_max_shift\r\n* dmu_object_alloc_chunk_shift\r\n* send_holes_without_birth_time\r\n* zfs_abd_scatter_enabled\r\n* zfs_abd_scatter_max_order\r\n* zfs_compressed_arc_enabled\r\n* zfs_sync_taskq_batch_pct\r\n\r\nHappy to create a documentation patch for the man pages if someone can send me the a description of what the module parameter is, what the default should be and what valid options are if it is being changed.\r\n\r\nBest regards,\r\n\r\nAlex", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7034/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "rincebrain": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7024", "title": "zfs send -R | zfs recv can fail in the middle due to a snapshot being taken", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Debian\r\nDistribution Version    | 9.3\r\nLinux Kernel                 | 4.9.0-4-amd64\r\nArchitecture                 | amd64\r\nZFS Version                  | 0.7.3-3\r\nSPL Version                  | 0.7.3-1\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing + how to reproduce the problem\r\nWhen doing a long-running `zfs send -R foo/bar/baz@ten | zfs recv -ds newfoo`, an automated utility helpfully took a recursive snapshot on newfoo, and zfs recv abruptly died with `cannot receive incremental stream: kernel modules must be upgraded to receive this stream.` with newfoo/bar/baz having completed snapshots one, ..., seven and throwing that error on attempting to resume.\r\n\r\nI would have expected the in-progress receiving dataset(s) to have remained immutable until the receives were completed, but apparently this isn't the case.\r\n\r\nDestroying the errant snapshot on newfoo/bar/baz allowed the zfs send to proceed like nothing ever happened.\r\n\r\nSince there's already a number of bugs suggesting that this message should be broken out and detailed further (#6547, #6574), this bug is mostly about the fact that nothing is stopping you from shooting yourself in the foot and not being able to discover why without making dramatic leaps or (presumably) reading zfs/dbgmsg.", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7024/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "h1z1": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7015", "title": "Impact of Intel bug (tm) on ZFS", "body": "Maybe the wrong avenue for this but no doubt like others watching the events of the last few days unfold, I've been asked to comment on the impact to ZFS in our environment.   I'm in a rather odd position as I don't really have the hardware to duplicate an entire production silo, running 4.15.x kernel.   I do however know at least 4.14 will bite us as per #6929.  \r\n\r\nHas anyone tested or confirmed what the impact of this will be going forward?  Would rather not duplicate effort if it's already being addressed.\r\n\r\nThanks", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7015/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "sanjeevbagewadi": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7011", "title": "With \"casesensitivity=mixed\" hitting an assert in ZAP code", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | CentOS release 6.8 (Final)\r\n  ---                                  |     --- \r\nDistribution Name       | CentOS\r\nDistribution Version    | 6.8\r\nLinux Kernel                 | 4.4.14-1.el6\r\nArchitecture                 | x86\r\nZFS Version                  | 0.7.1-1\r\nSPL Version                  |  0.7.1-1\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\n\r\nWith casesensitivity=mixed was running the following test :\r\nroot@NTNX-10-5-137-31-A-FSVM:/home/nutanix# cat names.py\r\n#!/usr/bin/python\r\nimport itertools\r\ns=\"abcdefghijklmnopqrstuvwxyz\"\r\nlength = len(s)\r\nnames = map(''.join, itertools.product(*zip(s.upper(), s.lower())))\r\nfor name in names:\r\n    print name\r\n\r\nroot@NTNX-10-5-137-31-A-FSVM:/home/nutanix# ./names.py | while read file\r\n> do\r\n> touch /test/fs2/dir1/$file\r\n> done\r\n\r\nAnd hit the following panic \r\n-- snip --\r\n[    1.068019] VERIFY(!RW_LOCK_HELD(&l->l_rwlock)) failed\r\n[    1.068077] PANIC at zap.c:407:zap_leaf_evict_sync()\r\n[    1.068113] Showing stack for process 67625\r\n[    1.068116] CPU: 0 PID: 67625 Comm: touch Tainted: P           OE   4.4.14-1.el6.nutanix.10272016.x86_64 #1\r\n[    1.068117] Hardware name: Nutanix AHV, BIOS seabios-1.7.5-11.el6 04/01/2014\r\n[    1.068122]  0000000000000000 ffff88015312b2a8 ffffffff81319ae3 0000000000000001\r\n[    1.068125]  0000000100480b8b ffff88015312b2f8 ffffffffa0b5a9c0 ffff88015312b2b8\r\n[    1.068127]  ffffffffa09918c4 ffff88015312b458 ffffffffa0991aeb 0000000000000040\r\n[    1.068129] Call Trace:\r\n[    1.068136]  [<ffffffff81319ae3>] dump_stack+0x67/0x94\r\n[    1.068146]  [<ffffffffa09918c4>] spl_dumpstack+0x44/0x50 [spl]\r\n[    1.068150]  [<ffffffffa0991aeb>] spl_panic+0xcb/0xe0 [spl]\r\n[    1.068153]  [<ffffffff8132a483>] ? __sg_free_table+0x63/0x90\r\n[    1.068157]  [<ffffffff811e447e>] ? kmem_cache_free+0x1ee/0x210\r\n[    1.068160]  [<ffffffffa098d477>] ? spl_kmem_cache_free+0x117/0x140 [spl]\r\n[    1.068200]  [<ffffffffa0a46ecc>] ? arc_hdr_destroy+0x17c/0x1d0 [zfs]\r\n[    1.068231]  [<ffffffffa0acf457>] zap_leaf_evict_sync+0x57/0x60 [zfs]\r\n[    1.068248]  [<ffffffffa0a4d575>] dbuf_evict_user+0x45/0x70 [zfs]\r\n[    1.068265]  [<ffffffffa0a4f95f>] dbuf_destroy+0x4f/0x330 [zfs]\r\n[    1.068282]  [<ffffffffa0a4f561>] dbuf_rele_and_unlock+0x221/0x3e0 [zfs]\r\n[    1.068313]  [<ffffffffa0ad514f>] ? zap_lockdir+0x7f/0xa0 [zfs]\r\n[    1.068344]  [<ffffffffa0ad15e6>] ? zap_grow_ptrtbl+0x186/0x1a0 [zfs]\r\n[    1.068361]  [<ffffffffa0a4f900>] dbuf_rele+0x40/0x50 [zfs]\r\n[    1.068394]  [<ffffffffa0a4fd1e>] dmu_buf_rele+0xe/0x10 [zfs]\r\n[    1.068427]  [<ffffffffa0acf3dd>] zap_put_leaf+0x3d/0x60 [zfs]\r\n[    1.068460]  [<ffffffffa0ad16c7>] zap_put_leaf_maybe_grow_ptrtbl+0xc7/0x130 [zfs]\r\n[    1.068492]  [<ffffffffa0ad1be8>] fzap_add_cd+0xd8/0x130 [zfs]\r\n[    1.068541]  [<ffffffffa0ad4ce4>] mzap_upgrade+0x194/0x210 [zfs]\r\n[    1.068593]  [<ffffffffa0ad4fba>] zap_lockdir_impl+0x25a/0x370 [zfs]\r\n[    1.068628]  [<ffffffffa0ad514f>] zap_lockdir+0x7f/0xa0 [zfs]\r\n[    1.068664]  [<ffffffffa0ad695b>] zap_add+0x5b/0xa0 [zfs]\r\n[    1.068668]  [<ffffffff810ca871>] ? __raw_callee_save___pv_queued_spin_unlock+0x11/0x20\r\n[    1.068703]  [<ffffffffa0adfcbf>] zfs_link_create+0x37f/0x520 [zfs]\r\n[    1.068761]  [<ffffffffa0b00b2a>] zfs_create+0x62a/0x810 [zfs]\r\n[    1.068764]  [<ffffffff811e76f6>] ? __kmalloc_node+0x1f6/0x2b0\r\n[    1.068798]  [<ffffffffa0b19bf2>] zpl_create+0xb2/0x160 [zfs]\r\n[    1.068802]  [<ffffffff81210424>] vfs_create+0xd4/0x100\r\n[    1.068804]  [<ffffffff8120dc4d>] ? lookup_real+0x1d/0x60\r\n[    1.068806]  [<ffffffff812111e3>] lookup_open+0x173/0x1a0\r\n[    1.068808]  [<ffffffff812138d9>] do_last+0x299/0x760\r\n[    1.068811]  [<ffffffff812056d7>] ? get_empty_filp+0xd7/0x1c0\r\n[    1.068813]  [<ffffffff81213e1c>] path_openat+0x7c/0x140\r\n[    1.068832]  [<ffffffff811b53c2>] ? __pte_alloc+0xe2/0x190\r\n[    1.068834]  [<ffffffff81213f65>] do_filp_open+0x85/0xe0\r\n[    1.068836]  [<ffffffff8120eade>] ? getname_flags+0xce/0x1f0\r\n[    1.068838]  [<ffffffff8120311a>] do_sys_open+0x11a/0x220\r\n[    1.068842]  [<ffffffff81003513>] ? syscall_trace_enter_phase1+0x133/0x150\r\n[    1.068844]  [<ffffffff8120325e>] SyS_open+0x1e/0x20\r\n[    1.068850]  [<ffffffff816cf76e>] entry_SYSCALL_64_fastpath+0x12/0x71\r\n-- snip --\r\n\r\n### Describe how to reproduce the problem\r\n\r\nThe following are the steps\\:\r\n- Create zfs dataset with casesensitivity=mixed\r\n- Run the above listed code.\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n<!-- \r\n*IMPORTANT* - Please mark logs and text output from terminal commands \r\nor else Github will not display them correctly. \r\nAn example is provided below.\r\n\r\nExample:\r\n```\r\nthis is an example how log text should be marked (wrap it with ```)\r\n```\r\n-->", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7011/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/7054", "title": "Handle zap_add() failures in \"casesensitivity=mixed\" mode.", "body": "With \"casesensitivity=mixed\", zap_add() could fail when the number of\r\nfiles/directories with the same name (varying in case) exceed the\r\ncapacity of the leaf node of a Fatzap. This results in a ASSERT()\r\nfailure as zfs_link_create() does not expect zap_add() to fail. The fix\r\nis to handle these failures and rollback the transactions.\r\n\r\nSigned-off-by: Sanjeev Bagewadi <sanjeev.bagewadi@gmail.com>\r\n\r\n<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\nFor a dataset with \"casesensitivity=mixed\", when a large number of files/directories\r\nwith same name (varying only in case e.g: ABCD, ABCd, ABcD and so on) are created\r\nzap_add() could fail. With mixed mode zap_add() normalises the names before the hash\r\nis computed. And all the names would generate the same hash and land in the same leaf.\r\nWhen the number of entries exceed the capacity of the leaf-block, zap_add() tries to split\r\nthe leaf-block which fails as well and zap_add() fails. This trips an ASSERT in zfs_link_create()\r\nas it does not expect zap_add() to fail.\r\n\r\nThe fix does the following :\r\n- fzap_add_cd() : Handle the case when zap_expand_leaf() fails with ENOSPC and bailout\r\n   without calling zap_put_leaf_maybe_grow_ptrtbl(). \r\n- zap_add_impl() : When adding to a micro-zap check if the total number of entries\r\n  with colliding/same hash value can fit into fatzap-leaf-block. This is important because, if/when\r\n  the microzap needs to be upgraded to fatzap, all the entries with the same hash would need to\r\n  fit into the same leaf-block (16K). If the number of such entries donot fit fail the zap_add().\r\n  \r\n   The routine mze_canfit_fzap_leaf() today assumes the MZAP_NAME_LEN for every entry.\r\n   This is erring on the safer side but, ends up accommodating lesser number (127) of entries\r\n    with same hash value in microzap. We could find out the size of name of every mze and that\r\n    would be accurate. But, it is expensive to compute the length every time. Alternatively, we\r\n    could compute the length of each entry and cache it. I felt that the amount of code needed\r\n    for this is not worth the gain. I am open to changing it if necessary.\r\n\r\n- zfs_link_create() : Move the call to zap_add() to the beginning and in case of a failure\r\n  return. This ensures that we can bailout easily before making any other modifications to\r\n  the parent-zap or the child-dnode. Keeps the code simpler.\r\n- ZPL interfaces (zfs_create(), zfs_mkdir(), zfs_symlink()) : Handle the failure of zfs_link_create()\r\n  and rollback the operation.\r\n\r\nWith these changes a call to create a file could fail with ENOSPC. Not the best error value.\r\nBut, this is the closest I found. Any alternate suggestions are welcome.\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\nWith \"casesensitivity=mixed\" it is easy to panic the node with a simple test case\r\nas described in https://github.com/zfsonlinux/zfs/issues/7011\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\nThe following tests were run : \r\n- zfs-testsuite\r\n- ztest\r\n- Unit-test described in the #7011 \r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [x] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "woffs": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7003", "title": "autoreplace = on, but spare not automatically activated on drive error", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Debian\r\nDistribution Version    | Stretch (9)\r\nLinux Kernel                 | 4.9.51\r\nArchitecture                 | x86_64\r\nZFS Version                  | 0.7.3\r\nSPL Version                  | 0.7.3\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\n \r\nA disk was failing, zed reported errors ...\r\n\r\n```\r\nZFS has detected that a device was removed.\r\n\r\n impact: Fault tolerance of the pool may be compromised.\r\n    eid: 71656\r\n  class: statechange\r\n  state: REMOVED\r\n   host: inferno\r\n   time: 2017-12-29 19:57:19+0100\r\n  vpath: /dev/disk/by-vdev/E2-part1\r\n  vguid: 0x8F23CA44FDEBE82C\r\n   pool: 0x83BBC476EFE065A2\r\n```\r\n\r\n```\r\nThe number of I/O errors associated with a ZFS device exceeded\r\nacceptable levels. ZFS has marked the device as faulted.\r\n\r\n impact: Fault tolerance of the pool may be compromised.\r\n    eid: 71662\r\n  class: statechange\r\n  state: FAULTED\r\n   host: inferno\r\n   time: 2017-12-29 19:57:19+0100\r\n  vpath: /dev/disk/by-vdev/E2-part1\r\n  vguid: 0x8F23CA44FDEBE82C\r\n   pool: 0x83BBC476EFE065A2\r\n```\r\n\r\n... but the spare was not activated automatically, although the autoreplace property was set to `on`.\r\n\r\n```\r\n        inferno# zpool status\r\n  [...]\r\n                pool: torx\r\n         state: DEGRADED\r\n        status: One or more devices are faulted in response to persistent errors.\r\n                Sufficient replicas exist for the pool to continue functioning in a\r\n                degraded state.\r\n        action: Replace the faulted device, or use 'zpool clear' to mark the device\r\n                repaired.\r\n                scan: scrub repaired 0B in 188h32m with 0 errors on Sun Dec 17 20:56:54 2017\r\n        config:\r\n\r\n                NAME        STATE     READ WRITE CKSUM\r\n                torx        DEGRADED     0     0     0\r\n                        raidz2-0  DEGRADED     0     0     0\r\n                                E0      ONLINE       0     0     0\r\n                                E1      ONLINE       0     0     0\r\n                                E2      FAULTED      0     0     0  too many errors\r\n                                E3      ONLINE       0     0     0\r\n                                E4      ONLINE       0     0     0\r\n                                E5      ONLINE       0     0     0\r\n                                E6      ONLINE       0     0     0\r\n                                E7      ONLINE       0     0     0\r\n                                E8      ONLINE       0     0     0\r\n                                E9      ONLINE       0     0     0\r\n                spares\r\n                        EA        AVAIL\r\n\r\n        errors: No known data errors\r\n```\r\n\r\nAfter manually issuing `zpool replace torx E2 EA` the resilver to the spare started.\r\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7003/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "krichter722": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7002", "title": "\"VERIFY3(range_tree_space(rt) == space) failed\" after I/O freeze", "body": "### System information\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Ubuntu\r\nDistribution Version    | 17.10\r\nLinux Kernel                 | 4.13.0-21-generic\r\nArchitecture                 | amd64\r\nZFS Version                  | 0.7.0-227_g823d48bfb\r\nSPL Version                  | 0.7.0-22_gc9821f1c\r\n\r\n### Describe the problem you're observing\r\nMy pool consisting of 1 HDD vdev and 1 SSD cache and 1 SSD log device experienced an I/O freeze under heavy load including heavy dedup action (parallel checkout and building of Firefox on docker images) where all commands doing I/O on the pool switched to uninterruptible state and no I/O occured anymore according to `iotop`.\r\n\r\nAfter starting the machine again I'm no longer able to import the pool because the `zpool import` command never returns and after a few seconds of reading a few 100 MB the I/O stops and the stack below is printed in `dmesg`.\r\n\r\nA readonly import is possible. `zfs set mountpoint=none data/docker` fails due to `internal error: out of memory` immediately without any noticable memory issues.\r\n\r\n### Describe how to reproduce the problem\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\nThe I/O freeze was caused by\r\n\r\n```\r\n[27969.280956] VERIFY3(range_tree_space(rt) == space) failed (6922371072 == 6922383360)\r\n[27969.280960] PANIC at space_map.c:127:space_map_load()\r\n[27969.280961] Showing stack for process 13639\r\n[27969.280963] CPU: 5 PID: 13639 Comm: z_wr_iss Tainted: P        W  OE   4.13.0-21-generic #24-Ubuntu\r\n[27969.280964] Hardware name: LENOVO 20221/INVALID, BIOS 71CN51WW(V1.21) 07/12/2013\r\n[27969.280964] Call Trace:\r\n[27969.280970]  dump_stack+0x63/0x8b\r\n[27969.280979]  spl_dumpstack+0x42/0x50 [spl]\r\n[27969.280982]  spl_panic+0xc8/0x110 [spl]\r\n[27969.280985]  ? kmem_cache_free+0x197/0x1c0\r\n[27969.280988]  ? avl_add+0x65/0xb0 [zavl]\r\n[27969.281027]  ? rt_avl_add+0x11/0x20 [zfs]\r\n[27969.281054]  ? range_tree_add_impl+0x2f5/0x440 [zfs]\r\n[27969.281078]  ? dnode_rele+0x39/0x40 [zfs]\r\n[27969.281108]  space_map_load+0x470/0x4f0 [zfs]\r\n[27969.281109]  ? avl_nearest+0x2b/0x30 [zavl]\r\n[27969.281136]  metaslab_load+0x36/0xf0 [zfs]\r\n[27969.281162]  metaslab_activate+0x93/0xc0 [zfs]\r\n[27969.281186]  metaslab_alloc+0x4b9/0x1170 [zfs]\r\n[27969.281217]  zio_dva_allocate+0xac/0x630 [zfs]\r\n[27969.281245]  ? zio_execute+0x8a/0xf0 [zfs]\r\n[27969.281274]  ? vdev_config_sync+0x180/0x180 [zfs]\r\n[27969.281301]  ? vdev_mirror_io_start+0xa4/0x180 [zfs]\r\n[27969.281305]  ? tsd_hash_search.isra.3+0x47/0xa0 [spl]\r\n[27969.281308]  ? tsd_get_by_thread+0x2e/0x40 [spl]\r\n[27969.281311]  ? taskq_member+0x18/0x30 [spl]\r\n[27969.281340]  zio_execute+0x8a/0xf0 [zfs]\r\n[27969.281343]  taskq_thread+0x2aa/0x4d0 [spl]\r\n[27969.281345]  ? wake_up_q+0x80/0x80\r\n[27969.281373]  ? zio_reexecute+0x3e0/0x3e0 [zfs]\r\n[27969.281375]  kthread+0x125/0x140\r\n[27969.281378]  ? taskq_thread_should_stop+0x70/0x70 [spl]\r\n[27969.281379]  ? kthread_create_on_node+0x70/0x70\r\n[27969.281382]  ret_from_fork+0x25/0x30\r\n```\r\nwhich I captured before having to shutdown the machine with the power button. After every reboot the import fails due to\r\n\r\n```\r\n[  274.685568]  dump_stack+0x63/0x8b\r\n[  274.685575]  spl_dumpstack+0x42/0x50 [spl]\r\n[  274.685578]  spl_panic+0xc8/0x110 [spl]\r\n[  274.685581]  ? kmem_cache_free+0x197/0x1c0\r\n[  274.685583]  ? avl_add+0x65/0xb0 [zavl]\r\n[  274.685619]  ? rt_avl_add+0x11/0x20 [zfs]\r\n[  274.685645]  ? range_tree_add_impl+0x2f5/0x440 [zfs]\r\n[  274.685667]  ? dnode_rele+0x39/0x40 [zfs]\r\n[  274.685694]  space_map_load+0x470/0x4f0 [zfs]\r\n[  274.685720]  metaslab_load+0x36/0xf0 [zfs]\r\n[  274.685743]  metaslab_activate+0x93/0xc0 [zfs]\r\n[  274.685766]  metaslab_alloc+0x4b9/0x1170 [zfs]\r\n[  274.685794]  zio_dva_allocate+0xac/0x630 [zfs]\r\n[  274.685795]  ? mutex_lock+0x12/0x40\r\n[  274.685799]  ? tsd_hash_search.isra.3+0x47/0xa0 [spl]\r\n[  274.685802]  ? tsd_get_by_thread+0x2e/0x40 [spl]\r\n[  274.685805]  ? taskq_member+0x18/0x30 [spl]\r\n[  274.685832]  zio_execute+0x8a/0xf0 [zfs]\r\n[  274.685835]  taskq_thread+0x2aa/0x4d0 [spl]\r\n[  274.685837]  ? wake_up_q+0x80/0x80\r\n[  274.685864]  ? zio_reexecute+0x3e0/0x3e0 [zfs]\r\n[  274.685865]  kthread+0x125/0x140\r\n[  274.685869]  ? taskq_thread_should_stop+0x70/0x70 [spl]\r\n[  274.685870]  ? kthread_create_on_node+0x70/0x70\r\n[  274.685871]  ret_from_fork+0x25/0x30\r\n```\r\nalso after a successful readonly import.", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7002/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "redzhang1990": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6995", "title": "Can ZFS support numa binding?", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Redhat\r\nDistribution Version    | 7.4\r\nLinux Kernel                 | 4.11.0\r\nArchitecture                 | ARM\r\nZFS Version                  | 0.7.1\r\nSPL Version                  | 0.7.1\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\nCan the ZFS support or willing support numa binding?\r\n### Describe how to reproduce the problem\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n<!-- \r\n*IMPORTANT* - Please mark logs and text output from terminal commands \r\nor else Github will not display them correctly. \r\nAn example is provided below.\r\n\r\nExample:\r\n```\r\n```\r\n-->\r\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6995/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "fejesjoco": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6994", "title": "Documentation of ACLs should be fixed", "body": "There are issues in the manpage of zfs(8).\r\n\r\naclinherit talks about ACEs, acltype talks about ACLs, this is inconsistent.\r\n\r\naclinherit doesn't mention what kind of ACEs it's talking about. Since neither regular file permission bits not POSIX ACLs have write_acl/write_owner, this must be NFSv4. So that should be mentioned here explicitly.\r\n\r\nacltype has two values. Again this doesn't say what it's talking about and one can only guess. Does \"off\" turn off both NFSv4 and POSIX ACLs, or just POSIX? Does \"posixacl\" enable both NFSv4 and POSIX, or only POSIX? I can even read it in a way that I can either have POSIX ACLs or no ACLs, which would mean NFSv4 ACLs are not even supported under Linux.\r\n\r\nThe source code has many mentions of an aclmode property but this is not documented anywhere.\r\n\r\nSince the document talks about multiple ACL types, it might be worth mentioning if regular file permission bits work as usual or not (this is especially interesting across dataset mount boundaries).\r\n\r\nIf you can confirm these points, I can volunteer to send a PR.", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6994/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "dechamps": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6988", "title": "zil_itx_needcopy_bytes kstat counter is corrupted", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Debian\r\nDistribution Version    | Unstable\r\nLinux Kernel                 | 4.13.0-1-amd64\r\nArchitecture                 | amd64\r\nZFS Version                  | 0.7.3-3\r\nSPL Version                  | 0.7.3-1\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\n\r\n```\r\n$ cat /proc/spl/kstat/zfs/zil\r\n15 1 0x01 13 624 31503034653 382758011634377\r\nname                            type data\r\nzil_commit_count                4    197902\r\nzil_commit_writer_count         4    197884\r\nzil_itx_count                   4    611431070\r\nzil_itx_indirect_count          4    0\r\nzil_itx_indirect_bytes          4    0\r\nzil_itx_copied_count            4    0\r\nzil_itx_copied_bytes            4    0\r\nzil_itx_needcopy_count          4    611266365\r\nzil_itx_needcopy_bytes          4    18446744072731425348\r\nzil_itx_metaslab_normal_count   4    0\r\nzil_itx_metaslab_normal_bytes   4    0\r\nzil_itx_metaslab_slog_count     4    1169526\r\nzil_itx_metaslab_slog_bytes     4    140983216376\r\n```\r\n\r\nThe `zil_itx_needcopy_bytes` counter is blatantly wrong - I'm pretty sure I did not write 16 exabytes of data in that pool :) Its value is quite close to `UINT64_MAX`, which suggests some kind of overflow or memory corruption.\r\n\r\n### Describe how to reproduce the problem\r\n\r\nNot sure. However I can tell that it started after I did a system upgrade, which included the following version changes:\r\n\r\n- Kernel: 4.12 \u2192 4.13\r\n- SPL: 0.6.5 \u2192 0.7.3\r\n- ZFS: 0.6.5 \u2192 0.7.3\r\n\r\nFor this reason I suspect this might be a regression introduced between SPL/ZFS 0.6.5 and SPL/ZFS 0.7.3.\r\n\r\nThis issue might seem benign, but in my case it's really not because it prevents [Prometheus Node exporter](https://github.com/prometheus/node_exporter) from exporting ZFS metrics correctly. Here's the log message from the node exporter in an attempt to make this issue easier to search for:\r\n\r\n```\r\ntime=\"2017-12-20T22:32:39Z\" level=error msg=\"ERROR: zfs collector failed after 0.000693s: could not parse expected integer value for \\\"kstat.zfs.misc.zil.zil_itx_needcopy_bytes\\\"\" source=\"node_exporter.go:95\"\r\n```", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6988/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374490", "body": "Hmmm\u2026 in fact this line is supposed to be in pull request #384. Seems like I seriously screwed up while doing the merges: all my pull requests show the same commits. What a mess\u2026 git is new to me, I guess this was bound to happen. There should be only one commit in this pull request: 90e1b2108f3b8fd3d2b92bdaa4775fe2321cffa3, so if you're just interested in ZVOL synchronicity, you should check it out. I'm not sure how to fix this, I guess I'll have to recreate the pull requests.\n\nFYI, in the context of #384, this comment means that maybe the discard operation should be added to the log. This is not very important since losing discard operations cannot result in data corruption.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374490/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374498", "body": "That's what I did, basically; the problem is, when updating my master branch from upstream I guessed it would be a good idea to also update individual pull request branches from my master branch. Alas, it was a very bad idea, because my master branch add commits from all my pull requests, so by merging master into each pull request, I merged all commits from all pull requests into each pull request, hence the mess. In the future I'll just let my pull requests alone when I'm done with them.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374498/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374511", "body": "I never commited anything to my master branch, just merges. I wrote the pull request's code into the appropriate pull request branches, as I should. The issue is, I was merging master into my pull requests without realizing what I was doing. The solution is to stop doing that. I just emailed Brian so that we decide what to do about the already messed up pull requests.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374511/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}, "ScaMar": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6985", "title": "\"space map refcount mismatch\" on never used zpool after reboot", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       |  Ubuntu\r\nDistribution Version    |  LTS 16.04.03\r\nLinux Kernel                 |  4.4.0-104-generic\r\nArchitecture                 |  x86_64\r\nZFS Version                  |  0.6.5.6\r\nSPL Version                  |  0.6.5.6\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\n\r\nHi all,\r\non my live zpool i've found the \"space map refcount mismatch\" (error? warning?).\r\nBecause the pool wasn't too big, i've copied data on an external storage, so i've destroyes the zpool then i've recreated it.\r\nI've execute \"zdb <pool>\" and it was ok. After the first reboot (no data were copied/created on zpool), i've executed \"zdb <pool>\" again and i've found the message \"space map refcount mismatch\".\r\n\r\nI've destroyed - recreated the pool several times, always i got the \"space map refcount mismatch\".\r\nEach time before reboot i've tried something like \"zfs unmount <pool>\".\r\nI think the message is related to the first zpool.cache creation.\r\nAfter i've deleted the zpool.cache, the error was not present after the reboot.\r\n\r\nSo my problem are these lines in the zdb output:\r\n```\r\nspace map refcount mismatch: expected 11 != actual 5\r\n```\r\n\r\n### Describe how to reproduce the problem\r\nInstall Ubuntu 16.04. Update it. Create a zpool. Reboot.\r\n\r\n### Questions, considerations, any suggestions?\r\nAbout such issue, i have some questions:\r\n\r\n1) Is it something i need to worry about?\r\n2) Is there a way to recalculate/rebuild space map?\r\n\r\nThere are similar issues about such message someone wrote \"It is a problem in claiming empty space\", some other wrote \"This situation may lead to data corruption\", \"Ignore it if the delta beetwen refcount and space is fixed (if not?)\".\r\nMay we have a clear/human about the consequencies of this error / warning?\r\n\r\nThe only think i know, and sincerily i don't understand a single line (my fault, i'm not a coder), this is the line of code where the counts are compared:\r\n```\r\nstatic int\r\nverify_spacemap_refcounts(spa_t *spa)\r\n{\r\n\tuint64_t expected_refcount = 0;\r\n\tuint64_t actual_refcount;\r\n\r\n\t(void) feature_get_refcount(spa,\r\n\t    &spa_feature_table[SPA_FEATURE_SPACEMAP_HISTOGRAM],\r\n\t    &expected_refcount);\r\n\tactual_refcount = get_dtl_refcount(spa->spa_root_vdev);\r\n\tactual_refcount += get_metaslab_refcount(spa->spa_root_vdev);\r\n\r\n\tif (expected_refcount != actual_refcount) {\r\n\t\t(void) printf(\"space map refcount mismatch: expected %lld != \"\r\n\t\t    \"actual %lld\\n\",\r\n\t\t    (longlong_t)expected_refcount,\r\n\t\t    (longlong_t)actual_refcount);\r\n\t\treturn (2);\r\n\t}\r\n\treturn (0);\r\n}\r\n```\r\nPlease let me know if i must worry about this, so i can evaluate other ways to achieve my personal storage:\r\n1) linux with btrfs\r\n2) OpenIndiana/FreeBSD with ZFS\r\n3) Old but stable md / lvm / xfs (i will risk the cosmic ray bitrotter...)\r\n\r\nThank you,\r\nMarco\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n<!-- \r\n*IMPORTANT* - Please mark logs and text output from terminal commands \r\nor else Github will not display them correctly. \r\nAn example is provided below.\r\n\r\nExample:\r\n```\r\nthis is an example how log text should be marked (wrap it with ```)\r\n```\r\n-->\r\n\r\n\r\n[zdbout.newcreated.txt](https://github.com/zfsonlinux/zfs/files/1571863/zdbout.newcreated.txt)\r\n[zdbout.firstreboot.txt](https://github.com/zfsonlinux/zfs/files/1571864/zdbout.firstreboot.txt)\r\n```\r\nHistory for 'magazzino':\r\n2017-12-19.13:28:20 zpool create magazzino mirror /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K0KA3UYK /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K7NF5E20\r\n2017-12-19.13:28:21 zpool add magazzino mirror /dev/disk/by-id/ata-WDC_WD30EFRX-68EUZN0_WD-WCC4N7UUHR2X /dev/disk/by-id/ata-WDC_WD30EFRX-68EUZN0_WD-WCC4N3CHVS8X\r\n2017-12-19.13:28:22 zpool add magazzino cache /dev/disk/by-id/ata-KINGSTON_SUV400S37120G_50026B77720127CB-part5 /dev/disk/by-id/ata-KINGSTON_SUV400S37120G_50026B776B0175F0-part5\r\n2017-12-19.13:28:22 zpool add magazzino log mirror /dev/disk/by-id/ata-KINGSTON_SUV400S37120G_50026B77720127CB-part6 /dev/disk/by-id/ata-KINGSTON_SUV400S37120G_50026B776B0175F0-part6\r\n2017-12-19.13:28:22 zfs create magazzino/video\r\n2017-12-19.13:28:22 zfs create magazzino/foto\r\n2017-12-19.13:28:23 zfs create magazzino/owncloud\r\n2017-12-19.13:28:29 zpool scrub magazzino\r\n```\r\n--> deleted /etc/zfs/zpool.cache\r\n--> reboot\r\n```\r\n2017-12-19.13:31:24 zpool import -d /dev/disk/by-id -aN\r\n```\r\n--> new reboot withouth deleting zpool.cache\r\n```\r\n2017-12-19.13:37:03 zpool import -c /etc/zfs/zpool.cache -aN\r\n```\r\n--> another reboot withouth deleting zpool.cache\r\n```\r\n2017-12-19.13:41:01 zpool import -c /etc/zfs/zpool.cache -aN\r\n```\r\n\r\n\r\n\r\n\r\n\r\n\r\n ", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6985/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "samis": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6984", "title": "zpool property 'freeing' partially stuck", "body": "### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Gentoo\r\nDistribution Version    | Profile 17.0\r\nLinux Kernel                 | 4.14.5-gentoo\r\nArchitecture                 | X86_64\r\nZFS Version                  | 0.7.0-211_g4e9b1569\r\nSPL Version                  | 0.7.0-21_ged19bcc\r\n\r\n\r\n### Describe the problem you're observing\r\nI recently decided to clean up and delete two unused sparse zvols. After this, the freeing property increased as expected and did initially decrease. However, it's almost 24 hours (and two reboots) later and the property is still reporting the exact same value. \r\n\r\nAs a test, I filled a zvol with 1G of /dev/urandom and then destroyed it. The property increased from it's original value of 14353956864 to 14605664256 but shortly afterwards the data was freed and the value was back to 14353956864. This is similar to #5808 but both the scenario and the behaviour appear to be different, as neither zvol was ever used for NFS purposes.\r\n### Describe how to reproduce the problem\r\nI have not yet reproduced this beyond the above test. I can't be certain that the freeing value was correct before, but the timing seems right for this issue.\r\n### Include any warning/errors/backtraces from the system logs\r\nSo far there have been no warnings, errors or backtraces created as a result of this problem. \r\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6984/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "kithrup": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/43cb30b3ce6ee3c3041276c93594ae61e7daaf86", "message": "OpenZFS 8959 - Add notifications when a scrub is paused or resumed\n\nAuthored by: Sean Eric Fagan <sef@ixsystems.com>\nReviewed by: Alek Pinchuk <pinchuk.alek@gmail.com>\nReviewed by: Matthew Ahrens <mahrens@delphix.com>\nReviewed-by: George Melikov <mail@gmelikov.ru>\nReviewed-by: Tony Hutter <hutter2@llnl.gov>\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\nApproved by: Gordon Ross <gwr@nexenta.com>\nPorted-by: Giuseppe Di Natale <dinatale2@llnl.gov>\n\nPorting Notes:\n- Brought #defines in eventdefs.h in line with ZFS on Linux format.\n- Updated zfs-events.5 with the new events.\n\nOpenZFS-issue: https://www.illumos.org/issues/8959\nOpenZFS-commit: https://github.com/openzfs/openzfs/commit/c862b93eea\nCloses #7049"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "DeHackEd": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/d658b2caa95726c13d99123874910cdedc7ce866", "message": "Remove l2arc_nocompress from zfs-module-parameters(5)\n\nParameter was removed in d3c2ae1c0806\r\n(OpenZFS 6950 - ARC should cache compressed data)\r\n\r\nReviewed by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: DHE <git@dehacked.net>\r\nCloses #7043"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/460f239e6999195dbcf9b8443c029f07765b21e9", "message": "Fix -fsanitize=address memory leak\n\nkmem_alloc(0, ...) in userspace returns a leakable pointer.\n\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\nSigned-off-by: DHE <git@dehacked.net>\nIssue #6941"}], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6673", "title": "Fail importing if cached config has wrong number of vdev children", "body": "During import compare the labels' configs with the import config\r\nand fail if the labels indicate more vdevs than the cached config\r\n\r\nSigned-off-by: DHE <git@dehacked.net>\r\nFixes #6671\r\n\r\n### Description\r\nWhen the zpool.cache says `vdev_children=X` but the pool actually has `vdev_children=Y` where `X<Y`, blkptr errors will occur during the import process. We detect this specific case and refuse imports from this cache file.\r\n\r\n### Motivation and Context\r\nSee #6671\r\n\r\n### How Has This Been Tested?\r\n`ztest` only\r\n\r\n### Types of changes\r\n- [X] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n- [X] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [ ] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [X] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "prometheanfire": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/c10cdcb55f81ea773486161b31bc91bb7b58b4c8", "message": "Fix copy-builtin to work with ASAN patch\n\nCommit fed90353 didn't fully update the copy-builtin script\r\nas needed to perform in-kernel builds.  Add the missing\r\noptions and flags.\r\n\r\nReviewed by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: Matthew Thode <mthode@mthode.org>\r\nCloses #7033 \r\nCloses #7037"}], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/7008", "title": "DNM: make zfs-mount service work with encryption", "body": "", "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/7004", "title": "Run zfs load-key if needed in dracut", "body": "'zfs load-key -a' will only be called if needed.  If a dataset not\r\nneeded for boot does not have it's key loaded (home directories for\r\nexample) boot can still continue.", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "yuripv": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/6df9f8ebd73c05da627144bcc3823e6fe980cd75", "message": "OpenZFS 8899 - zpool list property documentation doesn't match actual behaviour\n\nAuthored by: Yuri Pankov <yuri.pankov@nexenta.com>\nReviewed by: Alexander Pyhalov <alp@rsu.ru>\nReviewed-by: George Melikov <mail@gmelikov.ru>\nApproved by: Dan McDonald <danmcd@joyent.com>\nPorted-by: Brian Behlendorf <behlendorf1@llnl.gov>\n\nOpenZFS-issue: https://www.illumos.org/issues/8899\nOpenZFS-commit: https://github.com/openzfs/openzfs/commit/b0e142e57d\nCloses #7032"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/bcb1a8a25e4ee9a94478378710de53b45a9b1517", "message": "OpenZFS 8898 - creating fs with checksum=skein on the boot pools fails ungracefully\n\nAuthored by: Yuri Pankov <yuri.pankov@nexenta.com>\nReviewed by: Toomas Soome <tsoome@me.com>\nReviewed by: Andy Stormont <astormont@racktopsystems.com>\nReviewed-by: George Melikov <mail@gmelikov.ru>\nApproved by: Dan McDonald <danmcd@joyent.com>\nPorted-by: Brian Behlendorf <behlendorf1@llnl.gov>\n\nOpenZFS-issue: https://www.illumos.org/issues/8898\nOpenZFS-commit: https://github.com/openzfs/openzfs/commit/9fa2266d9a\nCloses #7031"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/8198c57b21d5e503f7e72221aa714aaabb2079cc", "message": "OpenZFS 8897 - zpool online -e fails assertion when run on non-leaf vdevs\n\nAuthored by: Yuri Pankov <yuri.pankov@nexenta.com>\nReviewed by: Toomas Soome <tsoome@me.com>\nReviewed by: Igor Kozhukhov <igor@dilos.org>\nReviewed-by: George Melikov <mail@gmelikov.ru>\nApproved by: Dan McDonald <danmcd@joyent.com>\nPorted-by: Brian Behlendorf <behlendorf1@llnl.gov>\n\nOpenZFS-issue: https://www.illumos.org/issues/8897\nOpenZFS-commit: https://github.com/openzfs/openzfs/commit/9a551dd645\nCloses #7030"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "avg-I": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/6a2185660d000c99b14556c7eb1108c5609faf41", "message": "OpenZFS 8930 - zfs_zinactive: do not remove the node if the filesystem is readonly\n\nAuthored by: Andriy Gapon <avg@FreeBSD.org>\nReviewed by: Matthew Ahrens <mahrens@delphix.com>\nReviewed-by: George Melikov <mail@gmelikov.ru>\nApproved by: Gordon Ross <gwr@nexenta.com>\nPorted-by: Brian Behlendorf <behlendorf1@llnl.gov>\n\nOpenZFS-issue: https://www.illumos.org/issues/8930\nOpenZFS-commit: https://github.com/openzfs/openzfs/commit/93c618e0f4\nCloses #7029"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ryao": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/1d53657bf561564162e2ad6449f80fa0140f1dd6", "message": "Fix incompatibility with Reiser4 patched kernels\n\nIn ZFSOnLinux, our sources and build system are self contained such that\r\nwe do not need to make changes to the Linux kernel sources. Reiser4 on\r\nthe other hand exists solely as a kernel tree patch and opts to make\r\nchanges to the kernel rather than adapt to it. After Linux 4.1 made a\r\nVFS change that replaced new_sync_read with do_sync_read, Reiser4's\r\nmaintainer decided to modify the kernel VFS to export the old function.\r\nThis caused our autotools check to misidentify the kernel API as\r\npredating Linux 4.1 on kernels that have been patched with Reiser4\r\nsupport, which breaks our build.\r\n\r\nReiser4 really should be patched to stop doing this, but lets modify our\r\ncheck to be more strict to help the affected users of both filesystems.\r\n\r\nAlso, we were not checking the types of arguments and return value of\r\nnew_sync_read() and new_sync_write() . Lets fix that too.\r\n\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nReviewed-by: Giuseppe Di Natale <dinatale2@llnl.gov>\r\nReviewed-by: George Melikov <mail@gmelikov.ru>\r\nSigned-off-by: Richard Yao <ryao@gentoo.org>\r\nCloses #6241 \r\nCloses #7021"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "nwf": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/cba6fc61a2898395c47380a0c2303f19842a2ff0", "message": "Revert raidz_map and _col structure types\n\nAs part of the refactoring of ab9f4b0b824ab4cc64a4fa382c037f4154de12d6,\r\nseveral uint64_t-s and uint8_t-s were changed to other types.  This\r\ncaused ZoL github issue #6981, an overflow of a size_t on a 32-bit ARM\r\nmachine.  In absense of any strong motivation for the type changes, this\r\nsimply puts them back, modulo the changes accumulated for ABD.\r\n\r\nCompile-tested on amd64 and run-tested on armhf.\r\n\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nReviewed-by: Gvozden Neskovic <neskovic@gmail.com>\r\nSigned-off-by: Nathaniel Wesley Filardo <nwf@cs.jhu.edu>\r\nCloses #6981 \r\nCloses #7023"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/8b20a9f996b90abe439ce14303fc440f26390e38", "message": "zhack: fix getopt return type\n\nThis fixes zhack's command processing on ARM.  On ARM char\r\nis unsigned, and so, in promotion to an int, it will never\r\ncompare equal to -1.\r\n\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: Nathaniel Wesley Filardo <nwf@cs.jhu.edu>\r\nCloses #7016"}], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6209", "title": "[RFC] new zscrub command for offline scrubs in userland", "body": "### Description\r\n\r\nThis PR adds a \"zhack scrub\" subcommand which, in user-land, finds and scrubs a pool.  This has proven useful for experimenting with the scan logic (especially the in-order-scrub patches) without having to reload the kernel module and seems like it may be useful to others.\r\n\r\nAt this point, it is not yet ready to merge -- there are no tests, no docs, &c... but I am curious for anyone's commentary and/or suggestions. :)\r\n\r\n### How Has This Been Tested?\r\n\r\nLimited testing against both files and actual block-device-backed pools.  Scrubs and resilvers appear to work just fine.\r\n\r\n### Types of changes\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [ ] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "gamanakis": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/be54a13c3e7db423ffdb3f7983d4dd1141cc94a0", "message": "Fix percentage styling in zfs-module-parameters.5\n\nReplace \"percent\" with \"%\", add bold to default values.\r\n\r\nReviewed-by: bunder2015 <omfgbunder@gmail.com>\r\nReviewed-by: George Melikov <mail@gmelikov.ru>\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: George Amanakis <gamanakis@gmail.com>\r\nCloses #7018"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "loli10K": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/390d679acdfa6a2498280a4dcd33b7600ace27ce", "message": "Fix 'zpool add' handling of nested interior VDEVs\n\nWhen replacing a faulted device which was previously handled by a spare\r\nmultiple levels of nested interior VDEVs will be present in the pool\r\nconfiguration; the following example illustrates one of the possible\r\nsituations:\r\n\r\n   NAME                          STATE     READ WRITE CKSUM\r\n   testpool                      DEGRADED     0     0     0\r\n     raidz1-0                    DEGRADED     0     0     0\r\n       spare-0                   DEGRADED     0     0     0\r\n         replacing-0             DEGRADED     0     0     0\r\n           /var/tmp/fault-dev    UNAVAIL      0     0     0  cannot open\r\n           /var/tmp/replace-dev  ONLINE       0     0     0\r\n         /var/tmp/spare-dev1     ONLINE       0     0     0\r\n       /var/tmp/safe-dev         ONLINE       0     0     0\r\n   spares\r\n     /var/tmp/spare-dev1         INUSE     currently in use\r\n\r\nThis is safe and allowed, but get_replication() needs to handle this\r\nsituation gracefully to let zpool add new devices to the pool.\r\n\r\nReviewed-by: George Melikov <mail@gmelikov.ru>\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: loli10K <ezomori.nozomu@gmail.com>\r\nCloses #6678 \r\nCloses #6996"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/c4ba46deade0a14d089228a56a5d0aa0ffd5fadd", "message": "Handle invalid options in arc_summary\n\nIf an invalid option is provided to arc_summary.py we handle any error\r\nthrown from the getopt Python module and print the usage help message.\r\n\r\nReviewed-by: George Melikov <mail@gmelikov.ru>\r\nReviewed-by: Giuseppe Di Natale <dinatale2@llnl.gov>\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: loli10K <ezomori.nozomu@gmail.com>\r\nCloses #6983"}], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/7058", "title": "Fix Debian packaging on ARMv7/ARM64", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\n\r\nWhen building packages on Debian-based systems specify the target architecture used by `alien` to convert .rpm packages into .deb: this avoids detecting an incorrect value which results in the following errors:\r\n\r\n```\r\n<package>.aarch64.rpm is for architecture aarch64 ; the package cannot be built on this system\r\n<package>.armv7l.rpm is for architecture armel ; the package cannot be built on this system\r\n```\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\nFix https://github.com/zfsonlinux/zfs/issues/7046\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\nTested on a local aarch64 and armhf debootstrapped rootfs\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "prakashsurya": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/2fe61a7ecc507d031451c21b3077fae549b58ec3", "message": "OpenZFS 8909 - 8585 can cause a use-after-free kernel panic\n\nAuthored by: Prakash Surya <prakash.surya@delphix.com>\nReviewed by: John Kennedy <jwk404@gmail.com>\nReviewed by: Matthew Ahrens <mahrens@delphix.com>\nReviewed by: George Wilson <george.wilson@delphix.com>\nReviewed by: Brad Lewis <brad.lewis@delphix.com>\nReviewed by: Igor Kozhukhov <igor@dilos.org>\nReviewed by: Brian Behlendorf <behlendorf1@llnl.gov>\nApproved by: Robert Mustacchi <rm@joyent.com>\nPorted-by: Prakash Surya <prakash.surya@delphix.com>\n\nPROBLEM\n=======\n\nThere's a race condition that exists if `zil_free_lwb` races with either\n`zil_commit_waiter_timeout` and/or `zil_lwb_flush_vdevs_done`.\n\nHere's an example panic due to this bug:\n\n    > ::status\n    debugging crash dump vmcore.0 (64-bit) from ip-10-110-205-40\n    operating system: 5.11 dlpx-5.2.2.0_2017-12-04-17-28-32b6ba51fb (i86pc)\n    image uuid: 4af0edfb-e58e-6ed8-cafc-d3e9167c7513\n    panic message:\n    BAD TRAP: type=e (#pf Page fault) rp=ffffff0010555970 addr=60 occurred in module \"zfs\" due to a NULL pointer dereference\n    dump content: kernel pages only\n\n    > $c\n    zio_shrink+0x12()\n    zil_lwb_write_issue+0x30d(ffffff03dcd15cc0, ffffff03e0730e20)\n    zil_commit_waiter_timeout+0xa2(ffffff03dcd15cc0, ffffff03d97ffcf8)\n    zil_commit_waiter+0xf3(ffffff03dcd15cc0, ffffff03d97ffcf8)\n    zil_commit+0x80(ffffff03dcd15cc0, 9a9)\n    zfs_write+0xc34(ffffff03dc38b140, ffffff0010555e60, 40, ffffff03e00fb758, 0)\n    fop_write+0x5b(ffffff03dc38b140, ffffff0010555e60, 40, ffffff03e00fb758, 0)\n    write+0x250(42, fffffd7ff4832000, 2000)\n    sys_syscall+0x177()\n\nIf there's an outstanding lwb that's in `zil_commit_waiter_timeout`\nwaiting to timeout, waiting on it's waiter's CV, we must be sure not to\ncall `zil_free_lwb`. If we end up calling `zil_free_lwb`, then that LWB\nmay be freed and can result in a use-after-free situation where the\nstale lwb pointer stored in the `zil_commit_waiter_t` structure of the\nthread waiting on the waiter's CV is used.\n\nA similar situation can occur if an lwb is issued to disk, and thus in\nthe `LWB_STATE_ISSUED` state, and `zil_free_lwb` is called while the\ndisk is servicing that lwb. In this situation, the lwb will be freed by\n`zil_free_lwb`, which will result in a use-after-free situation when the\nlwb's zio completes, and `zil_lwb_flush_vdevs_done` is called.\n\nThis race condition is prevented in `zil_close` by calling `zil_commit`\nbefore `zil_free_lwb` is called, which will ensure all outstanding (i.e.\nall lwb's in the `LWB_STATE_OPEN` and/or `LWB_STATE_ISSUED` states)\nreach the `LWB_STATE_DONE` state before the lwb's are freed\n(`zil_commit` will not return untill all the lwb's are\n`LWB_STATE_DONE`).\n\nFurther, this race condition is prevented in `zil_sync` by only calling\n`zil_free_lwb` for lwb's that do not have their `lwb_buf` pointer set.\nAll lwb's not in the `LWB_STATE_DONE` state will have a non-null value\nfor this pointer; the pointer is only cleared in\n`zil_lwb_flush_vdevs_done`, at which point the lwb's state will be\nchanged to `LWB_STATE_DONE`.\n\nThis race *is* present in `zil_suspend`, leading to this bug.\n\nAt first glance, it would appear as though this would not be true\nbecause `zil_suspend` will call `zil_commit`, just like `zil_close`, but\nthe problem is that `zil_suspend` will set the zilog's `zl_suspend`\nfield prior to calling `zil_commit`. Further, in `zil_commit`, if\n`zl_suspend` is set, `zil_commit` will take a special branch of logic\nand use `txg_wait_synced` instead of performing the normal `zil_commit`\nlogic.\n\nThis call to `txg_wait_synced` might be good enough for the data to\nreach disk safely before it returns, but it does not ensure that all\noutstanding lwb's reach the `LWB_STATE_DONE` state before it returns.\nThis is because, if there's an lwb \"stuck\" in\n`zil_commit_waiter_timeout`, waiting for it's lwb to timeout, it will\nmaintain a non-null value for it's `lwb_buf` field and thus `zil_sync`\nwill not free that lwb. Thus, even though the lwb's data is already on\ndisk, the lwb will be left lingering, waiting on the CV, and will\neventually timeout and be issued to disk even though the write is\nunnecessary.\n\nSo, after `zil_commit` is called from `zil_suspend`, we incorrectly\nassume that there are not outstanding lwb's, and proceed to free all\nlwb's found on the zilog's lwb list. As a result, we free the lwb that\nwill later be used `zil_commit_waiter_timeout`.\n\nSOLUTION\n========\n\nThe solution to this, is to ensure all outstanding lwb's complete before\ncalling `zil_free_lwb` via `zil_destroy` in `zil_suspend`. This patch\naccomplishes this goal by forcing the normal `zil_commit` logic when\ncalled from `zil_sync`.\n\nNow, `zil_suspend` will call `zil_commit_impl` which will always use the\nnormal logic of waiting/issuing lwb's to disk before it returns. As a\nresult, any lwb's outstanding when `zil_commit_impl` is called will be\nguaranteed to reach the `LWB_STATE_DONE` state by the time it returns.\n\nFurther, no new lwb's will be created via `zil_commit` since the zilog's\n`zl_suspend` flag will be set. This will force all new callers of\n`zil_commit` to use `txg_wait_synced` instead of creating and issuing\nnew lwb's.\n\nThus, all lwb's left on the zilog's lwb list when `zil_destroy` is\ncalled will be in the `LWB_STATE_DONE` state, and we'll avoid this race\ncondition.\n\nOpenZFS-issue: https://www.illumos.org/issues/8909\nOpenZFS-commit: https://github.com/openzfs/openzfs/commit/ece62b6f8d\nCloses #6940"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "lidongyang": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/823d48bfb182137c53b9432498f1f0564eaa8bfc", "message": "Call commit callbacks from the tail of the list\n\nOur zfs backed Lustre MDT had soft lockups while under heavy metadata\r\nworkloads while handling transaction callbacks from osd_zfs.\r\n\r\nThe problem is zfs is not taking advantage of the fast path in\r\nLustre's trans callback handling, where Lustre will skip the calls\r\nto ptlrpc_commit_replies() when it already saw a higher transaction\r\nnumber.\r\n\r\nThis patch corrects this, it also has a positive impact on metadata\r\nperformance on Lustre with osd_zfs, plus some cleanup in the headers.\r\n\r\nA similar issue for ext4/ldiskfs is described on:\r\nhttps://jira.hpdd.intel.com/browse/LU-6527\r\n\r\nReviewed-by: Olaf Faaland <faaland1@llnl.gov>\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: Li Dongyang <dongyang.li@anu.edu.au>\r\nCloses #6986"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "tcaputi": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/44b61ea506212c287333e03d2cf8933216810800", "message": "Remove empty files accidentally added by a8b2e306 \n\nThis patch simply removes 2 empty files that were accidentally\r\nadded a part of the scrub priority patch.\r\n\r\nReviewed-by: George Melikov <mail@gmelikov.ru>\r\nReviewed-by: Giuseppe Di Natale <dinatale2@llnl.gov>\r\nSigned-off-by: Tom Caputi <tcaputi@datto.com>\r\nCloses #6990"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/a8b2e30685c9214ccfd0181977540e080340df4e", "message": "Support re-prioritizing asynchronous prefetches\n\nWhen sequential scrubs were merged, all calls to arc_read()\r\n(including prefetch IOs) were given ZIO_PRIORITY_ASYNC_READ.\r\nUnfortunately, this behaves badly with an existing issue where\r\nprefetch IOs cannot be re-prioritized after the issue. The\r\nresult is that synchronous reads end up in the same vdev_queue\r\nas the scrub IOs and can have (in some workloads) multiple\r\nseconds of latency.\r\n\r\nThis patch incorporates 2 changes. The first ensures that all\r\nscrub IOs are given ZIO_PRIORITY_SCRUB to allow the vdev_queue\r\ncode to differentiate between these I/Os and user prefetches.\r\nSecond, this patch introduces zio_change_priority() to provide\r\nthe missing capability to upgrade a zio's priority.\r\n\r\nReviewed by: George Wilson <george.wilson@delphix.com>\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: Tom Caputi <tcaputi@datto.com>\r\nCloses #6921 \r\nCloses #6926"}], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6864", "title": "Encryption and Raw Send Stability Improvements", "body": "The current on-disk format for encrypted datasets protects\r\nnot only the encrypted and authenticated blocks, but also\r\nthe order and interpretation of these blocks. In order to\r\nmake this work while maintaining the ability to do raw sends\r\nthe indirect bps maintain a secure checksum of all the MACs\r\nin the block below it, along with a few other fields that\r\ndetermine how the data is interpretted.\r\n\r\nUnfortunately, the current on-disk format erroniously\r\nincludes some fields which are not portable and thus cannot\r\nsupport raw sends. It is also not possible to easily work\r\naround this issue due to a separate and much smaller bug\r\nwhich causes indirect blocks for encrypted dnodes to not\r\nbe compressed, which conflicts with the previous bug. In\r\naddition, raw send streams do not currently include\r\ndn_maxblkid which is needed in order to ensure that we are\r\ncorrectly maintaining the portable objset MAC.\r\n\r\nThis patch zero's out the offending fields when computing the\r\nbp MAC (as they should have been) and registers an errata for\r\nthe on-disk format bug. We detect the errata by adding a\r\n\"version\" field to newly created DSL Crypto Keys. We allow\r\ndatasets without a version (version 0) to only be mounted for\r\nread so that they can easily be migrated. We also now include\r\ndn_maxblkid in raw send streams to ensure the MAC can be\r\nmaintained correctly.\r\n\r\nNote that this fix has not yet been finalized and should not be used until it is tested, reviewed, and merged unless you are ok with losing your data.\r\n\r\nSigned-off-by: Tom Caputi <tcaputi@datto.com>\r\n\r\n### How Has This Been Tested?\r\nI have added a new test for raw sends that essentially stresses as many edge cases as I could think of. In addition, I have manually tested that the recovery process laid out in https://github.com/zfsonlinux/zfsonlinux.github.com/pull/35 works as advertised, and that both old and new datasets function predictably.\r\n\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [x] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [x] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "tesujimath": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/993669a7bf17a26843630c547999be0b27483497", "message": "vdev_id: new slot type ses\n\nThis extends vdev_id to support a new slot type, ses, for SCSI Enclosure\r\nServices.  With slot type ses, the disk slot numbers are determined by\r\nusing the device slot number reported by sg_ses for the device with\r\nmatching SAS address, found by querying all available enclosures.\r\n\r\nThis is primarily of use on systems with a deficient driver omitting\r\nsupport for bay_identifier in /sys/devices.  In my testing, I found that\r\nthe existing slot types of port and id were not stable across disk\r\nreplacement, so an alternative was required.\r\n\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: Simon Guest <simon.guest@tesujimath.org>\r\nCloses #6956"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "dinatale2": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/89a66a0457cd392ab8c6ad6d9c138fedaa425067", "message": "Handle broken pipes in arc_summary\n\nUsing a command similar to 'arc_summary.py | head' causes\r\na broken pipe exception. Gracefully exit in the case of a\r\nbroken pipe in arc_summary.py.\r\n\r\nReviewed-by: Richard Elling <Richard.Elling@RichardElling.com>\r\nReviewed-by: loli10K <ezomori.nozomu@gmail.com>\r\nSigned-off-by: Giuseppe Di Natale <dinatale2@llnl.gov>\r\nCloses #6965 \r\nCloses #6969"}], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6906", "title": "Add dbuf hash and dbuf cache kstats", "body": "### Description\r\n<!--- Describe your changes in detail -->\r\nIntroduce kstats about the dbuf hash and dbuf cache\r\nto make it easier to inspect state. This should help\r\nwith debugging and understanding of these portions\r\nof the codebase.\r\n\r\nCorrect format of dbuf kstat file.\r\n\r\nIntroduce a dbc column to dbufs kstat to indicate if\r\na dbuf is in the dbuf cache.\r\n\r\nIntroduce field filtering in the dbufstat python script.\r\n\r\nI will also be introducing some basic test cases to test the new dbufstats kstat and other basic scenarios.\r\n\r\n<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\nGain a better understanding how dbufs are cached and provide another useful tool for users/developer.\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\nLocally on a VM.\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [x] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6294", "title": "Enforce request limits on zvols", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\nCurrently, zvols do not handle heavy random IO\r\nworkloads. zvols should limit the number of outstanding\r\nin-flight IO requests. This should improve performance.\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n#6127 \r\n#6278 \r\n\r\n### How Has This Been Tested?\r\nBuilds on my VM. Buildbot will help me test. Hoping to test on hardware soon.\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [x] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "MEMBER"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "avw1987": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/7055", "title": "Update README.initramfs.markdown", "body": "Fixed a typo\r\n\r\n<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [x] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [ ] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [ ] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "tonyhutter": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/7051", "title": "zfs-0.7.6 patchset", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\nTest 0.7.6 patchset in buildbot\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [ ] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [ ] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "MEMBER"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "sckobras": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/7007", "title": "Allow to limit zed's syslog chattiness", "body": "### Description\r\n\r\nSome usage patterns like send/recv of replication streams can\r\nproduce a large number of events. In such a case, the current\r\nall-syslog.sh zedlet will hold up to its name, and flood the\r\nlogs with mostly redundant information. To mitigate this\r\nsituation, this changeset introduces two new variables\r\nZED_SYSLOG_SUBCLASS_INCLUDE and ZED_SYSLOG_SUBCLASS_EXCLUDE\r\nto zed.rc that give more control over which event classes end\r\nup in the syslog.\r\n\r\nSigned-off-by: Daniel Kobras <d.kobras@science-computing.de>\r\nCloses: #6886\r\n\r\n### Motivation and Context\r\nIt seems that each time a dataset that also uses =zfs-auto-snapshot= is replicated, a =history_event= for the =com.sun:auto-snapshot-desc= property in each snapshot is logged. This easily spams the logs with thousands of redundant, and rather useless messages as described in #6886, so adding a facility to trim down the noise without disabling the syslog feature altogether seems to be in order.\r\n\r\n### How Has This Been Tested?\r\nTested on EL7.4 with ZoL 0.7.2.\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [x] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "aerusso": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6974", "title": "fstab integration", "body": "Generate a tracked, updateable section in /etc/fstab for zfs filesystems\r\n\r\n### Description\r\nA contrib script fstab-generator is implemented that creates a trackable section in /etc/fstab (or another user-specified file) with fstab syntax reflecting the zfs mount and canmount parameters.\r\n\r\n### Motivation and Context\r\nWhile #4943 implements a per-pool granular import, the user will still \"need to add an entry like this in fstab:\r\n\r\n```rpool/home /home zfs rw,defaults,x-systemd.requires=zpool@rpool.service```\r\n\r\nThis script performs precisely that mechanical task, allowing for filesystem dependencies to be correctly identified, and mounted in time to guarantee their availability. A monolithic import of all zfs filesystems is not required to have system files on native zfs mountpoints. \r\n\r\nMoreover, by including this information in /etc/fstab, tools can fail appropriately if essential mountpoints are unavailable. This helps address the common annoyance where zfs fails to mount an important system directory, files then get placed on the zfs mountpoint, and then zfs will fail to mount on the subsequent boot (because overlay=off) even though the underlying problem was corrected. \r\n\r\n#### Why not a systemd-generator?\r\nBesides the obvious lack of integration for users without systemd, other tools may rely on /etc/fstab to determine what filesystems are present on a system. This approach immediately achieves integration with those tools--e.g., for analogous dependency tracking for other init systems that may develop in the future. Additionally, systemd generators may change syntax in the future, but they will have to remain compatible with /etc/fstab.\r\n\r\n### How Has This Been Tested?\r\nI'm running with the output of this script on a machine that has several `/var/` directories, and `/tmp` with purely zfs mountpoints.\r\n\r\n### RFC\r\nThis is a work in progress.\r\n1. Should this be converted to fstab-generator.in, and use `%sbindir%`, etc?\r\n2. Should this name be changed? Should this be installed elsewhere?\r\n3. How could/should this be integrated with the rest of the tools?\r\n4. Is there some reason `mount -ozfsutil` is ill-advised for zfs filesystems?\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6964", "title": "Use zfs-import.target in contrib/dracut", "body": "### Description\r\nThe new zfs-import.target should be used in place of the zfs-import-*.service units in `contrib/dracut`.\r\n\r\n### Motivation and Context\r\nPR #6764 added `zfs-import.target` to simplify dependency on pool importing. #6822 did some cleanup. The recent #6955 (re: #6953) added RPM support for enabling this units. That bug report has prompted me to grep the code base for zfs-import. The last remaining code section to be updated is under `control/dracut/90zfs`.\r\n\r\nThis PR is  a **work in progress**. I don't think dracut users are exposed to any bug presently, because `sysroot.mount` is still ordered `After=zfs-import-*.service`\r\n\r\nTwo files are affected:\r\n1. `zfs-generator.sh.in` is straightforwardly modified to order `sysroot.mount` `After=zfs-import.target` (instead of each `zfs-import-*.service`). \r\n2. `module-setup.sh.in` is also modified. **I need input, because I don't know how precisely dracut works.** `zfs-import.target` (and each `zfs-import-*.service`) is `dracut_install`-ed (and *unconditionally* `mark_hostonly`-ed). Do we need to build a `zfs-import.target.wants` directory with `zfs-import-*.service` links? Or will that be inherited from the host system?\r\n\r\n### How Has This Been Tested?\r\nThis has NOT been tested. This is a place to centralize discussion about these changes.\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [x] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "dweeezil": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6900", "title": "OpenZFS 7614 - zfs device evacuation/removal", "body": "### Description\r\n<!--- Describe your changes in detail -->\r\nThis project allows top-level vdevs to be removed from the storage pool\r\nwith \"zpool remove\", reducing the total amount of storage in the pool.\r\nThis operation copies all allocated regions of the device to be removed\r\nonto other devices, recording the mapping from old to new location.\r\nAfter the removal is complete, read and free operations to the removed\r\n(now \"indirect\") vdev must be remapped and performed at the new location\r\non disk.  The indirect mapping table is kept in memory whenever the pool\r\nis loaded, so there is minimal performance overhead when doing\r\noperations on the indirect vdev.\r\n\r\nThe size of the in-memory mapping table will be reduced when its entries\r\nbecome \"obsolete\" because they are no longer used by any block pointers\r\nin the pool.  An entry becomes obsolete when all the blocks that use it\r\nare freed.  An entry can also become obsolete when all the snapshots\r\nthat reference it are deleted, and the block pointers that reference it\r\nhave been \"remapped\" in all filesystems/zvols (and clones).  Whenever an\r\nindirect block is written, all the block pointers in it will be\r\n\"remapped\" to their new (concrete) locations if possible.  This process\r\ncan be accelerated by using the \"zfs remap\" command to proactively\r\nrewrite all indirect blocks that reference indirect (removed) vdevs.\r\n\r\nNote that when a device is removed, we do not verify the checksum of the\r\ndata that is copied.  This makes the process much faster, but if it were\r\nused on redundant vdevs (i.e. mirror or raidz vdevs), it would be\r\npossible to copy the wrong data, when we have the correct data on e.g.\r\nthe other side of the mirror.  Therefore, mirror and raidz devices can\r\nnot be removed.\r\n\r\n### Motivation and Context\r\nSee above.\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\n### How Has This Been Tested?\r\nAdditions to the test suite in functional/removal.\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "MEMBER"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "scotws": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6892", "title": "Add Python 3 rewrite of arc_summary.py (#6873)", "body": "### Description\r\n\r\nAdd new Python 3 script `arc_summary3.py` as a complete rewrite of `arc_summary.py` to display basic information on the ARC status and various other parameters. This is provided in addition - not as a replacement - to the existing `arc_summary.py` tool. See #6873 for a discussion of the reasoning behind adding a new version of this tool while keeping a legacy version as well.\r\n\r\nNew options:\r\n\r\n        -g/--graph    - Display crude graphic representation of ARC status and quit\r\n        -r/--raw      - Print all available information as minimally formatted list and quit\r\n        -s/--section  - Print a single section. This supersedes -p/--page, which is kept for\r\n                        backwards use but marked as DEPRECIATED\r\n\r\nAdds new sections with information on the ZIL and SPL. \r\n\r\nWe now notify the user if sections L2ARC and VDEV are skipped instead of failing silently; note VDEV caching is currently disabled and slated for possible removal (see source code). Adds information on the ZFS and SPL versions to the header.\r\n\r\nThe **-s/--section** option is intended to replace the page number system, which required the user to remember which page number was of interest. The -p/--page options are still supported, but marked as DEPRECIATED. Current legal sections are `arc archits dmu l2arc spl tunables vdev zil`. It should be easier now to add and modify sections.\r\n\r\nThe **-r/--raw** option is intended to work with other tools such as `grep`. It respects the -a/-d options (alternate output format / descriptions included) where possible. \r\n\r\nThe output of the **-g/--graph** option is intended to give a quick, rough overview as a visual orientation. An example (Ubuntu 16.04 LTS x86_64 with 24 GB RAM, 8 GB ARC max, ZFS stock version 0.6.5.9-2 with `/home` as ZFS mirror pool immediately after starting _Civilization VI_ on Steam on otherwise quiet machine): \r\n```\r\n        ARC: 3.0 GiB (37.5 %)  MFU: 610.5 MiB  MRU: 2.3 GiB\r\n    +----------------------------------------------------------+\r\n    |FFFFRRRRRRRRRRRRRRRRR                                     |\r\n    +----------------------------------------------------------+\r\n```\r\n`F` is for MFU, `R` for MRU, and `O` is used for \"other\" if necessary (not present in this example). \r\n\r\n`arc_summary3.py` was developed for Python 3.5. This follows the version of Python currently installed in Ubuntu 16.04 LTS. Few systems will have Python 3.6 installed yet.\r\n\r\n### Known issues\r\n\r\nThe new script is based on the same internal logic as the original, so any error or issue present there will probably show up here as well. For instance, the number of anonymous hits can be negative the way it is calculated in both scripts; they both simply hide any negative value.\r\n\r\nThis script will probably make a bunch of test suites unhappy where Python 3 is not included. There is no experience with this script under extreme conditions (for example ARC throttling).\r\n\r\n### How Has This Been Tested?\r\n\r\nThere is a unittest script `test_arc_summary3.py` at https://gist.github.com/scotws/aaf5d9c9317081e249b664a371ec4907\r\nMost testing was done in-tree, comparing the output to that of the current `arc_summary.py` version.\r\n\r\nThe L2ARC section has **not seen any real-world use** because I do not have access to a L2ARC device on my machine.\r\n\r\n### Other \r\n\r\nSwitching to Python 3 results in a noticeably smaller file size despite the addition of several new features. Output of `wc` for both scripts:\r\n```\r\n    837    2586   28021 arc_summary3.py\r\n   1020    2593   35538 arc_summary.py\r\n```\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [ ] I have read the **CONTRIBUTING** document.\r\n- [x] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "Blub": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6865", "title": "user namespace bugfixes and features", "body": "This series can be seen as 4 separate \"chunks\":\r\n\r\nChunk 1: setgid mode bugfix & regression test:\r\n* Patch 1 fixes the main issue.\r\n* Patch 2 adds a helper for running user namespace tests. Currently uses a fixed\r\n  user id range. (I saw no reason for anything more complex than that.)\r\n* Patch 3 adds a regression test for the issue fixed in patch 1.\r\n\r\nChunk 2: mounting from user namespaces (RFC):\r\n* Patch 4 is an RFC useful for when a user can have a mount namespace (usually\r\n  in combination with user namespaces. Eg. giving `zfs allow`ing create+mount\r\n  permissions to a container.\r\n* Patch 5 is necessary when including the third chunk but is otherwise there\r\n  since it made writing the test case of patch 6 more convenient.\r\n* Patch 6 tests create+mount permissions with user namespaces.\r\n\r\nChunk 3: mapping user ids when using zfs allow from within user namespaces.\r\n* Patch 7 causes `ZFS_IOC_GET_FSACL` and `ZFS_IOC_SET_FSACL` to perform user id\r\n  mapping (as well as checking!) on the sent/received data. Otherwise root in a\r\n  user namespace would not be able to run `zfs allow` with the user IDs as seen\r\n  from within its namespace, but would have to perform the mapping to real IDs.\r\n  This is also what easily enables users to create allow entries for user IDs\r\n  which do not exist in the host namespace's `/etc/passwd` and therefore would\r\n  show up empty and indistinguishable to the host (making patch 5 a\r\n  requirement).\r\n\r\nChunk 4: change the 'unallow' check:\r\n* Patch 8 allows users who have CAP_SYS_ADMIN in the current namespace (iow.\r\n  root in containers) to remove permissions of others if they're also allowed\r\n  to add the permission.\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements. (at least according to `make checkstyle`)\r\n- [ ] I have updated the documentation accordingly. (not yet)\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [x] I have added tests to cover my changes.\r\n- [x] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ironMann": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6568", "title": "[wip][test] Prefetch dmu", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\nRun testers\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [ ] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [ ] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6107", "title": "LOCK tracking: disable tracking of ARC and dbuf hashmap locks (16384 mutexes)", "body": "Test for zfsonlinux/spl#587\r\n\r\nRequires-spl: refs/pull/587/head\r\n\r\n### Description\r\nDisable tracking of per-bucket locks.\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [ ] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "MEMBER"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "don-brady": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6558", "title": "OpenZFS 7431 - ZFS Channel Programs", "body": "Authored by: Chris Williamson <chris.williamson@delphix.com>\r\nReviewed by: Matthew Ahrens <mahrens@delphix.com>\r\nReviewed by: George Wilson <george.wilson@delphix.com>\r\nReviewed by: John Kennedy <john.kennedy@delphix.com>\r\nReviewed by: Dan Kimmel <dan.kimmel@delphix.com>\r\nApproved by: Garrett D'Amore <garrett@damore.org>\r\nPorted-by: Don Brady <don.brady@delphix.com>\r\nPorted-by: John Kennedy <john.kennedy@delphix.com>\r\n\r\nOpenZFS-issue: https://www.illumos.org/issues/7431\r\nOpenZFS-commit: https://github.com/openzfs/openzfs/commit/dfc11533\r\n\r\nPorting Notes:\r\n* The CLI long option arguments for '-t' and '-m' don't parse on linux\r\n* Switched from kmem_alloc to vmem_alloc in zcp_lua_alloc\r\n* Lua implementation is built as its own module (zlua.ko)\r\n* Lua headers consumed directly by zfs code moved to 'include/sys/lua/'\r\n* There is no native setjmp/longjump available in stock Linux kernel.  Brought over implementation from illumos and FreeBSD\r\n* The get_temporary_prop() was adapted due to VFS platform differences\r\n* Use of in-lining functions in lua parser code to reduce stack usage per nested C call\r\n\r\n### How Has This Been Tested?\r\n#### Manual tests\r\n- running basic get-props channel programs from CLI\r\n- exercised the zfs property get CLI with the envr *ZFS_PROP_DEBUG=1* set\r\n#### Automated tests\r\n- ztest runs that exercise the new ZCP destroy snapshots path\r\n- new ZTS channel_program functional tests\r\n\r\n### Types of changes\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [x] I have added tests to cover my changes.\r\n- [x] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "MEMBER"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "dong-liuliu": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6546", "title": "Use Multi-buffer sha256 support from SPL", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\nLet sha256 checksum using multi-buffer api if it is exported by SPL\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n Using multi-buffer type, performance of sha256 will be increased 2~7 times.\r\nNow a patch for multi-buffer sha256 facility in kernel space is implemented and submitted to SPL.\r\nIts userspace facility and sha512 parts will be following up after this patch is reviewed and commented.\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\nRun FIO sequential write test, on Intel Xeon server (Haswell E5-2699 v3, 18 core), with 6x SSD :\r\n\r\nSha256 | CPU-sys% | BW(MB/s)\r\n-- | -- | --\r\nmulti-buffer version | 27 | 1859\r\nicp version | 71 | 1876\r\n\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [x] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ahrens": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6536", "title": "diff and bookmark enhancements", "body": "\r\n<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\nThis PR includes 3 related features that work well together:\r\n\r\n`zfs diff -a` shows which specific blocks were modified\r\n\r\n`zfs diff` from a bookmark (but it can't show renamed files)\r\n\r\n`zfs bookmark` from a filesystem, creating a bookmark which represents current point in time.  Not useful for `zfs send`, but can be used with `zfs diff`.\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\nThis makes `zfs diff` useful in more situations.  For example, to find which blocks in a database or VDI file were changed.\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n\r\nManual testing only at this point.  I'd like to add test cases to the test suite, but there aren't any tests for \"zfs diff\" at all, so it seems strange to add tests for just the new functionality I'm adding.  I'm open to input on what should be required for this PR.\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [x] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ofaaland": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6479", "title": "Merge SPL into ZFS [WIP]", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\nMerge the SPL into ZFS to eliminate the extra work required when SPL code must change due to kernel or distro changes, and to simplify the build process.\r\n\r\nWork In Progress.\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [x] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [ ] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "Nasf-Fan": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6290", "title": "Project Quota on ZFS", "body": "Project quota is a new ZFS system space/object usage accounting\r\nand enforcement mechanism. Similar as user/group quota, project\r\nquota is another dimension of system quota. It bases on the new\r\nobject attribute - project ID.\r\n\r\nProject ID is a numerical value to indicate to which project an\r\nobject belongs. An object only can belong to one project though\r\nyou (the object owner or privileged user) can change the object\r\nproject ID that can be set/modified via 'chattr -p' explicitly,\r\nor inherited from its parent object when created if such parent\r\nhas the project inherit flag (via 'chattr +P').\r\n\r\nBy accounting the spaces/objects belong to the same project, we\r\ncan know how many spaces/objects used by the project. And if we\r\nset the upper limit then we can control the spaces/objects that\r\nare consumed by such project. It is useful when multiple groups\r\nand users cooperate for the same project, or when an user/group\r\nneeds to participate in multiple projects.\r\n\r\nSupport the following commands and functionalities:\r\n\r\nzfs set projectquota@project\r\nzfs set projectobjquota@project\r\n\r\nzfs get projectquota@project\r\nzfs get projectobjquota@project\r\nzfs get projectused@project\r\nzfs get projectobjused@project\r\n\r\nzfs projectspace\r\n\r\nzfs allow projectquota\r\nzfs allow projectobjquota\r\nzfs allow projectused\r\nzfs allow projectobjused\r\n\r\nzfs unallow projectquota\r\nzfs unallow projectobjquota\r\nzfs unallow projectused\r\nzfs unallow projectobjused\r\n\r\nchattr +/-P\r\nchattr -p project_id\r\nlsattr -p\r\n\r\nSigned-off-by: Fan Yong <fan.yong@intel.com>\r\nChange-Id: Ib4f0544602e03fb61fd46a849d7ba51a6005693c\r\n\r\n<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [x] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "tuxoko": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6277", "title": "[WIP] Add pool prop `partition` to disable auto partition", "body": "### Description\r\n\r\nzfsonlinux always partition disk when it detects the device given is a\r\nwhole disk. This legacy behavior from Illumos, however, has no apparent\r\nbenefit on Linux, but has some down sides besides confusion. E.g.\r\nautoexpand, switching to dm device requires partprobe.\r\n\r\nWe add a pool property `partition` to be set during pool create. It\r\ncurrently has two values, legacy and raw. When setting it to legacy, it\r\nwill behave as it did. When setiing it to raw, it will always use the\r\ndevice as is without partitioning even if it's a whole disk.\r\n\r\nThis property applies to all commands that add disks to pool, so zpool\r\nadd/attach/replace will partition or not partition based on the property\r\non the target pool.\r\n    \r\nA pool without this property will be treated as legacy. Newly created\r\npool will by default have partition=legacy.\r\n\r\nSigned-off-by: Chunwei Chen <david.chen@osnexus.com>\r\n\r\n### Note\r\n\r\nI use PROP_ONETIME for the property, but it seems that this is not enforced at all, so you can still modify it after the fact. But you shouldn't change it after the fact, as it would cause device name appending wrong.", "author_association": "MEMBER"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "inkdot7": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6078", "title": "Metadata classes wip no accounting", "body": "Please ignore this PR.\r\nI just want to see how the metadata allocation classes behave if the special accounting is removed.  (Which would allow the small-block-size limit to be changed after creation more easily.)\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "n1kl": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/5929", "title": "Quality of service for ZFS + improvement through compression", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\nAs part of my master thesis at University of Hamburg I have targeted to improve ZFS through compression. Now I would like to share my 3 feature branches with the community.\r\n\r\n1. lz4fast #5927 \r\n2. autocompression #5928 \r\n3. qos (current)\r\n### Description\r\n<!--- Describe your changes in detail -->\r\nThis patch adds quality of service to ZFS datasets.\r\nzfs set compression=qos-[10,20,30,40,50,+50*n,1000]\r\nThe chosen value sets the throughput in MB/s.\r\nLow values will result in better compression ratio but less throughput.\r\n\r\n### Motivation1\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\nQuality of service is an important aspect in dealing with limited resources.\r\nAt the moment the user can control storage requirement by choosing a compression algorithm like gzip for high compression. Depending on the hardware and the current CPU load the performance might be either poor or well.\r\nBy using the qos compression feature the desired write throughput can be chosen to meet the requirement for the application.\r\nThe qos algorithm keeps track of the compression speed and chooses either lz4 or gzip-[1-9] to speed up / slow down while compressing data. \r\n\r\n<!--- ### How Has This Been Tested? -->\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n### Benchmark1\r\n\r\nCopy file from Tempfs to ZFS into 1 Dataset:\r\n\r\nName | MB/s\t| Ratio\r\n ---   \t|  --- \t| ---\r\ngzip9\t| 11\t| 0.37\r\nqos10\t| 10\t| 0.38\r\nqos20\t| 22\t| 0.41\r\nqos30\t| 35\t| 0.45\r\nqos40\t| 45\t| 0.48\r\nqos50\t| 55\t| 0.50\r\nlz4\t| 71\t| 0.57\r\noff\t| 62\t| 1\r\n\r\n\r\n### Motivation2\r\n\r\nTransactiongroups in ZFS cause simultaneous writes into multiple datasets to wait for each other to complete. The slowest dataset is the limitation to the overall performance.\r\nThe qos feature can prevent this through dataset prioritisation.\r\nThe maximum bandwidth is limited by the disk throughput. Every dataset can request a part of this bandwidth by setting the qos property value.\r\nData can now be organised into low priority datasets with low quality of service requirements (but high compression, see Motivation1) and high priority to which also all non qos datasets belong.\r\nAll inheriting datasets and their parent share the same requested bandwidth. If the value of an inheriting dataset (lower hierarchy) is explicitly changed from \"inherit\" to \"qos\" then this dataset will request its own bandwidth.\r\n\r\n\r\n### Benchmark2\r\n\r\nCopy 2 files from Tempfs to ZFS into 2 Datasets:\r\n\r\nName     \t\t\t|MB/s\t|MB/s\t|Ratio\t|Ratio\t| Comment\r\n--- | --- | --- | --- | --- | ---\r\nqos10/qos10 - qos10/qos10_2\t|5\t|5\t|0.47\t|0.49\t|use of inheritance\r\nqos10 - qos10/qos10\t\t|5\t|5\t|0.49\t|0.47\t|use of inheritance\r\nqos10 - qos10_2\t\t\t|11\t|10\t|0.46\t|0.48\t| \r\nqos10/qos10 - qos10/qos10x\t|11\t|9\t|0.48\t|0.46\t|qos-10 explicit <br>set on qos10x\r\nqos10/qos20 - qos10\t\t|20\t|9\t|0.49\t|0.43\t| \r\nqos30 - qos10\t\t\t|29\t|9\t|0.52\t|0.40\t| \r\nqos40 - qos10\t\t\t|44\t|10\t|0.54\t|0.40\t| \r\nqos50 - qos10\t\t\t|51\t|9\t|0.53\t|0.40\t| \r\nlz4 - qos10\t\t\t|71\t|9\t|0.57\t|0.39\t| lz4 has high priority\r\noff - qos10\t\t\t|62\t|8\t|1\t|0.38\t| \r\ngzip9 - qos10\t\t\t|13\t|5\t|0.37\t|0.39\t| \r\nlz4 - gzip9\t\t\t|10\t|10\t|0.57\t|0.37\t|  lz4 waiting for gzip\r\n\r\n\r\n### Benchmark3\r\n\r\nCopy 2 files from Tempfs to ZFS into 1 Datasets:\r\n\r\nName     \t\t\t|MB/s\t|MB/s\t|Ratio\r\n--- | --- | --- | --- \r\nqos10 - qos10 |\t5\t|5|\t0,38\r\noff - off|\t22|\t22|\t1\r\nlz4 - lz4|\t30|\t27|\t0,57\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n\r\n#### Branch overlapping changes (feature, compress values)\r\nThe patch has read-only backward compatibility by using the new introduced SPA_FEATURE_COMPRESS_QOS feature. The feature activation procedure is equivalent to my other code branches.\r\nRegarding the limited namespace of BP_GET_COMPRESS() (128 values), the\r\nzio_compress enum's first part is for block pointer & dataset values, the second part for dataset values only. Or should I make use of a new property? This is an alternative suggestion to #3908.\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/5928", "title": "auto compression", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\nAs part of my master thesis at University of Hamburg I have targeted to improve ZFS through compression. Now I would like to share my 3 feature branches with the community.\r\n\r\n1. lz4fast #5927 \r\n2. autocompression (current)\r\n3. qos #5929 \r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\nThis patch adds auto as ZFS compression type.\r\nzfs set compression=auto\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\nWhich compression algorithm is best for high throughput? The answer to this depends on the type of hardware in use.\r\nIf compression takes long then the disk remains idle. If compression is faster than the writing speed of the disk then the CPU remains idle as compression and writing to the disk happens in parallel.\r\nAuto compression tries to keep both as busy as possible.\r\nThe disk load is observed through the vdev queue. If the queue is empty a fast compression algorithm like lz4 with low compression rates is used and if the queue is full then gzip-[1-9] can require more CPU time for higher compression rates.\r\nThe already existing zio_dva_throttle might conflict with the concept described above. Therefore it is recommended to deactivate zio_dva_throttle.\r\n\r\n<!--- ### How Has This Been Tested? -->\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n### Benchmark\r\n\r\nCopy file from Tempfs to ZFS\r\n\r\n\r\n8 Cores:\r\n\r\nName\t|Ratio\t|MB/s\r\n---\t|---\t|---\r\nauto\t|0.44  \t|245\r\ngzip-1\t|0.43  \t|255\r\nlz4\t|0.58  \t|195\r\noff\t|1 \t|99\r\n\r\n\r\n1 Core:\r\n\r\nName\t|Ratio\t|MB/s\r\n---\t|---\t|---\r\nauto\t|0.56 \t|151\r\ngzip-1\t|0.43\t|51\r\nlz4\t|0.58\t|179\r\noff\t|1\t|99\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n\r\n#### Branch overlapping changes (feature, compress values)\r\n\r\nThe patch is has read-only backward compatibility by using the new introduced SPA_FEATURE_COMPRESS_AUTO feature. The feature activation procedure is equivalent to my other code branches.\r\nRegarding the limited namespace of BP_GET_COMPRESS() (128 values), the\r\nzio_compress enum's first part is for block pointer & dataset values, the second part for dataset values only. This is an alternative suggestion to #3908.\r\n\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/5927", "title": "lz4fast compression", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\nAs part of my master thesis at University of Hamburg I have targeted to improve ZFS through compression. Now I would like to share my 3 feature branches with the community.\r\n\r\n1. lz4fast (current)\r\n2. autocompression #5928 \r\n3. qos #5929 \r\n\r\nThis patch updates the lz4 *1 code to version 1.7.3 to make use of lz4 fast compression.\r\nThe lz4 code is based on a seperate project for updating lz4 inside the linux kernel.\r\nThere a few changes were made for an clean implementation and to improve speed that are currently in review *2.\r\n\r\n*1: [https://github.com/lz4/lz4](https://github.com/lz4/lz4)\r\n*2: [https://patchwork.kernel.org/patch/9574745/](https://patchwork.kernel.org/patch/9574745/)\r\n\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\nLZ4-fast capability is now available.\r\nzfs set compression=lz4fast-[1-20,30,+10*n,100]\r\nHigher values result in improved compression speed and less ratio.\r\n\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\nLz4 fast trades in compression ratio for speed. This gives us more flexibility in environments with either low computational power or fast and many SSDs/HDDs where the lz4 is the limiting factor.\r\nAutocompression and qos can also be improved by adding lz4fast algorithms.\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\nChecksums were made to proof full compatibility between the old and new lz4 compressed files.\r\n\r\n#### Benchmark\r\n\r\nCopy file from Tempfs to ZFS (ZFS also in Tempfs for high disk throughput simulation).\r\n\r\n\r\nName         |Ratio   |MB/s\r\n---          |---     |---\r\nlz4          |0.58    |228\r\nlz4fast-2    |0.62    |249\r\nlz4fast-3    |0.65    |266\r\nlz4fast-4    |0.68    |282\r\nlz4fast-5    |0.71    |298\r\nlz4fast-7    |0.76    |329\r\nlz4fast-10   |0.80    |370\r\nlz4fast-20   |0.97    |469\r\nlz4fast-30   |0.98    |546\r\nlz4fast-50   |0.98    |634\r\nlz4fast-100  |0.99    |690\r\noff          |1       |744\r\n\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n\r\n#### Branch overlapping changes (feature, compress values)\r\n\r\nThe patch has read-only backward compatibility by using the new SPA_FEATURE_LZ4FAST_COMPRESS feature. The feature activation procedure is equivalent to my other code branches.\r\nRegarding the limited namespace of BP_GET_COMPRESS() (128 values), the\r\nzio_compress enum's first part is for block pointer & dataset values, the second part for dataset values only. Or should I make use of a new property? This is an alternative suggestion to #3908.\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ghost": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1276681", "body": "Has this issue been resolved? I'm having the same problem on OpenSolaris with ZFS. The zpool-rpool process is writing on average at 400MB/h on an idle system. I can't seem to find an answer anywhere on the net.\n\nThanks for your help.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1276681/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1277385", "body": "A quick DTrace on what the zpool-rpool process is doing reveals the following kernel function calls, accompanied by the number of times they have been called (the sampling lasted about a minute). Does this mean anything to you?\n\n``` DTrace\nrootnex`rootnex_coredma_allochdl          1\nrootnex`rootnex_dma_allochdl            1\nscsi`scsi_transport                     1\nzfs`buf_hash                            1\nzfs`arc_write_done                      1\nzfs`dbuf_find                           1\nzfs`dbuf_dirty                          1\nzfs`metaslab_ndf_alloc                  1\nzfs`spa_writeable                       1\nzfs`space_map_load                      1\nzfs`vdev_queue_deadline_compare          1\nzfs`vdev_queue_offset_compare           1\nzfs`vdev_queue_io                       1\nzfs`zio_buf_free                        1\nzfs`zio_remove_child                    1\nzfs`zio_destroy                         1\nzfs`zio_vdev_io_done                    1\nzfs`zrl_add                             1\nahci`ahci_check_ctl_handle              1\nsata`sata_scsi_start                    1\nsata`sata_txlt_write                    1\nsd`sdstrategy                           1\nsd`sd_core_iostart                      1\nsd`sd_initpkt_for_buf                   1\nsd`sd_start_cmds                        1\nunix`sep_save                           1\nunix`splr                               1\nunix`tsc_gethrtime                      1\nunix`tsc_scalehrtime                    1\nunix`bcopy                              1\nunix`gdt_update_usegd                   1\nunix`lock_set                           1\nunix`cmt_balance                        1\nunix`swtch                              1\nunix`disp_ratify                        1\nunix`default_lock_backoff               1\nunix`lock_set_spin                      1\ngenunix`avl_walk                        1\ngenunix`avl_rotation                    1\ngenunix`cv_broadcast                    1\ngenunix`ddi_fm_acc_err_get              1\ngenunix`disp_lock_enter                 1\ngenunix`thread_lock                     1\ngenunix`ldi_strategy                    1\ngenunix`copy_pattern                    1\ngenunix`kmem_zalloc                     1\ngenunix`list_create                     1\ngenunix`list_remove                     1\ngenunix`ddi_get_soft_state              1\ngenunix`restorectx                      1\nzfs`buf_hash_insert                     2\nzfs`dnode_diduse_space                  2\nzfs`zio_push_transform                  2\nzfs`zio_walk_parents                    2\nzfs`zio_done                            2\nzfs`zio_checksum_compute                2\nzfs`vdev_disk_io_start                  2\nsha2`SHA256TransformBlocks              2\nsd`sd_mapblockaddr_iostart              2\nsd`sd_add_buf_to_waitq                  2\nsd`ddi_xbuf_qstrategy                   2\nsd`xbuf_iostart                         2\nunix`rw_enter                           2\nunix`disp                               2\nunix`atomic_add_64_nv                   2\ngenunix`avl_remove                      2\ngenunix`avl_numnodes                    2\ngenunix`lbolt_event_driven              2\ngenunix`ddi_fm_dma_err_get              2\ngenunix`kmem_cache_free                 2\ngenunix`memcpy                          2\ngenunix`cpu_update_pct                  2\ngenunix`ndi_fmc_insert                  2\ngenunix`taskq_thread_wait               2\nzfs`arc_write_ready                     3\nzfs`metaslab_alloc_dva                  3\nzfs`vdev_accessible                     3\nzfs`zio_wait_for_children               3\nzfs`zio_notify_parent                   3\nzfs`zio_vdev_io_start                   3\nsd`sd_setup_rw_pkt                      3\nunix`mutex_owner_running                3\nunix`rw_exit                            3\nunix`mutex_vector_enter                 3\nunix`vsnprintf                          3\ngenunix`avl_last                        3\nzfs`space_map_remove                    4\nzfs`zio_execute                         4\nsd`sdinfo                               4\nunix`mutex_exit                         4\nzfs`metaslab_group_alloc                5\nzfs`vdev_queue_io_to_issue              5\nunix`bzero                              5\nunix`disp_getwork                       5\ngenunix`avl_insert                      5\nunix`0xfffffffffb85                     6\nunix`tsc_read                           6\ngenunix`kmem_cache_alloc                6\nunix`do_splx                            7\nzfs`space_map_seg_compare               9\nzfs`metaslab_segsize_compare           10\ngenunix`avl_find                       10\nunix`default_lock_delay                11\nzfs`fletcher_4_native                  12\nunix`mutex_enter                       16\nunix`mutex_delay_default               54\nzfs`lzjb_compress                     151\n```\n\nWe can see that the most called function is by far lzjb_compress. Again, DTrace reveals that all the kernel stacks that lead to lzjb_compress pass through the function zio_write_bp_init, which I assume is the guilty function behind all these writes...\n\nDoes this all mean anything to you?\n\nEdit:  kernel stacks\n\n``` DTrace\n              zfs`zio_compress_data+0x8e\n              zfs`zio_write_bp_init+0x216\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              genunix`taskq_thread+0x248\n              unix`thread_start+0x8\n                1\n\n              zfs`zio_compress_data+0x8e\n              zfs`zio_write_bp_init+0x216\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              genunix`taskq_thread+0x248\n              unix`thread_start+0x8\n                1\n\n              zfs`zio_compress_data+0x8e\n              zfs`zio_write_bp_init+0x216\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n                2\n\n              zfs`zio_compress_data+0x8e\n              zfs`zio_write_bp_init+0x216\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              genunix`taskq_thread+0x248\n              unix`thread_start+0x8\n                5\n\n              zfs`zio_compress_data+0x8e\n              zfs`zio_write_bp_init+0x216\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              genunix`taskq_thread+0x248\n              unix`thread_start+0x8\n                6\n\n              zfs`zio_compress_data+0x8e\n              zfs`zio_write_bp_init+0x216\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              genunix`taskq_thread+0x248\n              unix`thread_start+0x8\n               13\n\n              zfs`zio_compress_data+0x8e\n              zfs`zio_write_bp_init+0x216\n              zfs`zio_execute+0x8d\n              genunix`taskq_thread+0x248\n              unix`thread_start+0x8\n               31\n```\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1277385/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1281342", "body": "Here is a list processes which called the write system call on my system, accompanied by the filenames and the total number of bytes written to the files (sampled during one minute):\n\n```\ndtrace -n 'syscall::*write:entry {@[execname, fds[arg0].fi_pathname] = sum (arg2);}'\ndtrace: description 'syscall::*write:entry ' matched 2 probes\n^C\n\n  dtrace                                              /dev/pts/1                                                        1\n  sshd                                                /devices/pseudo/clone@0:ptm                                       1\n  sshd                                                <unknown>                                                        52\n  rsfcli                                              <unknown>                                                       105\n  basename                                            <unknown>                                                       164\n  hostname                                            <unknown>                                                       304\n  syslogd                                             /devices/pseudo/sysmsg@0:sysmsg                                 320\n  awk                                                 <unknown>                                                       331\n  zfs                                                 /devices/pseudo/mm@0:null                                       370\n  java                                                /var/opt/nest/config/site/scheduledjobs/emailnotifications/Notification_ERROR.xml              433\n  java                                                /var/opt/nest/config/site/scheduledjobs/emailnotifications/Notification_WARNING.xml              437\n  java                                                /var/opt/nest/config/site/scheduledjobs/configurationreplications/SiteConfigReplication.xml              511\n  grep                                                <unknown>                                                       725\n  cron                                                /var/cron/log                                                   976\n  java                                                /var/opt/nest/config/site/scheduledjobs/snapshots/Snapshot2290924711711069275.xml             1014\n  java                                                /var/opt/nest/config/site/scheduledjobs/snapshots/Snapshot12337134254217831034.xml             1020\n  java                                                /var/opt/nest/config/site/scheduledjobs/snapshots/Snapshot17476938304947820872.xml             1020\n  java                                                /var/opt/nest/config/site/scheduledjobs/asyncreplications/AsyncReplication13100962750907134551.xml             1056\n  java                                                /var/opt/nest/config/site/scheduledjobs/asyncreplications/AsyncReplication13881922923541859328.xml             1056\n  ksh                                                 <unknown>                                                      1096\n  fcinfo                                              <unknown>                                                      1152\n  zpool                                               <unknown>                                                      1452\n  ksh                                                 /tmp/sf0l.2ol                                                  1650\n  ksh                                                 /tmp/sf0p.gnd                                                  1650\n  ksh                                                 /tmp/sf10.jmu                                                  1650\n  ksh                                                 /tmp/sf1g.3nv                                                  1650\n  ksh                                                 /tmp/sf1i.jvb                                                  1650\n  ksh                                                 /tmp/sf24.5eq                                                  1650\n  ksh                                                 /tmp/sf2f.jop                                                  1650\n  ksh                                                 /tmp/sf3b.beh                                                  1650\n  ksh                                                 /tmp/sf10.ujs                                                  3000\n  ksh                                                 /tmp/sf19.9c4                                                  3000\n  ksh                                                 /tmp/sf2a.o3i                                                  3000\n  ksh                                                 /tmp/sf2p.8d0                                                  3000\n  ksh                                                 /tmp/sf3k.j08                                                  3000\n  svcprop                                             <unknown>                                                      3140\n  format                                              <unknown>                                                      3644\n  sed                                                 <unknown>                                                      3704\n  fmd                                                 /var/fm/fmd/infolog_hival                                      4480\n  nscd                                                <unknown>                                                      5268\n  zfs                                                 <unknown>                                                      5778\n  init                                                /etc/svc/volatile/init-next.state                              9064\n  iostat                                              <unknown>                                                      9102\n  svccfg                                              <unknown>                                                      9801\n  fmtopo                                              <unknown>                                                    429332\n```\n\nIn contrast, for the same duration, here is the list of actual disk writes that were initiated, again accompanied by the filenames and number of bytes.\n\n```\ndtrace -n 'io:::start /args[0]->b_flags & B_WRITE/ {@[execname, args[2]->fi_pathname]=sum(args[0]->b_bcount);}'\ndtrace: description 'io:::start ' matched 6 probes\n^C\n\n  sched                                               /var/opt/nest/config/site/scheduledjobs/configurationreplications/SiteConfigReplication.xml             4096\n  sched                                               /var/opt/nest/config/site/scheduledjobs/emailnotifications/Notification_ERROR.xml             4096\n  sched                                               /var/opt/nest/config/site/scheduledjobs/emailnotifications/Notification_WARNING.xml             4096\n  sched                                               /var/opt/nest/config/site/scheduledjobs/asyncreplications/AsyncReplication13100962750907134551.xml             8192\n  sched                                               /var/opt/nest/config/site/scheduledjobs/asyncreplications/AsyncReplication13881922923541859328.xml             8192\n  sched                                               /var/opt/nest/config/site/scheduledjobs/snapshots/Snapshot12337134254217831034.xml             8192\n  sched                                               /var/opt/nest/config/site/scheduledjobs/snapshots/Snapshot17476938304947820872.xml             8192\n  sched                                               /var/opt/nest/config/site/scheduledjobs/snapshots/Snapshot2290924711711069275.xml             8192\n  zpool-rpool                                         <none>                                                     10463232\n```\n\nThe total number of bytes written to the disk by zpool-rpool alone is much higher than the total of bytes for which the write system call was used. Doesn't that mean that zpool-rpool is acting on its own?\n\nEdit: The two dtrace commands were run in parallel.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1281342/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1283961", "body": "Hmmm it's too bad there isn't a moderately easy way of knowing where all this I/O activity comes from. I tried disabling fmtopo (which is the biggest write-system-call writer) and still, zpool-rpool's io activity didn't seem to lower as significantly as it should have.\n\nAnyway, thanks for your input. I'll post if I find a solution to this on my side.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1283961/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/7731553", "body": "hmm. why not to do it in that way: let O_DIRECT always return true? does it metter that ZFS copies everything in to the ARC cache? let fake a bit an OS. It shouldn't hurt so much.... oh, and that is just my freak idea\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/7731553/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1873708", "body": "Hi - Not sure what's going on here as I don't know much regarding the programming/debugging of zfs but I seems to experience that issue, that is with or without rsync. I never had to read much files on my system as I use zfs for backups storage, however I just had to restore things from the zfs pool and it crashed after a while.. rebooted.. crashed after a while..\n\nHere is the error I found in dmesg/syslog : http://pastebin.com/jMTCNEFy\n\nIf there is anything I can do to help, as far as testings, don't hesitate to let me know.\n\nThanks,\n\nedit: using git from 2011-08-22 on debian squeeze\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1873708/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/2064709", "body": "Alphalead : I think your trick allowed my rsync session to last longer but after a while it crashed again unfortunately\n\nMessage from syslogd@stor01 at Sep 11 12:18:11 ...\n kernel:[1714241.981661] Oops: 0002 [#1] SMP\n\nMessage from syslogd@stor01 at Sep 11 12:18:11 ...\n kernel:[1714241.981673] last sysfs file: /sys/module/mbcache/initstate\n\nMessage from syslogd@stor01 at Sep 11 12:18:11 ...\n kernel:[1714241.982056] Stack:\n\nMessage from syslogd@stor01 at Sep 11 12:18:11 ...\n kernel:[1714241.982133] Call Trace:\n\nMessage from syslogd@stor01 at Sep 11 12:18:11 ...\n kernel:[1714241.982206] Code: 49 8b 14 04 48 c1 e2 03 e8 83 88 ff ff 85 c0 75 10 48 8d 54 24 70 48 89 de 44 89 ef e8 5b f3 ff ff 48 8b 54 24 50 be d0 00 00 00 <48> c7 02 00 00 00 00 48 8b 54 24 48 48 8b 7c 24 70 e8 7d f6 ff\n\nMessage from syslogd@stor01 at Sep 11 12:18:11 ...\n kernel:[1714241.982346] CR2: 0000000000000000\n\nedit: version used is latest commit (2708f716c0)\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/2064709/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/2006354", "body": "I can confirm that his bug does **not exist** in zfs-fuse for linux. \n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/2006354/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/2352510", "body": "Gunnar Beutner was able to come up with a patch for this. I tested it on my development device and so far it works exactly as intended. We're doing some more testing later this week; at this point I would consider this ready for official evaluation so that it can be committed and this bug closed. I will post back here if we encounter any problems while we are testing this patch.\n\nhttps://gunnar-beutner.de/files/0001-Fixed-invalid-resource-re-use-in-file_find.patch\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/2352510/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/2811567", "body": "zfs-fuse:\n\n<pre>\ndd if=/dev/zero of=/tank/xxx/test.io bs=1024k count=1000\n1000+0 records in\n1000+0 records out\n1048576000 bytes (1.0 GB) copied, 8.48609 s, 124 MB/s\n</pre>\n\nubuntu-zfs:\n\n<pre>\ndd if=/dev/zero of=/tank/xxx/test.io bs=1024k count=1000\n1000+0 records in\n1000+0 records out\n1048576000 bytes (1.0 GB) copied, 114.533 s, 9.2 MB/s\n</pre>\n\nOk, i try recreate pool under ubuntu-zfs\n\n<pre>\n# zpool offline tank sdc\n# zpool detach tank sdc\n# zpool create -f test sdc\n# zpool status test\n  pool: test\n state: ONLINE\n scan: none requested\nconfig:\n\n        NAME        STATE     READ WRITE CKSUM\n        test        ONLINE       0     0     0\n          sdc       ONLINE       0     0     0\n\nerrors: No known data errors\n# zfs create test/xxx\n# dd if=/dev/zero of=/test/xxx/test.io bs=1024k count=1000\n1000+0 records in\n1000+0 records out\n1048576000 bytes (1.0 GB) copied, 53.5897 s, 19.6 MB/s\n</pre>\n\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/2811567/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/3299069", "body": "behlendorf, probably, i had bad results because i was try to use 32 bit OS.\nFresh install ferdora 16 32 bit was the same, but zfs on fedora 16 (x64) shows performance near to raw device.\nThanks.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/3299069/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/11986018", "body": "Please fix this, a year later it is still not working. Rudd-O has an open pull request, can it be pulled into te main branche?\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/11986018/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/3399837", "body": "Pretty much this is how I went about setting up everything.\n\nMy platform is Ubuntu 10.04.3 x86 (also used x64) running as a VMware VM on my laptop (as test).\n\nI downloaded the source and compiled as per the instructions on the ZFS on linux website.\n\nThen I compiled the Linux iSCSI target core backports from linux-iscsi.org. I also compiled the lio-utils and targetcli (the management tools).\n\nAfter I installed the deb packages of everything (iscsi target and ZFS) I created my zpool called (tank) and my zfs vol (fish). Because it was a test I just used the names from the website because it did not matter.\n\nThe command I use were the following;\n\nparted /dev/sdb\nmklabel gpt\nquit\n\nparted /dev/sdc\nmklabel gpt\nquit\n\nzpool create tank mirror /dev/sdb /dev/sdc\n\nzfs create tank/fish -V 18G\n\nAfter that was done I dropped into the targetcli tool and tried to add a block device to the /backstores/iblock section. The targetcli emulates a file system, kind of reminds me of /proc or /sys. When I execute the command \"create disk0 /dev/zd0\" it returns and error to me saying the chosen device is not a valid \"TYPE_DISK\". I am not sure though if \"TYPE_DISK\" is something internal to the target or if it is a Linux thing.\n\nThe only way I could use ZFS with the target was to format the ZFS vol with something like ext4 and then create an image file with dd then use the file_io feature of the target. But the is not only complicated but completely undermines the entire point of using ZFS.\n\nWhen I mentioned that the ZFS vols have no vendor information I was referring to what I see when I run \"parted -l\" and look at /dev/zd0. When compared to the VMware disks there is information about who made the disk or anything, not even faked information just to fill the space. I will add an output when I have a chance.\n\nIf you need anymore info let me know.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/3399837/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/3442037", "body": "I get the code from there git repo. git://risingtidesystems.com/\n\nThe only slightly annoying thing is you have to build several packages before you can build the targetcli tool.\n\nBut everything you need is there.\n\nYou need to build the tools in an similar order to this;\n1. lio-utils\n2. configshell\n3. rtslib\n4. targetcli\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/3442037/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/3707762", "body": "I have small update to announce based on my reported issue, I may have a source of the problem.\n\nI believe the error \"Not TYPE_DISK\" is a problem with the iSCSI target drivers and may have nothing to do with ZFS.\n\nThe reason for the error I hypothoize is because ZFS is not listing it ZVOLs in /dev/disk which is most likely where the iSCSI target is look for them and that would sort of explain the error, because it is say that the ZVOL is not a type of device found is /dev/disk. \n\nSo unless something changes with the iSCSI target drivers before the \"final\" release with kernel v3.4 then ZFS just may have sit out on that one.\n\nI will \"try\" to report the issue to the devs of the iSCSI target but I have not heard anything since before Christmas when I last attempted.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/3707762/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/5439790", "body": "Experiencing the same issues with 2.6.32-41 on 10.04 (AMD X2-555 proc in an ASUS M4A88T MB, 16GB ecc).  No apparent problems with 2.6.32-40.  Sorry for lack of trace info, may have time this weekend.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/5439790/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/5441206", "body": "Correction, 12GB.  Might as well mention this:\nJust did a quick check and BIOS version was latest but release date appeared inconsistent.  So updated BIOS anyway, disabled legacy USB, and booted 2x4GB with just channel A (matched pair).  Checked dmesg and errata message is still there.   There's a sleeping zfs mount -a process (configured automount) and any zpool/zfs commands in a shell hang.  FWIW.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/5441206/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/7986088", "body": "I've installed Fedora 17 to a test System with ZFS due to @Rudd-O  \n+1 to this\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/7986088/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/20962527", "body": "Allow me to shed some light on this.\n\nLet's consider an old-school nfs4 export using a native Linux filesystem, one share called 'pmr':\n\n``` /etc/fstab\n/dev/groups/pmr /storage/pmr      xfs    inode64,logdev=/dev/ssdcache/pmr,logbufs=8  1 2\n/storage/pmr    /exports/pmr      none   rw,bind         0 0\n```\n\n``` /etc/exports\n/exports     [nfs4 export root settings]\n/exports/pmr [per-share settings]\n```\n\nWhen the system is booting, the xfs filesystem will be mounted first, followed by a bind mount from /storage/pmr to /exports/pmr. The latter then is exported via /etc/exports using nfs4 and we're all happy.\n\nNow consider a zfs-based scenario.\n\nSince there are no zfs entries in fstab, it becomes:\n\n``` /etc/fstab\n/storage/pmr    /exports/pmr      none   rw,bind         0 0\n```\n\nWhen the system boots, a bind-type mount will be created from /storage/pmr to /exports/pmr which is effectively mounting the underlying filesystem (most likely / ) to the bind point and exporting that. The clients will see the contents of an empty directory as the exporter uses the / bind mount. On the server, the confused administrator will see the actual zfs and will scratch their head.\n\nI don't think this is a bug in zfs rather a race condition between the distribution's native localfs init script and zfs. Perhaps localfs should depend on zfs and not the other way around.\n\nAlternatively, the zfs service should parse some file that will tell it how the binds go and bind after mounting the zfs filesystem. Perhaps a file in /etc/zfs/ like 'binds' would work.\n\nPersonally (sysadmin cap on) /etc/zfs/binds would work for me (together with a bit of parsing in /etc/init.d/zfs) as it's sufficiently low-tech and doesn't require changes in the actual zfs stack.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/20962527/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/20965023", "body": "Proposed patch (only lsb script, others are most likely derivative):\n\n``` patch\n--- etc/init.d/zfs.lsb.in.orig  2013-07-15 12:47:20.055257882 +0100\n+++ etc/init.d/zfs.lsb.in       2013-07-15 12:49:44.732137370 +0100\n@@ -29,6 +29,7 @@\n ZFS=\"@sbindir@/zfs\"\n ZPOOL=\"@sbindir@/zpool\"\n ZPOOL_CACHE=\"@sysconfdir@/zfs/zpool.cache\"\n+ZFS_NFS4_BINDS=\"@sysconfdir@/zfs/binds\"\n\n # Source zfs configuration.\n [ -r '/etc/default/zfs' ] &&  . /etc/default/zfs\n@@ -78,6 +79,26 @@\n                log_end_msg $?\n        fi\n\n+        # Create (optional) binds to the NFS4 export tree\n+        if [ -e \"$ZFS_NFS4_BINDS\" ] ; then\n+                log_begin_msg \"Binding NFS4 mounts\"\n+                sed -e \"s/#.*//\" -e \"/^$/d\" $ZFS_NFS4_BINDS | while read LINE\n+                do\n+                        MODE=\"`echo $LINE | awk '{print $1}'`\"\n+                        SRC=\"`echo $LINE | awk '{print $2}'`\"\n+                        DEST=\"`echo $LINE | awk '{print $3}'`\"\n+                        case $MODE in\n+                                bind)   MOUNTPOINT=\"`zfs get mountpoint $SRC | grep \"$SRC\" | awk '{print $3}'`\"\n+                                        mount -o $MODE $MOUNTPOINT $DEST\n+                                        log_end_msg $?\n+                                        ;;\n+                                *)      echo \"Unknown bind mode ($MODE) in $ZFS_NFS4_BINDS. Aborting.\"\n+                                        exit 4\n+                                        ;;\n+                        esac\n+                done\n+        fi\n+\n        touch \"$LOCKFILE\"\n }\n\n@@ -85,6 +106,25 @@\n {\n        [ ! -f \"$LOCKFILE\" ] && return 3\n\n+       if [ -e \"$ZFS_NFS4_BINDS\" ] ; then\n+                log_begin_msg \"Detaching NFS4 binds\"\n+                sed -e \"s/#.*//\" -e \"/^$/d\" $ZFS_NFS4_BINDS | while read LINE\n+                do\n+                        MODE=\"`echo $LINE | awk '{print $1}'`\"\n+                        SRC=\"`echo $LINE | awk '{print $2}'`\"\n+                        DEST=\"`echo $LINE | awk '{print $3}'`\"\n+                        case $MODE in\n+                                bind)   MOUNTPOINT=\"`zfs get mountpoint $SRC | grep \"$SRC\" | awk '{print $3}'`\"\n+                                        umount $DEST\n+                                        log_end_msg $?\n+                                        ;;\n+                                *)      echo \"Unknown bind mode ($MODE) in $ZFS_NFS4_BINDS. Aborting.\"\n+                                        exit 4\n+                                        ;;\n+                        esac\n+                done\n+        fi\n+\n        log_begin_msg \"Unmounting ZFS filesystems\"\n        \"$ZFS\" umount -a\n        log_end_msg $?\n```\n\n$MODE may look redundant but perhaps could be kept for future expansion, maybe there could be other bind types.\n\nThe /etc/zfs/binds file would look like this:\n\n``` /etc/zfs/binds\n#    zpool[/dataset]        mountpoint\nbind storage/pmr            /exports/pmr\n```\n\nOf course the distribution source would only contain the first line. I believe this is consistent with other files in /etc/zfs.\n\nCheers,\ngrok\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/20965023/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/45432317", "body": "@FransUrbo `/etc/rc.local` does not exist and is not called in all distributions. Even more, `systemd` based distributions (good luck finding one without it these days) won't have it by definition.\n\nAre you suggesting that instead of editing a config file (present, documented) you would rather ask everyone to roll their own code, manually create bind mounts? That doesn't sound like a sane systems management practice.\n\nWhen ZoL filesystem needs to be exported over NFS4, a bind mount must be created. No standard mechanism in GNU/Linux will allow for it if the filesystem is not present in `/etc/fstab`. Since it's ZFS that's 'special', I will argue that it is its own responsibility to provide the functionality required for other parts of the system to continue to function.\n\nIf you don't like my solution, that's fine, please provide a better one or show where exactly am I incorrect. Saying something is 'hackish' and then suggesting that sysadmins 'sort it out in rc.local' isn't constructive.\n\nRegards,\njz\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/45432317/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/45433327", "body": "@FransUrbo \n\nWhat use is a filesystem that cannot be exported over network?\n\nNFS4 exports are different from NFS3 exports. There is a certain, established standard of creating them in GNU/Linux, there exists a well documented process that is different from Solaris-isms still present in ZoL.\n\nI wasn't aware `zfs set sharenfs=on` is able to produce NFS4 mounts. Could you please quote options required to make that happen? How do you define the mount tree? This is different from NFS3.\n\nWhat bugs in other software are you referring to? Exporting NFS4 works perfectly fine in GNU/Linux. Since ZoL provides PV, VG and LV management as well as filesystem mount points in a way that is abstracted from the current device paradigm on Linux, certain steps need to be taken to make those two work together.\n\nWhile you are free to disagree, I still haven't seen a patch that solves the problem. GNU/Linux nfs-kernel-server (and this is ZFS on _Linux_) requires mount points bound into a central exports tree. Since binding is done early (and you can't make the `zfs` init script depend on `$localfs`) ZoL needs to catch up. \n\nNFS4 provides capabilities like idmapd (how would you propose to integrate `zfs set sharenfs` with starting `idmapd`, are there hooks for that? How do I call them?), caching, subtree checks, consistent filesystem IDs and performance improvements over NFS3.\n\nThe logical way to do it (and I have consulted this with a number of Linux Sysadmins before presenting it here) is for the init script to have a mechanism to create the required bound mounts to the exports tree. The section in the init script is self-contained, fails safe (no action if the config file isn't present) and does introduce required compatibility with the host operating system. In one file that is owned by the ZFS package.\n\nIf you continue to disagree, please produce a patch that solves the issue for NFS4 and ZoL or provide a way of exporting NFS4, including all the required export options like the following excerpt from a production environment:\n\n``` /etc/exports\n/exports     172.5.125.0/24(ro,async,wdelay,insecure,root_squash,no_subtree_check,fsid=0)\n/exports     172.5.124.0/25(ro,async,wdelay,insecure,root_squash,no_subtree_check,fsid=0)\n/exports/pmr 172.5.125.0/24(rw,async,wdelay,root_squash,no_subtree_check)\n/exports/pmr 172.5.124.0/25(rw,sync,wdelay,no_root_squash,no_subtree_check)\n```\n\nPlease understand, `rc.local` is the last resort, it isn't available on all distributions, some don't even have an equivalent script and requiring systems administrators to manually do those steps is error-prone. Perhaps one can do it on their home computer but hardly in an enterprise environment where consistency and sustainability is key.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/45433327/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/45434151", "body": "@FransUrbo \n\nThe issue #1029 you referred me to is highlighting the problem I've solved; no way to correctly set up NFS4 shares using Solaris-isms under Linux.\n\n> > Could you please quote options required to make that happen?\n> \n> I did. You need to slow down and read what's given to you.\n\nUnless you meant the four dots at the end of `zfs set sharenfs=on`, I must have missed it.\n\nI'm not going to continue this conversation with you as it's no longer productive.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/45434151/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/73043264", "body": ":+1: \n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/73043264/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/10101505", "body": "oh, how embarrassing.. adding autogen.sh to my weekly routine. Thanks!\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/10101505/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/13097318", "body": "Hey, so while apt-get update automatically chooses 3.6.0-23-virtual for the chroot , I should rather install 3.6.0-29-generic which is the same as the hosts?  Gotcha.\nJust worth noting that i've followed the HOW TO step-by-step and that a virtual kernel (different from the hosts) gets installed by default when installing ubuntu-minimal in a chroot environment.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/13097318/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/13114557", "body": "Thanks for the replies, No objections behlendorf. \nCheers\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/13114557/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/17124603", "body": "http://zfsonlinux.org/faq.html#WhyShouldIUseA64BitSystem\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/17124603/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/39197997", "body": "Some testing on SLES11 SP3 (obs build instance):\n\nThe `path_lookup()` is also triggered on SLES' 3.0.101 kernel so it looks like a proper autoconf check is required.\n\n@Milan-Benes:\n\nSince `spl_kern_path_parent` macro can expand to either `path_lookup(path, LOOKUP_PARENT, nd)`, `kern_path_parent_fn(path, nd)` or `kern_path_parent(path, nd)`, a _quick and very, very dirty_ fix would be to manually patch and build if you're desperate for the functionality. \n\nNote that the `kern_` functions use 2 arguments and not 3 so (I'm going to hell for this!) the middle one needs to go.\n\nSo after applying https://github.com/zfsonlinux/zfs/pull/1655 to 0.6.2 you can try something like this:\n\n``` patch\n--- module/zfs/zfs_ctldir.c.orig        2014-04-01 12:48:37.756605773 +0100\n+++ module/zfs/zfs_ctldir.c     2014-04-01 12:50:58.674195921 +0100\n@@ -997,8 +997,8 @@\n                goto out_path_buff;\n        }\n\n-       error = path_lookup(path_buff, LOOKUP_FOLLOW | LOOKUP_DIRECTORY, &nd);\n-       if (!error)\n+       error = kern_path_parent(path_buff, &nd);\n+       if (!error)\n                path_put(&nd.path);\n\n out_path_buff:\n```\n\nIt builds but **be warned**, may eat your gerbil.\n\n**Edit:** \n\n```\nZFS: snapshot home/tank@auto_daily-2014-03-27-1600 auto mounted at /home/tank/.zfs/snapshot/auto_daily-2014-03-27-1600 unexpectedly unmounted\n```\n\nAnd a nice NULL pointer:\n\n```\nApr  1 13:32:24 hematus kernel: [   83.305579] ZFS: snapshot home/tank@auto_daily-2014-03-27-1600 auto mounted at /home/tank/.zfs/snapshot/auto_daily-2014-03-27-1600 unexpectedly unmounted\nApr  1 13:35:00 hematus kernel: [  239.301971] BUG: unable to handle kernel NULL pointer dereference at 0000000000000020\nApr  1 13:35:00 hematus kernel: [  239.301978] IP: [<ffffffffa065e3a6>] zfsctl_lookup_snapshot_path+0x1a6/0x2c0 [zfs]\nApr  1 13:35:00 hematus kernel: [  239.302022] PGD 0\nApr  1 13:35:00 hematus kernel: [  239.302024] Oops: 0000 [#1] SMP\nApr  1 13:35:00 hematus kernel: [  239.302027] CPU 10\nApr  1 13:35:00 hematus kernel: [  239.302028] Modules linked in: md5 nfsd autofs4 binfmt_misc edd nfs lockd fscache auth_rpcgss nfs_acl sunrpc mpt3sas mpt2sas scsi_transport_sas raid_class mptctl mptbase bonding mperf microcode ext3 jbd mbcache loop flashcache(FN) pciehp zfs(PFN) zcommon(PFN) znvpair(PFN) zavl(PFN) zunicode(PFN) spl(FN) ipv6 ipv6_lib zlib_deflate ixgbe joydev usbhid hid igb usb_storage dca ptp dcdbas(X) pcspkr shpchp pci_hotplug sr_mod mei ses iTCO_wdt cdrom enclosure iTCO_vendor_support button wmi acpi_power_meter rtc_cmos pps_core acpi_pad sg mdio xfs dm_mirror dm_region_hash dm_log linear ehci_hcd usbcore usb_common sd_mod crc_t10dif processor thermal_sys hwmon scsi_dh_rdac scsi_dh_hp_sw scsi_dh_emc scsi_dh_alua scsi_dh dm_snapshot dm_mod ahci libahci libata megaraid_sas scsi_mod\nApr  1 13:35:00 hematus kernel: [  239.302072] Supported: No, Proprietary and Unsupported modules are loaded\nApr  1 13:35:00 hematus kernel: [  239.302074]\nApr  1 13:35:00 hematus kernel: [  239.302076] Pid: 7433, comm: nfsd Tainted: PF          NX 3.0.101-0.15-default #1 Dell Inc. PowerEdge R720/0X3D66\nApr  1 13:35:00 hematus kernel: [  239.302080] RIP: 0010:[<ffffffffa065e3a6>]  [<ffffffffa065e3a6>] zfsctl_lookup_snapshot_path+0x1a6/0x2c0 [zfs]\nApr  1 13:35:00 hematus kernel: [  239.302099] RSP: 0018:ffff8817dbee99e0  EFLAGS: 00010246\nApr  1 13:35:00 hematus kernel: [  239.302100] RAX: 0000000000000000 RBX: ffff8817f116c000 RCX: 0000000000000020\nApr  1 13:35:00 hematus kernel: [  239.302102] RDX: ffff8817f116e4c8 RSI: 0000000000001000 RDI: ffff8817dbee9ab0\nApr  1 13:35:00 hematus kernel: [  239.302104] RBP: 0000000000000da2 R08: e848000000000000 R09: 1200000000000000\nApr  1 13:35:00 hematus kernel: [  239.302106] R10: 0000000000000000 R11: ffffffff8120f630 R12: ffff8817dbee9b60\nApr  1 13:35:00 hematus kernel: [  239.302108] R13: ffff8817f116e4c8 R14: ffff8817f116c000 R15: 0000000000000006\nApr  1 13:35:00 hematus kernel: [  239.302110] FS:  0000000000000000(0000) GS:ffff88187faa0000(0000) knlGS:0000000000000000\nApr  1 13:35:00 hematus kernel: [  239.302112] CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b\nApr  1 13:35:00 hematus kernel: [  239.302114] CR2: 0000000000000020 CR3: 0000000001a09000 CR4: 00000000001407e0\nApr  1 13:35:00 hematus kernel: [  239.302116] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000\nApr  1 13:35:00 hematus kernel: [  239.302118] DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400\nApr  1 13:35:00 hematus kernel: [  239.302120] Process nfsd (pid: 7433, threadinfo ffff8817dbee8000, task ffff8817dbee6380)\nApr  1 13:35:00 hematus kernel: [  239.302122] Stack:\nApr  1 13:35:00 hematus kernel: [  239.302123]  0000000000011800 ffff8817dbee9c44 ffff88187f429a00 0000000000000da2\nApr  1 13:35:00 hematus kernel: [  239.302129]  ffff8817dbee9bd8 0000000000000004 0000000000000004 00000000000000a8\nApr  1 13:35:00 hematus kernel: [  239.302133]  00000000000000a8 ffffffff81145a8e ffff8817f420d400 ffff8817f1656800\nApr  1 13:35:00 hematus kernel: [  239.302137] Call Trace:\nApr  1 13:35:00 hematus kernel: [  239.302221]  [<ffffffffa065e52b>] zfsctl_lookup_objset+0x6b/0x90 [zfs]\nApr  1 13:35:00 hematus kernel: [  239.302284]  [<ffffffffa0672241>] zfs_vget+0xf1/0x350 [zfs]\nApr  1 13:35:00 hematus kernel: [  239.302356]  [<ffffffffa068edf1>] zpl_fh_to_dentry+0x41/0x60 [zfs]\nApr  1 13:35:00 hematus kernel: [  239.302420]  [<ffffffff811d69df>] exportfs_decode_fh+0x6f/0x290\nApr  1 13:35:00 hematus kernel: [  239.302429]  [<ffffffffa086198d>] nfsd_set_fh_dentry+0x17d/0x380 [nfsd]\nApr  1 13:35:00 hematus kernel: [  239.302440]  [<ffffffffa0861d6b>] fh_verify+0x1db/0x2b0 [nfsd]\nApr  1 13:35:00 hematus kernel: [  239.302448]  [<ffffffffa0870b41>] nfsd4_proc_compound+0x341/0x520 [nfsd]\nApr  1 13:35:00 hematus kernel: [  239.302463]  [<ffffffffa085e381>] nfsd_dispatch+0xb1/0x250 [nfsd]\nApr  1 13:35:00 hematus kernel: [  239.302474]  [<ffffffffa07826a3>] svc_process_common+0x333/0x620 [sunrpc]\nApr  1 13:35:00 hematus kernel: [  239.302488]  [<ffffffffa0782ce1>] svc_process+0x101/0x160 [sunrpc]\nApr  1 13:35:00 hematus kernel: [  239.302500]  [<ffffffffa085eb3d>] nfsd+0xcd/0x150 [nfsd]\nApr  1 13:35:00 hematus kernel: [  239.302505]  [<ffffffff81082966>] kthread+0x96/0xa0\nApr  1 13:35:00 hematus kernel: [  239.302511]  [<ffffffff81469ee4>] kernel_thread_helper+0x4/0x10\nApr  1 13:35:00 hematus kernel: [  239.302514] Code: 00 00 00 00 00 48 8b 87 c8 34 00 00 4c 8d af c8 24 00 00 48 8d bc 24 d0 00 00 00 be 00 10 00 00 4c 89 ea 48 89 84 24 d0 00 00 00\nApr  1 13:35:00 hematus kernel: <48>[  239.302527]  8b 40 20 48 89 84 24 d8 00 00 00 e8 49 fd ff ff 85 c0 0f 84\nApr  1 13:35:00 hematus kernel: [  239.302533] RIP  [<ffffffffa065e3a6>] zfsctl_lookup_snapshot_path+0x1a6/0x2c0 [zfs]\nApr  1 13:35:00 hematus kernel: [  239.302551]  RSP <ffff8817dbee99e0>\nApr  1 13:35:00 hematus kernel: [  239.302552] CR2: 0000000000000020\nApr  1 13:35:00 hematus kernel: [  239.302554] ---[ end trace c16be50e3596fc64 ]---\n```\n\nSo yeah, doesn't work just yet.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/39197997/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/39320535", "body": "@andrey-ve \n\nI grepped `/usr/src/linux/include` on a current SLES11 SP3 (and do bear in mind SuSE patches their kernels heavily so the 3.0.101 has interfaces probably similar to 3.6 vanilla) shows no 'HAVE_MOUNT_*' strings.\n\nThe only thing in the region of that was:\n\n```\n$ grep -Ri MOUNT_NODEV *\nlinux/fs.h:extern struct dentry *mount_nodev(struct file_system_type *fs_type,\n```\n\nit's defined as:\n\n``` h\nextern struct dentry *mount_nodev(struct file_system_type *fs_type,\n        int flags, void *data,\n        int (*fill_super)(struct super_block *, void *, int));\n```\n\nThere's also:\n\n``` h\n#define MNT_NODEV       0x02\n```\n\nin `linux/mount.h`.\n\nJust in case, I've put the src.rpm for the stock SLES11 SP3 kernel source at https://anorien.csc.warwick.ac.uk/kernel-source-3.0.76-0.11.1.x86_64.rpm - it will produce the /usr/src/linux used for building on SLES. \n\nHope this helps anyway, don't hesitate to ask if you need more information.\n(edit: updated rpm url)\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/39320535/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "JakeWharton": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/147018", "body": "These two lines should have four spaces before them so they are rendered like this:\n\n```\n$ ./configure\n$ make pkg\n```\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/147018/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "review_comments": []}, "rdylina": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/194382", "body": "Would it not be better to treat this somewhat like a security issue by blacklisting all known devices that are definitely not available to be used as block devices? Somehow seems safer to me.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/194382/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "review_comments": []}, "fajarnugraha": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/282697", "body": "Brian, cmd/zvol_id/Makefile.am is missing. Could you please upload it? Thanks.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/282697/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/282698", "body": "Sorry, I mean cmd/zvol_id/Makefile.in\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/282698/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/282796", "body": "Create another branch, then copy previous comments manually?\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/282796/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/283041", "body": "Copying previous note from email:\n\n<pre>\nfrom    : behlendorf <noreply@github.com>\ndate    : Fri, Feb 25, 2011 at 3:36 AM\nsubject : Re: [GitHub] Use udev to create /dev/zvol/[dataset_name] links [behlendorf/zfs feaf4b2]\n</pre>\n\n- Removed Makefile-sample, with the full integration in the build system it isn't needed.\n- Added all autogen.sh products (Makefile.in, configure) using the following versions of the utils.  Using the same versions of the tools minimizes how much change there is in the autogen products and makes it easier to review.\n  \n  autoconf (GNU Autoconf) 2.63\n  automake (GNU automake) 1.11.1\n  ltmain.sh (GNU libtool) 2.2.6b\n- Added the CDDL header to zvol_id_main.c, including correctly attributing the source.\n- Minor stray whitespace cleanup.\n- Update kmem_free() in zvol_remove_minors() to match  kmem_zalloc()'s use of MAXNAMELEN.  If we fail to do the the memory account code will flag this is a memory leak.  It's critical to ensure you alloc/free both use the same size for the buffer.\n- Add <sys/stat.h> header in zvol_id_main.c, without it my build was failing on RHEL6.\n\nhttps://github.com/behlendorf/zfs/commit/feaf4b287322d6123336f139049686114f6c6ee8#commitcomment-282533\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/283041/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "review_comments": []}, "nedbass": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/333338", "body": "Mixing tabs and spaces here\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/333338/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/333382", "body": "Done.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/333382/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/334541", "body": "Darn, missed this misaligned fi!  Oh well, I'll commit a new fix\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/334541/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/409893", "body": "Yay for killing abominable code!  Not sure if dbuf_hold_impl() is in the same call path, but \nfc5bb51f08a6c91ff9ad3559d0266eeeab0b1f61 employs the same hack to reduce its stack.\nYou may want to check if it can now be safely reverted as well.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/409893/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/413647", "body": "Opened Issue #263 to track this.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/413647/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}], "review_comments": []}, "Rudd-O": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/333340", "body": "## Fix it in your tree, pullrequest, then I will commit later on. \n\nSent from my Android phone with K-9 Mail. Please excuse my brevity.\n\nnedbass reply@reply.github.com wrote:\n\nMixing tabs and spaces here -- Reply to this email directly or view it on GitHub: https://github.com/behlendorf/zfs/commit/6583dcacdcca2aad7eaec51f31797a3533845099#commitcomment-333338\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/333340/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "review_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11071", "body": "don't hardcode the paths, please.  otherwise it will fail depending on where the utilities are installed.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11071/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11072", "body": "we sync.  we expect no unmounting to happen here since it either will fail if core file systems are mounted and have files open, or successfully unmount the file systems only to make the later initscripts crap out horribly because core file systems are not available anymore.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11072/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11073", "body": "show better status here\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11073/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11251", "body": "what should I do with these two lines?  Remove them?\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11251/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11252", "body": "should I re-add this file?\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11252/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11289", "body": "I will add this right now.\n\nEl Wednesday, March 23, 2011, behlendorf escribi\u00f3:\n\n> > @@ -1,6 +0,0 @@\n> > \n> > ## -Stub file for 'make dist' distdir rule.\n> > \n> > -This file is directly referenced by ../Makefile.am as a source\n> > -file and thus will be expected by 'make dist'.  To avoid this\n> \n> This file should be readded exactly for the reasons mentioned in the file.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11289/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11290", "body": "The file has been re-added as of commit 9549dd1 and pushed too.\n\nNow onto the next revision.\n\nEl Wednesday, March 23, 2011, behlendorf escribi\u00f3:\n\n> > @@ -1,6 +0,0 @@\n> > \n> > ## -Stub file for 'make dist' distdir rule.\n> > \n> > -This file is directly referenced by ../Makefile.am as a source\n> > -file and thus will be expected by 'make dist'.  To avoid this\n> \n> This file should be readded exactly for the reasons mentioned in the file.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11290/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11291", "body": "Commit 5469b88, just pushed, removes those by simply cherry-picking your own \ncommit on top of the merge.\n\nEl Wednesday, March 23, 2011, behlendorf escribi\u00f3:\n\n> > @@ -204,6 +204,8 @@ const struct super_operations zpl_super_operations =\n> > {\n> > \n> > ```\n> > .put_super  = zpl_put_super,\n> > .write_super    = NULL,\n> > .sync_fs    = zpl_sync_fs,\n> > ```\n> > -   .freeze_fs  = NULL,\n> \n> Yes, please remove them.  They are currently unused hooks and they cause\n> compile errors on older platforms.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11291/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11294", "body": "File removed.  Commit pushed.  Let me refresh the page to see how the merge \ndiff will look like.  You should do the same.\n\nEl Wednesday, March 23, 2011, behlendorf escribi\u00f3:\n\n> > @@ -0,0 +1,59 @@\n> > +put the dracut/90zfs directory in /usr/share/dracut/modules.d (or\n> > symlink it)\n> \n> A version of this file was already added to the dracut subdirectory.  If\n> you want to make changes/rewrite it that's fine but let's just keep one\n> copy of it around with the other dracut code.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11294/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}, "baryluk": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/383541", "body": "$ mkfs.ext3 /dev/zd0\n$ resize2fs /dev/zd0\n\nI hope you mean\n$ mkfs.ext3 /dev/tank/zd0\n$ resize2fs /dev/tank/zd0\n\nHaving full volume path as well pool name under dev is crucial to prevent conflicts. I would even like to have it under /dev/zvols/tank/zd0, to not conflict with default devices. Consider doing zpool create sda /dev/sda, zfs create -V 10g sda/sda. Horrible.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/383541/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/383556", "body": "See https://github.com/behlendorf/zfs/issues/152#issuecomment-1162158 for some more discussion.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/383556/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/383557", "body": "Probably releated to https://github.com/behlendorf/zfs/commit/4c0d8e50b99b4f3b4a9b7bc67ac7fc4e406f5755\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/383557/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/383767", "body": "Hmm. For me, more natural and more reliable will be to do this in opposite direction. Create device node in from start /dev/zvol/pool/dataset and then create symlink /dev/zd\\* (this actually can be skipped, as is in most practical cases useless beyond eventually symlinking to it from somewhere) and in /dev/disk/by-*/xxx pointing to /dev/zvol/pool/dataset. Is there any reasons or limitations of other tools (kernel, udev, sysfs?, creating DOS partitions on zvols? etc) that you want to put devices directly in the /dev/ directory? It is not necessary to put them there directly. \n\nPS. Hmm. I just checked open-iscsi, and do the same as you. First create /dev/sdX, and then symlink it into /dev/disk/by-path/ip-X.X.X.X:PP-iscsi-iqn-XYZ by udev. So you are right. IMHO it is remenescent of archaic structure of /dev/ directory. Not best possible and easy way, but looks to be standard in Linux. Neverthless /dev/zd\\* shouldn't be used anyway in such tools like fstab, mount, fdisk, fsck, mkfs.*, etc., as this names are unstable, for example doing zfs create -V 10g tank/zd1, will still create /dev/zd0 (at least if this was first volume create/mounted after reboot right?), and symlink in /dev/zvol/tank/zd1 -> ../../zd0. It is pretty confusing. This is the reason why I was somehow against it.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/383767/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "review_comments": []}, "dajhorn": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/461576", "body": "Kernel parameters are subject to decimal/octal/hexadecimal interpretation, so this example should be `spl_hostid=0x00bab10c`.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/461576/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/545339", "body": "zfsonlinux/zfs#370\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/545339/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/545340", "body": "zfsonlinux/zfs#370\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/545340/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/545341", "body": "zfsonlinux/zfs#370\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/545341/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/545343", "body": "zfsonlinux/zfs#370\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/545343/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}], "review_comments": []}, "kylef": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/511969", "body": "I didn't think about that.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/511969/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "review_comments": []}, "rlaager": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374212", "body": "What do you mean by this?\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374212/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374494", "body": "I've found this approach works best: Start from a checkout of upstream trunk. Then `git branch TOPIC; git checkout TOPIC`. Make your changes and commit. Push that branch to github. Repeat as necessary for the other features, starting from a checkout of upstream trunk each time. Then, do a pull request for each branch.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374494/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374507", "body": "The easiest solution is probably to leave your master tracking upstream master (i.e. you should not commit anything to master). Use a separate branch to combine your topic branches.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374507/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354255", "body": "domain should be 256 (255 + NUL). As a result, the other fields might need changing. I haven't looked closely.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354255/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354257", "body": "Is \"EPOH\" supposed to be \"epoch\"?\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354257/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354259", "body": "This should be checked for NUL-termination correctness.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354259/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354260", "body": "This should be checked for NUL-termination correctness.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354260/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354264", "body": "This should probably const char *.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354264/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354267", "body": "By \"EOL\", you probably meant \"NUL\"?\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354267/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354268", "body": "Like in the SMB patch, this usage of a function named file_is_executable() is really confusing.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354268/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354271", "body": "You're just blindly returning OK here. Should something be done?\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354271/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354272", "body": "What should this function do? Maybe I or someone can help flesh it out.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354272/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354276", "body": "You shouldn't be calling strlen() in a loop like this. This should be rewritten more like this (untested):\n\n```\nfor (c = line ; *c ; c++) {\n    if (*c == '\\r' || *c == '\\n') {\n      c = '\\0';\n      break;\n    }\n}\n```\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354276/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354281", "body": "The code inside this should be indented another level. (Is Github hiding that in the diff, maybe? I didn't check.)\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354281/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354285", "body": "What's the purpose of this check? I don't understand why /dev/zvol is hardcoded.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354285/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}}, "4": {"danielkza": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7059", "title": "Scrub gets stuck, becomes unstoppable and locks up user processes in uninterruptible sleep", "body": "Type                    | Version/Name\r\n---                     | ---\r\nDistribution Name       | Fedora\r\nDistribution Version    | 27\r\nLinux Kernel            | 4.14.13\r\nArchitecture            | x86_64\r\nZFS Version             | 0.7.5\r\nSPL Version             | 0.7.5\r\n\r\n### Describe the problem you're observing\r\n\r\nAfter a routine scrub starting on the background, some programs seem stuck in uninterruptible IO due to ZFS. Attempting\r\nto pause or stop the scrub does not work - the `zpool` command hangs and also becomes unkillable.\r\n\r\nHere is the `/proc/PID/stack` of the stuck `zpool`:\r\n\r\n```\r\n[<ffffffffc11f1c23>] cv_wait_common+0x113/0x130 [spl]\r\n[<ffffffffc11f1c55>] __cv_wait+0x15/0x20 [spl]\r\n[<ffffffffc182972d>] txg_wait_synced+0xdd/0x120 [zfs]\r\n[<ffffffffc1801f36>] dsl_sync_task+0x176/0x260 [zfs]\r\n[<ffffffffc180041e>] dsl_scrub_set_pause_resume+0x3e/0x40 [zfs]\r\n[<ffffffffc181e511>] spa_scrub_pause_resume+0x31/0x60 [zfs]\r\n[<ffffffffc1858f85>] zfs_ioc_pool_scan+0xb5/0xc0 [zfs]\r\n[<ffffffffc18592d6>] zfsdev_ioctl+0x1d6/0x600 [zfs]\r\n[<ffffffff9429f575>] do_vfs_ioctl+0xa5/0x610\r\n[<ffffffff9429fb59>] SyS_ioctl+0x79/0x90\r\n[<ffffffff94a0008d>] entry_SYSCALL_64_fastpath+0x20/0x83\r\n```\r\n\r\nAnd of one of the stuck user processes:\r\n\r\n```\r\n[<ffffffff940d7746>] io_schedule+0x16/0x40\r\n[<ffffffffc11f1bb9>] cv_wait_common+0xa9/0x130 [spl]\r\n[<ffffffffc11f1c98>] __cv_wait_io+0x18/0x20 [spl]\r\n[<ffffffffc187f7f2>] zio_wait+0xf2/0x1b0 [zfs]\r\n[<ffffffffc17c38d3>] dbuf_read+0x6e3/0x910 [zfs]\r\n[<ffffffffc17c5c19>] __dbuf_hold_impl+0x549/0x600 [zfs]\r\n[<ffffffffc17c5d71>] dbuf_hold_impl+0xa1/0xd0 [zfs]\r\n[<ffffffffc17c5e33>] dbuf_hold+0x33/0x60 [zfs]\r\n[<ffffffffc17cf1cd>] dmu_buf_hold_noread+0x8d/0x100 [zfs]\r\n[<ffffffffc17cf26f>] dmu_buf_hold+0x2f/0x80 [zfs]\r\n[<ffffffffc1845a5e>] zap_lockdir+0x4e/0xb0 [zfs]\r\n[<ffffffffc1845c3a>] zap_cursor_retrieve+0x17a/0x2e0 [zfs]\r\n[<ffffffffc1869abc>] zfs_readdir+0x13c/0x460 [zfs]\r\n[<ffffffffc1886911>] zpl_iterate+0x51/0x80 [zfs]\r\n[<ffffffff9429fce0>] iterate_dir+0x170/0x1a0\r\n[<ffffffff942a046a>] SyS_getdents+0xaa/0x140\r\n[<ffffffff94a0008d>] entry_SYSCALL_64_fastpath+0x20/0x83\r\n[<ffffffffffffffff>] 0xffffffffffffffff\r\n```\r\n\r\nHere is the affected pool status:\r\n\r\n```\r\n  pool: daniel-pc-media\r\n state: ONLINE\r\n  scan: scrub in progress since Thu Jan 18 03:29:02 2018\r\n    102G scanned out of 2,45T at 2,60M/s, 263h46m to go\r\n    0B repaired, 4,06% done\r\nconfig:\r\n\r\n    NAME                                 STATE     READ WRITE CKSUM\r\n    daniel-pc-media                      ONLINE       0     0     0\r\n      mirror-0                           ONLINE       0     0     0\r\n        ata-ST4000DM000-1F2168_Z301QGEZ  ONLINE       0     0     0\r\n        ata-ST4000DM000-1F2168_Z301QGCM  ONLINE       0     0     0\r\n```\r\n\r\nThere seems to be no progress actually being made, as none of the counters advance (other than the expected ETA).\r\n\r\n### Describe how to reproduce the problem\r\n\r\nNot able to so far. I can provide more observations of the running system if it doesn't force me to restart by\r\nbecoming unstable/unusable.\r\n\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n\r\nNothing of interest or related to ZFS is present in the kernel logs.\r\nThe problem *might* have been triggered by suspending and resuming the computer, but I was not monitoring the scrub before that, so I can't be sure.\r\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7059/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "makhomed": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7057", "title": "tasks txg_sync and zfs blocked for more than 120 seconds", "body": "### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       |  CentOS Linux\r\nDistribution Version    | 7.4.1708\r\nLinux Kernel                 |  3.10.0-693.11.6.el7\r\nArchitecture                 | x86_64\r\nZFS Version                  | 0.7.5-1\r\nSPL Version                  | 0.7.5-1\r\n\r\nZFS installed from zfs-kmod repo, ```baseurl=http://download.zfsonlinux.org/epel/7.4/kmod/$basearch/```\r\n\r\n### Describe the problem you're observing\r\n\r\nMessages in /var/log/messages about blocked tasks.\r\n\r\n### Describe how to reproduce the problem\r\n\r\nSorry, but I do not found way how to reproduce this bug.\r\nMay be stack trace will help to find root cause of this bug?\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n```\r\n\r\nJan 17 17:26:45 kvm-hardware-node kernel: INFO: task txg_sync:10906 blocked for more than 120 seconds.\r\nJan 17 17:26:45 kvm-hardware-node kernel: \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\nJan 17 17:26:45 kvm-hardware-node kernel: txg_sync        D ffff883f6a256eb0     0 10906      2 0x00000000\r\nJan 17 17:26:45 kvm-hardware-node kernel: Call Trace:\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04ddf57>] ? taskq_dispatch_ent+0x57/0x170 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff816ab6d9>] schedule+0x29/0x70\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff816a90e9>] schedule_timeout+0x239/0x2c0\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc07ba30f>] ? zio_taskq_dispatch+0x8f/0xa0 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc07ba352>] ? zio_issue_async+0x12/0x20 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc07bebcc>] ? zio_nowait+0xbc/0x150 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff816aac5d>] io_schedule_timeout+0xad/0x130\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff810b31a6>] ? prepare_to_wait_exclusive+0x56/0x90\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff816aacf8>] io_schedule+0x18/0x20\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04e24a2>] cv_wait_common+0xb2/0x150 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff810b34b0>] ? wake_up_atomic_t+0x30/0x30\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04e2598>] __cv_wait_io+0x18/0x20 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc07be49b>] zio_wait+0x10b/0x1b0 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc07346cf>] dsl_pool_sync+0xbf/0x440 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc07527c7>] spa_sync+0x437/0xdf0 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff810c6452>] ? default_wake_function+0x12/0x20\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff810bf074>] ? __wake_up+0x44/0x50\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0766a91>] txg_sync_thread+0x301/0x510 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0766790>] ? txg_fini+0x2a0/0x2a0 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04dcfa1>] thread_generic_wrapper+0x71/0x80 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04dcf30>] ? __thread_exit+0x20/0x20 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff810b252f>] kthread+0xcf/0xe0\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff810b2460>] ? insert_kthread_work+0x40/0x40\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff816b8798>] ret_from_fork+0x58/0x90\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff810b2460>] ? insert_kthread_work+0x40/0x40\r\nJan 17 17:26:45 kvm-hardware-node kernel: INFO: task zfs:21118 blocked for more than 120 seconds.\r\nJan 17 17:26:45 kvm-hardware-node kernel: \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\nJan 17 17:26:45 kvm-hardware-node kernel: zfs             D ffff883f79a38000     0 21118   8250 0x00000080\r\nJan 17 17:26:45 kvm-hardware-node kernel: Call Trace:\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff816ab6d9>] schedule+0x29/0x70\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04e2515>] cv_wait_common+0x125/0x150 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff810b34b0>] ? wake_up_atomic_t+0x30/0x30\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04e2555>] __cv_wait+0x15/0x20 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0765a2f>] txg_wait_synced+0xef/0x140 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0727d50>] ? dsl_dataset_snapshot_check_impl+0x210/0x210 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc073d017>] dsl_sync_task+0x177/0x270 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc07289d0>] ? dsl_dataset_snapshot_sync_impl+0x760/0x760 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0727d50>] ? dsl_dataset_snapshot_check_impl+0x210/0x210 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc07289d0>] ? dsl_dataset_snapshot_sync_impl+0x760/0x760 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0728dc3>] dsl_dataset_snapshot+0x133/0x2e0 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0479157>] ? nvlist_remove_all+0x77/0xd0 [znvpair]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0479655>] ? nvlist_add_common.part.51+0x325/0x430 [znvpair]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff811df99c>] ? __kmalloc_node+0x5c/0x2b0\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04db31d>] ? spl_kmem_alloc_impl+0xcd/0x170 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04db31d>] ? spl_kmem_alloc_impl+0xcd/0x170 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04db31d>] ? spl_kmem_alloc_impl+0xcd/0x170 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0479fc2>] ? nvlist_lookup_common.part.71+0xa2/0xb0 [znvpair]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0796868>] zfs_ioc_snapshot+0x348/0x3b0 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0798606>] zfsdev_ioctl+0x1d6/0x650 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff8121710d>] do_vfs_ioctl+0x33d/0x540\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff816b3801>] ? __do_page_fault+0x171/0x450\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff812173b1>] SyS_ioctl+0xa1/0xc0\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff816b89fd>] system_call_fastpath+0x16/0x1b\r\n```", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7057/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "beren12": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7056", "title": "Improve snapshot listing error message", "body": "### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Debian\r\nDistribution Version    | 9\r\nLinux Kernel                 | 4.13.13-1~bpo9+1\r\nArchitecture                 | x64\r\nZFS Version                  | 0.7.4\r\nSPL Version                  | 0.7.4\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\nlisting snapshots for a single dataset fails unless -r is used, but this is not mentioned in the error message. -r is not needed to list all snapshots, so it can be a confusing behavior.\r\n\r\n### Describe how to reproduce the problem\r\n\r\n```\r\nzfs list -t snap rpool\r\n```\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n\r\n```\r\nzfs list -t snap rpool\r\ncannot open 'rpool': missing '@' delimiter in snapshot name\r\n```\r\n\r\nCould we amend the error message to also give a hint? Or possibly be consistent and list all snapshots without -r, just as giving no dataset does? Bookmarks might also need the same edit, ike here:\r\n\r\n```diff\r\n--- lib/libzfs/libzfs_dataset.c\t2018-01-17 10:07:12.178817043 -0500\r\n+++ lib/libzfs/libzfs_dataset.c.new\t2018-01-17 10:06:47.307290884 -0500\r\n@@ -175,7 +175,7 @@\r\n \tif (type == ZFS_TYPE_SNAPSHOT && strchr(path, '@') == NULL) {\r\n \t\tif (hdl != NULL)\r\n \t\t\tzfs_error_aux(hdl, dgettext(TEXT_DOMAIN,\r\n-\t\t\t    \"missing '@' delimiter in snapshot name\"));\r\n+\t\t\t    \"missing '@' delimiter in snapshot name, did you mean to use -r?\"));\r\n \t\treturn (0);\r\n \t}\r\n```", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7056/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "behlendorf": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7052", "title": "zfs load-key double free", "body": "### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | CentOS\r\nDistribution Version    | 7\r\nLinux Kernel                 | 3.10.0-693.11.6.1\r\nArchitecture                 | x86_64\r\nZFS Version                  | zfs-0.7.0-246-gd658b2c\r\nSPL Version                  | master\r\n\r\n### Describe the problem you're observing\r\n\r\nWhen zfs is built with `--enable-debug --enable-debuginfo` and an incorrect passphrase is provided to `zfs load-key` followed by an empty one a \"double free or leak\" is reported.  Observed during manual testing.\r\n\r\n### Describe how to reproduce the problem\r\n\r\nAt build time `--enable-debug --enable-debuginfo`, then,\r\n\r\n```sh\r\n$ truncate -s 512M /var/tmp/vdev\r\n$ zpool create tank /var/tmp/vdev\r\n$ zfs create -o encryption=on -o keyformat=passphrase tank/fs\r\nEnter passphrase: password\r\nRe-enter passphrase: password\r\n$ zfs unload-key -a\r\n```\r\n\r\nReload the key giving the wrong password first \"password1\" which is correctly rejected.  Then just hit enter when prompted again.\r\n\r\n```sh\r\n$ zfs load-key -a\r\nEnter passphrase for 'tank/fs': password1\r\nKey load error: Incorrect key provided for 'tank/fs'.\r\nEnter passphrase for 'tank/fs': <empty>\r\nKey load error: Passphrase too short (min 8).\r\n*** Error in `cmd/zfs/.libs/lt-zfs': double free or corruption (fasttop): 0x000000000061f150 ***\r\n======= Backtrace: =========\r\n/lib64/libc.so.6(+0x7c619)[0x2aaaacc65619]\r\nlib/libzfs/.libs/libzfs.so.2(zfs_crypto_load_key+0xf3)[0x2aaaab109023]\r\ncmd/zfs/.libs/lt-zfs[0x406557]\r\ncmd/zfs/.libs/lt-zfs[0x405d41]\r\ncmd/zfs/.libs/lt-zfs[0x408298]\r\ncmd/zfs/.libs/lt-zfs[0x4051ef]\r\n/lib64/libc.so.6(__libc_start_main+0xf5)[0x2aaaacc0ac05]\r\ncmd/zfs/.libs/lt-zfs[0x405318]\r\n...\r\n```", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7052/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7026", "title": "Test case history_004_pos", "body": "### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | all\r\nDistribution Version    | all\r\nLinux Kernel                 | all\r\nArchitecture                 | all\r\nZFS Version                  | zfs-0.7.0-230-gb02beca\r\nSPL Version                  | 0.7\r\n\r\n### Describe the problem you're observing\r\n\r\nRarely observed failure of history_004_pos during automated testing.\r\n\r\n### Describe how to reproduce the problem\r\n\r\nReproducible by the buildbot.\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n\r\n\r\nhttp://build.zfsonlinux.org/builders/Amazon%202%20x86_64%20Release%20%28TEST%29/builds/105/\r\n\r\n```\r\nTest: /usr/share/zfs/zfs-tests/tests/functional/history/history_004_pos (run as root) [00:04] [FAIL]\r\n02:51:58.52 ASSERTION: 'zpool history' can cope with simultaneous commands.\r\n02:52:01.35 umount: testpool/clone3: mountpoint not found\r\n02:52:01.35 cannot unmount 'testpool/clone3': umount failed\r\n02:52:01.55 cannot create 'testpool/clone3': dataset already exists\r\n02:52:01.62 cannot promote 'testpool/clone3': not a cloned filesystem\r\n02:52:01.66 cannot destroy 'testpool/testfs3': filesystem has children\r\n02:52:01.66 use '-r' to destroy the following datasets:\r\n02:52:01.66 testpool/testfs3@snap\r\n02:52:01.81 cannot create 'testpool/testfs3': dataset already exists\r\n02:52:01.92 cannot create snapshot 'testpool/testfs3@snap': dataset already exists\r\n02:52:02.69 The entries count error: entry_count=297  orig_count = 103\r\n02:52:02.69 NOTE: Performing test-fail callback (/usr/share/zfs/zfs-tests/callbacks/zfs_dbgmsg.ksh)\r\n```", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7026/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/3da3488e6339ff2dc5c7f3da8c8a0c552d018d68", "message": "Fix shellcheck v0.4.6 warnings\n\nResolve new warnings reported after upgrading to shellcheck\r\nversion 0.4.6.  This patch contains no functional changes.\r\n\r\n* egrep is non-standard and deprecated. Use grep -E instead. [SC2196]\r\n* Check exit code directly with e.g. 'if mycmd;', not indirectly\r\n  with $?.  [SC2181]  Suppressed.\r\n\r\nReviewed-by: George Melikov <mail@gmelikov.ru>\r\nReviewed-by: Giuseppe Di Natale <dinatale2@llnl.gov>\r\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nCloses #7040"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/e1a0850c3570ae53df5779bc656f17b98b86f160", "message": "Force ztest to always use /dev/urandom\n\nFor ztest, which is solely for testing, using a pseudo random\r\nis entirely reasonable.  Using /dev/urandom ensures the system\r\nentropy pool doesn't get depleted thus stalling the testing.\r\nThis is a particular problem when testing in VMs.\r\n\r\nReviewed-by: Tim Chase <tim@chase2k.com>\r\nReviewed by: Thomas Caputi <tcaputi@datto.com>\r\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nCloses #7017 \r\nCloses #7036"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/fed90353d799acbc5e81b0dfadc6d649b0f2e8b5", "message": "Support -fsanitize=address with --enable-asan\n\nWhen --enable-asan is provided to configure then build all user\r\nspace components with fsanitize=address.  For kernel support\r\nuse the Linux KASAN feature instead.\r\n\r\nhttps://github.com/google/sanitizers/wiki/AddressSanitizer\r\n\r\nWhen using gcc version 4.8 any test case which intentionally\r\ngenerates a core dump will fail when using --enable-asan.\r\nThe default behavior is to disable core dumps and only newer\r\nversions allow this behavior to be controled at run time with\r\nthe ASAN_OPTIONS environment variable.\r\n\r\nAdditionally, this patch includes some build system cleanup.\r\n\r\n* Rules.am updated to set the minimum AM_CFLAGS, AM_CPPFLAGS,\r\n  and AM_LDFLAGS.  Any additional flags should be added on a\r\n  per-Makefile basic.  The --enable-debug and --enable-asan\r\n  options apply to all user space binaries and libraries.\r\n\r\n* Compiler checks consolidated in always-compiler-options.m4\r\n  and renamed for consistency.\r\n\r\n* -fstack-check compiler flag was removed, this functionality\r\n  is provided by asan when configured with --enable-asan.\r\n\r\n* Split DEBUG_CFLAGS in to DEBUG_CFLAGS, DEBUG_CPPFLAGS, and\r\n  DEBUG_LDFLAGS.\r\n\r\n* Moved default kernel build flags in to module/Makefile.in and\r\n  split in to ZFS_MODULE_CFLAGS and ZFS_MODULE_CPPFLAGS.  These\r\n  flags are set with the standard ccflags-y kbuild mechanism.\r\n\r\n* -Wframe-larger-than checks applied only to binaries or\r\n  libraries which include source files which are built in\r\n  both user space and kernel space.  This restriction is\r\n  relaxed for user space only utilities.\r\n\r\n* -Wno-unused-but-set-variable applied only to libzfs and\r\n  libzpool.  The remaining warnings are the result of an\r\n  ASSERT using a variable when is always declared.\r\n\r\n* -D_POSIX_PTHREAD_SEMANTICS and -D__EXTENSIONS__ dropped\r\n  because they are Solaris specific and thus not needed.\r\n\r\n* Ensure $GDB is defined as gdb by default in zloop.sh.\r\n\r\nSigned-off-by: DHE <git@dehacked.net>\r\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nCloses #7027"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/7e7f5132779a04da0070cf6e6ffd8e9b5f7692de", "message": "Disable history_004_pos\n\nOccasionally observed failure of history_004_pos due to the test\r\ncase not being 100% reliable.  In order to prevent false positives\r\ndisable this test case until it can be made reliable.\r\n\r\nReviewed-by: George Melikov <mail@gmelikov.ru>\r\nReviewed-by: Giuseppe Di Natale <dinatale2@llnl.gov>\r\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nIssue #7026 \r\nCloses #7028"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/bfe27ace0de64838d50ff351396423a481de6c84", "message": "Fix unused variable warnings\n\nResolved unused variable warnings observed after restricting\n-Wno-unused-but-set-variable to only libzfs and libzpool.\n\nReviewed-by: DHE <git@dehacked.net>\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\nCloses #6941"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/06401e42221d2f5130065caf70f8276ba4d19acd", "message": "Fix ztest_verify_dnode_bt() test case\n\nIn ztest_verify_dnode_bt the ztest_object_lock must be held in\norder to safely verify the unused bonus space.\n\nReviewed-by: DHE <git@dehacked.net>\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\nCloses #6941"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/b02becaa00aef3d25b30588bf49affbf1e9a84a4", "message": "Reduce codecov PR comments\n\nAttempt to reduce the number of comments posted by codecov\r\nto PR requests.  Based on the codecov documenation setting\r\n\"require_changes=yes\" and \"behavior=once\" should result in\r\na single comment under most circumstances.\r\n\r\nhttps://docs.codecov.io/v4.3.6/docs/pull-request-comments\r\n\r\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nIssue #7022 \r\nCloses #7025"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/0873bb6337452e3e028e40f5dad945b30deab185", "message": "Fix ARC hit rate\n\nWhen the compressed ARC feature was added in commit d3c2ae1\r\nthe method of reference counting in the ARC was modified.  As\r\npart of this accounting change the arc_buf_add_ref() function\r\nwas removed entirely.\r\n\r\nThis would have be fine but the arc_buf_add_ref() function\r\nserved a second undocumented purpose of updating the ARC access\r\ninformation when taking a hold on a dbuf.  Without this logic\r\nin place a cached dbuf would not migrate its associated\r\narc_buf_hdr_t to the MFU list.  This would negatively impact\r\nthe ARC hit rate, particularly on systems with a small ARC.\r\n\r\nThis change reinstates the missing call to arc_access() from\r\ndbuf_hold() by implementing a new arc_buf_access() function.\r\n\r\nReviewed-by: Giuseppe Di Natale <dinatale2@llnl.gov>\r\nReviewed-by: Tony Hutter <hutter2@llnl.gov>\r\nReviewed-by: Tim Chase <tim@chase2k.com>\r\nReviewed by: George Wilson <george.wilson@delphix.com>\r\nReviewed-by: George Melikov <mail@gmelikov.ru>\r\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nCloses #6171 \r\nCloses #6852 \r\nCloses #6989"}], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6999", "title": "Extend deadman logic", "body": "### Description\r\n\r\nThe intent of this patch is extend the existing deadman code such that it's flexible enough to be used by both ztest and on production systems.  The proposed changes include:\r\n\r\n* Added a new `zfs_deadman_failmode` module option which is used to dynamically control the behavior of the deadman.  It's loosely modeled after, but independant from, the pool failmode property.  It can be set to wait, continue, or panic.\r\n\r\n    * wait     - Wait for the \"hung\" I/O (default)\r\n    * continue - Attempt to recover from a \"hung\" I/O\r\n    * panic    - Panic the system\r\n\r\n* Added a new `zfs_deadman_ziotime_ms` module option which is analogous to zfs_deadman_synctime_ms` except instead of applying to a pool TXG sync it applies to zio_wait().  A   default value of 300s is used to define a \"hung\" zio.\r\n\r\n* The ztest deadman thread has been re-enabled by default, aligned with the upstream OpenZFS code, and then extended to terminate the process when it takes significantly longer to complete than expected.\r\n\r\n* The -G option was added to ztest to print the internal debug log when a fatal error is encountered.  This same option was previously added to zdb in commit fa603f82.  Update zloop.sh to unconditionally pass -G to obtain additional debugging.\r\n\r\n* The FM_EREPORT_ZFS_DELAY event which was previously posted when the deadman detect a \"hung\" pool has been replaced by a new dedicated FM_EREPORT_ZFS_DEADMAN event.\r\n\r\n* The proposed recovery logic attempts to restart a \"hung\"  zio by calling zio_interrupt() on any outstanding leaf zios.  We may want to further restrict this to zios in either the  ZIO_STAGE_VDEV_IO_START or ZIO_STAGE_VDEV_IO_DONE stages.  Calling zio_interrupt() is expected to only be useful for cases when an IO has been submitted to the physical device\r\n  but for some reasonable the completion callback hasn't been called by the lower layers.  This shouldn't be possible but  has been observed and may be caused by kernel/driver bugs.\r\n\r\n* The 'zfs_deadman_synctime_ms' default value was reduced from 1000s to 600s.\r\n\r\n* Depending on how ztest fails there may be no cache file to move.  This should not be considered fatal, collect the logs which are available and carry on.\r\n\r\n### Motivation and Context\r\n\r\nAdd some of the needed infrastructure to make it possible to root cause `ztest` \"hangs\" observed during automated testing.  With this change applied at least basic debugging information will be collected for any \"hangs\".  This change can be further augmented with improvements to the debugging infrastructure.\r\n\r\nIssue #6901.\r\n\r\n### How Has This Been Tested?\r\n\r\nLocally by running `zloop.sh` in-tree for approximated 4 days.  Over this time period the deadman behaved as expected and properly terminated `ztest` when it appeared to be hung.  Further analysis of the debug logs and cores obtained is still needed.  The expectation is they will provide some statistical insight in the most often observed failures.\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [x] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [x] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "OWNER"}], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11254", "body": "This file should be readded exactly for the reasons mentioned in the file.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11254/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11255", "body": "Yes, please remove them.  They are currently unused hooks and they cause compile errors on older platforms.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11255/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11259", "body": "A version of this file was already added to the dracut subdirectory.  If you want to make changes/rewrite it that's fine but let's just keep one copy of it around with the other dracut code.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11259/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}]}, "wphilips": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7050", "title": "zfs-dracut boot failure with out of date zpool.cache - zfs_force not working", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       |  Fedora \r\nDistribution Version    |  26 \r\nLinux Kernel                 |  any (e.g., 4.14.6-200.fc26.x86_64)\r\nArchitecture                 |  x86_64\r\nZFS Version                  |   v0.7.5-1\r\nSPL Version                  |  v0.7.5-1\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\nI have several systems with root and boot on zfs. The systems boot with grub initramfs \r\nis generated by dracut with zfs-dracut-0.7.5-1.fc26.x86_64\r\n\r\nThe problem occurs whenever significant changes are made to the zpools attached to the\r\nsystem, or even when adding empty disks.  Very often, dracut enters the emergency shell\r\nbecause it cannot import the pools based on the zpool.cache file. Even adding zfs_force \r\nas a kernel option does not work. E.g., I tried:\r\n\r\nlinux16 /boot/@/vmlinuz-4.14.13-200.fc26.x86_64 root=zfs:ssd/fc26 boot=ssd ro rd_NO_PLYMOUTH audit=0 zfs_force=1\r\n\r\n\r\nThe reason seems to be that the zpoool.cache file does not reflect the current (changed) configuration of the system. It is not clear why zfs.force  or zfs_force does not work.\r\n\r\n\r\nHere are 2 use cases:\r\n\r\n1. to defragment  the pool on which the zfs root is installed, I attach a new disk, create a new\r\nzpool on it, copy all the data, remove the old disk, reboot and change some grub parameters so\r\nthat it boots the new bool. Before the reboot, zpool.cache refers to the old pool on the old disk.\r\nRunning 'dracut -f ...' will therefore copy the \"old\" zpool.cache into initamfs. After boot, the disks\r\nhave changed and this zpool.cache is outdated. \r\n\r\n2. in a system with 3 rpools, I remove one of the disks which contains a non-essential \r\nrpool (after exporting it). I then add two new empty disks. The system boots into the dracut \r\nshell even though the root pool has not changed. The now missing, but non-essential pool\r\nprevents a normal boot.\r\n\r\n\r\nIt is possible to somewhat prevent these problems by removing zpool.cache, then running\r\ndracut and then rebooting. In this case, often dracut still enters the emergency shell claiming\r\nthat the pool(s) are in use in another system, but by force importing them in the dracut shell\r\nand rebooting it is possible to boot the system. Then it is possible to recreate zpool.cache, \r\nand rerun dracut to create a working system. Alternatively, one can continue to use the initramfs\r\nwith the missing zpool.cache.\r\n\r\nIt is probably also possible to create a zpool.cache file for the future new configuration, but it probably \r\ninvolves deleting the current one and it is easy to make a mistake.\r\n\r\nIn any case, make a simple mistake or  forget to take these  \"preventive\" measures \r\nand you end up with a system which will always enter the dracut emergency shell with \r\nno way to recover (except if you have e.g., a usb boot disk with zfs at hand. Even then\r\nit is really hard to recover).\r\n\r\nIn the good old days it also use to be  possible to fix problems in the dracut shell and then continue to boot. These days, systemd prevents this from working (probably related to the message \"transaction is destructive\")\r\n\r\nWhile fixing the zfs_force option would help, adding a configuration option to dracut to never \r\ncreate zfs.cache and/or adding a kernel command line option to ignore zpool.cache might \r\nalso help.\r\n \r\n\r\nPS. Even better would be to fix dracut or systemd so that a boot can continue after fixing problems \r\nin dracut. For instance, in the emergency shell you would remove the zpool.cache file and \r\nthen type some command to continue boot. However, that is probably a more general (non zfsonlinux)\r\nissue.\r\n\r\n\r\n\r\n\r\n\r\n\r\n### Describe how to reproduce the problem\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n<!-- \r\n*IMPORTANT* - Please mark logs and text output from terminal commands \r\nor else Github will not display them correctly. \r\nAn example is provided below.\r\n\r\nExample:\r\n```\r\nthis is an example how log text should be marked (wrap it with ```)\r\n```\r\n-->\r\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7050/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "jhammond-intel": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7045", "title": "pool suspension due to delayed MMP writes needs a better error message", "body": "### System information\r\nDistribution Name       | *\r\nDistribution Version    | *\r\nLinux Kernel                 | * \r\nArchitecture                 | *\r\nZFS Version                  | 0.7.5\r\nSPL Version                  | 0.7.5\r\n\r\nThis is related to Lustre issue https://jira.hpdd.intel.com/browse/LU-9845.\r\n\r\nWhen an MMP thread suspends a pool because \"no MMP write has succeeded in over mmp_interval * mmp_fail_intervals nanoseconds\" the only message we see on the console is \"WARNING: Pool 'blahblah' has encountered an uncorrectable I/O failure and has been suspended.\" This is not really informative enough and probably a bit misleading. We encountered these mysteriously suspended pool in our test clusters and were only able to attribute this to MMP by setting the pool failure mode to panic.\r\n\r\nI was able to easily reproduce using the Lustre backed zfs setup (VM has hostid set and 2 vCPUs, pool has MMP enabled) using the following:\r\n```\r\nm:~# export FSTYPE=zfs\r\nm:~# bash $LUSTRE/tests/llmount.sh\r\n...\r\nm:~# cat /sys/module/zfs/parameters/zfs_multihost_interval \r\n1000\r\nm:~# echo 100 > /sys/module/zfs/parameters/zfs_multihost_interval # set mmp interval to 100ms\r\nm:~# chrt -f 20 dd if=/dev/zero of=/dev/null &\r\nm:~# chrt -f 20 dd if=/dev/zero of=/dev/null &\r\n```\r\n\r\nI think we should probably keep the message from `zio_suspend()` as is but add a suitable message to `mmp_thread()` before calling `zio_suspend()`.", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7045/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/51d1b58ef3467c3a9711c65458f93063dd17354f", "message": "Emit an error message before MMP suspends pool\n\nIn mmp_thread(), emit an MMP specific error message before calling\r\nzio_suspend() so that the administrator will understand why the pool\r\nis being suspended.\r\n\r\nReviewed-by: Olaf Faaland <faaland1@llnl.gov>\r\nReviewed-by: Giuseppe Di Natale <dinatale2@llnl.gov>\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: John L. Hammond <john.hammond@intel.com>\r\nCloses #7048"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "samuelbernardo": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7042", "title": "BUG: soft lockup - CPU# stuck for 22s! [z_wr_iss]", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Gentoo\r\nDistribution Version    | -\r\nLinux Kernel                 | 4.14.12\r\nArchitecture                 | x86_64\r\nZFS Version                  | 0.7.5\r\nSPL Version                  | 0.7.5\r\n\r\n\r\n### Describe the problem you're observing\r\n\r\nzfs thread lock after some intensive IO. It allows to continue to access data, but all writes won't be commited to disk, since reboot needs ctrl+shift+sysreq reisub. It remains locked after trying soft reboot, and the only solution is a forced reboot with sysreq.\r\nThe zfs lock is registered systematically after some intensive IO on each OS reboot.\r\n\r\n### Describe how to reproduce the problem\r\n\r\nThis is the configuration of zfs volume that has the deadlock (using deduplication and lz4 compression):\r\n\r\nNAME   SIZE  ALLOC   FREE  EXPANDSZ   FRAG    CAP  DEDUP  HEALTH  ALTROOT\r\nzfs  21.8T  5.69T  16.1T         -     6%    26%  1.07x  ONLINE  -\r\n  raidz1  10.9T  2.85T  8.03T         -     6%    26%\r\n    ata-TOSHIBA_DT01ACA300_Z5RS6H0KS      -      -      -         -      -      -\r\n    ata-TOSHIBA_HDWD130_678KR5JAS      -      -      -         -      -      -\r\n    ata-TOSHIBA_DT01ACA300_16QUEEEKS      -      -      -         -      -      -\r\n    ata-TOSHIBA_HDWD130_678KPYLAS      -      -      -         -      -      -\r\n  raidz1  10.9T  2.85T  8.03T         -     6%    26%\r\n    ata-TOSHIBA_HDWD130_678KTDUAS      -      -      -         -      -      -\r\n    ata-TOSHIBA_DT01ACA300_16QUDE3KS      -      -      -         -      -      -\r\n    ata-WDC_WD40EZRX-75SPEB0_WD-WCC4E2YAA98J-part6      -      -      -         -      -      -\r\n    ata-TOSHIBA_HDWD130_678KPP7AS      -      -      -         -      -      -\r\ncache      -      -      -         -      -      -\r\n  sdc   699G  79.7M   699G         -     0%     0%\r\n  sde   699G  78.2M   699G         -     0%     0%\r\n\r\n  pool: zfs\r\n state: ONLINE\r\n  scan: resilvered 75.5G in 0h38m with 0 errors on Mon Oct 16 03:45:53 2017\r\nconfig:\r\n        NAME                                                STATE     READ WRITE CKSUM\r\n        zfs                                                 ONLINE       0     0     0\r\n          raidz1-0                                          ONLINE       0     0     0\r\n            ata-TOSHIBA_DT01ACA300_Z5RS6H0KS                ONLINE       0     0     0\r\n            ata-TOSHIBA_HDWD130_678KR5JAS                   ONLINE       0     0     0\r\n            ata-TOSHIBA_DT01ACA300_16QUEEEKS                ONLINE       0     0     0\r\n            ata-TOSHIBA_HDWD130_678KPYLAS                   ONLINE       0     0     0\r\n          raidz1-1                                          ONLINE       0     0     0\r\n            ata-TOSHIBA_HDWD130_678KTDUAS                   ONLINE       0     0     0\r\n            ata-TOSHIBA_DT01ACA300_16QUDE3KS                ONLINE       0     0     0\r\n            ata-WDC_WD40EZRX-75SPEB0_WD-WCC4E2YAA98J-part6  ONLINE       0     0     0\r\n            ata-TOSHIBA_HDWD130_678KPP7AS                   ONLINE       0     0     0\r\n        cache\r\n          sdc                                               ONLINE       0     0     0\r\n          sde                                               ONLINE       0     0     0\r\n\r\ncapacity  |   operations  |   bandwidth  |  total_wait   |  disk_wait  |  syncq_wait  |  asyncq_wait | scrub\r\n\r\npool |  alloc |  free |  read | write |  read | write |  read | write |  read | write  | read | write |  read | write |  wait \r\n  --- |   --- |   --- |   --- |  --- |   --- |  --- |   --- |  --- |   --- |  ---  |  --- |  --- |   --- |  --- |   --- \r\nzfs     |    5.69T | 16.1T  |   81 |   109 |  500K |  950K |   4us  |  1us  |  4us | 543ns | 187ns  |  2ns  |  1us |   1us | 723ns\r\n\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n```\r\nJan 10 21:57:11 x99 kernel: INFO: rcu_sched detected expedited stalls on CPUs/tasks: { 9-... } 218109 jiffies s: 401 root: 0x200/.\r\nJan 10 21:57:11 x99 kernel: blocking rcu_node structures:\r\nJan 10 21:57:11 x99 kernel: Task dump for CPU 9:\r\nJan 10 21:57:11 x99 kernel: z_wr_iss        R  running task    12256   749      2 0x80000008\r\nJan 10 21:57:11 x99 kernel: Call Trace:\r\nJan 10 21:57:11 x99 kernel:  ? arc_buf_info+0xcc7/0xf80 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? mutex_lock+0x9/0x30\r\nJan 10 21:57:11 x99 kernel:  ? dbuf_rele_and_unlock+0x4cb/0x540 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? mutex_lock+0x9/0x30\r\nJan 10 21:57:11 x99 kernel:  ? mutex_lock+0x9/0x30\r\nJan 10 21:57:11 x99 kernel:  ? zio_worst_error+0x60f/0x1250 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? zio_wait+0x113/0x160 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? dbuf_read+0x617/0xd80 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? __kmalloc_node+0x27d/0x290\r\nJan 10 21:57:11 x99 kernel:  ? spl_kmem_zalloc+0x85/0x150 [spl]\r\nJan 10 21:57:11 x99 kernel:  ? zap_leaf_lookup+0x6d/0x130 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? fzap_length+0x48/0x90 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? zap_name_alloc_uint64+0x50/0x60 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? zap_length_uint64+0x74/0x230 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? ddt_walk+0x31b/0x450 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? ddt_lookup+0xb4/0x190 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? zio_checksum_compute+0x15d/0x2a0 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? spl_kmem_cache_alloc+0x5b/0xb10 [spl]\r\nJan 10 21:57:11 x99 kernel:  ? __kmalloc_node+0x27d/0x290\r\nJan 10 21:57:11 x99 kernel:  ? spl_kmem_alloc+0x8e/0x160 [spl]\r\nJan 10 21:57:11 x99 kernel:  ? spl_kmem_alloc+0x8e/0x160 [spl]\r\nJan 10 21:57:11 x99 kernel:  ? zio_flush+0x867/0xde0 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? zio_push_transform+0x662/0xbe0 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? zio_execute+0x7c/0x430 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? taskq_dispatch_delay+0x51f/0x950 [spl]\r\nJan 10 21:57:11 x99 kernel:  ? wake_up_q+0x70/0x70\r\nJan 10 21:57:11 x99 kernel:  ? zio_interrupt+0x1030/0x1030 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? kthread+0xf7/0x130\r\nJan 10 21:57:11 x99 kernel:  ? taskq_dispatch_delay+0x2c0/0x950 [spl]\r\nJan 10 21:57:11 x99 kernel:  ? kthread_create_on_node+0x40/0x40\r\nJan 10 21:57:11 x99 kernel:  ? do_group_exit+0x35/0xa0\r\nJan 10 21:57:11 x99 kernel:  ? ret_from_fork+0x1f/0x30\r\nJan 10 21:57:13 x99 kernel: watchdog: BUG: soft lockup - CPU#9 stuck for 22s! [z_wr_iss:749]\r\nJan 10 21:57:13 x99 kernel: Modules linked in: nvidia_uvm(PO) zfs(PO) zunicode(PO) zavl(PO) icp(PO) zcommon(PO) znvpair(PO) spl(O) nv>\r\nJan 10 21:57:13 x99 kernel: CPU: 9 PID: 749 Comm: z_wr_iss Tainted: P        W  O L  4.14.12-gentoox99 #1\r\nJan 10 21:57:13 x99 kernel: Hardware name: ASUS All Series/X99-S, BIOS 3402 08/18/2016\r\nJan 10 21:57:13 x99 kernel: task: ffff880fef778e00 task.stack: ffffc9000a2dc000\r\nJan 10 21:57:13 x99 kernel: RIP: 0010:zap_leaf_lookup+0x92/0x130 [zfs]\r\nJan 10 21:57:13 x99 kernel: RSP: 0018:ffffc9000a2dfa40 EFLAGS: 00000213 ORIG_RAX: ffffffffffffff10\r\nJan 10 21:57:13 x99 kernel: RAX: 0000000000000000 RBX: ffff880d59b78130 RCX: 0000000000000007\r\nJan 10 21:57:13 x99 kernel: RDX: 000000000000000c RSI: ffff880d59b78000 RDI: 5d7f96b690640000\r\nJan 10 21:57:13 x99 kernel: RBP: ffffc9000a2dfa88 R08: 00000000002ebfcb R09: ffff880de2c53800\r\nJan 10 21:57:13 x99 kernel: R10: ffff880de2c53800 R11: ffff880fe497a000 R12: ffff880de2c53800\r\nJan 10 21:57:13 x99 kernel: R13: ffff880c575f3600 R14: ffff880d59b78132 R15: 0000000000000001\r\nJan 10 21:57:13 x99 kernel: FS:  0000000000000000(0000) GS:ffff880fff440000(0000) knlGS:0000000000000000\r\nJan 10 21:57:13 x99 kernel: CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\r\nJan 10 21:57:13 x99 kernel: CR2: 00007f767108b850 CR3: 0000000004823006 CR4: 00000000001606e0\r\nJan 10 21:57:13 x99 kernel: Call Trace:\r\nJan 10 21:57:13 x99 kernel:  fzap_length+0x48/0x90 [zfs]\r\nJan 10 21:57:13 x99 kernel:  ? zap_name_alloc_uint64+0x50/0x60 [zfs]\r\nJan 10 21:57:13 x99 kernel:  zap_length_uint64+0x74/0x230 [zfs]\r\nJan 10 21:57:13 x99 kernel:  ddt_walk+0x31b/0x450 [zfs]\r\nJan 10 21:57:13 x99 kernel:  ddt_lookup+0xb4/0x190 [zfs]\r\nJan 10 21:57:13 x99 kernel:  ? zio_checksum_compute+0x15d/0x2a0 [zfs]\r\nJan 10 21:57:13 x99 kernel:  ? spl_kmem_cache_alloc+0x5b/0xb10 [spl]\r\nJan 10 21:57:13 x99 kernel:  ? __kmalloc_node+0x27d/0x290\r\nJan 10 21:57:13 x99 kernel:  ? spl_kmem_alloc+0x8e/0x160 [spl]\r\nJan 10 21:57:13 x99 kernel:  ? spl_kmem_alloc+0x8e/0x160 [spl]\r\nJan 10 21:57:13 x99 kernel:  zio_flush+0x867/0xde0 [zfs]\r\nJan 10 21:57:13 x99 kernel:  ? zio_push_transform+0x662/0xbe0 [zfs]\r\nJan 10 21:57:13 x99 kernel:  zio_execute+0x7c/0x430 [zfs]\r\nJan 10 21:57:13 x99 kernel:  taskq_dispatch_delay+0x51f/0x950 [spl]\r\nJan 10 21:57:13 x99 kernel:  ? wake_up_q+0x70/0x70\r\nJan 10 21:57:13 x99 kernel:  ? zio_interrupt+0x1030/0x1030 [zfs]\r\nJan 10 21:57:13 x99 kernel:  kthread+0xf7/0x130\r\nJan 10 21:57:13 x99 kernel:  ? taskq_dispatch_delay+0x2c0/0x950 [spl]\r\nJan 10 21:57:13 x99 kernel:  ? kthread_create_on_node+0x40/0x40\r\nJan 10 21:57:13 x99 kernel:  ? do_group_exit+0x35/0xa0\r\nJan 10 21:57:13 x99 kernel:  ret_from_fork+0x1f/0x30\r\nJan 10 21:57:13 x99 kernel: Code: eb 29 0f b7 43 02 4c 8d 73 02 66 83 f8 ff 74 7f 49 8b 8c 24 d8 00 00 00 41 8b 94 24 d0 00 00 00 49 >\r\nJan 10 21:57:18 x99 systemd[1]: Received SIGINT.\r\n```", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7042/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ltz3317": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7038", "title": "zfs sync hang ", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       |  centos 7.2 \uff0csync hang\r\nDistribution Version    | \r\nLinux Kernel                 | 3.10.0-327.13.1.el7.x86_64 \r\nArchitecture                 | \r\nZFS Version                  | v0.7.5-1\r\nSPL Version                  |  v0.7.5-1\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\nsync hang \uff0cmysql hang\uff0ckworker cpu 100\r\n### Describe how to reproduce the problem\r\nhigh frequency  create/destroy/clone\r\n### Include any warning/errors/backtraces from the system logs\r\ndmsg:\r\n[  189.990968] Adjusting tsc more than 11% (8039035 vs 7759471)\r\n[ 2522.644734] INFO: task mysqld:6608 blocked for more than 120 seconds.\r\n[ 2522.644790] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2522.644854] mysqld          D 0000000000000000     0  6608   5602 0x00000000\r\n[ 2522.644860]  ffff880feb913da0 0000000000000086 ffff881006eac500 ffff880feb913fd8\r\n[ 2522.644865]  ffff880feb913fd8 ffff880feb913fd8 ffff881006eac500 ffff880fffc8a180\r\n[ 2522.644869]  ffff880fffc8a000 ffff880fffc8a188 ffff880fffc8a028 0000000000000000\r\n[ 2522.644873] Call Trace:\r\n[ 2522.644882]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2522.644906]  [<ffffffffa04744d5>] cv_wait_common+0x125/0x150 [spl]\r\n[ 2522.644911]  [<ffffffff810a6ae0>] ? wake_up_atomic_t+0x30/0x30\r\n[ 2522.644922]  [<ffffffffa0474515>] __cv_wait+0x15/0x20 [spl]\r\n[ 2522.644995]  [<ffffffffa062bd7b>] zil_commit.part.12+0x8b/0x830 [zfs]\r\n[ 2522.645006]  [<ffffffffa046d037>] ? spl_kmem_alloc+0xc7/0x170 [spl]\r\n[ 2522.645017]  [<ffffffffa0475cb4>] ? tsd_set+0x324/0x500 [spl]\r\n[ 2522.645022]  [<ffffffff81639082>] ? mutex_lock+0x12/0x2f\r\n[ 2522.645075]  [<ffffffffa062c537>] zil_commit+0x17/0x20 [zfs]\r\n[ 2522.645128]  [<ffffffffa0621a27>] zfs_fsync+0x77/0xf0 [zfs]\r\n[ 2522.645179]  [<ffffffffa0639665>] zpl_fsync+0x65/0x90 [zfs]\r\n[ 2522.645186]  [<ffffffff8120fa45>] do_fsync+0x65/0xa0\r\n[ 2522.645191]  [<ffffffff8120fd10>] SyS_fsync+0x10/0x20\r\n[ 2522.645196]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2522.645202] INFO: task mysqld:7514 blocked for more than 120 seconds.\r\n[ 2522.645245] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2522.645296] mysqld          D ffff880fb554bda0     0  7514   5602 0x00000000\r\n[ 2522.645299]  ffff880fb554bd30 0000000000000086 ffff880ff4c8f300 ffff880fb554bfd8\r\n[ 2522.645303]  ffff880fb554bfd8 ffff880fb554bfd8 ffff880ff4c8f300 ffff880fb554bdb0\r\n[ 2522.645307]  ffff88107ff8dec0 0000000000000002 ffffffff811f9420 ffff880fb554bda0\r\n[ 2522.645312] Call Trace:\r\n[ 2522.645316]  [<ffffffff811f9420>] ? unlock_two_nondirectories+0x60/0x60\r\n[ 2522.645321]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2522.645324]  [<ffffffff811f942e>] inode_wait+0xe/0x20\r\n[ 2522.645328]  [<ffffffff81638cc0>] __wait_on_bit+0x60/0x90\r\n[ 2522.645335]  [<ffffffff812083bf>] __inode_wait_for_writeback+0xaf/0xf0\r\n[ 2522.645339]  [<ffffffff810a6b60>] ? wake_atomic_t_function+0x40/0x40\r\n[ 2522.645345]  [<ffffffff8120b996>] inode_wait_for_writeback+0x26/0x40\r\n[ 2522.645348]  [<ffffffff811fa135>] evict+0x95/0x170\r\n[ 2522.645351]  [<ffffffff811fa985>] iput+0xf5/0x180\r\n[ 2522.645357]  [<ffffffff811ef41e>] do_unlinkat+0x1ae/0x2b0\r\n[ 2522.645362]  [<ffffffff811e3fe1>] ? SyS_readlinkat+0xd1/0x140\r\n[ 2522.645367]  [<ffffffff811f0426>] SyS_unlink+0x16/0x20\r\n[ 2522.645371]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2522.645402] INFO: task sync:2653 blocked for more than 120 seconds.\r\n[ 2522.645443] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2522.645494] sync            D ffffffff8120f8c0     0  2653   1455 0x00000000\r\n[ 2522.645498]  ffff880ffedd7d50 0000000000000082 ffff880f01449700 ffff880ffedd7fd8\r\n[ 2522.645502]  ffff880ffedd7fd8 ffff880ffedd7fd8 ffff880f01449700 ffff880ffedd7e80\r\n[ 2522.645506]  ffff880ffedd7e88 7fffffffffffffff ffff880f01449700 ffffffff8120f8c0\r\n[ 2522.645509] Call Trace:\r\n[ 2522.645515]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2522.645519]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2522.645523]  [<ffffffff81638b39>] schedule_timeout+0x209/0x2d0\r\n[ 2522.645527]  [<ffffffff8109b426>] ? __queue_work+0x136/0x320\r\n[ 2522.645530]  [<ffffffff8109b6da>] ? __queue_delayed_work+0xaa/0x1a0\r\n[ 2522.645534]  [<ffffffff8109ba41>] ? try_to_grab_pending+0xb1/0x160\r\n[ 2522.645538]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2522.645543]  [<ffffffff8163b216>] wait_for_completion+0x116/0x170\r\n[ 2522.645548]  [<ffffffff810b8c30>] ? wake_up_state+0x20/0x20\r\n[ 2522.645552]  [<ffffffff81208987>] sync_inodes_sb+0xb7/0x1e0\r\n[ 2522.645557]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2522.645561]  [<ffffffff8120f8d9>] sync_inodes_one_sb+0x19/0x20\r\n[ 2522.645565]  [<ffffffff811e2182>] iterate_supers+0xb2/0x110\r\n[ 2522.645570]  [<ffffffff8120fb94>] sys_sync+0x44/0xb0\r\n[ 2522.645575]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2642.739175] INFO: task mysqld:6608 blocked for more than 120 seconds.\r\n[ 2642.739228] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2642.739284] mysqld          D 0000000000000000     0  6608   5602 0x00000000\r\n[ 2642.739290]  ffff880feb913da0 0000000000000086 ffff881006eac500 ffff880feb913fd8\r\n[ 2642.739296]  ffff880feb913fd8 ffff880feb913fd8 ffff881006eac500 ffff880fffc8a180\r\n[ 2642.739300]  ffff880fffc8a000 ffff880fffc8a188 ffff880fffc8a028 0000000000000000\r\n[ 2642.739305] Call Trace:\r\n[ 2642.739315]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2642.739340]  [<ffffffffa04744d5>] cv_wait_common+0x125/0x150 [spl]\r\n[ 2642.739345]  [<ffffffff810a6ae0>] ? wake_up_atomic_t+0x30/0x30\r\n[ 2642.739357]  [<ffffffffa0474515>] __cv_wait+0x15/0x20 [spl]\r\n[ 2642.739434]  [<ffffffffa062bd7b>] zil_commit.part.12+0x8b/0x830 [zfs]\r\n[ 2642.739447]  [<ffffffffa046d037>] ? spl_kmem_alloc+0xc7/0x170 [spl]\r\n[ 2642.739460]  [<ffffffffa0475cb4>] ? tsd_set+0x324/0x500 [spl]\r\n[ 2642.739466]  [<ffffffff81639082>] ? mutex_lock+0x12/0x2f\r\n[ 2642.739526]  [<ffffffffa062c537>] zil_commit+0x17/0x20 [zfs]\r\n[ 2642.739587]  [<ffffffffa0621a27>] zfs_fsync+0x77/0xf0 [zfs]\r\n[ 2642.739647]  [<ffffffffa0639665>] zpl_fsync+0x65/0x90 [zfs]\r\n[ 2642.739654]  [<ffffffff8120fa45>] do_fsync+0x65/0xa0\r\n[ 2642.739659]  [<ffffffff8120fd10>] SyS_fsync+0x10/0x20\r\n[ 2642.739665]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2642.739670] INFO: task mysqld:7514 blocked for more than 120 seconds.\r\n[ 2642.739727] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2642.739793] mysqld          D ffff880fb554bda0     0  7514   5602 0x00000000\r\n[ 2642.739798]  ffff880fb554bd30 0000000000000086 ffff880ff4c8f300 ffff880fb554bfd8\r\n[ 2642.739803]  ffff880fb554bfd8 ffff880fb554bfd8 ffff880ff4c8f300 ffff880fb554bdb0\r\n[ 2642.739808]  ffff88107ff8dec0 0000000000000002 ffffffff811f9420 ffff880fb554bda0\r\n[ 2642.739812] Call Trace:\r\n[ 2642.739818]  [<ffffffff811f9420>] ? unlock_two_nondirectories+0x60/0x60\r\n[ 2642.739823]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2642.739826]  [<ffffffff811f942e>] inode_wait+0xe/0x20\r\n[ 2642.739831]  [<ffffffff81638cc0>] __wait_on_bit+0x60/0x90\r\n[ 2642.739839]  [<ffffffff812083bf>] __inode_wait_for_writeback+0xaf/0xf0\r\n[ 2642.739843]  [<ffffffff810a6b60>] ? wake_atomic_t_function+0x40/0x40\r\n[ 2642.739850]  [<ffffffff8120b996>] inode_wait_for_writeback+0x26/0x40\r\n[ 2642.739854]  [<ffffffff811fa135>] evict+0x95/0x170\r\n[ 2642.739857]  [<ffffffff811fa985>] iput+0xf5/0x180\r\n[ 2642.739862]  [<ffffffff811ef41e>] do_unlinkat+0x1ae/0x2b0\r\n[ 2642.739868]  [<ffffffff811e3fe1>] ? SyS_readlinkat+0xd1/0x140\r\n[ 2642.739873]  [<ffffffff811f0426>] SyS_unlink+0x16/0x20\r\n[ 2642.739878]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2642.739897] INFO: task sync:2653 blocked for more than 120 seconds.\r\n[ 2642.739951] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2642.740017] sync            D ffffffff8120f8c0     0  2653   1455 0x00000000\r\n[ 2642.740021]  ffff880ffedd7d50 0000000000000082 ffff880f01449700 ffff880ffedd7fd8\r\n[ 2642.740026]  ffff880ffedd7fd8 ffff880ffedd7fd8 ffff880f01449700 ffff880ffedd7e80\r\n[ 2642.740031]  ffff880ffedd7e88 7fffffffffffffff ffff880f01449700 ffffffff8120f8c0\r\n[ 2642.740036] Call Trace:\r\n[ 2642.740042]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2642.740047]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2642.740051]  [<ffffffff81638b39>] schedule_timeout+0x209/0x2d0\r\n[ 2642.740056]  [<ffffffff8109b426>] ? __queue_work+0x136/0x320\r\n[ 2642.740060]  [<ffffffff8109b6da>] ? __queue_delayed_work+0xaa/0x1a0\r\n[ 2642.740064]  [<ffffffff8109ba41>] ? try_to_grab_pending+0xb1/0x160\r\n[ 2642.740069]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2642.740093]  [<ffffffff8163b216>] wait_for_completion+0x116/0x170\r\n[ 2642.740100]  [<ffffffff810b8c30>] ? wake_up_state+0x20/0x20\r\n[ 2642.740105]  [<ffffffff81208987>] sync_inodes_sb+0xb7/0x1e0\r\n[ 2642.740110]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2642.740116]  [<ffffffff8120f8d9>] sync_inodes_one_sb+0x19/0x20\r\n[ 2642.740121]  [<ffffffff811e2182>] iterate_supers+0xb2/0x110\r\n[ 2642.740127]  [<ffffffff8120fb94>] sys_sync+0x44/0xb0\r\n[ 2642.740134]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2762.834495] INFO: task mysqld:6608 blocked for more than 120 seconds.\r\n[ 2762.834547] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2762.834604] mysqld          D 0000000000000000     0  6608   5602 0x00000000\r\n[ 2762.834609]  ffff880feb913da0 0000000000000086 ffff881006eac500 ffff880feb913fd8\r\n[ 2762.834615]  ffff880feb913fd8 ffff880feb913fd8 ffff881006eac500 ffff880fffc8a180\r\n[ 2762.834619]  ffff880fffc8a000 ffff880fffc8a188 ffff880fffc8a028 0000000000000000\r\n[ 2762.834624] Call Trace:\r\n[ 2762.834634]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2762.834659]  [<ffffffffa04744d5>] cv_wait_common+0x125/0x150 [spl]\r\n[ 2762.834665]  [<ffffffff810a6ae0>] ? wake_up_atomic_t+0x30/0x30\r\n[ 2762.834677]  [<ffffffffa0474515>] __cv_wait+0x15/0x20 [spl]\r\n[ 2762.834748]  [<ffffffffa062bd7b>] zil_commit.part.12+0x8b/0x830 [zfs]\r\n[ 2762.834761]  [<ffffffffa046d037>] ? spl_kmem_alloc+0xc7/0x170 [spl]\r\n[ 2762.834774]  [<ffffffffa0475cb4>] ? tsd_set+0x324/0x500 [spl]\r\n[ 2762.834779]  [<ffffffff81639082>] ? mutex_lock+0x12/0x2f\r\n[ 2762.834843]  [<ffffffffa062c537>] zil_commit+0x17/0x20 [zfs]\r\n[ 2762.834908]  [<ffffffffa0621a27>] zfs_fsync+0x77/0xf0 [zfs]\r\n[ 2762.834971]  [<ffffffffa0639665>] zpl_fsync+0x65/0x90 [zfs]\r\n[ 2762.834978]  [<ffffffff8120fa45>] do_fsync+0x65/0xa0\r\n[ 2762.834983]  [<ffffffff8120fd10>] SyS_fsync+0x10/0x20\r\n[ 2762.834989]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2762.834994] INFO: task mysqld:7514 blocked for more than 120 seconds.\r\n[ 2762.835051] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2762.835118] mysqld          D ffff880fb554bda0     0  7514   5602 0x00000000\r\n[ 2762.835122]  ffff880fb554bd30 0000000000000086 ffff880ff4c8f300 ffff880fb554bfd8\r\n[ 2762.835127]  ffff880fb554bfd8 ffff880fb554bfd8 ffff880ff4c8f300 ffff880fb554bdb0\r\n[ 2762.835132]  ffff88107ff8dec0 0000000000000002 ffffffff811f9420 ffff880fb554bda0\r\n[ 2762.835137] Call Trace:\r\n[ 2762.835143]  [<ffffffff811f9420>] ? unlock_two_nondirectories+0x60/0x60\r\n[ 2762.835148]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2762.835151]  [<ffffffff811f942e>] inode_wait+0xe/0x20\r\n[ 2762.835156]  [<ffffffff81638cc0>] __wait_on_bit+0x60/0x90\r\n[ 2762.835164]  [<ffffffff812083bf>] __inode_wait_for_writeback+0xaf/0xf0\r\n[ 2762.835168]  [<ffffffff810a6b60>] ? wake_atomic_t_function+0x40/0x40\r\n[ 2762.835175]  [<ffffffff8120b996>] inode_wait_for_writeback+0x26/0x40\r\n[ 2762.835179]  [<ffffffff811fa135>] evict+0x95/0x170\r\n[ 2762.835183]  [<ffffffff811fa985>] iput+0xf5/0x180\r\n[ 2762.835188]  [<ffffffff811ef41e>] do_unlinkat+0x1ae/0x2b0\r\n[ 2762.835195]  [<ffffffff811e3fe1>] ? SyS_readlinkat+0xd1/0x140\r\n[ 2762.835199]  [<ffffffff811f0426>] SyS_unlink+0x16/0x20\r\n[ 2762.835205]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2762.835223] INFO: task sync:2653 blocked for more than 120 seconds.\r\n[ 2762.835277] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2762.835343] sync            D ffffffff8120f8c0     0  2653   1455 0x00000000\r\n[ 2762.835348]  ffff880ffedd7d50 0000000000000082 ffff880f01449700 ffff880ffedd7fd8\r\n[ 2762.835352]  ffff880ffedd7fd8 ffff880ffedd7fd8 ffff880f01449700 ffff880ffedd7e80\r\n[ 2762.835357]  ffff880ffedd7e88 7fffffffffffffff ffff880f01449700 ffffffff8120f8c0\r\n[ 2762.835362] Call Trace:\r\n[ 2762.835369]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2762.835374]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2762.835378]  [<ffffffff81638b39>] schedule_timeout+0x209/0x2d0\r\n[ 2762.835382]  [<ffffffff8109b426>] ? __queue_work+0x136/0x320\r\n[ 2762.835386]  [<ffffffff8109b6da>] ? __queue_delayed_work+0xaa/0x1a0\r\n[ 2762.835390]  [<ffffffff8109ba41>] ? try_to_grab_pending+0xb1/0x160\r\n[ 2762.835396]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2762.835409]  [<ffffffff8163b216>] wait_for_completion+0x116/0x170\r\n[ 2762.835417]  [<ffffffff810b8c30>] ? wake_up_state+0x20/0x20\r\n[ 2762.835422]  [<ffffffff81208987>] sync_inodes_sb+0xb7/0x1e0\r\n[ 2762.835427]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2762.835433]  [<ffffffff8120f8d9>] sync_inodes_one_sb+0x19/0x20\r\n[ 2762.835438]  [<ffffffff811e2182>] iterate_supers+0xb2/0x110\r\n[ 2762.835443]  [<ffffffff8120fb94>] sys_sync+0x44/0xb0\r\n[ 2762.835451]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2882.929813] INFO: task mysqld:6608 blocked for more than 120 seconds.\r\n[ 2882.929861] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2882.929913] mysqld          D 0000000000000000     0  6608   5602 0x00000000\r\n[ 2882.929919]  ffff880feb913da0 0000000000000086 ffff881006eac500 ffff880feb913fd8\r\n[ 2882.929924]  ffff880feb913fd8 ffff880feb913fd8 ffff881006eac500 ffff880fffc8a180\r\n[ 2882.929928]  ffff880fffc8a000 ffff880fffc8a188 ffff880fffc8a028 0000000000000000\r\n[ 2882.929932] Call Trace:\r\n[ 2882.929942]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2882.929967]  [<ffffffffa04744d5>] cv_wait_common+0x125/0x150 [spl]\r\n[ 2882.929972]  [<ffffffff810a6ae0>] ? wake_up_atomic_t+0x30/0x30\r\n[ 2882.929983]  [<ffffffffa0474515>] __cv_wait+0x15/0x20 [spl]\r\n[ 2882.930049]  [<ffffffffa062bd7b>] zil_commit.part.12+0x8b/0x830 [zfs]\r\n[ 2882.930059]  [<ffffffffa046d037>] ? spl_kmem_alloc+0xc7/0x170 [spl]\r\n[ 2882.930070]  [<ffffffffa0475cb4>] ? tsd_set+0x324/0x500 [spl]\r\n[ 2882.930075]  [<ffffffff81639082>] ? mutex_lock+0x12/0x2f\r\n[ 2882.930129]  [<ffffffffa062c537>] zil_commit+0x17/0x20 [zfs]\r\n[ 2882.930181]  [<ffffffffa0621a27>] zfs_fsync+0x77/0xf0 [zfs]\r\n[ 2882.930232]  [<ffffffffa0639665>] zpl_fsync+0x65/0x90 [zfs]\r\n[ 2882.930238]  [<ffffffff8120fa45>] do_fsync+0x65/0xa0\r\n[ 2882.930243]  [<ffffffff8120fd10>] SyS_fsync+0x10/0x20\r\n[ 2882.930248]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 4802.367346] perf interrupt took too long (2507 > 2500), lowering kernel.perf_event_max_sample_rate to 50000\r\n\r\nsync process stack:\r\n[<ffffffff81208987>] sync_inodes_sb+0xb7/0x1e0\r\n[<ffffffff8120f8d9>] sync_inodes_one_sb+0x19/0x20\r\n[<ffffffff811e2182>] iterate_supers+0xb2/0x110\r\n[<ffffffff8120fb94>] sys_sync+0x44/0xb0\r\n[<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[<ffffffffffffffff>] 0xffffffffffffffff\r\n\r\nkworker process stack:\r\n cat /proc/3445/stack \r\n[<ffffffffa058feb5>] dmu_zfetch+0x455/0x4f0 [zfs]\r\n[<ffffffffa05711ea>] dbuf_read+0x8ea/0x9f0 [zfs]\r\n[<ffffffffa0591246>] dnode_hold_impl+0xc6/0xc30 [zfs]\r\n[<ffffffffffffffff>] 0xffffffffffffffff\r\n\r\ncat /proc/3445/stack \r\n[<ffffffffffffffff>] 0xffffffffffffffff\r\n[root@ifcos ~]# cat /proc/3445/stack \r\n[<ffffffffa062879c>] zfs_zget+0xfc/0x250 [zfs]\r\n[<ffffffffa0623db7>] zfs_get_data+0x57/0x2d0 [zfs]\r\n[<ffffffffa062c10c>] zil_commit.part.12+0x41c/0x830 [zfs]\r\n[<ffffffffa062c537>] zil_commit+0x17/0x20 [zfs]\r\n[<ffffffffa06394b6>] zpl_writepages+0xd6/0x170 [zfs]\r\n[<ffffffff811759fe>] do_writepages+0x1e/0x40\r\n[<ffffffff812084e0>] __writeback_single_inode+0x40/0x220\r\n[<ffffffff81208f4e>] writeback_sb_inodes+0x25e/0x420\r\n[<ffffffff8120988f>] wb_writeback+0xff/0x2f0\r\n[<ffffffff8120bac5>] bdi_writeback_workfn+0x115/0x460\r\n[<ffffffff8109d5fb>] process_one_work+0x17b/0x470\r\n[<ffffffff8109e3cb>] worker_thread+0x11b/0x400\r\n[<ffffffff810a5aef>] kthread+0xcf/0xe0\r\n[<ffffffff81645e18>] ret_from_fork+0x58/0x90\r\n[<ffffffffffffffff>] 0xffffffffffffffff\r\n\r\n cat /proc/3445/stack \r\n[<ffffffffa058feb5>] dmu_zfetch+0x455/0x4f0 [zfs]\r\n[<ffffffffa0572fd5>] __dbuf_hold_impl+0x135/0x5a0 [zfs]\r\n[<ffffffffffffffff>] 0xffffffffffffffff\r\n\r\n cat /proc/3445/stack \r\n[<ffffffffa056fa69>] dbuf_find+0x1c9/0x1d0 [zfs]\r\n[<ffffffffa0572ee2>] __dbuf_hold_impl+0x42/0x5a0 [zfs]\r\n[<ffffffffffffffff>] 0xffffffffffffffff\r\n\r\n cat /proc/3445/stack \r\n[<ffffffffa058feb5>] dmu_zfetch+0x455/0x4f0 [zfs]\r\n[<ffffffffa0571056>] dbuf_read+0x756/0x9f0 [zfs]\r\n[<ffffffffa0591246>] dnode_hold_impl+0xc6/0xc30 [zfs]\r\n\r\n<!-- \r\n*IMPORTANT* - Please mark logs and text output from terminal commands \r\nor else Github will not display them correctly. \r\nAn example is provided below.\r\n\r\nExample:\r\n```\r\nthis is an example how log text should be marked (wrap it with ```)\r\n```\r\n-->\r\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7038/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "sempervictus": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7035", "title": "Consider adding mitigations for speculative execution related concerns", "body": "GCC should get retpoline support soon, and Intel seems to be proposing kernel code with barriers to speculative execution - https://patchwork.ozlabs.org/cover/856316/. ZFS is already pretty unhappy from KPTI, but since there's a good deal of user controlled data going into it, this might be worth investigating.", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7035/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "abraunegg": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7034", "title": "Missing parameter descriptions in ZFS-Module-Parameters man page", "body": "The following zfs module parameters are missing from the zfs-module-parameters man page (updated 28th Oct 2017) using ZFS 0.7.5:\r\n\r\n* dbuf_cache_hiwater_pct\r\n* dbuf_cache_lowater_pct\r\n* dbuf_cache_max_bytes\r\n* dbuf_cache_max_shift\r\n* dmu_object_alloc_chunk_shift\r\n* send_holes_without_birth_time\r\n* zfs_abd_scatter_enabled\r\n* zfs_abd_scatter_max_order\r\n* zfs_compressed_arc_enabled\r\n* zfs_sync_taskq_batch_pct\r\n\r\nHappy to create a documentation patch for the man pages if someone can send me the a description of what the module parameter is, what the default should be and what valid options are if it is being changed.\r\n\r\nBest regards,\r\n\r\nAlex", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7034/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "rincebrain": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7024", "title": "zfs send -R | zfs recv can fail in the middle due to a snapshot being taken", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Debian\r\nDistribution Version    | 9.3\r\nLinux Kernel                 | 4.9.0-4-amd64\r\nArchitecture                 | amd64\r\nZFS Version                  | 0.7.3-3\r\nSPL Version                  | 0.7.3-1\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing + how to reproduce the problem\r\nWhen doing a long-running `zfs send -R foo/bar/baz@ten | zfs recv -ds newfoo`, an automated utility helpfully took a recursive snapshot on newfoo, and zfs recv abruptly died with `cannot receive incremental stream: kernel modules must be upgraded to receive this stream.` with newfoo/bar/baz having completed snapshots one, ..., seven and throwing that error on attempting to resume.\r\n\r\nI would have expected the in-progress receiving dataset(s) to have remained immutable until the receives were completed, but apparently this isn't the case.\r\n\r\nDestroying the errant snapshot on newfoo/bar/baz allowed the zfs send to proceed like nothing ever happened.\r\n\r\nSince there's already a number of bugs suggesting that this message should be broken out and detailed further (#6547, #6574), this bug is mostly about the fact that nothing is stopping you from shooting yourself in the foot and not being able to discover why without making dramatic leaps or (presumably) reading zfs/dbgmsg.", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7024/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "h1z1": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7015", "title": "Impact of Intel bug (tm) on ZFS", "body": "Maybe the wrong avenue for this but no doubt like others watching the events of the last few days unfold, I've been asked to comment on the impact to ZFS in our environment.   I'm in a rather odd position as I don't really have the hardware to duplicate an entire production silo, running 4.15.x kernel.   I do however know at least 4.14 will bite us as per #6929.  \r\n\r\nHas anyone tested or confirmed what the impact of this will be going forward?  Would rather not duplicate effort if it's already being addressed.\r\n\r\nThanks", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7015/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "sanjeevbagewadi": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7011", "title": "With \"casesensitivity=mixed\" hitting an assert in ZAP code", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | CentOS release 6.8 (Final)\r\n  ---                                  |     --- \r\nDistribution Name       | CentOS\r\nDistribution Version    | 6.8\r\nLinux Kernel                 | 4.4.14-1.el6\r\nArchitecture                 | x86\r\nZFS Version                  | 0.7.1-1\r\nSPL Version                  |  0.7.1-1\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\n\r\nWith casesensitivity=mixed was running the following test :\r\nroot@NTNX-10-5-137-31-A-FSVM:/home/nutanix# cat names.py\r\n#!/usr/bin/python\r\nimport itertools\r\ns=\"abcdefghijklmnopqrstuvwxyz\"\r\nlength = len(s)\r\nnames = map(''.join, itertools.product(*zip(s.upper(), s.lower())))\r\nfor name in names:\r\n    print name\r\n\r\nroot@NTNX-10-5-137-31-A-FSVM:/home/nutanix# ./names.py | while read file\r\n> do\r\n> touch /test/fs2/dir1/$file\r\n> done\r\n\r\nAnd hit the following panic \r\n-- snip --\r\n[    1.068019] VERIFY(!RW_LOCK_HELD(&l->l_rwlock)) failed\r\n[    1.068077] PANIC at zap.c:407:zap_leaf_evict_sync()\r\n[    1.068113] Showing stack for process 67625\r\n[    1.068116] CPU: 0 PID: 67625 Comm: touch Tainted: P           OE   4.4.14-1.el6.nutanix.10272016.x86_64 #1\r\n[    1.068117] Hardware name: Nutanix AHV, BIOS seabios-1.7.5-11.el6 04/01/2014\r\n[    1.068122]  0000000000000000 ffff88015312b2a8 ffffffff81319ae3 0000000000000001\r\n[    1.068125]  0000000100480b8b ffff88015312b2f8 ffffffffa0b5a9c0 ffff88015312b2b8\r\n[    1.068127]  ffffffffa09918c4 ffff88015312b458 ffffffffa0991aeb 0000000000000040\r\n[    1.068129] Call Trace:\r\n[    1.068136]  [<ffffffff81319ae3>] dump_stack+0x67/0x94\r\n[    1.068146]  [<ffffffffa09918c4>] spl_dumpstack+0x44/0x50 [spl]\r\n[    1.068150]  [<ffffffffa0991aeb>] spl_panic+0xcb/0xe0 [spl]\r\n[    1.068153]  [<ffffffff8132a483>] ? __sg_free_table+0x63/0x90\r\n[    1.068157]  [<ffffffff811e447e>] ? kmem_cache_free+0x1ee/0x210\r\n[    1.068160]  [<ffffffffa098d477>] ? spl_kmem_cache_free+0x117/0x140 [spl]\r\n[    1.068200]  [<ffffffffa0a46ecc>] ? arc_hdr_destroy+0x17c/0x1d0 [zfs]\r\n[    1.068231]  [<ffffffffa0acf457>] zap_leaf_evict_sync+0x57/0x60 [zfs]\r\n[    1.068248]  [<ffffffffa0a4d575>] dbuf_evict_user+0x45/0x70 [zfs]\r\n[    1.068265]  [<ffffffffa0a4f95f>] dbuf_destroy+0x4f/0x330 [zfs]\r\n[    1.068282]  [<ffffffffa0a4f561>] dbuf_rele_and_unlock+0x221/0x3e0 [zfs]\r\n[    1.068313]  [<ffffffffa0ad514f>] ? zap_lockdir+0x7f/0xa0 [zfs]\r\n[    1.068344]  [<ffffffffa0ad15e6>] ? zap_grow_ptrtbl+0x186/0x1a0 [zfs]\r\n[    1.068361]  [<ffffffffa0a4f900>] dbuf_rele+0x40/0x50 [zfs]\r\n[    1.068394]  [<ffffffffa0a4fd1e>] dmu_buf_rele+0xe/0x10 [zfs]\r\n[    1.068427]  [<ffffffffa0acf3dd>] zap_put_leaf+0x3d/0x60 [zfs]\r\n[    1.068460]  [<ffffffffa0ad16c7>] zap_put_leaf_maybe_grow_ptrtbl+0xc7/0x130 [zfs]\r\n[    1.068492]  [<ffffffffa0ad1be8>] fzap_add_cd+0xd8/0x130 [zfs]\r\n[    1.068541]  [<ffffffffa0ad4ce4>] mzap_upgrade+0x194/0x210 [zfs]\r\n[    1.068593]  [<ffffffffa0ad4fba>] zap_lockdir_impl+0x25a/0x370 [zfs]\r\n[    1.068628]  [<ffffffffa0ad514f>] zap_lockdir+0x7f/0xa0 [zfs]\r\n[    1.068664]  [<ffffffffa0ad695b>] zap_add+0x5b/0xa0 [zfs]\r\n[    1.068668]  [<ffffffff810ca871>] ? __raw_callee_save___pv_queued_spin_unlock+0x11/0x20\r\n[    1.068703]  [<ffffffffa0adfcbf>] zfs_link_create+0x37f/0x520 [zfs]\r\n[    1.068761]  [<ffffffffa0b00b2a>] zfs_create+0x62a/0x810 [zfs]\r\n[    1.068764]  [<ffffffff811e76f6>] ? __kmalloc_node+0x1f6/0x2b0\r\n[    1.068798]  [<ffffffffa0b19bf2>] zpl_create+0xb2/0x160 [zfs]\r\n[    1.068802]  [<ffffffff81210424>] vfs_create+0xd4/0x100\r\n[    1.068804]  [<ffffffff8120dc4d>] ? lookup_real+0x1d/0x60\r\n[    1.068806]  [<ffffffff812111e3>] lookup_open+0x173/0x1a0\r\n[    1.068808]  [<ffffffff812138d9>] do_last+0x299/0x760\r\n[    1.068811]  [<ffffffff812056d7>] ? get_empty_filp+0xd7/0x1c0\r\n[    1.068813]  [<ffffffff81213e1c>] path_openat+0x7c/0x140\r\n[    1.068832]  [<ffffffff811b53c2>] ? __pte_alloc+0xe2/0x190\r\n[    1.068834]  [<ffffffff81213f65>] do_filp_open+0x85/0xe0\r\n[    1.068836]  [<ffffffff8120eade>] ? getname_flags+0xce/0x1f0\r\n[    1.068838]  [<ffffffff8120311a>] do_sys_open+0x11a/0x220\r\n[    1.068842]  [<ffffffff81003513>] ? syscall_trace_enter_phase1+0x133/0x150\r\n[    1.068844]  [<ffffffff8120325e>] SyS_open+0x1e/0x20\r\n[    1.068850]  [<ffffffff816cf76e>] entry_SYSCALL_64_fastpath+0x12/0x71\r\n-- snip --\r\n\r\n### Describe how to reproduce the problem\r\n\r\nThe following are the steps\\:\r\n- Create zfs dataset with casesensitivity=mixed\r\n- Run the above listed code.\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n<!-- \r\n*IMPORTANT* - Please mark logs and text output from terminal commands \r\nor else Github will not display them correctly. \r\nAn example is provided below.\r\n\r\nExample:\r\n```\r\nthis is an example how log text should be marked (wrap it with ```)\r\n```\r\n-->", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7011/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/7054", "title": "Handle zap_add() failures in \"casesensitivity=mixed\" mode.", "body": "With \"casesensitivity=mixed\", zap_add() could fail when the number of\r\nfiles/directories with the same name (varying in case) exceed the\r\ncapacity of the leaf node of a Fatzap. This results in a ASSERT()\r\nfailure as zfs_link_create() does not expect zap_add() to fail. The fix\r\nis to handle these failures and rollback the transactions.\r\n\r\nSigned-off-by: Sanjeev Bagewadi <sanjeev.bagewadi@gmail.com>\r\n\r\n<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\nFor a dataset with \"casesensitivity=mixed\", when a large number of files/directories\r\nwith same name (varying only in case e.g: ABCD, ABCd, ABcD and so on) are created\r\nzap_add() could fail. With mixed mode zap_add() normalises the names before the hash\r\nis computed. And all the names would generate the same hash and land in the same leaf.\r\nWhen the number of entries exceed the capacity of the leaf-block, zap_add() tries to split\r\nthe leaf-block which fails as well and zap_add() fails. This trips an ASSERT in zfs_link_create()\r\nas it does not expect zap_add() to fail.\r\n\r\nThe fix does the following :\r\n- fzap_add_cd() : Handle the case when zap_expand_leaf() fails with ENOSPC and bailout\r\n   without calling zap_put_leaf_maybe_grow_ptrtbl(). \r\n- zap_add_impl() : When adding to a micro-zap check if the total number of entries\r\n  with colliding/same hash value can fit into fatzap-leaf-block. This is important because, if/when\r\n  the microzap needs to be upgraded to fatzap, all the entries with the same hash would need to\r\n  fit into the same leaf-block (16K). If the number of such entries donot fit fail the zap_add().\r\n  \r\n   The routine mze_canfit_fzap_leaf() today assumes the MZAP_NAME_LEN for every entry.\r\n   This is erring on the safer side but, ends up accommodating lesser number (127) of entries\r\n    with same hash value in microzap. We could find out the size of name of every mze and that\r\n    would be accurate. But, it is expensive to compute the length every time. Alternatively, we\r\n    could compute the length of each entry and cache it. I felt that the amount of code needed\r\n    for this is not worth the gain. I am open to changing it if necessary.\r\n\r\n- zfs_link_create() : Move the call to zap_add() to the beginning and in case of a failure\r\n  return. This ensures that we can bailout easily before making any other modifications to\r\n  the parent-zap or the child-dnode. Keeps the code simpler.\r\n- ZPL interfaces (zfs_create(), zfs_mkdir(), zfs_symlink()) : Handle the failure of zfs_link_create()\r\n  and rollback the operation.\r\n\r\nWith these changes a call to create a file could fail with ENOSPC. Not the best error value.\r\nBut, this is the closest I found. Any alternate suggestions are welcome.\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\nWith \"casesensitivity=mixed\" it is easy to panic the node with a simple test case\r\nas described in https://github.com/zfsonlinux/zfs/issues/7011\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\nThe following tests were run : \r\n- zfs-testsuite\r\n- ztest\r\n- Unit-test described in the #7011 \r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [x] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "woffs": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7003", "title": "autoreplace = on, but spare not automatically activated on drive error", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Debian\r\nDistribution Version    | Stretch (9)\r\nLinux Kernel                 | 4.9.51\r\nArchitecture                 | x86_64\r\nZFS Version                  | 0.7.3\r\nSPL Version                  | 0.7.3\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\n \r\nA disk was failing, zed reported errors ...\r\n\r\n```\r\nZFS has detected that a device was removed.\r\n\r\n impact: Fault tolerance of the pool may be compromised.\r\n    eid: 71656\r\n  class: statechange\r\n  state: REMOVED\r\n   host: inferno\r\n   time: 2017-12-29 19:57:19+0100\r\n  vpath: /dev/disk/by-vdev/E2-part1\r\n  vguid: 0x8F23CA44FDEBE82C\r\n   pool: 0x83BBC476EFE065A2\r\n```\r\n\r\n```\r\nThe number of I/O errors associated with a ZFS device exceeded\r\nacceptable levels. ZFS has marked the device as faulted.\r\n\r\n impact: Fault tolerance of the pool may be compromised.\r\n    eid: 71662\r\n  class: statechange\r\n  state: FAULTED\r\n   host: inferno\r\n   time: 2017-12-29 19:57:19+0100\r\n  vpath: /dev/disk/by-vdev/E2-part1\r\n  vguid: 0x8F23CA44FDEBE82C\r\n   pool: 0x83BBC476EFE065A2\r\n```\r\n\r\n... but the spare was not activated automatically, although the autoreplace property was set to `on`.\r\n\r\n```\r\n        inferno# zpool status\r\n  [...]\r\n                pool: torx\r\n         state: DEGRADED\r\n        status: One or more devices are faulted in response to persistent errors.\r\n                Sufficient replicas exist for the pool to continue functioning in a\r\n                degraded state.\r\n        action: Replace the faulted device, or use 'zpool clear' to mark the device\r\n                repaired.\r\n                scan: scrub repaired 0B in 188h32m with 0 errors on Sun Dec 17 20:56:54 2017\r\n        config:\r\n\r\n                NAME        STATE     READ WRITE CKSUM\r\n                torx        DEGRADED     0     0     0\r\n                        raidz2-0  DEGRADED     0     0     0\r\n                                E0      ONLINE       0     0     0\r\n                                E1      ONLINE       0     0     0\r\n                                E2      FAULTED      0     0     0  too many errors\r\n                                E3      ONLINE       0     0     0\r\n                                E4      ONLINE       0     0     0\r\n                                E5      ONLINE       0     0     0\r\n                                E6      ONLINE       0     0     0\r\n                                E7      ONLINE       0     0     0\r\n                                E8      ONLINE       0     0     0\r\n                                E9      ONLINE       0     0     0\r\n                spares\r\n                        EA        AVAIL\r\n\r\n        errors: No known data errors\r\n```\r\n\r\nAfter manually issuing `zpool replace torx E2 EA` the resilver to the spare started.\r\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7003/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "krichter722": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7002", "title": "\"VERIFY3(range_tree_space(rt) == space) failed\" after I/O freeze", "body": "### System information\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Ubuntu\r\nDistribution Version    | 17.10\r\nLinux Kernel                 | 4.13.0-21-generic\r\nArchitecture                 | amd64\r\nZFS Version                  | 0.7.0-227_g823d48bfb\r\nSPL Version                  | 0.7.0-22_gc9821f1c\r\n\r\n### Describe the problem you're observing\r\nMy pool consisting of 1 HDD vdev and 1 SSD cache and 1 SSD log device experienced an I/O freeze under heavy load including heavy dedup action (parallel checkout and building of Firefox on docker images) where all commands doing I/O on the pool switched to uninterruptible state and no I/O occured anymore according to `iotop`.\r\n\r\nAfter starting the machine again I'm no longer able to import the pool because the `zpool import` command never returns and after a few seconds of reading a few 100 MB the I/O stops and the stack below is printed in `dmesg`.\r\n\r\nA readonly import is possible. `zfs set mountpoint=none data/docker` fails due to `internal error: out of memory` immediately without any noticable memory issues.\r\n\r\n### Describe how to reproduce the problem\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\nThe I/O freeze was caused by\r\n\r\n```\r\n[27969.280956] VERIFY3(range_tree_space(rt) == space) failed (6922371072 == 6922383360)\r\n[27969.280960] PANIC at space_map.c:127:space_map_load()\r\n[27969.280961] Showing stack for process 13639\r\n[27969.280963] CPU: 5 PID: 13639 Comm: z_wr_iss Tainted: P        W  OE   4.13.0-21-generic #24-Ubuntu\r\n[27969.280964] Hardware name: LENOVO 20221/INVALID, BIOS 71CN51WW(V1.21) 07/12/2013\r\n[27969.280964] Call Trace:\r\n[27969.280970]  dump_stack+0x63/0x8b\r\n[27969.280979]  spl_dumpstack+0x42/0x50 [spl]\r\n[27969.280982]  spl_panic+0xc8/0x110 [spl]\r\n[27969.280985]  ? kmem_cache_free+0x197/0x1c0\r\n[27969.280988]  ? avl_add+0x65/0xb0 [zavl]\r\n[27969.281027]  ? rt_avl_add+0x11/0x20 [zfs]\r\n[27969.281054]  ? range_tree_add_impl+0x2f5/0x440 [zfs]\r\n[27969.281078]  ? dnode_rele+0x39/0x40 [zfs]\r\n[27969.281108]  space_map_load+0x470/0x4f0 [zfs]\r\n[27969.281109]  ? avl_nearest+0x2b/0x30 [zavl]\r\n[27969.281136]  metaslab_load+0x36/0xf0 [zfs]\r\n[27969.281162]  metaslab_activate+0x93/0xc0 [zfs]\r\n[27969.281186]  metaslab_alloc+0x4b9/0x1170 [zfs]\r\n[27969.281217]  zio_dva_allocate+0xac/0x630 [zfs]\r\n[27969.281245]  ? zio_execute+0x8a/0xf0 [zfs]\r\n[27969.281274]  ? vdev_config_sync+0x180/0x180 [zfs]\r\n[27969.281301]  ? vdev_mirror_io_start+0xa4/0x180 [zfs]\r\n[27969.281305]  ? tsd_hash_search.isra.3+0x47/0xa0 [spl]\r\n[27969.281308]  ? tsd_get_by_thread+0x2e/0x40 [spl]\r\n[27969.281311]  ? taskq_member+0x18/0x30 [spl]\r\n[27969.281340]  zio_execute+0x8a/0xf0 [zfs]\r\n[27969.281343]  taskq_thread+0x2aa/0x4d0 [spl]\r\n[27969.281345]  ? wake_up_q+0x80/0x80\r\n[27969.281373]  ? zio_reexecute+0x3e0/0x3e0 [zfs]\r\n[27969.281375]  kthread+0x125/0x140\r\n[27969.281378]  ? taskq_thread_should_stop+0x70/0x70 [spl]\r\n[27969.281379]  ? kthread_create_on_node+0x70/0x70\r\n[27969.281382]  ret_from_fork+0x25/0x30\r\n```\r\nwhich I captured before having to shutdown the machine with the power button. After every reboot the import fails due to\r\n\r\n```\r\n[  274.685568]  dump_stack+0x63/0x8b\r\n[  274.685575]  spl_dumpstack+0x42/0x50 [spl]\r\n[  274.685578]  spl_panic+0xc8/0x110 [spl]\r\n[  274.685581]  ? kmem_cache_free+0x197/0x1c0\r\n[  274.685583]  ? avl_add+0x65/0xb0 [zavl]\r\n[  274.685619]  ? rt_avl_add+0x11/0x20 [zfs]\r\n[  274.685645]  ? range_tree_add_impl+0x2f5/0x440 [zfs]\r\n[  274.685667]  ? dnode_rele+0x39/0x40 [zfs]\r\n[  274.685694]  space_map_load+0x470/0x4f0 [zfs]\r\n[  274.685720]  metaslab_load+0x36/0xf0 [zfs]\r\n[  274.685743]  metaslab_activate+0x93/0xc0 [zfs]\r\n[  274.685766]  metaslab_alloc+0x4b9/0x1170 [zfs]\r\n[  274.685794]  zio_dva_allocate+0xac/0x630 [zfs]\r\n[  274.685795]  ? mutex_lock+0x12/0x40\r\n[  274.685799]  ? tsd_hash_search.isra.3+0x47/0xa0 [spl]\r\n[  274.685802]  ? tsd_get_by_thread+0x2e/0x40 [spl]\r\n[  274.685805]  ? taskq_member+0x18/0x30 [spl]\r\n[  274.685832]  zio_execute+0x8a/0xf0 [zfs]\r\n[  274.685835]  taskq_thread+0x2aa/0x4d0 [spl]\r\n[  274.685837]  ? wake_up_q+0x80/0x80\r\n[  274.685864]  ? zio_reexecute+0x3e0/0x3e0 [zfs]\r\n[  274.685865]  kthread+0x125/0x140\r\n[  274.685869]  ? taskq_thread_should_stop+0x70/0x70 [spl]\r\n[  274.685870]  ? kthread_create_on_node+0x70/0x70\r\n[  274.685871]  ret_from_fork+0x25/0x30\r\n```\r\nalso after a successful readonly import.", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7002/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "redzhang1990": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6995", "title": "Can ZFS support numa binding?", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Redhat\r\nDistribution Version    | 7.4\r\nLinux Kernel                 | 4.11.0\r\nArchitecture                 | ARM\r\nZFS Version                  | 0.7.1\r\nSPL Version                  | 0.7.1\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\nCan the ZFS support or willing support numa binding?\r\n### Describe how to reproduce the problem\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n<!-- \r\n*IMPORTANT* - Please mark logs and text output from terminal commands \r\nor else Github will not display them correctly. \r\nAn example is provided below.\r\n\r\nExample:\r\n```\r\n```\r\n-->\r\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6995/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "fejesjoco": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6994", "title": "Documentation of ACLs should be fixed", "body": "There are issues in the manpage of zfs(8).\r\n\r\naclinherit talks about ACEs, acltype talks about ACLs, this is inconsistent.\r\n\r\naclinherit doesn't mention what kind of ACEs it's talking about. Since neither regular file permission bits not POSIX ACLs have write_acl/write_owner, this must be NFSv4. So that should be mentioned here explicitly.\r\n\r\nacltype has two values. Again this doesn't say what it's talking about and one can only guess. Does \"off\" turn off both NFSv4 and POSIX ACLs, or just POSIX? Does \"posixacl\" enable both NFSv4 and POSIX, or only POSIX? I can even read it in a way that I can either have POSIX ACLs or no ACLs, which would mean NFSv4 ACLs are not even supported under Linux.\r\n\r\nThe source code has many mentions of an aclmode property but this is not documented anywhere.\r\n\r\nSince the document talks about multiple ACL types, it might be worth mentioning if regular file permission bits work as usual or not (this is especially interesting across dataset mount boundaries).\r\n\r\nIf you can confirm these points, I can volunteer to send a PR.", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6994/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "dechamps": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6988", "title": "zil_itx_needcopy_bytes kstat counter is corrupted", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Debian\r\nDistribution Version    | Unstable\r\nLinux Kernel                 | 4.13.0-1-amd64\r\nArchitecture                 | amd64\r\nZFS Version                  | 0.7.3-3\r\nSPL Version                  | 0.7.3-1\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\n\r\n```\r\n$ cat /proc/spl/kstat/zfs/zil\r\n15 1 0x01 13 624 31503034653 382758011634377\r\nname                            type data\r\nzil_commit_count                4    197902\r\nzil_commit_writer_count         4    197884\r\nzil_itx_count                   4    611431070\r\nzil_itx_indirect_count          4    0\r\nzil_itx_indirect_bytes          4    0\r\nzil_itx_copied_count            4    0\r\nzil_itx_copied_bytes            4    0\r\nzil_itx_needcopy_count          4    611266365\r\nzil_itx_needcopy_bytes          4    18446744072731425348\r\nzil_itx_metaslab_normal_count   4    0\r\nzil_itx_metaslab_normal_bytes   4    0\r\nzil_itx_metaslab_slog_count     4    1169526\r\nzil_itx_metaslab_slog_bytes     4    140983216376\r\n```\r\n\r\nThe `zil_itx_needcopy_bytes` counter is blatantly wrong - I'm pretty sure I did not write 16 exabytes of data in that pool :) Its value is quite close to `UINT64_MAX`, which suggests some kind of overflow or memory corruption.\r\n\r\n### Describe how to reproduce the problem\r\n\r\nNot sure. However I can tell that it started after I did a system upgrade, which included the following version changes:\r\n\r\n- Kernel: 4.12 \u2192 4.13\r\n- SPL: 0.6.5 \u2192 0.7.3\r\n- ZFS: 0.6.5 \u2192 0.7.3\r\n\r\nFor this reason I suspect this might be a regression introduced between SPL/ZFS 0.6.5 and SPL/ZFS 0.7.3.\r\n\r\nThis issue might seem benign, but in my case it's really not because it prevents [Prometheus Node exporter](https://github.com/prometheus/node_exporter) from exporting ZFS metrics correctly. Here's the log message from the node exporter in an attempt to make this issue easier to search for:\r\n\r\n```\r\ntime=\"2017-12-20T22:32:39Z\" level=error msg=\"ERROR: zfs collector failed after 0.000693s: could not parse expected integer value for \\\"kstat.zfs.misc.zil.zil_itx_needcopy_bytes\\\"\" source=\"node_exporter.go:95\"\r\n```", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6988/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374490", "body": "Hmmm\u2026 in fact this line is supposed to be in pull request #384. Seems like I seriously screwed up while doing the merges: all my pull requests show the same commits. What a mess\u2026 git is new to me, I guess this was bound to happen. There should be only one commit in this pull request: 90e1b2108f3b8fd3d2b92bdaa4775fe2321cffa3, so if you're just interested in ZVOL synchronicity, you should check it out. I'm not sure how to fix this, I guess I'll have to recreate the pull requests.\n\nFYI, in the context of #384, this comment means that maybe the discard operation should be added to the log. This is not very important since losing discard operations cannot result in data corruption.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374490/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374498", "body": "That's what I did, basically; the problem is, when updating my master branch from upstream I guessed it would be a good idea to also update individual pull request branches from my master branch. Alas, it was a very bad idea, because my master branch add commits from all my pull requests, so by merging master into each pull request, I merged all commits from all pull requests into each pull request, hence the mess. In the future I'll just let my pull requests alone when I'm done with them.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374498/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374511", "body": "I never commited anything to my master branch, just merges. I wrote the pull request's code into the appropriate pull request branches, as I should. The issue is, I was merging master into my pull requests without realizing what I was doing. The solution is to stop doing that. I just emailed Brian so that we decide what to do about the already messed up pull requests.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374511/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}, "ScaMar": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6985", "title": "\"space map refcount mismatch\" on never used zpool after reboot", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       |  Ubuntu\r\nDistribution Version    |  LTS 16.04.03\r\nLinux Kernel                 |  4.4.0-104-generic\r\nArchitecture                 |  x86_64\r\nZFS Version                  |  0.6.5.6\r\nSPL Version                  |  0.6.5.6\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\n\r\nHi all,\r\non my live zpool i've found the \"space map refcount mismatch\" (error? warning?).\r\nBecause the pool wasn't too big, i've copied data on an external storage, so i've destroyes the zpool then i've recreated it.\r\nI've execute \"zdb <pool>\" and it was ok. After the first reboot (no data were copied/created on zpool), i've executed \"zdb <pool>\" again and i've found the message \"space map refcount mismatch\".\r\n\r\nI've destroyed - recreated the pool several times, always i got the \"space map refcount mismatch\".\r\nEach time before reboot i've tried something like \"zfs unmount <pool>\".\r\nI think the message is related to the first zpool.cache creation.\r\nAfter i've deleted the zpool.cache, the error was not present after the reboot.\r\n\r\nSo my problem are these lines in the zdb output:\r\n```\r\nspace map refcount mismatch: expected 11 != actual 5\r\n```\r\n\r\n### Describe how to reproduce the problem\r\nInstall Ubuntu 16.04. Update it. Create a zpool. Reboot.\r\n\r\n### Questions, considerations, any suggestions?\r\nAbout such issue, i have some questions:\r\n\r\n1) Is it something i need to worry about?\r\n2) Is there a way to recalculate/rebuild space map?\r\n\r\nThere are similar issues about such message someone wrote \"It is a problem in claiming empty space\", some other wrote \"This situation may lead to data corruption\", \"Ignore it if the delta beetwen refcount and space is fixed (if not?)\".\r\nMay we have a clear/human about the consequencies of this error / warning?\r\n\r\nThe only think i know, and sincerily i don't understand a single line (my fault, i'm not a coder), this is the line of code where the counts are compared:\r\n```\r\nstatic int\r\nverify_spacemap_refcounts(spa_t *spa)\r\n{\r\n\tuint64_t expected_refcount = 0;\r\n\tuint64_t actual_refcount;\r\n\r\n\t(void) feature_get_refcount(spa,\r\n\t    &spa_feature_table[SPA_FEATURE_SPACEMAP_HISTOGRAM],\r\n\t    &expected_refcount);\r\n\tactual_refcount = get_dtl_refcount(spa->spa_root_vdev);\r\n\tactual_refcount += get_metaslab_refcount(spa->spa_root_vdev);\r\n\r\n\tif (expected_refcount != actual_refcount) {\r\n\t\t(void) printf(\"space map refcount mismatch: expected %lld != \"\r\n\t\t    \"actual %lld\\n\",\r\n\t\t    (longlong_t)expected_refcount,\r\n\t\t    (longlong_t)actual_refcount);\r\n\t\treturn (2);\r\n\t}\r\n\treturn (0);\r\n}\r\n```\r\nPlease let me know if i must worry about this, so i can evaluate other ways to achieve my personal storage:\r\n1) linux with btrfs\r\n2) OpenIndiana/FreeBSD with ZFS\r\n3) Old but stable md / lvm / xfs (i will risk the cosmic ray bitrotter...)\r\n\r\nThank you,\r\nMarco\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n<!-- \r\n*IMPORTANT* - Please mark logs and text output from terminal commands \r\nor else Github will not display them correctly. \r\nAn example is provided below.\r\n\r\nExample:\r\n```\r\nthis is an example how log text should be marked (wrap it with ```)\r\n```\r\n-->\r\n\r\n\r\n[zdbout.newcreated.txt](https://github.com/zfsonlinux/zfs/files/1571863/zdbout.newcreated.txt)\r\n[zdbout.firstreboot.txt](https://github.com/zfsonlinux/zfs/files/1571864/zdbout.firstreboot.txt)\r\n```\r\nHistory for 'magazzino':\r\n2017-12-19.13:28:20 zpool create magazzino mirror /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K0KA3UYK /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K7NF5E20\r\n2017-12-19.13:28:21 zpool add magazzino mirror /dev/disk/by-id/ata-WDC_WD30EFRX-68EUZN0_WD-WCC4N7UUHR2X /dev/disk/by-id/ata-WDC_WD30EFRX-68EUZN0_WD-WCC4N3CHVS8X\r\n2017-12-19.13:28:22 zpool add magazzino cache /dev/disk/by-id/ata-KINGSTON_SUV400S37120G_50026B77720127CB-part5 /dev/disk/by-id/ata-KINGSTON_SUV400S37120G_50026B776B0175F0-part5\r\n2017-12-19.13:28:22 zpool add magazzino log mirror /dev/disk/by-id/ata-KINGSTON_SUV400S37120G_50026B77720127CB-part6 /dev/disk/by-id/ata-KINGSTON_SUV400S37120G_50026B776B0175F0-part6\r\n2017-12-19.13:28:22 zfs create magazzino/video\r\n2017-12-19.13:28:22 zfs create magazzino/foto\r\n2017-12-19.13:28:23 zfs create magazzino/owncloud\r\n2017-12-19.13:28:29 zpool scrub magazzino\r\n```\r\n--> deleted /etc/zfs/zpool.cache\r\n--> reboot\r\n```\r\n2017-12-19.13:31:24 zpool import -d /dev/disk/by-id -aN\r\n```\r\n--> new reboot withouth deleting zpool.cache\r\n```\r\n2017-12-19.13:37:03 zpool import -c /etc/zfs/zpool.cache -aN\r\n```\r\n--> another reboot withouth deleting zpool.cache\r\n```\r\n2017-12-19.13:41:01 zpool import -c /etc/zfs/zpool.cache -aN\r\n```\r\n\r\n\r\n\r\n\r\n\r\n\r\n ", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6985/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "samis": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6984", "title": "zpool property 'freeing' partially stuck", "body": "### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Gentoo\r\nDistribution Version    | Profile 17.0\r\nLinux Kernel                 | 4.14.5-gentoo\r\nArchitecture                 | X86_64\r\nZFS Version                  | 0.7.0-211_g4e9b1569\r\nSPL Version                  | 0.7.0-21_ged19bcc\r\n\r\n\r\n### Describe the problem you're observing\r\nI recently decided to clean up and delete two unused sparse zvols. After this, the freeing property increased as expected and did initially decrease. However, it's almost 24 hours (and two reboots) later and the property is still reporting the exact same value. \r\n\r\nAs a test, I filled a zvol with 1G of /dev/urandom and then destroyed it. The property increased from it's original value of 14353956864 to 14605664256 but shortly afterwards the data was freed and the value was back to 14353956864. This is similar to #5808 but both the scenario and the behaviour appear to be different, as neither zvol was ever used for NFS purposes.\r\n### Describe how to reproduce the problem\r\nI have not yet reproduced this beyond the above test. I can't be certain that the freeing value was correct before, but the timing seems right for this issue.\r\n### Include any warning/errors/backtraces from the system logs\r\nSo far there have been no warnings, errors or backtraces created as a result of this problem. \r\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6984/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "prometheanfire": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6982", "title": "encrypted root pools fail to boot with dracut", "body": "I have a fully encrypted pool that fails to boot with dracut, I'm having problems finding the right place to add `zfs load-key -a` before sysroot.mount is run.\r\n\r\nI'm able to move on though by running the following once the rescue shell pops up\r\n\r\n    zfs load-key -a\r\n    systemctl start sysroot.mount\r\n    systemctl restart initrd-switch-root.service", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6982/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/c10cdcb55f81ea773486161b31bc91bb7b58b4c8", "message": "Fix copy-builtin to work with ASAN patch\n\nCommit fed90353 didn't fully update the copy-builtin script\r\nas needed to perform in-kernel builds.  Add the missing\r\noptions and flags.\r\n\r\nReviewed by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: Matthew Thode <mthode@mthode.org>\r\nCloses #7033 \r\nCloses #7037"}], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/7008", "title": "DNM: make zfs-mount service work with encryption", "body": "", "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/7004", "title": "Run zfs load-key if needed in dracut", "body": "'zfs load-key -a' will only be called if needed.  If a dataset not\r\nneeded for boot does not have it's key loaded (home directories for\r\nexample) boot can still continue.", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "zielony360": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6979", "title": "Increasing zfs_vdev_aggregation_limit with zvols", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Debian\r\nDistribution Version    | 7\r\nLinux Kernel                 | 4.0.4\r\nArchitecture                 |x86_64 \r\nZFS Version                  | 0.6.5.7\r\nSPL Version                  | 0.6.5.7\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\nHello,\r\n\r\nwe have pool consisting 5 x 10-disk raidz2 group and using zvols with volblocksize=128k, shared through LIO FC target. Due to the fact that zfs_vdev_aggregation_limit is limited to 128k too, writes on singular disk are very small, like 13 kB average, what causes performance issues. Unfortunately, there is no large blocks for zvols to prevent it.\r\n\r\nMy questions are:\r\n1. Can I somehow safely increase zfs_vdev_aggregation_limit to 512 kB with existing configuration?\r\n2. If not, how can I migrate to large blocks datasets using the same pool? I mean I would like to create datasets, set recordsize=512k on them, but also raise zfs_vdev_aggregation_limit to make it sensible. For some time zvols will coexist with datasets during such migration.\r\n\r\n### Describe how to reproduce the problem\r\nCreate a pool with wide raidz2 vdevs and use zvols.\r\n\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n<!-- \r\n*IMPORTANT* - Please mark logs and text output from terminal commands \r\nor else Github will not display them correctly. \r\nAn example is provided below.\r\n\r\nExample:\r\n```\r\nthis is an example how log text should be marked (wrap it with ```)\r\n```\r\n-->\r\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6979/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "loli10K": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/79c3270476b7140220c7946dd0a709a31bb9ed1b", "message": "Fix Debian packaging on ARMv7/ARM64\n\nWhen building packages on Debian-based systems specify the target\r\narchitecture used by 'alien' to convert .rpm packages into .deb: this\r\navoids detecting an incorrect value which results in the following\r\nerrors:\r\n\r\n<package>.aarch64.rpm is for architecture aarch64 ; the package cannot be built on this system\r\n<package>.armv7l.rpm is for architecture armel ; the package cannot be built on this system\r\n\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nReviewed-by: George Melikov <mail@gmelikov.ru>\r\nSigned-off-by: loli10K <ezomori.nozomu@gmail.com>\r\nCloses #7046 \r\nCloses #7058"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/390d679acdfa6a2498280a4dcd33b7600ace27ce", "message": "Fix 'zpool add' handling of nested interior VDEVs\n\nWhen replacing a faulted device which was previously handled by a spare\r\nmultiple levels of nested interior VDEVs will be present in the pool\r\nconfiguration; the following example illustrates one of the possible\r\nsituations:\r\n\r\n   NAME                          STATE     READ WRITE CKSUM\r\n   testpool                      DEGRADED     0     0     0\r\n     raidz1-0                    DEGRADED     0     0     0\r\n       spare-0                   DEGRADED     0     0     0\r\n         replacing-0             DEGRADED     0     0     0\r\n           /var/tmp/fault-dev    UNAVAIL      0     0     0  cannot open\r\n           /var/tmp/replace-dev  ONLINE       0     0     0\r\n         /var/tmp/spare-dev1     ONLINE       0     0     0\r\n       /var/tmp/safe-dev         ONLINE       0     0     0\r\n   spares\r\n     /var/tmp/spare-dev1         INUSE     currently in use\r\n\r\nThis is safe and allowed, but get_replication() needs to handle this\r\nsituation gracefully to let zpool add new devices to the pool.\r\n\r\nReviewed-by: George Melikov <mail@gmelikov.ru>\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: loli10K <ezomori.nozomu@gmail.com>\r\nCloses #6678 \r\nCloses #6996"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "kithrup": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/43cb30b3ce6ee3c3041276c93594ae61e7daaf86", "message": "OpenZFS 8959 - Add notifications when a scrub is paused or resumed\n\nAuthored by: Sean Eric Fagan <sef@ixsystems.com>\nReviewed by: Alek Pinchuk <pinchuk.alek@gmail.com>\nReviewed by: Matthew Ahrens <mahrens@delphix.com>\nReviewed-by: George Melikov <mail@gmelikov.ru>\nReviewed-by: Tony Hutter <hutter2@llnl.gov>\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\nApproved by: Gordon Ross <gwr@nexenta.com>\nPorted-by: Giuseppe Di Natale <dinatale2@llnl.gov>\n\nPorting Notes:\n- Brought #defines in eventdefs.h in line with ZFS on Linux format.\n- Updated zfs-events.5 with the new events.\n\nOpenZFS-issue: https://www.illumos.org/issues/8959\nOpenZFS-commit: https://github.com/openzfs/openzfs/commit/c862b93eea\nCloses #7049"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "DeHackEd": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/d658b2caa95726c13d99123874910cdedc7ce866", "message": "Remove l2arc_nocompress from zfs-module-parameters(5)\n\nParameter was removed in d3c2ae1c0806\r\n(OpenZFS 6950 - ARC should cache compressed data)\r\n\r\nReviewed by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: DHE <git@dehacked.net>\r\nCloses #7043"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/460f239e6999195dbcf9b8443c029f07765b21e9", "message": "Fix -fsanitize=address memory leak\n\nkmem_alloc(0, ...) in userspace returns a leakable pointer.\n\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\nSigned-off-by: DHE <git@dehacked.net>\nIssue #6941"}], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6673", "title": "Fail importing if cached config has wrong number of vdev children", "body": "During import compare the labels' configs with the import config\r\nand fail if the labels indicate more vdevs than the cached config\r\n\r\nSigned-off-by: DHE <git@dehacked.net>\r\nFixes #6671\r\n\r\n### Description\r\nWhen the zpool.cache says `vdev_children=X` but the pool actually has `vdev_children=Y` where `X<Y`, blkptr errors will occur during the import process. We detect this specific case and refuse imports from this cache file.\r\n\r\n### Motivation and Context\r\nSee #6671\r\n\r\n### How Has This Been Tested?\r\n`ztest` only\r\n\r\n### Types of changes\r\n- [X] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n- [X] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [ ] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [X] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "yuripv": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/6df9f8ebd73c05da627144bcc3823e6fe980cd75", "message": "OpenZFS 8899 - zpool list property documentation doesn't match actual behaviour\n\nAuthored by: Yuri Pankov <yuri.pankov@nexenta.com>\nReviewed by: Alexander Pyhalov <alp@rsu.ru>\nReviewed-by: George Melikov <mail@gmelikov.ru>\nApproved by: Dan McDonald <danmcd@joyent.com>\nPorted-by: Brian Behlendorf <behlendorf1@llnl.gov>\n\nOpenZFS-issue: https://www.illumos.org/issues/8899\nOpenZFS-commit: https://github.com/openzfs/openzfs/commit/b0e142e57d\nCloses #7032"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/bcb1a8a25e4ee9a94478378710de53b45a9b1517", "message": "OpenZFS 8898 - creating fs with checksum=skein on the boot pools fails ungracefully\n\nAuthored by: Yuri Pankov <yuri.pankov@nexenta.com>\nReviewed by: Toomas Soome <tsoome@me.com>\nReviewed by: Andy Stormont <astormont@racktopsystems.com>\nReviewed-by: George Melikov <mail@gmelikov.ru>\nApproved by: Dan McDonald <danmcd@joyent.com>\nPorted-by: Brian Behlendorf <behlendorf1@llnl.gov>\n\nOpenZFS-issue: https://www.illumos.org/issues/8898\nOpenZFS-commit: https://github.com/openzfs/openzfs/commit/9fa2266d9a\nCloses #7031"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/8198c57b21d5e503f7e72221aa714aaabb2079cc", "message": "OpenZFS 8897 - zpool online -e fails assertion when run on non-leaf vdevs\n\nAuthored by: Yuri Pankov <yuri.pankov@nexenta.com>\nReviewed by: Toomas Soome <tsoome@me.com>\nReviewed by: Igor Kozhukhov <igor@dilos.org>\nReviewed-by: George Melikov <mail@gmelikov.ru>\nApproved by: Dan McDonald <danmcd@joyent.com>\nPorted-by: Brian Behlendorf <behlendorf1@llnl.gov>\n\nOpenZFS-issue: https://www.illumos.org/issues/8897\nOpenZFS-commit: https://github.com/openzfs/openzfs/commit/9a551dd645\nCloses #7030"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "avg-I": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/6a2185660d000c99b14556c7eb1108c5609faf41", "message": "OpenZFS 8930 - zfs_zinactive: do not remove the node if the filesystem is readonly\n\nAuthored by: Andriy Gapon <avg@FreeBSD.org>\nReviewed by: Matthew Ahrens <mahrens@delphix.com>\nReviewed-by: George Melikov <mail@gmelikov.ru>\nApproved by: Gordon Ross <gwr@nexenta.com>\nPorted-by: Brian Behlendorf <behlendorf1@llnl.gov>\n\nOpenZFS-issue: https://www.illumos.org/issues/8930\nOpenZFS-commit: https://github.com/openzfs/openzfs/commit/93c618e0f4\nCloses #7029"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ryao": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/1d53657bf561564162e2ad6449f80fa0140f1dd6", "message": "Fix incompatibility with Reiser4 patched kernels\n\nIn ZFSOnLinux, our sources and build system are self contained such that\r\nwe do not need to make changes to the Linux kernel sources. Reiser4 on\r\nthe other hand exists solely as a kernel tree patch and opts to make\r\nchanges to the kernel rather than adapt to it. After Linux 4.1 made a\r\nVFS change that replaced new_sync_read with do_sync_read, Reiser4's\r\nmaintainer decided to modify the kernel VFS to export the old function.\r\nThis caused our autotools check to misidentify the kernel API as\r\npredating Linux 4.1 on kernels that have been patched with Reiser4\r\nsupport, which breaks our build.\r\n\r\nReiser4 really should be patched to stop doing this, but lets modify our\r\ncheck to be more strict to help the affected users of both filesystems.\r\n\r\nAlso, we were not checking the types of arguments and return value of\r\nnew_sync_read() and new_sync_write() . Lets fix that too.\r\n\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nReviewed-by: Giuseppe Di Natale <dinatale2@llnl.gov>\r\nReviewed-by: George Melikov <mail@gmelikov.ru>\r\nSigned-off-by: Richard Yao <ryao@gentoo.org>\r\nCloses #6241 \r\nCloses #7021"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "nwf": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/cba6fc61a2898395c47380a0c2303f19842a2ff0", "message": "Revert raidz_map and _col structure types\n\nAs part of the refactoring of ab9f4b0b824ab4cc64a4fa382c037f4154de12d6,\r\nseveral uint64_t-s and uint8_t-s were changed to other types.  This\r\ncaused ZoL github issue #6981, an overflow of a size_t on a 32-bit ARM\r\nmachine.  In absense of any strong motivation for the type changes, this\r\nsimply puts them back, modulo the changes accumulated for ABD.\r\n\r\nCompile-tested on amd64 and run-tested on armhf.\r\n\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nReviewed-by: Gvozden Neskovic <neskovic@gmail.com>\r\nSigned-off-by: Nathaniel Wesley Filardo <nwf@cs.jhu.edu>\r\nCloses #6981 \r\nCloses #7023"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/8b20a9f996b90abe439ce14303fc440f26390e38", "message": "zhack: fix getopt return type\n\nThis fixes zhack's command processing on ARM.  On ARM char\r\nis unsigned, and so, in promotion to an int, it will never\r\ncompare equal to -1.\r\n\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: Nathaniel Wesley Filardo <nwf@cs.jhu.edu>\r\nCloses #7016"}], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6209", "title": "[RFC] new zscrub command for offline scrubs in userland", "body": "### Description\r\n\r\nThis PR adds a \"zhack scrub\" subcommand which, in user-land, finds and scrubs a pool.  This has proven useful for experimenting with the scan logic (especially the in-order-scrub patches) without having to reload the kernel module and seems like it may be useful to others.\r\n\r\nAt this point, it is not yet ready to merge -- there are no tests, no docs, &c... but I am curious for anyone's commentary and/or suggestions. :)\r\n\r\n### How Has This Been Tested?\r\n\r\nLimited testing against both files and actual block-device-backed pools.  Scrubs and resilvers appear to work just fine.\r\n\r\n### Types of changes\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [ ] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "gamanakis": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/be54a13c3e7db423ffdb3f7983d4dd1141cc94a0", "message": "Fix percentage styling in zfs-module-parameters.5\n\nReplace \"percent\" with \"%\", add bold to default values.\r\n\r\nReviewed-by: bunder2015 <omfgbunder@gmail.com>\r\nReviewed-by: George Melikov <mail@gmelikov.ru>\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: George Amanakis <gamanakis@gmail.com>\r\nCloses #7018"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "prakashsurya": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/2fe61a7ecc507d031451c21b3077fae549b58ec3", "message": "OpenZFS 8909 - 8585 can cause a use-after-free kernel panic\n\nAuthored by: Prakash Surya <prakash.surya@delphix.com>\nReviewed by: John Kennedy <jwk404@gmail.com>\nReviewed by: Matthew Ahrens <mahrens@delphix.com>\nReviewed by: George Wilson <george.wilson@delphix.com>\nReviewed by: Brad Lewis <brad.lewis@delphix.com>\nReviewed by: Igor Kozhukhov <igor@dilos.org>\nReviewed by: Brian Behlendorf <behlendorf1@llnl.gov>\nApproved by: Robert Mustacchi <rm@joyent.com>\nPorted-by: Prakash Surya <prakash.surya@delphix.com>\n\nPROBLEM\n=======\n\nThere's a race condition that exists if `zil_free_lwb` races with either\n`zil_commit_waiter_timeout` and/or `zil_lwb_flush_vdevs_done`.\n\nHere's an example panic due to this bug:\n\n    > ::status\n    debugging crash dump vmcore.0 (64-bit) from ip-10-110-205-40\n    operating system: 5.11 dlpx-5.2.2.0_2017-12-04-17-28-32b6ba51fb (i86pc)\n    image uuid: 4af0edfb-e58e-6ed8-cafc-d3e9167c7513\n    panic message:\n    BAD TRAP: type=e (#pf Page fault) rp=ffffff0010555970 addr=60 occurred in module \"zfs\" due to a NULL pointer dereference\n    dump content: kernel pages only\n\n    > $c\n    zio_shrink+0x12()\n    zil_lwb_write_issue+0x30d(ffffff03dcd15cc0, ffffff03e0730e20)\n    zil_commit_waiter_timeout+0xa2(ffffff03dcd15cc0, ffffff03d97ffcf8)\n    zil_commit_waiter+0xf3(ffffff03dcd15cc0, ffffff03d97ffcf8)\n    zil_commit+0x80(ffffff03dcd15cc0, 9a9)\n    zfs_write+0xc34(ffffff03dc38b140, ffffff0010555e60, 40, ffffff03e00fb758, 0)\n    fop_write+0x5b(ffffff03dc38b140, ffffff0010555e60, 40, ffffff03e00fb758, 0)\n    write+0x250(42, fffffd7ff4832000, 2000)\n    sys_syscall+0x177()\n\nIf there's an outstanding lwb that's in `zil_commit_waiter_timeout`\nwaiting to timeout, waiting on it's waiter's CV, we must be sure not to\ncall `zil_free_lwb`. If we end up calling `zil_free_lwb`, then that LWB\nmay be freed and can result in a use-after-free situation where the\nstale lwb pointer stored in the `zil_commit_waiter_t` structure of the\nthread waiting on the waiter's CV is used.\n\nA similar situation can occur if an lwb is issued to disk, and thus in\nthe `LWB_STATE_ISSUED` state, and `zil_free_lwb` is called while the\ndisk is servicing that lwb. In this situation, the lwb will be freed by\n`zil_free_lwb`, which will result in a use-after-free situation when the\nlwb's zio completes, and `zil_lwb_flush_vdevs_done` is called.\n\nThis race condition is prevented in `zil_close` by calling `zil_commit`\nbefore `zil_free_lwb` is called, which will ensure all outstanding (i.e.\nall lwb's in the `LWB_STATE_OPEN` and/or `LWB_STATE_ISSUED` states)\nreach the `LWB_STATE_DONE` state before the lwb's are freed\n(`zil_commit` will not return untill all the lwb's are\n`LWB_STATE_DONE`).\n\nFurther, this race condition is prevented in `zil_sync` by only calling\n`zil_free_lwb` for lwb's that do not have their `lwb_buf` pointer set.\nAll lwb's not in the `LWB_STATE_DONE` state will have a non-null value\nfor this pointer; the pointer is only cleared in\n`zil_lwb_flush_vdevs_done`, at which point the lwb's state will be\nchanged to `LWB_STATE_DONE`.\n\nThis race *is* present in `zil_suspend`, leading to this bug.\n\nAt first glance, it would appear as though this would not be true\nbecause `zil_suspend` will call `zil_commit`, just like `zil_close`, but\nthe problem is that `zil_suspend` will set the zilog's `zl_suspend`\nfield prior to calling `zil_commit`. Further, in `zil_commit`, if\n`zl_suspend` is set, `zil_commit` will take a special branch of logic\nand use `txg_wait_synced` instead of performing the normal `zil_commit`\nlogic.\n\nThis call to `txg_wait_synced` might be good enough for the data to\nreach disk safely before it returns, but it does not ensure that all\noutstanding lwb's reach the `LWB_STATE_DONE` state before it returns.\nThis is because, if there's an lwb \"stuck\" in\n`zil_commit_waiter_timeout`, waiting for it's lwb to timeout, it will\nmaintain a non-null value for it's `lwb_buf` field and thus `zil_sync`\nwill not free that lwb. Thus, even though the lwb's data is already on\ndisk, the lwb will be left lingering, waiting on the CV, and will\neventually timeout and be issued to disk even though the write is\nunnecessary.\n\nSo, after `zil_commit` is called from `zil_suspend`, we incorrectly\nassume that there are not outstanding lwb's, and proceed to free all\nlwb's found on the zilog's lwb list. As a result, we free the lwb that\nwill later be used `zil_commit_waiter_timeout`.\n\nSOLUTION\n========\n\nThe solution to this, is to ensure all outstanding lwb's complete before\ncalling `zil_free_lwb` via `zil_destroy` in `zil_suspend`. This patch\naccomplishes this goal by forcing the normal `zil_commit` logic when\ncalled from `zil_sync`.\n\nNow, `zil_suspend` will call `zil_commit_impl` which will always use the\nnormal logic of waiting/issuing lwb's to disk before it returns. As a\nresult, any lwb's outstanding when `zil_commit_impl` is called will be\nguaranteed to reach the `LWB_STATE_DONE` state by the time it returns.\n\nFurther, no new lwb's will be created via `zil_commit` since the zilog's\n`zl_suspend` flag will be set. This will force all new callers of\n`zil_commit` to use `txg_wait_synced` instead of creating and issuing\nnew lwb's.\n\nThus, all lwb's left on the zilog's lwb list when `zil_destroy` is\ncalled will be in the `LWB_STATE_DONE` state, and we'll avoid this race\ncondition.\n\nOpenZFS-issue: https://www.illumos.org/issues/8909\nOpenZFS-commit: https://github.com/openzfs/openzfs/commit/ece62b6f8d\nCloses #6940"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "lidongyang": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/823d48bfb182137c53b9432498f1f0564eaa8bfc", "message": "Call commit callbacks from the tail of the list\n\nOur zfs backed Lustre MDT had soft lockups while under heavy metadata\r\nworkloads while handling transaction callbacks from osd_zfs.\r\n\r\nThe problem is zfs is not taking advantage of the fast path in\r\nLustre's trans callback handling, where Lustre will skip the calls\r\nto ptlrpc_commit_replies() when it already saw a higher transaction\r\nnumber.\r\n\r\nThis patch corrects this, it also has a positive impact on metadata\r\nperformance on Lustre with osd_zfs, plus some cleanup in the headers.\r\n\r\nA similar issue for ext4/ldiskfs is described on:\r\nhttps://jira.hpdd.intel.com/browse/LU-6527\r\n\r\nReviewed-by: Olaf Faaland <faaland1@llnl.gov>\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: Li Dongyang <dongyang.li@anu.edu.au>\r\nCloses #6986"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "tcaputi": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/44b61ea506212c287333e03d2cf8933216810800", "message": "Remove empty files accidentally added by a8b2e306 \n\nThis patch simply removes 2 empty files that were accidentally\r\nadded a part of the scrub priority patch.\r\n\r\nReviewed-by: George Melikov <mail@gmelikov.ru>\r\nReviewed-by: Giuseppe Di Natale <dinatale2@llnl.gov>\r\nSigned-off-by: Tom Caputi <tcaputi@datto.com>\r\nCloses #6990"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/a8b2e30685c9214ccfd0181977540e080340df4e", "message": "Support re-prioritizing asynchronous prefetches\n\nWhen sequential scrubs were merged, all calls to arc_read()\r\n(including prefetch IOs) were given ZIO_PRIORITY_ASYNC_READ.\r\nUnfortunately, this behaves badly with an existing issue where\r\nprefetch IOs cannot be re-prioritized after the issue. The\r\nresult is that synchronous reads end up in the same vdev_queue\r\nas the scrub IOs and can have (in some workloads) multiple\r\nseconds of latency.\r\n\r\nThis patch incorporates 2 changes. The first ensures that all\r\nscrub IOs are given ZIO_PRIORITY_SCRUB to allow the vdev_queue\r\ncode to differentiate between these I/Os and user prefetches.\r\nSecond, this patch introduces zio_change_priority() to provide\r\nthe missing capability to upgrade a zio's priority.\r\n\r\nReviewed by: George Wilson <george.wilson@delphix.com>\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: Tom Caputi <tcaputi@datto.com>\r\nCloses #6921 \r\nCloses #6926"}], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6864", "title": "Encryption and Raw Send Stability Improvements", "body": "The current on-disk format for encrypted datasets protects\r\nnot only the encrypted and authenticated blocks, but also\r\nthe order and interpretation of these blocks. In order to\r\nmake this work while maintaining the ability to do raw sends\r\nthe indirect bps maintain a secure checksum of all the MACs\r\nin the block below it, along with a few other fields that\r\ndetermine how the data is interpretted.\r\n\r\nUnfortunately, the current on-disk format erroniously\r\nincludes some fields which are not portable and thus cannot\r\nsupport raw sends. It is also not possible to easily work\r\naround this issue due to a separate and much smaller bug\r\nwhich causes indirect blocks for encrypted dnodes to not\r\nbe compressed, which conflicts with the previous bug. In\r\naddition, raw send streams do not currently include\r\ndn_maxblkid which is needed in order to ensure that we are\r\ncorrectly maintaining the portable objset MAC.\r\n\r\nThis patch zero's out the offending fields when computing the\r\nbp MAC (as they should have been) and registers an errata for\r\nthe on-disk format bug. We detect the errata by adding a\r\n\"version\" field to newly created DSL Crypto Keys. We allow\r\ndatasets without a version (version 0) to only be mounted for\r\nread so that they can easily be migrated. We also now include\r\ndn_maxblkid in raw send streams to ensure the MAC can be\r\nmaintained correctly.\r\n\r\nNote that this fix has not yet been finalized and should not be used until it is tested, reviewed, and merged unless you are ok with losing your data.\r\n\r\nSigned-off-by: Tom Caputi <tcaputi@datto.com>\r\n\r\n### How Has This Been Tested?\r\nI have added a new test for raw sends that essentially stresses as many edge cases as I could think of. In addition, I have manually tested that the recovery process laid out in https://github.com/zfsonlinux/zfsonlinux.github.com/pull/35 works as advertised, and that both old and new datasets function predictably.\r\n\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [x] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [x] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "tesujimath": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/993669a7bf17a26843630c547999be0b27483497", "message": "vdev_id: new slot type ses\n\nThis extends vdev_id to support a new slot type, ses, for SCSI Enclosure\r\nServices.  With slot type ses, the disk slot numbers are determined by\r\nusing the device slot number reported by sg_ses for the device with\r\nmatching SAS address, found by querying all available enclosures.\r\n\r\nThis is primarily of use on systems with a deficient driver omitting\r\nsupport for bay_identifier in /sys/devices.  In my testing, I found that\r\nthe existing slot types of port and id were not stable across disk\r\nreplacement, so an alternative was required.\r\n\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: Simon Guest <simon.guest@tesujimath.org>\r\nCloses #6956"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "dinatale2": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/89a66a0457cd392ab8c6ad6d9c138fedaa425067", "message": "Handle broken pipes in arc_summary\n\nUsing a command similar to 'arc_summary.py | head' causes\r\na broken pipe exception. Gracefully exit in the case of a\r\nbroken pipe in arc_summary.py.\r\n\r\nReviewed-by: Richard Elling <Richard.Elling@RichardElling.com>\r\nReviewed-by: loli10K <ezomori.nozomu@gmail.com>\r\nSigned-off-by: Giuseppe Di Natale <dinatale2@llnl.gov>\r\nCloses #6965 \r\nCloses #6969"}], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6906", "title": "Add dbuf hash and dbuf cache kstats", "body": "### Description\r\n<!--- Describe your changes in detail -->\r\nIntroduce kstats about the dbuf hash and dbuf cache\r\nto make it easier to inspect state. This should help\r\nwith debugging and understanding of these portions\r\nof the codebase.\r\n\r\nCorrect format of dbuf kstat file.\r\n\r\nIntroduce a dbc column to dbufs kstat to indicate if\r\na dbuf is in the dbuf cache.\r\n\r\nIntroduce field filtering in the dbufstat python script.\r\n\r\nI will also be introducing some basic test cases to test the new dbufstats kstat and other basic scenarios.\r\n\r\n<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\nGain a better understanding how dbufs are cached and provide another useful tool for users/developer.\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\nLocally on a VM.\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [x] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6294", "title": "Enforce request limits on zvols", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\nCurrently, zvols do not handle heavy random IO\r\nworkloads. zvols should limit the number of outstanding\r\nin-flight IO requests. This should improve performance.\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n#6127 \r\n#6278 \r\n\r\n### How Has This Been Tested?\r\nBuilds on my VM. Buildbot will help me test. Hoping to test on hardware soon.\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [x] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "MEMBER"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "avw1987": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/7055", "title": "Update README.initramfs.markdown", "body": "Fixed a typo\r\n\r\n<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [x] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [ ] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [ ] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "tonyhutter": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/7051", "title": "zfs-0.7.6 patchset", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\nTest 0.7.6 patchset in buildbot\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [ ] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [ ] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "MEMBER"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "sckobras": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/7007", "title": "Allow to limit zed's syslog chattiness", "body": "### Description\r\n\r\nSome usage patterns like send/recv of replication streams can\r\nproduce a large number of events. In such a case, the current\r\nall-syslog.sh zedlet will hold up to its name, and flood the\r\nlogs with mostly redundant information. To mitigate this\r\nsituation, this changeset introduces two new variables\r\nZED_SYSLOG_SUBCLASS_INCLUDE and ZED_SYSLOG_SUBCLASS_EXCLUDE\r\nto zed.rc that give more control over which event classes end\r\nup in the syslog.\r\n\r\nSigned-off-by: Daniel Kobras <d.kobras@science-computing.de>\r\nCloses: #6886\r\n\r\n### Motivation and Context\r\nIt seems that each time a dataset that also uses =zfs-auto-snapshot= is replicated, a =history_event= for the =com.sun:auto-snapshot-desc= property in each snapshot is logged. This easily spams the logs with thousands of redundant, and rather useless messages as described in #6886, so adding a facility to trim down the noise without disabling the syslog feature altogether seems to be in order.\r\n\r\n### How Has This Been Tested?\r\nTested on EL7.4 with ZoL 0.7.2.\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [x] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "aerusso": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6974", "title": "fstab integration", "body": "Generate a tracked, updateable section in /etc/fstab for zfs filesystems\r\n\r\n### Description\r\nA contrib script fstab-generator is implemented that creates a trackable section in /etc/fstab (or another user-specified file) with fstab syntax reflecting the zfs mount and canmount parameters.\r\n\r\n### Motivation and Context\r\nWhile #4943 implements a per-pool granular import, the user will still \"need to add an entry like this in fstab:\r\n\r\n```rpool/home /home zfs rw,defaults,x-systemd.requires=zpool@rpool.service```\r\n\r\nThis script performs precisely that mechanical task, allowing for filesystem dependencies to be correctly identified, and mounted in time to guarantee their availability. A monolithic import of all zfs filesystems is not required to have system files on native zfs mountpoints. \r\n\r\nMoreover, by including this information in /etc/fstab, tools can fail appropriately if essential mountpoints are unavailable. This helps address the common annoyance where zfs fails to mount an important system directory, files then get placed on the zfs mountpoint, and then zfs will fail to mount on the subsequent boot (because overlay=off) even though the underlying problem was corrected. \r\n\r\n#### Why not a systemd-generator?\r\nBesides the obvious lack of integration for users without systemd, other tools may rely on /etc/fstab to determine what filesystems are present on a system. This approach immediately achieves integration with those tools--e.g., for analogous dependency tracking for other init systems that may develop in the future. Additionally, systemd generators may change syntax in the future, but they will have to remain compatible with /etc/fstab.\r\n\r\n### How Has This Been Tested?\r\nI'm running with the output of this script on a machine that has several `/var/` directories, and `/tmp` with purely zfs mountpoints.\r\n\r\n### RFC\r\nThis is a work in progress.\r\n1. Should this be converted to fstab-generator.in, and use `%sbindir%`, etc?\r\n2. Should this name be changed? Should this be installed elsewhere?\r\n3. How could/should this be integrated with the rest of the tools?\r\n4. Is there some reason `mount -ozfsutil` is ill-advised for zfs filesystems?\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6964", "title": "Use zfs-import.target in contrib/dracut", "body": "### Description\r\nThe new zfs-import.target should be used in place of the zfs-import-*.service units in `contrib/dracut`.\r\n\r\n### Motivation and Context\r\nPR #6764 added `zfs-import.target` to simplify dependency on pool importing. #6822 did some cleanup. The recent #6955 (re: #6953) added RPM support for enabling this units. That bug report has prompted me to grep the code base for zfs-import. The last remaining code section to be updated is under `control/dracut/90zfs`.\r\n\r\nThis PR is  a **work in progress**. I don't think dracut users are exposed to any bug presently, because `sysroot.mount` is still ordered `After=zfs-import-*.service`\r\n\r\nTwo files are affected:\r\n1. `zfs-generator.sh.in` is straightforwardly modified to order `sysroot.mount` `After=zfs-import.target` (instead of each `zfs-import-*.service`). \r\n2. `module-setup.sh.in` is also modified. **I need input, because I don't know how precisely dracut works.** `zfs-import.target` (and each `zfs-import-*.service`) is `dracut_install`-ed (and *unconditionally* `mark_hostonly`-ed). Do we need to build a `zfs-import.target.wants` directory with `zfs-import-*.service` links? Or will that be inherited from the host system?\r\n\r\n### How Has This Been Tested?\r\nThis has NOT been tested. This is a place to centralize discussion about these changes.\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [x] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "dweeezil": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6900", "title": "OpenZFS 7614 - zfs device evacuation/removal", "body": "### Description\r\n<!--- Describe your changes in detail -->\r\nThis project allows top-level vdevs to be removed from the storage pool\r\nwith \"zpool remove\", reducing the total amount of storage in the pool.\r\nThis operation copies all allocated regions of the device to be removed\r\nonto other devices, recording the mapping from old to new location.\r\nAfter the removal is complete, read and free operations to the removed\r\n(now \"indirect\") vdev must be remapped and performed at the new location\r\non disk.  The indirect mapping table is kept in memory whenever the pool\r\nis loaded, so there is minimal performance overhead when doing\r\noperations on the indirect vdev.\r\n\r\nThe size of the in-memory mapping table will be reduced when its entries\r\nbecome \"obsolete\" because they are no longer used by any block pointers\r\nin the pool.  An entry becomes obsolete when all the blocks that use it\r\nare freed.  An entry can also become obsolete when all the snapshots\r\nthat reference it are deleted, and the block pointers that reference it\r\nhave been \"remapped\" in all filesystems/zvols (and clones).  Whenever an\r\nindirect block is written, all the block pointers in it will be\r\n\"remapped\" to their new (concrete) locations if possible.  This process\r\ncan be accelerated by using the \"zfs remap\" command to proactively\r\nrewrite all indirect blocks that reference indirect (removed) vdevs.\r\n\r\nNote that when a device is removed, we do not verify the checksum of the\r\ndata that is copied.  This makes the process much faster, but if it were\r\nused on redundant vdevs (i.e. mirror or raidz vdevs), it would be\r\npossible to copy the wrong data, when we have the correct data on e.g.\r\nthe other side of the mirror.  Therefore, mirror and raidz devices can\r\nnot be removed.\r\n\r\n### Motivation and Context\r\nSee above.\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\n### How Has This Been Tested?\r\nAdditions to the test suite in functional/removal.\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/5925", "title": "OpenZFS - 6363 Add UNMAP/TRIM functionality", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n### Description\r\nAdd TRIM support.  Replacement for #3656.\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\nVarious stress testing with an assortment of vdev types.\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [x] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [ ] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [ ] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n\r\nThis PR should integrate all the recent changes in the upstream patch set.  The stack also includes the separate fixes which were in #3656.  It seems stable so far during some fairly abusive testing on SSDs with various types of vdevs.  It does _not_ include the \"partial\" trim support of the previous PR.", "author_association": "MEMBER"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "scotws": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6892", "title": "Add Python 3 rewrite of arc_summary.py (#6873)", "body": "### Description\r\n\r\nAdd new Python 3 script `arc_summary3.py` as a complete rewrite of `arc_summary.py` to display basic information on the ARC status and various other parameters. This is provided in addition - not as a replacement - to the existing `arc_summary.py` tool. See #6873 for a discussion of the reasoning behind adding a new version of this tool while keeping a legacy version as well.\r\n\r\nNew options:\r\n\r\n        -g/--graph    - Display crude graphic representation of ARC status and quit\r\n        -r/--raw      - Print all available information as minimally formatted list and quit\r\n        -s/--section  - Print a single section. This supersedes -p/--page, which is kept for\r\n                        backwards use but marked as DEPRECIATED\r\n\r\nAdds new sections with information on the ZIL and SPL. \r\n\r\nWe now notify the user if sections L2ARC and VDEV are skipped instead of failing silently; note VDEV caching is currently disabled and slated for possible removal (see source code). Adds information on the ZFS and SPL versions to the header.\r\n\r\nThe **-s/--section** option is intended to replace the page number system, which required the user to remember which page number was of interest. The -p/--page options are still supported, but marked as DEPRECIATED. Current legal sections are `arc archits dmu l2arc spl tunables vdev zil`. It should be easier now to add and modify sections.\r\n\r\nThe **-r/--raw** option is intended to work with other tools such as `grep`. It respects the -a/-d options (alternate output format / descriptions included) where possible. \r\n\r\nThe output of the **-g/--graph** option is intended to give a quick, rough overview as a visual orientation. An example (Ubuntu 16.04 LTS x86_64 with 24 GB RAM, 8 GB ARC max, ZFS stock version 0.6.5.9-2 with `/home` as ZFS mirror pool immediately after starting _Civilization VI_ on Steam on otherwise quiet machine): \r\n```\r\n        ARC: 3.0 GiB (37.5 %)  MFU: 610.5 MiB  MRU: 2.3 GiB\r\n    +----------------------------------------------------------+\r\n    |FFFFRRRRRRRRRRRRRRRRR                                     |\r\n    +----------------------------------------------------------+\r\n```\r\n`F` is for MFU, `R` for MRU, and `O` is used for \"other\" if necessary (not present in this example). \r\n\r\n`arc_summary3.py` was developed for Python 3.5. This follows the version of Python currently installed in Ubuntu 16.04 LTS. Few systems will have Python 3.6 installed yet.\r\n\r\n### Known issues\r\n\r\nThe new script is based on the same internal logic as the original, so any error or issue present there will probably show up here as well. For instance, the number of anonymous hits can be negative the way it is calculated in both scripts; they both simply hide any negative value.\r\n\r\nThis script will probably make a bunch of test suites unhappy where Python 3 is not included. There is no experience with this script under extreme conditions (for example ARC throttling).\r\n\r\n### How Has This Been Tested?\r\n\r\nThere is a unittest script `test_arc_summary3.py` at https://gist.github.com/scotws/aaf5d9c9317081e249b664a371ec4907\r\nMost testing was done in-tree, comparing the output to that of the current `arc_summary.py` version.\r\n\r\nThe L2ARC section has **not seen any real-world use** because I do not have access to a L2ARC device on my machine.\r\n\r\n### Other \r\n\r\nSwitching to Python 3 results in a noticeably smaller file size despite the addition of several new features. Output of `wc` for both scripts:\r\n```\r\n    837    2586   28021 arc_summary3.py\r\n   1020    2593   35538 arc_summary.py\r\n```\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [ ] I have read the **CONTRIBUTING** document.\r\n- [x] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "Blub": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6865", "title": "user namespace bugfixes and features", "body": "This series can be seen as 4 separate \"chunks\":\r\n\r\nChunk 1: setgid mode bugfix & regression test:\r\n* Patch 1 fixes the main issue.\r\n* Patch 2 adds a helper for running user namespace tests. Currently uses a fixed\r\n  user id range. (I saw no reason for anything more complex than that.)\r\n* Patch 3 adds a regression test for the issue fixed in patch 1.\r\n\r\nChunk 2: mounting from user namespaces (RFC):\r\n* Patch 4 is an RFC useful for when a user can have a mount namespace (usually\r\n  in combination with user namespaces. Eg. giving `zfs allow`ing create+mount\r\n  permissions to a container.\r\n* Patch 5 is necessary when including the third chunk but is otherwise there\r\n  since it made writing the test case of patch 6 more convenient.\r\n* Patch 6 tests create+mount permissions with user namespaces.\r\n\r\nChunk 3: mapping user ids when using zfs allow from within user namespaces.\r\n* Patch 7 causes `ZFS_IOC_GET_FSACL` and `ZFS_IOC_SET_FSACL` to perform user id\r\n  mapping (as well as checking!) on the sent/received data. Otherwise root in a\r\n  user namespace would not be able to run `zfs allow` with the user IDs as seen\r\n  from within its namespace, but would have to perform the mapping to real IDs.\r\n  This is also what easily enables users to create allow entries for user IDs\r\n  which do not exist in the host namespace's `/etc/passwd` and therefore would\r\n  show up empty and indistinguishable to the host (making patch 5 a\r\n  requirement).\r\n\r\nChunk 4: change the 'unallow' check:\r\n* Patch 8 allows users who have CAP_SYS_ADMIN in the current namespace (iow.\r\n  root in containers) to remove permissions of others if they're also allowed\r\n  to add the permission.\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements. (at least according to `make checkstyle`)\r\n- [ ] I have updated the documentation accordingly. (not yet)\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [x] I have added tests to cover my changes.\r\n- [x] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ironMann": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6568", "title": "[wip][test] Prefetch dmu", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\nRun testers\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [ ] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [ ] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6107", "title": "LOCK tracking: disable tracking of ARC and dbuf hashmap locks (16384 mutexes)", "body": "Test for zfsonlinux/spl#587\r\n\r\nRequires-spl: refs/pull/587/head\r\n\r\n### Description\r\nDisable tracking of per-bucket locks.\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [ ] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "MEMBER"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "don-brady": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6558", "title": "OpenZFS 7431 - ZFS Channel Programs", "body": "Authored by: Chris Williamson <chris.williamson@delphix.com>\r\nReviewed by: Matthew Ahrens <mahrens@delphix.com>\r\nReviewed by: George Wilson <george.wilson@delphix.com>\r\nReviewed by: John Kennedy <john.kennedy@delphix.com>\r\nReviewed by: Dan Kimmel <dan.kimmel@delphix.com>\r\nApproved by: Garrett D'Amore <garrett@damore.org>\r\nPorted-by: Don Brady <don.brady@delphix.com>\r\nPorted-by: John Kennedy <john.kennedy@delphix.com>\r\n\r\nOpenZFS-issue: https://www.illumos.org/issues/7431\r\nOpenZFS-commit: https://github.com/openzfs/openzfs/commit/dfc11533\r\n\r\nPorting Notes:\r\n* The CLI long option arguments for '-t' and '-m' don't parse on linux\r\n* Switched from kmem_alloc to vmem_alloc in zcp_lua_alloc\r\n* Lua implementation is built as its own module (zlua.ko)\r\n* Lua headers consumed directly by zfs code moved to 'include/sys/lua/'\r\n* There is no native setjmp/longjump available in stock Linux kernel.  Brought over implementation from illumos and FreeBSD\r\n* The get_temporary_prop() was adapted due to VFS platform differences\r\n* Use of in-lining functions in lua parser code to reduce stack usage per nested C call\r\n\r\n### How Has This Been Tested?\r\n#### Manual tests\r\n- running basic get-props channel programs from CLI\r\n- exercised the zfs property get CLI with the envr *ZFS_PROP_DEBUG=1* set\r\n#### Automated tests\r\n- ztest runs that exercise the new ZCP destroy snapshots path\r\n- new ZTS channel_program functional tests\r\n\r\n### Types of changes\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [x] I have added tests to cover my changes.\r\n- [x] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "MEMBER"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "dong-liuliu": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6546", "title": "Use Multi-buffer sha256 support from SPL", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\nLet sha256 checksum using multi-buffer api if it is exported by SPL\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n Using multi-buffer type, performance of sha256 will be increased 2~7 times.\r\nNow a patch for multi-buffer sha256 facility in kernel space is implemented and submitted to SPL.\r\nIts userspace facility and sha512 parts will be following up after this patch is reviewed and commented.\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\nRun FIO sequential write test, on Intel Xeon server (Haswell E5-2699 v3, 18 core), with 6x SSD :\r\n\r\nSha256 | CPU-sys% | BW(MB/s)\r\n-- | -- | --\r\nmulti-buffer version | 27 | 1859\r\nicp version | 71 | 1876\r\n\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [x] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ahrens": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6536", "title": "diff and bookmark enhancements", "body": "\r\n<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\nThis PR includes 3 related features that work well together:\r\n\r\n`zfs diff -a` shows which specific blocks were modified\r\n\r\n`zfs diff` from a bookmark (but it can't show renamed files)\r\n\r\n`zfs bookmark` from a filesystem, creating a bookmark which represents current point in time.  Not useful for `zfs send`, but can be used with `zfs diff`.\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\nThis makes `zfs diff` useful in more situations.  For example, to find which blocks in a database or VDI file were changed.\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n\r\nManual testing only at this point.  I'd like to add test cases to the test suite, but there aren't any tests for \"zfs diff\" at all, so it seems strange to add tests for just the new functionality I'm adding.  I'm open to input on what should be required for this PR.\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [x] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ofaaland": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6479", "title": "Merge SPL into ZFS [WIP]", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\nMerge the SPL into ZFS to eliminate the extra work required when SPL code must change due to kernel or distro changes, and to simplify the build process.\r\n\r\nWork In Progress.\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [x] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [ ] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "Nasf-Fan": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6290", "title": "Project Quota on ZFS", "body": "Project quota is a new ZFS system space/object usage accounting\r\nand enforcement mechanism. Similar as user/group quota, project\r\nquota is another dimension of system quota. It bases on the new\r\nobject attribute - project ID.\r\n\r\nProject ID is a numerical value to indicate to which project an\r\nobject belongs. An object only can belong to one project though\r\nyou (the object owner or privileged user) can change the object\r\nproject ID that can be set/modified via 'chattr -p' explicitly,\r\nor inherited from its parent object when created if such parent\r\nhas the project inherit flag (via 'chattr +P').\r\n\r\nBy accounting the spaces/objects belong to the same project, we\r\ncan know how many spaces/objects used by the project. And if we\r\nset the upper limit then we can control the spaces/objects that\r\nare consumed by such project. It is useful when multiple groups\r\nand users cooperate for the same project, or when an user/group\r\nneeds to participate in multiple projects.\r\n\r\nSupport the following commands and functionalities:\r\n\r\nzfs set projectquota@project\r\nzfs set projectobjquota@project\r\n\r\nzfs get projectquota@project\r\nzfs get projectobjquota@project\r\nzfs get projectused@project\r\nzfs get projectobjused@project\r\n\r\nzfs projectspace\r\n\r\nzfs allow projectquota\r\nzfs allow projectobjquota\r\nzfs allow projectused\r\nzfs allow projectobjused\r\n\r\nzfs unallow projectquota\r\nzfs unallow projectobjquota\r\nzfs unallow projectused\r\nzfs unallow projectobjused\r\n\r\nchattr +/-P\r\nchattr -p project_id\r\nlsattr -p\r\n\r\nSigned-off-by: Fan Yong <fan.yong@intel.com>\r\nChange-Id: Ib4f0544602e03fb61fd46a849d7ba51a6005693c\r\n\r\n<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [x] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "tuxoko": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6277", "title": "[WIP] Add pool prop `partition` to disable auto partition", "body": "### Description\r\n\r\nzfsonlinux always partition disk when it detects the device given is a\r\nwhole disk. This legacy behavior from Illumos, however, has no apparent\r\nbenefit on Linux, but has some down sides besides confusion. E.g.\r\nautoexpand, switching to dm device requires partprobe.\r\n\r\nWe add a pool property `partition` to be set during pool create. It\r\ncurrently has two values, legacy and raw. When setting it to legacy, it\r\nwill behave as it did. When setiing it to raw, it will always use the\r\ndevice as is without partitioning even if it's a whole disk.\r\n\r\nThis property applies to all commands that add disks to pool, so zpool\r\nadd/attach/replace will partition or not partition based on the property\r\non the target pool.\r\n    \r\nA pool without this property will be treated as legacy. Newly created\r\npool will by default have partition=legacy.\r\n\r\nSigned-off-by: Chunwei Chen <david.chen@osnexus.com>\r\n\r\n### Note\r\n\r\nI use PROP_ONETIME for the property, but it seems that this is not enforced at all, so you can still modify it after the fact. But you shouldn't change it after the fact, as it would cause device name appending wrong.", "author_association": "MEMBER"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "inkdot7": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6078", "title": "Metadata classes wip no accounting", "body": "Please ignore this PR.\r\nI just want to see how the metadata allocation classes behave if the special accounting is removed.  (Which would allow the small-block-size limit to be changed after creation more easily.)\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "n1kl": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/5929", "title": "Quality of service for ZFS + improvement through compression", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\nAs part of my master thesis at University of Hamburg I have targeted to improve ZFS through compression. Now I would like to share my 3 feature branches with the community.\r\n\r\n1. lz4fast #5927 \r\n2. autocompression #5928 \r\n3. qos (current)\r\n### Description\r\n<!--- Describe your changes in detail -->\r\nThis patch adds quality of service to ZFS datasets.\r\nzfs set compression=qos-[10,20,30,40,50,+50*n,1000]\r\nThe chosen value sets the throughput in MB/s.\r\nLow values will result in better compression ratio but less throughput.\r\n\r\n### Motivation1\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\nQuality of service is an important aspect in dealing with limited resources.\r\nAt the moment the user can control storage requirement by choosing a compression algorithm like gzip for high compression. Depending on the hardware and the current CPU load the performance might be either poor or well.\r\nBy using the qos compression feature the desired write throughput can be chosen to meet the requirement for the application.\r\nThe qos algorithm keeps track of the compression speed and chooses either lz4 or gzip-[1-9] to speed up / slow down while compressing data. \r\n\r\n<!--- ### How Has This Been Tested? -->\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n### Benchmark1\r\n\r\nCopy file from Tempfs to ZFS into 1 Dataset:\r\n\r\nName | MB/s\t| Ratio\r\n ---   \t|  --- \t| ---\r\ngzip9\t| 11\t| 0.37\r\nqos10\t| 10\t| 0.38\r\nqos20\t| 22\t| 0.41\r\nqos30\t| 35\t| 0.45\r\nqos40\t| 45\t| 0.48\r\nqos50\t| 55\t| 0.50\r\nlz4\t| 71\t| 0.57\r\noff\t| 62\t| 1\r\n\r\n\r\n### Motivation2\r\n\r\nTransactiongroups in ZFS cause simultaneous writes into multiple datasets to wait for each other to complete. The slowest dataset is the limitation to the overall performance.\r\nThe qos feature can prevent this through dataset prioritisation.\r\nThe maximum bandwidth is limited by the disk throughput. Every dataset can request a part of this bandwidth by setting the qos property value.\r\nData can now be organised into low priority datasets with low quality of service requirements (but high compression, see Motivation1) and high priority to which also all non qos datasets belong.\r\nAll inheriting datasets and their parent share the same requested bandwidth. If the value of an inheriting dataset (lower hierarchy) is explicitly changed from \"inherit\" to \"qos\" then this dataset will request its own bandwidth.\r\n\r\n\r\n### Benchmark2\r\n\r\nCopy 2 files from Tempfs to ZFS into 2 Datasets:\r\n\r\nName     \t\t\t|MB/s\t|MB/s\t|Ratio\t|Ratio\t| Comment\r\n--- | --- | --- | --- | --- | ---\r\nqos10/qos10 - qos10/qos10_2\t|5\t|5\t|0.47\t|0.49\t|use of inheritance\r\nqos10 - qos10/qos10\t\t|5\t|5\t|0.49\t|0.47\t|use of inheritance\r\nqos10 - qos10_2\t\t\t|11\t|10\t|0.46\t|0.48\t| \r\nqos10/qos10 - qos10/qos10x\t|11\t|9\t|0.48\t|0.46\t|qos-10 explicit <br>set on qos10x\r\nqos10/qos20 - qos10\t\t|20\t|9\t|0.49\t|0.43\t| \r\nqos30 - qos10\t\t\t|29\t|9\t|0.52\t|0.40\t| \r\nqos40 - qos10\t\t\t|44\t|10\t|0.54\t|0.40\t| \r\nqos50 - qos10\t\t\t|51\t|9\t|0.53\t|0.40\t| \r\nlz4 - qos10\t\t\t|71\t|9\t|0.57\t|0.39\t| lz4 has high priority\r\noff - qos10\t\t\t|62\t|8\t|1\t|0.38\t| \r\ngzip9 - qos10\t\t\t|13\t|5\t|0.37\t|0.39\t| \r\nlz4 - gzip9\t\t\t|10\t|10\t|0.57\t|0.37\t|  lz4 waiting for gzip\r\n\r\n\r\n### Benchmark3\r\n\r\nCopy 2 files from Tempfs to ZFS into 1 Datasets:\r\n\r\nName     \t\t\t|MB/s\t|MB/s\t|Ratio\r\n--- | --- | --- | --- \r\nqos10 - qos10 |\t5\t|5|\t0,38\r\noff - off|\t22|\t22|\t1\r\nlz4 - lz4|\t30|\t27|\t0,57\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n\r\n#### Branch overlapping changes (feature, compress values)\r\nThe patch has read-only backward compatibility by using the new introduced SPA_FEATURE_COMPRESS_QOS feature. The feature activation procedure is equivalent to my other code branches.\r\nRegarding the limited namespace of BP_GET_COMPRESS() (128 values), the\r\nzio_compress enum's first part is for block pointer & dataset values, the second part for dataset values only. Or should I make use of a new property? This is an alternative suggestion to #3908.\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/5928", "title": "auto compression", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\nAs part of my master thesis at University of Hamburg I have targeted to improve ZFS through compression. Now I would like to share my 3 feature branches with the community.\r\n\r\n1. lz4fast #5927 \r\n2. autocompression (current)\r\n3. qos #5929 \r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\nThis patch adds auto as ZFS compression type.\r\nzfs set compression=auto\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\nWhich compression algorithm is best for high throughput? The answer to this depends on the type of hardware in use.\r\nIf compression takes long then the disk remains idle. If compression is faster than the writing speed of the disk then the CPU remains idle as compression and writing to the disk happens in parallel.\r\nAuto compression tries to keep both as busy as possible.\r\nThe disk load is observed through the vdev queue. If the queue is empty a fast compression algorithm like lz4 with low compression rates is used and if the queue is full then gzip-[1-9] can require more CPU time for higher compression rates.\r\nThe already existing zio_dva_throttle might conflict with the concept described above. Therefore it is recommended to deactivate zio_dva_throttle.\r\n\r\n<!--- ### How Has This Been Tested? -->\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n### Benchmark\r\n\r\nCopy file from Tempfs to ZFS\r\n\r\n\r\n8 Cores:\r\n\r\nName\t|Ratio\t|MB/s\r\n---\t|---\t|---\r\nauto\t|0.44  \t|245\r\ngzip-1\t|0.43  \t|255\r\nlz4\t|0.58  \t|195\r\noff\t|1 \t|99\r\n\r\n\r\n1 Core:\r\n\r\nName\t|Ratio\t|MB/s\r\n---\t|---\t|---\r\nauto\t|0.56 \t|151\r\ngzip-1\t|0.43\t|51\r\nlz4\t|0.58\t|179\r\noff\t|1\t|99\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n\r\n#### Branch overlapping changes (feature, compress values)\r\n\r\nThe patch is has read-only backward compatibility by using the new introduced SPA_FEATURE_COMPRESS_AUTO feature. The feature activation procedure is equivalent to my other code branches.\r\nRegarding the limited namespace of BP_GET_COMPRESS() (128 values), the\r\nzio_compress enum's first part is for block pointer & dataset values, the second part for dataset values only. This is an alternative suggestion to #3908.\r\n\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/5927", "title": "lz4fast compression", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\nAs part of my master thesis at University of Hamburg I have targeted to improve ZFS through compression. Now I would like to share my 3 feature branches with the community.\r\n\r\n1. lz4fast (current)\r\n2. autocompression #5928 \r\n3. qos #5929 \r\n\r\nThis patch updates the lz4 *1 code to version 1.7.3 to make use of lz4 fast compression.\r\nThe lz4 code is based on a seperate project for updating lz4 inside the linux kernel.\r\nThere a few changes were made for an clean implementation and to improve speed that are currently in review *2.\r\n\r\n*1: [https://github.com/lz4/lz4](https://github.com/lz4/lz4)\r\n*2: [https://patchwork.kernel.org/patch/9574745/](https://patchwork.kernel.org/patch/9574745/)\r\n\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\nLZ4-fast capability is now available.\r\nzfs set compression=lz4fast-[1-20,30,+10*n,100]\r\nHigher values result in improved compression speed and less ratio.\r\n\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\nLz4 fast trades in compression ratio for speed. This gives us more flexibility in environments with either low computational power or fast and many SSDs/HDDs where the lz4 is the limiting factor.\r\nAutocompression and qos can also be improved by adding lz4fast algorithms.\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\nChecksums were made to proof full compatibility between the old and new lz4 compressed files.\r\n\r\n#### Benchmark\r\n\r\nCopy file from Tempfs to ZFS (ZFS also in Tempfs for high disk throughput simulation).\r\n\r\n\r\nName         |Ratio   |MB/s\r\n---          |---     |---\r\nlz4          |0.58    |228\r\nlz4fast-2    |0.62    |249\r\nlz4fast-3    |0.65    |266\r\nlz4fast-4    |0.68    |282\r\nlz4fast-5    |0.71    |298\r\nlz4fast-7    |0.76    |329\r\nlz4fast-10   |0.80    |370\r\nlz4fast-20   |0.97    |469\r\nlz4fast-30   |0.98    |546\r\nlz4fast-50   |0.98    |634\r\nlz4fast-100  |0.99    |690\r\noff          |1       |744\r\n\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n\r\n#### Branch overlapping changes (feature, compress values)\r\n\r\nThe patch has read-only backward compatibility by using the new SPA_FEATURE_LZ4FAST_COMPRESS feature. The feature activation procedure is equivalent to my other code branches.\r\nRegarding the limited namespace of BP_GET_COMPRESS() (128 values), the\r\nzio_compress enum's first part is for block pointer & dataset values, the second part for dataset values only. Or should I make use of a new property? This is an alternative suggestion to #3908.\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ghost": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1276681", "body": "Has this issue been resolved? I'm having the same problem on OpenSolaris with ZFS. The zpool-rpool process is writing on average at 400MB/h on an idle system. I can't seem to find an answer anywhere on the net.\n\nThanks for your help.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1276681/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1277385", "body": "A quick DTrace on what the zpool-rpool process is doing reveals the following kernel function calls, accompanied by the number of times they have been called (the sampling lasted about a minute). Does this mean anything to you?\n\n``` DTrace\nrootnex`rootnex_coredma_allochdl          1\nrootnex`rootnex_dma_allochdl            1\nscsi`scsi_transport                     1\nzfs`buf_hash                            1\nzfs`arc_write_done                      1\nzfs`dbuf_find                           1\nzfs`dbuf_dirty                          1\nzfs`metaslab_ndf_alloc                  1\nzfs`spa_writeable                       1\nzfs`space_map_load                      1\nzfs`vdev_queue_deadline_compare          1\nzfs`vdev_queue_offset_compare           1\nzfs`vdev_queue_io                       1\nzfs`zio_buf_free                        1\nzfs`zio_remove_child                    1\nzfs`zio_destroy                         1\nzfs`zio_vdev_io_done                    1\nzfs`zrl_add                             1\nahci`ahci_check_ctl_handle              1\nsata`sata_scsi_start                    1\nsata`sata_txlt_write                    1\nsd`sdstrategy                           1\nsd`sd_core_iostart                      1\nsd`sd_initpkt_for_buf                   1\nsd`sd_start_cmds                        1\nunix`sep_save                           1\nunix`splr                               1\nunix`tsc_gethrtime                      1\nunix`tsc_scalehrtime                    1\nunix`bcopy                              1\nunix`gdt_update_usegd                   1\nunix`lock_set                           1\nunix`cmt_balance                        1\nunix`swtch                              1\nunix`disp_ratify                        1\nunix`default_lock_backoff               1\nunix`lock_set_spin                      1\ngenunix`avl_walk                        1\ngenunix`avl_rotation                    1\ngenunix`cv_broadcast                    1\ngenunix`ddi_fm_acc_err_get              1\ngenunix`disp_lock_enter                 1\ngenunix`thread_lock                     1\ngenunix`ldi_strategy                    1\ngenunix`copy_pattern                    1\ngenunix`kmem_zalloc                     1\ngenunix`list_create                     1\ngenunix`list_remove                     1\ngenunix`ddi_get_soft_state              1\ngenunix`restorectx                      1\nzfs`buf_hash_insert                     2\nzfs`dnode_diduse_space                  2\nzfs`zio_push_transform                  2\nzfs`zio_walk_parents                    2\nzfs`zio_done                            2\nzfs`zio_checksum_compute                2\nzfs`vdev_disk_io_start                  2\nsha2`SHA256TransformBlocks              2\nsd`sd_mapblockaddr_iostart              2\nsd`sd_add_buf_to_waitq                  2\nsd`ddi_xbuf_qstrategy                   2\nsd`xbuf_iostart                         2\nunix`rw_enter                           2\nunix`disp                               2\nunix`atomic_add_64_nv                   2\ngenunix`avl_remove                      2\ngenunix`avl_numnodes                    2\ngenunix`lbolt_event_driven              2\ngenunix`ddi_fm_dma_err_get              2\ngenunix`kmem_cache_free                 2\ngenunix`memcpy                          2\ngenunix`cpu_update_pct                  2\ngenunix`ndi_fmc_insert                  2\ngenunix`taskq_thread_wait               2\nzfs`arc_write_ready                     3\nzfs`metaslab_alloc_dva                  3\nzfs`vdev_accessible                     3\nzfs`zio_wait_for_children               3\nzfs`zio_notify_parent                   3\nzfs`zio_vdev_io_start                   3\nsd`sd_setup_rw_pkt                      3\nunix`mutex_owner_running                3\nunix`rw_exit                            3\nunix`mutex_vector_enter                 3\nunix`vsnprintf                          3\ngenunix`avl_last                        3\nzfs`space_map_remove                    4\nzfs`zio_execute                         4\nsd`sdinfo                               4\nunix`mutex_exit                         4\nzfs`metaslab_group_alloc                5\nzfs`vdev_queue_io_to_issue              5\nunix`bzero                              5\nunix`disp_getwork                       5\ngenunix`avl_insert                      5\nunix`0xfffffffffb85                     6\nunix`tsc_read                           6\ngenunix`kmem_cache_alloc                6\nunix`do_splx                            7\nzfs`space_map_seg_compare               9\nzfs`metaslab_segsize_compare           10\ngenunix`avl_find                       10\nunix`default_lock_delay                11\nzfs`fletcher_4_native                  12\nunix`mutex_enter                       16\nunix`mutex_delay_default               54\nzfs`lzjb_compress                     151\n```\n\nWe can see that the most called function is by far lzjb_compress. Again, DTrace reveals that all the kernel stacks that lead to lzjb_compress pass through the function zio_write_bp_init, which I assume is the guilty function behind all these writes...\n\nDoes this all mean anything to you?\n\nEdit:  kernel stacks\n\n``` DTrace\n              zfs`zio_compress_data+0x8e\n              zfs`zio_write_bp_init+0x216\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              genunix`taskq_thread+0x248\n              unix`thread_start+0x8\n                1\n\n              zfs`zio_compress_data+0x8e\n              zfs`zio_write_bp_init+0x216\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              genunix`taskq_thread+0x248\n              unix`thread_start+0x8\n                1\n\n              zfs`zio_compress_data+0x8e\n              zfs`zio_write_bp_init+0x216\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n                2\n\n              zfs`zio_compress_data+0x8e\n              zfs`zio_write_bp_init+0x216\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              genunix`taskq_thread+0x248\n              unix`thread_start+0x8\n                5\n\n              zfs`zio_compress_data+0x8e\n              zfs`zio_write_bp_init+0x216\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              genunix`taskq_thread+0x248\n              unix`thread_start+0x8\n                6\n\n              zfs`zio_compress_data+0x8e\n              zfs`zio_write_bp_init+0x216\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              genunix`taskq_thread+0x248\n              unix`thread_start+0x8\n               13\n\n              zfs`zio_compress_data+0x8e\n              zfs`zio_write_bp_init+0x216\n              zfs`zio_execute+0x8d\n              genunix`taskq_thread+0x248\n              unix`thread_start+0x8\n               31\n```\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1277385/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1281342", "body": "Here is a list processes which called the write system call on my system, accompanied by the filenames and the total number of bytes written to the files (sampled during one minute):\n\n```\ndtrace -n 'syscall::*write:entry {@[execname, fds[arg0].fi_pathname] = sum (arg2);}'\ndtrace: description 'syscall::*write:entry ' matched 2 probes\n^C\n\n  dtrace                                              /dev/pts/1                                                        1\n  sshd                                                /devices/pseudo/clone@0:ptm                                       1\n  sshd                                                <unknown>                                                        52\n  rsfcli                                              <unknown>                                                       105\n  basename                                            <unknown>                                                       164\n  hostname                                            <unknown>                                                       304\n  syslogd                                             /devices/pseudo/sysmsg@0:sysmsg                                 320\n  awk                                                 <unknown>                                                       331\n  zfs                                                 /devices/pseudo/mm@0:null                                       370\n  java                                                /var/opt/nest/config/site/scheduledjobs/emailnotifications/Notification_ERROR.xml              433\n  java                                                /var/opt/nest/config/site/scheduledjobs/emailnotifications/Notification_WARNING.xml              437\n  java                                                /var/opt/nest/config/site/scheduledjobs/configurationreplications/SiteConfigReplication.xml              511\n  grep                                                <unknown>                                                       725\n  cron                                                /var/cron/log                                                   976\n  java                                                /var/opt/nest/config/site/scheduledjobs/snapshots/Snapshot2290924711711069275.xml             1014\n  java                                                /var/opt/nest/config/site/scheduledjobs/snapshots/Snapshot12337134254217831034.xml             1020\n  java                                                /var/opt/nest/config/site/scheduledjobs/snapshots/Snapshot17476938304947820872.xml             1020\n  java                                                /var/opt/nest/config/site/scheduledjobs/asyncreplications/AsyncReplication13100962750907134551.xml             1056\n  java                                                /var/opt/nest/config/site/scheduledjobs/asyncreplications/AsyncReplication13881922923541859328.xml             1056\n  ksh                                                 <unknown>                                                      1096\n  fcinfo                                              <unknown>                                                      1152\n  zpool                                               <unknown>                                                      1452\n  ksh                                                 /tmp/sf0l.2ol                                                  1650\n  ksh                                                 /tmp/sf0p.gnd                                                  1650\n  ksh                                                 /tmp/sf10.jmu                                                  1650\n  ksh                                                 /tmp/sf1g.3nv                                                  1650\n  ksh                                                 /tmp/sf1i.jvb                                                  1650\n  ksh                                                 /tmp/sf24.5eq                                                  1650\n  ksh                                                 /tmp/sf2f.jop                                                  1650\n  ksh                                                 /tmp/sf3b.beh                                                  1650\n  ksh                                                 /tmp/sf10.ujs                                                  3000\n  ksh                                                 /tmp/sf19.9c4                                                  3000\n  ksh                                                 /tmp/sf2a.o3i                                                  3000\n  ksh                                                 /tmp/sf2p.8d0                                                  3000\n  ksh                                                 /tmp/sf3k.j08                                                  3000\n  svcprop                                             <unknown>                                                      3140\n  format                                              <unknown>                                                      3644\n  sed                                                 <unknown>                                                      3704\n  fmd                                                 /var/fm/fmd/infolog_hival                                      4480\n  nscd                                                <unknown>                                                      5268\n  zfs                                                 <unknown>                                                      5778\n  init                                                /etc/svc/volatile/init-next.state                              9064\n  iostat                                              <unknown>                                                      9102\n  svccfg                                              <unknown>                                                      9801\n  fmtopo                                              <unknown>                                                    429332\n```\n\nIn contrast, for the same duration, here is the list of actual disk writes that were initiated, again accompanied by the filenames and number of bytes.\n\n```\ndtrace -n 'io:::start /args[0]->b_flags & B_WRITE/ {@[execname, args[2]->fi_pathname]=sum(args[0]->b_bcount);}'\ndtrace: description 'io:::start ' matched 6 probes\n^C\n\n  sched                                               /var/opt/nest/config/site/scheduledjobs/configurationreplications/SiteConfigReplication.xml             4096\n  sched                                               /var/opt/nest/config/site/scheduledjobs/emailnotifications/Notification_ERROR.xml             4096\n  sched                                               /var/opt/nest/config/site/scheduledjobs/emailnotifications/Notification_WARNING.xml             4096\n  sched                                               /var/opt/nest/config/site/scheduledjobs/asyncreplications/AsyncReplication13100962750907134551.xml             8192\n  sched                                               /var/opt/nest/config/site/scheduledjobs/asyncreplications/AsyncReplication13881922923541859328.xml             8192\n  sched                                               /var/opt/nest/config/site/scheduledjobs/snapshots/Snapshot12337134254217831034.xml             8192\n  sched                                               /var/opt/nest/config/site/scheduledjobs/snapshots/Snapshot17476938304947820872.xml             8192\n  sched                                               /var/opt/nest/config/site/scheduledjobs/snapshots/Snapshot2290924711711069275.xml             8192\n  zpool-rpool                                         <none>                                                     10463232\n```\n\nThe total number of bytes written to the disk by zpool-rpool alone is much higher than the total of bytes for which the write system call was used. Doesn't that mean that zpool-rpool is acting on its own?\n\nEdit: The two dtrace commands were run in parallel.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1281342/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1283961", "body": "Hmmm it's too bad there isn't a moderately easy way of knowing where all this I/O activity comes from. I tried disabling fmtopo (which is the biggest write-system-call writer) and still, zpool-rpool's io activity didn't seem to lower as significantly as it should have.\n\nAnyway, thanks for your input. I'll post if I find a solution to this on my side.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1283961/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/7731553", "body": "hmm. why not to do it in that way: let O_DIRECT always return true? does it metter that ZFS copies everything in to the ARC cache? let fake a bit an OS. It shouldn't hurt so much.... oh, and that is just my freak idea\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/7731553/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1873708", "body": "Hi - Not sure what's going on here as I don't know much regarding the programming/debugging of zfs but I seems to experience that issue, that is with or without rsync. I never had to read much files on my system as I use zfs for backups storage, however I just had to restore things from the zfs pool and it crashed after a while.. rebooted.. crashed after a while..\n\nHere is the error I found in dmesg/syslog : http://pastebin.com/jMTCNEFy\n\nIf there is anything I can do to help, as far as testings, don't hesitate to let me know.\n\nThanks,\n\nedit: using git from 2011-08-22 on debian squeeze\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1873708/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/2064709", "body": "Alphalead : I think your trick allowed my rsync session to last longer but after a while it crashed again unfortunately\n\nMessage from syslogd@stor01 at Sep 11 12:18:11 ...\n kernel:[1714241.981661] Oops: 0002 [#1] SMP\n\nMessage from syslogd@stor01 at Sep 11 12:18:11 ...\n kernel:[1714241.981673] last sysfs file: /sys/module/mbcache/initstate\n\nMessage from syslogd@stor01 at Sep 11 12:18:11 ...\n kernel:[1714241.982056] Stack:\n\nMessage from syslogd@stor01 at Sep 11 12:18:11 ...\n kernel:[1714241.982133] Call Trace:\n\nMessage from syslogd@stor01 at Sep 11 12:18:11 ...\n kernel:[1714241.982206] Code: 49 8b 14 04 48 c1 e2 03 e8 83 88 ff ff 85 c0 75 10 48 8d 54 24 70 48 89 de 44 89 ef e8 5b f3 ff ff 48 8b 54 24 50 be d0 00 00 00 <48> c7 02 00 00 00 00 48 8b 54 24 48 48 8b 7c 24 70 e8 7d f6 ff\n\nMessage from syslogd@stor01 at Sep 11 12:18:11 ...\n kernel:[1714241.982346] CR2: 0000000000000000\n\nedit: version used is latest commit (2708f716c0)\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/2064709/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/2006354", "body": "I can confirm that his bug does **not exist** in zfs-fuse for linux. \n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/2006354/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/2352510", "body": "Gunnar Beutner was able to come up with a patch for this. I tested it on my development device and so far it works exactly as intended. We're doing some more testing later this week; at this point I would consider this ready for official evaluation so that it can be committed and this bug closed. I will post back here if we encounter any problems while we are testing this patch.\n\nhttps://gunnar-beutner.de/files/0001-Fixed-invalid-resource-re-use-in-file_find.patch\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/2352510/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/2811567", "body": "zfs-fuse:\n\n<pre>\ndd if=/dev/zero of=/tank/xxx/test.io bs=1024k count=1000\n1000+0 records in\n1000+0 records out\n1048576000 bytes (1.0 GB) copied, 8.48609 s, 124 MB/s\n</pre>\n\nubuntu-zfs:\n\n<pre>\ndd if=/dev/zero of=/tank/xxx/test.io bs=1024k count=1000\n1000+0 records in\n1000+0 records out\n1048576000 bytes (1.0 GB) copied, 114.533 s, 9.2 MB/s\n</pre>\n\nOk, i try recreate pool under ubuntu-zfs\n\n<pre>\n# zpool offline tank sdc\n# zpool detach tank sdc\n# zpool create -f test sdc\n# zpool status test\n  pool: test\n state: ONLINE\n scan: none requested\nconfig:\n\n        NAME        STATE     READ WRITE CKSUM\n        test        ONLINE       0     0     0\n          sdc       ONLINE       0     0     0\n\nerrors: No known data errors\n# zfs create test/xxx\n# dd if=/dev/zero of=/test/xxx/test.io bs=1024k count=1000\n1000+0 records in\n1000+0 records out\n1048576000 bytes (1.0 GB) copied, 53.5897 s, 19.6 MB/s\n</pre>\n\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/2811567/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/3299069", "body": "behlendorf, probably, i had bad results because i was try to use 32 bit OS.\nFresh install ferdora 16 32 bit was the same, but zfs on fedora 16 (x64) shows performance near to raw device.\nThanks.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/3299069/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/11986018", "body": "Please fix this, a year later it is still not working. Rudd-O has an open pull request, can it be pulled into te main branche?\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/11986018/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/3399837", "body": "Pretty much this is how I went about setting up everything.\n\nMy platform is Ubuntu 10.04.3 x86 (also used x64) running as a VMware VM on my laptop (as test).\n\nI downloaded the source and compiled as per the instructions on the ZFS on linux website.\n\nThen I compiled the Linux iSCSI target core backports from linux-iscsi.org. I also compiled the lio-utils and targetcli (the management tools).\n\nAfter I installed the deb packages of everything (iscsi target and ZFS) I created my zpool called (tank) and my zfs vol (fish). Because it was a test I just used the names from the website because it did not matter.\n\nThe command I use were the following;\n\nparted /dev/sdb\nmklabel gpt\nquit\n\nparted /dev/sdc\nmklabel gpt\nquit\n\nzpool create tank mirror /dev/sdb /dev/sdc\n\nzfs create tank/fish -V 18G\n\nAfter that was done I dropped into the targetcli tool and tried to add a block device to the /backstores/iblock section. The targetcli emulates a file system, kind of reminds me of /proc or /sys. When I execute the command \"create disk0 /dev/zd0\" it returns and error to me saying the chosen device is not a valid \"TYPE_DISK\". I am not sure though if \"TYPE_DISK\" is something internal to the target or if it is a Linux thing.\n\nThe only way I could use ZFS with the target was to format the ZFS vol with something like ext4 and then create an image file with dd then use the file_io feature of the target. But the is not only complicated but completely undermines the entire point of using ZFS.\n\nWhen I mentioned that the ZFS vols have no vendor information I was referring to what I see when I run \"parted -l\" and look at /dev/zd0. When compared to the VMware disks there is information about who made the disk or anything, not even faked information just to fill the space. I will add an output when I have a chance.\n\nIf you need anymore info let me know.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/3399837/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/3442037", "body": "I get the code from there git repo. git://risingtidesystems.com/\n\nThe only slightly annoying thing is you have to build several packages before you can build the targetcli tool.\n\nBut everything you need is there.\n\nYou need to build the tools in an similar order to this;\n1. lio-utils\n2. configshell\n3. rtslib\n4. targetcli\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/3442037/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/3707762", "body": "I have small update to announce based on my reported issue, I may have a source of the problem.\n\nI believe the error \"Not TYPE_DISK\" is a problem with the iSCSI target drivers and may have nothing to do with ZFS.\n\nThe reason for the error I hypothoize is because ZFS is not listing it ZVOLs in /dev/disk which is most likely where the iSCSI target is look for them and that would sort of explain the error, because it is say that the ZVOL is not a type of device found is /dev/disk. \n\nSo unless something changes with the iSCSI target drivers before the \"final\" release with kernel v3.4 then ZFS just may have sit out on that one.\n\nI will \"try\" to report the issue to the devs of the iSCSI target but I have not heard anything since before Christmas when I last attempted.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/3707762/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/5439790", "body": "Experiencing the same issues with 2.6.32-41 on 10.04 (AMD X2-555 proc in an ASUS M4A88T MB, 16GB ecc).  No apparent problems with 2.6.32-40.  Sorry for lack of trace info, may have time this weekend.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/5439790/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/5441206", "body": "Correction, 12GB.  Might as well mention this:\nJust did a quick check and BIOS version was latest but release date appeared inconsistent.  So updated BIOS anyway, disabled legacy USB, and booted 2x4GB with just channel A (matched pair).  Checked dmesg and errata message is still there.   There's a sleeping zfs mount -a process (configured automount) and any zpool/zfs commands in a shell hang.  FWIW.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/5441206/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/7986088", "body": "I've installed Fedora 17 to a test System with ZFS due to @Rudd-O  \n+1 to this\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/7986088/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/20962527", "body": "Allow me to shed some light on this.\n\nLet's consider an old-school nfs4 export using a native Linux filesystem, one share called 'pmr':\n\n``` /etc/fstab\n/dev/groups/pmr /storage/pmr      xfs    inode64,logdev=/dev/ssdcache/pmr,logbufs=8  1 2\n/storage/pmr    /exports/pmr      none   rw,bind         0 0\n```\n\n``` /etc/exports\n/exports     [nfs4 export root settings]\n/exports/pmr [per-share settings]\n```\n\nWhen the system is booting, the xfs filesystem will be mounted first, followed by a bind mount from /storage/pmr to /exports/pmr. The latter then is exported via /etc/exports using nfs4 and we're all happy.\n\nNow consider a zfs-based scenario.\n\nSince there are no zfs entries in fstab, it becomes:\n\n``` /etc/fstab\n/storage/pmr    /exports/pmr      none   rw,bind         0 0\n```\n\nWhen the system boots, a bind-type mount will be created from /storage/pmr to /exports/pmr which is effectively mounting the underlying filesystem (most likely / ) to the bind point and exporting that. The clients will see the contents of an empty directory as the exporter uses the / bind mount. On the server, the confused administrator will see the actual zfs and will scratch their head.\n\nI don't think this is a bug in zfs rather a race condition between the distribution's native localfs init script and zfs. Perhaps localfs should depend on zfs and not the other way around.\n\nAlternatively, the zfs service should parse some file that will tell it how the binds go and bind after mounting the zfs filesystem. Perhaps a file in /etc/zfs/ like 'binds' would work.\n\nPersonally (sysadmin cap on) /etc/zfs/binds would work for me (together with a bit of parsing in /etc/init.d/zfs) as it's sufficiently low-tech and doesn't require changes in the actual zfs stack.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/20962527/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/20965023", "body": "Proposed patch (only lsb script, others are most likely derivative):\n\n``` patch\n--- etc/init.d/zfs.lsb.in.orig  2013-07-15 12:47:20.055257882 +0100\n+++ etc/init.d/zfs.lsb.in       2013-07-15 12:49:44.732137370 +0100\n@@ -29,6 +29,7 @@\n ZFS=\"@sbindir@/zfs\"\n ZPOOL=\"@sbindir@/zpool\"\n ZPOOL_CACHE=\"@sysconfdir@/zfs/zpool.cache\"\n+ZFS_NFS4_BINDS=\"@sysconfdir@/zfs/binds\"\n\n # Source zfs configuration.\n [ -r '/etc/default/zfs' ] &&  . /etc/default/zfs\n@@ -78,6 +79,26 @@\n                log_end_msg $?\n        fi\n\n+        # Create (optional) binds to the NFS4 export tree\n+        if [ -e \"$ZFS_NFS4_BINDS\" ] ; then\n+                log_begin_msg \"Binding NFS4 mounts\"\n+                sed -e \"s/#.*//\" -e \"/^$/d\" $ZFS_NFS4_BINDS | while read LINE\n+                do\n+                        MODE=\"`echo $LINE | awk '{print $1}'`\"\n+                        SRC=\"`echo $LINE | awk '{print $2}'`\"\n+                        DEST=\"`echo $LINE | awk '{print $3}'`\"\n+                        case $MODE in\n+                                bind)   MOUNTPOINT=\"`zfs get mountpoint $SRC | grep \"$SRC\" | awk '{print $3}'`\"\n+                                        mount -o $MODE $MOUNTPOINT $DEST\n+                                        log_end_msg $?\n+                                        ;;\n+                                *)      echo \"Unknown bind mode ($MODE) in $ZFS_NFS4_BINDS. Aborting.\"\n+                                        exit 4\n+                                        ;;\n+                        esac\n+                done\n+        fi\n+\n        touch \"$LOCKFILE\"\n }\n\n@@ -85,6 +106,25 @@\n {\n        [ ! -f \"$LOCKFILE\" ] && return 3\n\n+       if [ -e \"$ZFS_NFS4_BINDS\" ] ; then\n+                log_begin_msg \"Detaching NFS4 binds\"\n+                sed -e \"s/#.*//\" -e \"/^$/d\" $ZFS_NFS4_BINDS | while read LINE\n+                do\n+                        MODE=\"`echo $LINE | awk '{print $1}'`\"\n+                        SRC=\"`echo $LINE | awk '{print $2}'`\"\n+                        DEST=\"`echo $LINE | awk '{print $3}'`\"\n+                        case $MODE in\n+                                bind)   MOUNTPOINT=\"`zfs get mountpoint $SRC | grep \"$SRC\" | awk '{print $3}'`\"\n+                                        umount $DEST\n+                                        log_end_msg $?\n+                                        ;;\n+                                *)      echo \"Unknown bind mode ($MODE) in $ZFS_NFS4_BINDS. Aborting.\"\n+                                        exit 4\n+                                        ;;\n+                        esac\n+                done\n+        fi\n+\n        log_begin_msg \"Unmounting ZFS filesystems\"\n        \"$ZFS\" umount -a\n        log_end_msg $?\n```\n\n$MODE may look redundant but perhaps could be kept for future expansion, maybe there could be other bind types.\n\nThe /etc/zfs/binds file would look like this:\n\n``` /etc/zfs/binds\n#    zpool[/dataset]        mountpoint\nbind storage/pmr            /exports/pmr\n```\n\nOf course the distribution source would only contain the first line. I believe this is consistent with other files in /etc/zfs.\n\nCheers,\ngrok\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/20965023/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/45432317", "body": "@FransUrbo `/etc/rc.local` does not exist and is not called in all distributions. Even more, `systemd` based distributions (good luck finding one without it these days) won't have it by definition.\n\nAre you suggesting that instead of editing a config file (present, documented) you would rather ask everyone to roll their own code, manually create bind mounts? That doesn't sound like a sane systems management practice.\n\nWhen ZoL filesystem needs to be exported over NFS4, a bind mount must be created. No standard mechanism in GNU/Linux will allow for it if the filesystem is not present in `/etc/fstab`. Since it's ZFS that's 'special', I will argue that it is its own responsibility to provide the functionality required for other parts of the system to continue to function.\n\nIf you don't like my solution, that's fine, please provide a better one or show where exactly am I incorrect. Saying something is 'hackish' and then suggesting that sysadmins 'sort it out in rc.local' isn't constructive.\n\nRegards,\njz\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/45432317/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/45433327", "body": "@FransUrbo \n\nWhat use is a filesystem that cannot be exported over network?\n\nNFS4 exports are different from NFS3 exports. There is a certain, established standard of creating them in GNU/Linux, there exists a well documented process that is different from Solaris-isms still present in ZoL.\n\nI wasn't aware `zfs set sharenfs=on` is able to produce NFS4 mounts. Could you please quote options required to make that happen? How do you define the mount tree? This is different from NFS3.\n\nWhat bugs in other software are you referring to? Exporting NFS4 works perfectly fine in GNU/Linux. Since ZoL provides PV, VG and LV management as well as filesystem mount points in a way that is abstracted from the current device paradigm on Linux, certain steps need to be taken to make those two work together.\n\nWhile you are free to disagree, I still haven't seen a patch that solves the problem. GNU/Linux nfs-kernel-server (and this is ZFS on _Linux_) requires mount points bound into a central exports tree. Since binding is done early (and you can't make the `zfs` init script depend on `$localfs`) ZoL needs to catch up. \n\nNFS4 provides capabilities like idmapd (how would you propose to integrate `zfs set sharenfs` with starting `idmapd`, are there hooks for that? How do I call them?), caching, subtree checks, consistent filesystem IDs and performance improvements over NFS3.\n\nThe logical way to do it (and I have consulted this with a number of Linux Sysadmins before presenting it here) is for the init script to have a mechanism to create the required bound mounts to the exports tree. The section in the init script is self-contained, fails safe (no action if the config file isn't present) and does introduce required compatibility with the host operating system. In one file that is owned by the ZFS package.\n\nIf you continue to disagree, please produce a patch that solves the issue for NFS4 and ZoL or provide a way of exporting NFS4, including all the required export options like the following excerpt from a production environment:\n\n``` /etc/exports\n/exports     172.5.125.0/24(ro,async,wdelay,insecure,root_squash,no_subtree_check,fsid=0)\n/exports     172.5.124.0/25(ro,async,wdelay,insecure,root_squash,no_subtree_check,fsid=0)\n/exports/pmr 172.5.125.0/24(rw,async,wdelay,root_squash,no_subtree_check)\n/exports/pmr 172.5.124.0/25(rw,sync,wdelay,no_root_squash,no_subtree_check)\n```\n\nPlease understand, `rc.local` is the last resort, it isn't available on all distributions, some don't even have an equivalent script and requiring systems administrators to manually do those steps is error-prone. Perhaps one can do it on their home computer but hardly in an enterprise environment where consistency and sustainability is key.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/45433327/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/45434151", "body": "@FransUrbo \n\nThe issue #1029 you referred me to is highlighting the problem I've solved; no way to correctly set up NFS4 shares using Solaris-isms under Linux.\n\n> > Could you please quote options required to make that happen?\n> \n> I did. You need to slow down and read what's given to you.\n\nUnless you meant the four dots at the end of `zfs set sharenfs=on`, I must have missed it.\n\nI'm not going to continue this conversation with you as it's no longer productive.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/45434151/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/73043264", "body": ":+1: \n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/73043264/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/10101505", "body": "oh, how embarrassing.. adding autogen.sh to my weekly routine. Thanks!\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/10101505/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/13097318", "body": "Hey, so while apt-get update automatically chooses 3.6.0-23-virtual for the chroot , I should rather install 3.6.0-29-generic which is the same as the hosts?  Gotcha.\nJust worth noting that i've followed the HOW TO step-by-step and that a virtual kernel (different from the hosts) gets installed by default when installing ubuntu-minimal in a chroot environment.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/13097318/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/13114557", "body": "Thanks for the replies, No objections behlendorf. \nCheers\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/13114557/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/17124603", "body": "http://zfsonlinux.org/faq.html#WhyShouldIUseA64BitSystem\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/17124603/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/39197997", "body": "Some testing on SLES11 SP3 (obs build instance):\n\nThe `path_lookup()` is also triggered on SLES' 3.0.101 kernel so it looks like a proper autoconf check is required.\n\n@Milan-Benes:\n\nSince `spl_kern_path_parent` macro can expand to either `path_lookup(path, LOOKUP_PARENT, nd)`, `kern_path_parent_fn(path, nd)` or `kern_path_parent(path, nd)`, a _quick and very, very dirty_ fix would be to manually patch and build if you're desperate for the functionality. \n\nNote that the `kern_` functions use 2 arguments and not 3 so (I'm going to hell for this!) the middle one needs to go.\n\nSo after applying https://github.com/zfsonlinux/zfs/pull/1655 to 0.6.2 you can try something like this:\n\n``` patch\n--- module/zfs/zfs_ctldir.c.orig        2014-04-01 12:48:37.756605773 +0100\n+++ module/zfs/zfs_ctldir.c     2014-04-01 12:50:58.674195921 +0100\n@@ -997,8 +997,8 @@\n                goto out_path_buff;\n        }\n\n-       error = path_lookup(path_buff, LOOKUP_FOLLOW | LOOKUP_DIRECTORY, &nd);\n-       if (!error)\n+       error = kern_path_parent(path_buff, &nd);\n+       if (!error)\n                path_put(&nd.path);\n\n out_path_buff:\n```\n\nIt builds but **be warned**, may eat your gerbil.\n\n**Edit:** \n\n```\nZFS: snapshot home/tank@auto_daily-2014-03-27-1600 auto mounted at /home/tank/.zfs/snapshot/auto_daily-2014-03-27-1600 unexpectedly unmounted\n```\n\nAnd a nice NULL pointer:\n\n```\nApr  1 13:32:24 hematus kernel: [   83.305579] ZFS: snapshot home/tank@auto_daily-2014-03-27-1600 auto mounted at /home/tank/.zfs/snapshot/auto_daily-2014-03-27-1600 unexpectedly unmounted\nApr  1 13:35:00 hematus kernel: [  239.301971] BUG: unable to handle kernel NULL pointer dereference at 0000000000000020\nApr  1 13:35:00 hematus kernel: [  239.301978] IP: [<ffffffffa065e3a6>] zfsctl_lookup_snapshot_path+0x1a6/0x2c0 [zfs]\nApr  1 13:35:00 hematus kernel: [  239.302022] PGD 0\nApr  1 13:35:00 hematus kernel: [  239.302024] Oops: 0000 [#1] SMP\nApr  1 13:35:00 hematus kernel: [  239.302027] CPU 10\nApr  1 13:35:00 hematus kernel: [  239.302028] Modules linked in: md5 nfsd autofs4 binfmt_misc edd nfs lockd fscache auth_rpcgss nfs_acl sunrpc mpt3sas mpt2sas scsi_transport_sas raid_class mptctl mptbase bonding mperf microcode ext3 jbd mbcache loop flashcache(FN) pciehp zfs(PFN) zcommon(PFN) znvpair(PFN) zavl(PFN) zunicode(PFN) spl(FN) ipv6 ipv6_lib zlib_deflate ixgbe joydev usbhid hid igb usb_storage dca ptp dcdbas(X) pcspkr shpchp pci_hotplug sr_mod mei ses iTCO_wdt cdrom enclosure iTCO_vendor_support button wmi acpi_power_meter rtc_cmos pps_core acpi_pad sg mdio xfs dm_mirror dm_region_hash dm_log linear ehci_hcd usbcore usb_common sd_mod crc_t10dif processor thermal_sys hwmon scsi_dh_rdac scsi_dh_hp_sw scsi_dh_emc scsi_dh_alua scsi_dh dm_snapshot dm_mod ahci libahci libata megaraid_sas scsi_mod\nApr  1 13:35:00 hematus kernel: [  239.302072] Supported: No, Proprietary and Unsupported modules are loaded\nApr  1 13:35:00 hematus kernel: [  239.302074]\nApr  1 13:35:00 hematus kernel: [  239.302076] Pid: 7433, comm: nfsd Tainted: PF          NX 3.0.101-0.15-default #1 Dell Inc. PowerEdge R720/0X3D66\nApr  1 13:35:00 hematus kernel: [  239.302080] RIP: 0010:[<ffffffffa065e3a6>]  [<ffffffffa065e3a6>] zfsctl_lookup_snapshot_path+0x1a6/0x2c0 [zfs]\nApr  1 13:35:00 hematus kernel: [  239.302099] RSP: 0018:ffff8817dbee99e0  EFLAGS: 00010246\nApr  1 13:35:00 hematus kernel: [  239.302100] RAX: 0000000000000000 RBX: ffff8817f116c000 RCX: 0000000000000020\nApr  1 13:35:00 hematus kernel: [  239.302102] RDX: ffff8817f116e4c8 RSI: 0000000000001000 RDI: ffff8817dbee9ab0\nApr  1 13:35:00 hematus kernel: [  239.302104] RBP: 0000000000000da2 R08: e848000000000000 R09: 1200000000000000\nApr  1 13:35:00 hematus kernel: [  239.302106] R10: 0000000000000000 R11: ffffffff8120f630 R12: ffff8817dbee9b60\nApr  1 13:35:00 hematus kernel: [  239.302108] R13: ffff8817f116e4c8 R14: ffff8817f116c000 R15: 0000000000000006\nApr  1 13:35:00 hematus kernel: [  239.302110] FS:  0000000000000000(0000) GS:ffff88187faa0000(0000) knlGS:0000000000000000\nApr  1 13:35:00 hematus kernel: [  239.302112] CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b\nApr  1 13:35:00 hematus kernel: [  239.302114] CR2: 0000000000000020 CR3: 0000000001a09000 CR4: 00000000001407e0\nApr  1 13:35:00 hematus kernel: [  239.302116] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000\nApr  1 13:35:00 hematus kernel: [  239.302118] DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400\nApr  1 13:35:00 hematus kernel: [  239.302120] Process nfsd (pid: 7433, threadinfo ffff8817dbee8000, task ffff8817dbee6380)\nApr  1 13:35:00 hematus kernel: [  239.302122] Stack:\nApr  1 13:35:00 hematus kernel: [  239.302123]  0000000000011800 ffff8817dbee9c44 ffff88187f429a00 0000000000000da2\nApr  1 13:35:00 hematus kernel: [  239.302129]  ffff8817dbee9bd8 0000000000000004 0000000000000004 00000000000000a8\nApr  1 13:35:00 hematus kernel: [  239.302133]  00000000000000a8 ffffffff81145a8e ffff8817f420d400 ffff8817f1656800\nApr  1 13:35:00 hematus kernel: [  239.302137] Call Trace:\nApr  1 13:35:00 hematus kernel: [  239.302221]  [<ffffffffa065e52b>] zfsctl_lookup_objset+0x6b/0x90 [zfs]\nApr  1 13:35:00 hematus kernel: [  239.302284]  [<ffffffffa0672241>] zfs_vget+0xf1/0x350 [zfs]\nApr  1 13:35:00 hematus kernel: [  239.302356]  [<ffffffffa068edf1>] zpl_fh_to_dentry+0x41/0x60 [zfs]\nApr  1 13:35:00 hematus kernel: [  239.302420]  [<ffffffff811d69df>] exportfs_decode_fh+0x6f/0x290\nApr  1 13:35:00 hematus kernel: [  239.302429]  [<ffffffffa086198d>] nfsd_set_fh_dentry+0x17d/0x380 [nfsd]\nApr  1 13:35:00 hematus kernel: [  239.302440]  [<ffffffffa0861d6b>] fh_verify+0x1db/0x2b0 [nfsd]\nApr  1 13:35:00 hematus kernel: [  239.302448]  [<ffffffffa0870b41>] nfsd4_proc_compound+0x341/0x520 [nfsd]\nApr  1 13:35:00 hematus kernel: [  239.302463]  [<ffffffffa085e381>] nfsd_dispatch+0xb1/0x250 [nfsd]\nApr  1 13:35:00 hematus kernel: [  239.302474]  [<ffffffffa07826a3>] svc_process_common+0x333/0x620 [sunrpc]\nApr  1 13:35:00 hematus kernel: [  239.302488]  [<ffffffffa0782ce1>] svc_process+0x101/0x160 [sunrpc]\nApr  1 13:35:00 hematus kernel: [  239.302500]  [<ffffffffa085eb3d>] nfsd+0xcd/0x150 [nfsd]\nApr  1 13:35:00 hematus kernel: [  239.302505]  [<ffffffff81082966>] kthread+0x96/0xa0\nApr  1 13:35:00 hematus kernel: [  239.302511]  [<ffffffff81469ee4>] kernel_thread_helper+0x4/0x10\nApr  1 13:35:00 hematus kernel: [  239.302514] Code: 00 00 00 00 00 48 8b 87 c8 34 00 00 4c 8d af c8 24 00 00 48 8d bc 24 d0 00 00 00 be 00 10 00 00 4c 89 ea 48 89 84 24 d0 00 00 00\nApr  1 13:35:00 hematus kernel: <48>[  239.302527]  8b 40 20 48 89 84 24 d8 00 00 00 e8 49 fd ff ff 85 c0 0f 84\nApr  1 13:35:00 hematus kernel: [  239.302533] RIP  [<ffffffffa065e3a6>] zfsctl_lookup_snapshot_path+0x1a6/0x2c0 [zfs]\nApr  1 13:35:00 hematus kernel: [  239.302551]  RSP <ffff8817dbee99e0>\nApr  1 13:35:00 hematus kernel: [  239.302552] CR2: 0000000000000020\nApr  1 13:35:00 hematus kernel: [  239.302554] ---[ end trace c16be50e3596fc64 ]---\n```\n\nSo yeah, doesn't work just yet.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/39197997/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/39320535", "body": "@andrey-ve \n\nI grepped `/usr/src/linux/include` on a current SLES11 SP3 (and do bear in mind SuSE patches their kernels heavily so the 3.0.101 has interfaces probably similar to 3.6 vanilla) shows no 'HAVE_MOUNT_*' strings.\n\nThe only thing in the region of that was:\n\n```\n$ grep -Ri MOUNT_NODEV *\nlinux/fs.h:extern struct dentry *mount_nodev(struct file_system_type *fs_type,\n```\n\nit's defined as:\n\n``` h\nextern struct dentry *mount_nodev(struct file_system_type *fs_type,\n        int flags, void *data,\n        int (*fill_super)(struct super_block *, void *, int));\n```\n\nThere's also:\n\n``` h\n#define MNT_NODEV       0x02\n```\n\nin `linux/mount.h`.\n\nJust in case, I've put the src.rpm for the stock SLES11 SP3 kernel source at https://anorien.csc.warwick.ac.uk/kernel-source-3.0.76-0.11.1.x86_64.rpm - it will produce the /usr/src/linux used for building on SLES. \n\nHope this helps anyway, don't hesitate to ask if you need more information.\n(edit: updated rpm url)\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/39320535/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "Rudd-O": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11071", "body": "don't hardcode the paths, please.  otherwise it will fail depending on where the utilities are installed.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11071/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11072", "body": "we sync.  we expect no unmounting to happen here since it either will fail if core file systems are mounted and have files open, or successfully unmount the file systems only to make the later initscripts crap out horribly because core file systems are not available anymore.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11072/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11073", "body": "show better status here\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11073/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11251", "body": "what should I do with these two lines?  Remove them?\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11251/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11252", "body": "should I re-add this file?\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11252/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11289", "body": "I will add this right now.\n\nEl Wednesday, March 23, 2011, behlendorf escribi\u00f3:\n\n> > @@ -1,6 +0,0 @@\n> > \n> > ## -Stub file for 'make dist' distdir rule.\n> > \n> > -This file is directly referenced by ../Makefile.am as a source\n> > -file and thus will be expected by 'make dist'.  To avoid this\n> \n> This file should be readded exactly for the reasons mentioned in the file.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11289/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11290", "body": "The file has been re-added as of commit 9549dd1 and pushed too.\n\nNow onto the next revision.\n\nEl Wednesday, March 23, 2011, behlendorf escribi\u00f3:\n\n> > @@ -1,6 +0,0 @@\n> > \n> > ## -Stub file for 'make dist' distdir rule.\n> > \n> > -This file is directly referenced by ../Makefile.am as a source\n> > -file and thus will be expected by 'make dist'.  To avoid this\n> \n> This file should be readded exactly for the reasons mentioned in the file.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11290/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11291", "body": "Commit 5469b88, just pushed, removes those by simply cherry-picking your own \ncommit on top of the merge.\n\nEl Wednesday, March 23, 2011, behlendorf escribi\u00f3:\n\n> > @@ -204,6 +204,8 @@ const struct super_operations zpl_super_operations =\n> > {\n> > \n> > ```\n> > .put_super  = zpl_put_super,\n> > .write_super    = NULL,\n> > .sync_fs    = zpl_sync_fs,\n> > ```\n> > -   .freeze_fs  = NULL,\n> \n> Yes, please remove them.  They are currently unused hooks and they cause\n> compile errors on older platforms.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11291/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11294", "body": "File removed.  Commit pushed.  Let me refresh the page to see how the merge \ndiff will look like.  You should do the same.\n\nEl Wednesday, March 23, 2011, behlendorf escribi\u00f3:\n\n> > @@ -0,0 +1,59 @@\n> > +put the dracut/90zfs directory in /usr/share/dracut/modules.d (or\n> > symlink it)\n> \n> A version of this file was already added to the dracut subdirectory.  If\n> you want to make changes/rewrite it that's fine but let's just keep one\n> copy of it around with the other dracut code.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11294/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}, "rlaager": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374212", "body": "What do you mean by this?\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374212/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374494", "body": "I've found this approach works best: Start from a checkout of upstream trunk. Then `git branch TOPIC; git checkout TOPIC`. Make your changes and commit. Push that branch to github. Repeat as necessary for the other features, starting from a checkout of upstream trunk each time. Then, do a pull request for each branch.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374494/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374507", "body": "The easiest solution is probably to leave your master tracking upstream master (i.e. you should not commit anything to master). Use a separate branch to combine your topic branches.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374507/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354255", "body": "domain should be 256 (255 + NUL). As a result, the other fields might need changing. I haven't looked closely.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354255/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354257", "body": "Is \"EPOH\" supposed to be \"epoch\"?\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354257/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354259", "body": "This should be checked for NUL-termination correctness.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354259/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354260", "body": "This should be checked for NUL-termination correctness.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354260/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354264", "body": "This should probably const char *.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354264/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354267", "body": "By \"EOL\", you probably meant \"NUL\"?\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354267/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354268", "body": "Like in the SMB patch, this usage of a function named file_is_executable() is really confusing.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354268/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354271", "body": "You're just blindly returning OK here. Should something be done?\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354271/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354272", "body": "What should this function do? Maybe I or someone can help flesh it out.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354272/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354276", "body": "You shouldn't be calling strlen() in a loop like this. This should be rewritten more like this (untested):\n\n```\nfor (c = line ; *c ; c++) {\n    if (*c == '\\r' || *c == '\\n') {\n      c = '\\0';\n      break;\n    }\n}\n```\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354276/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354281", "body": "The code inside this should be indented another level. (Is Github hiding that in the diff, maybe? I didn't check.)\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354281/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354285", "body": "What's the purpose of this check? I don't understand why /dev/zvol is hardcoded.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354285/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}}, "5": {"danielkza": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7059", "title": "Scrub gets stuck, becomes unstoppable and locks up user processes in uninterruptible sleep", "body": "Type                    | Version/Name\r\n---                     | ---\r\nDistribution Name       | Fedora\r\nDistribution Version    | 27\r\nLinux Kernel            | 4.14.13\r\nArchitecture            | x86_64\r\nZFS Version             | 0.7.5\r\nSPL Version             | 0.7.5\r\n\r\n### Describe the problem you're observing\r\n\r\nAfter a routine scrub starting on the background, some programs seem stuck in uninterruptible IO due to ZFS. Attempting\r\nto pause or stop the scrub does not work - the `zpool` command hangs and also becomes unkillable.\r\n\r\nHere is the `/proc/PID/stack` of the stuck `zpool`:\r\n\r\n```\r\n[<ffffffffc11f1c23>] cv_wait_common+0x113/0x130 [spl]\r\n[<ffffffffc11f1c55>] __cv_wait+0x15/0x20 [spl]\r\n[<ffffffffc182972d>] txg_wait_synced+0xdd/0x120 [zfs]\r\n[<ffffffffc1801f36>] dsl_sync_task+0x176/0x260 [zfs]\r\n[<ffffffffc180041e>] dsl_scrub_set_pause_resume+0x3e/0x40 [zfs]\r\n[<ffffffffc181e511>] spa_scrub_pause_resume+0x31/0x60 [zfs]\r\n[<ffffffffc1858f85>] zfs_ioc_pool_scan+0xb5/0xc0 [zfs]\r\n[<ffffffffc18592d6>] zfsdev_ioctl+0x1d6/0x600 [zfs]\r\n[<ffffffff9429f575>] do_vfs_ioctl+0xa5/0x610\r\n[<ffffffff9429fb59>] SyS_ioctl+0x79/0x90\r\n[<ffffffff94a0008d>] entry_SYSCALL_64_fastpath+0x20/0x83\r\n```\r\n\r\nAnd of one of the stuck user processes:\r\n\r\n```\r\n[<ffffffff940d7746>] io_schedule+0x16/0x40\r\n[<ffffffffc11f1bb9>] cv_wait_common+0xa9/0x130 [spl]\r\n[<ffffffffc11f1c98>] __cv_wait_io+0x18/0x20 [spl]\r\n[<ffffffffc187f7f2>] zio_wait+0xf2/0x1b0 [zfs]\r\n[<ffffffffc17c38d3>] dbuf_read+0x6e3/0x910 [zfs]\r\n[<ffffffffc17c5c19>] __dbuf_hold_impl+0x549/0x600 [zfs]\r\n[<ffffffffc17c5d71>] dbuf_hold_impl+0xa1/0xd0 [zfs]\r\n[<ffffffffc17c5e33>] dbuf_hold+0x33/0x60 [zfs]\r\n[<ffffffffc17cf1cd>] dmu_buf_hold_noread+0x8d/0x100 [zfs]\r\n[<ffffffffc17cf26f>] dmu_buf_hold+0x2f/0x80 [zfs]\r\n[<ffffffffc1845a5e>] zap_lockdir+0x4e/0xb0 [zfs]\r\n[<ffffffffc1845c3a>] zap_cursor_retrieve+0x17a/0x2e0 [zfs]\r\n[<ffffffffc1869abc>] zfs_readdir+0x13c/0x460 [zfs]\r\n[<ffffffffc1886911>] zpl_iterate+0x51/0x80 [zfs]\r\n[<ffffffff9429fce0>] iterate_dir+0x170/0x1a0\r\n[<ffffffff942a046a>] SyS_getdents+0xaa/0x140\r\n[<ffffffff94a0008d>] entry_SYSCALL_64_fastpath+0x20/0x83\r\n[<ffffffffffffffff>] 0xffffffffffffffff\r\n```\r\n\r\nHere is the affected pool status:\r\n\r\n```\r\n  pool: daniel-pc-media\r\n state: ONLINE\r\n  scan: scrub in progress since Thu Jan 18 03:29:02 2018\r\n    102G scanned out of 2,45T at 2,60M/s, 263h46m to go\r\n    0B repaired, 4,06% done\r\nconfig:\r\n\r\n    NAME                                 STATE     READ WRITE CKSUM\r\n    daniel-pc-media                      ONLINE       0     0     0\r\n      mirror-0                           ONLINE       0     0     0\r\n        ata-ST4000DM000-1F2168_Z301QGEZ  ONLINE       0     0     0\r\n        ata-ST4000DM000-1F2168_Z301QGCM  ONLINE       0     0     0\r\n```\r\n\r\nThere seems to be no progress actually being made, as none of the counters advance (other than the expected ETA).\r\n\r\n### Describe how to reproduce the problem\r\n\r\nNot able to so far. I can provide more observations of the running system if it doesn't force me to restart by\r\nbecoming unstable/unusable.\r\n\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n\r\nNothing of interest or related to ZFS is present in the kernel logs.\r\nThe problem *might* have been triggered by suspending and resuming the computer, but I was not monitoring the scrub before that, so I can't be sure.\r\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7059/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "makhomed": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7057", "title": "tasks txg_sync and zfs blocked for more than 120 seconds", "body": "### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       |  CentOS Linux\r\nDistribution Version    | 7.4.1708\r\nLinux Kernel                 |  3.10.0-693.11.6.el7\r\nArchitecture                 | x86_64\r\nZFS Version                  | 0.7.5-1\r\nSPL Version                  | 0.7.5-1\r\n\r\nZFS installed from zfs-kmod repo, ```baseurl=http://download.zfsonlinux.org/epel/7.4/kmod/$basearch/```\r\n\r\n### Describe the problem you're observing\r\n\r\nMessages in /var/log/messages about blocked tasks.\r\n\r\n### Describe how to reproduce the problem\r\n\r\nSorry, but I do not found way how to reproduce this bug.\r\nMay be stack trace will help to find root cause of this bug?\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n```\r\n\r\nJan 17 17:26:45 kvm-hardware-node kernel: INFO: task txg_sync:10906 blocked for more than 120 seconds.\r\nJan 17 17:26:45 kvm-hardware-node kernel: \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\nJan 17 17:26:45 kvm-hardware-node kernel: txg_sync        D ffff883f6a256eb0     0 10906      2 0x00000000\r\nJan 17 17:26:45 kvm-hardware-node kernel: Call Trace:\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04ddf57>] ? taskq_dispatch_ent+0x57/0x170 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff816ab6d9>] schedule+0x29/0x70\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff816a90e9>] schedule_timeout+0x239/0x2c0\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc07ba30f>] ? zio_taskq_dispatch+0x8f/0xa0 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc07ba352>] ? zio_issue_async+0x12/0x20 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc07bebcc>] ? zio_nowait+0xbc/0x150 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff816aac5d>] io_schedule_timeout+0xad/0x130\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff810b31a6>] ? prepare_to_wait_exclusive+0x56/0x90\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff816aacf8>] io_schedule+0x18/0x20\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04e24a2>] cv_wait_common+0xb2/0x150 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff810b34b0>] ? wake_up_atomic_t+0x30/0x30\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04e2598>] __cv_wait_io+0x18/0x20 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc07be49b>] zio_wait+0x10b/0x1b0 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc07346cf>] dsl_pool_sync+0xbf/0x440 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc07527c7>] spa_sync+0x437/0xdf0 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff810c6452>] ? default_wake_function+0x12/0x20\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff810bf074>] ? __wake_up+0x44/0x50\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0766a91>] txg_sync_thread+0x301/0x510 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0766790>] ? txg_fini+0x2a0/0x2a0 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04dcfa1>] thread_generic_wrapper+0x71/0x80 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04dcf30>] ? __thread_exit+0x20/0x20 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff810b252f>] kthread+0xcf/0xe0\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff810b2460>] ? insert_kthread_work+0x40/0x40\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff816b8798>] ret_from_fork+0x58/0x90\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff810b2460>] ? insert_kthread_work+0x40/0x40\r\nJan 17 17:26:45 kvm-hardware-node kernel: INFO: task zfs:21118 blocked for more than 120 seconds.\r\nJan 17 17:26:45 kvm-hardware-node kernel: \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\nJan 17 17:26:45 kvm-hardware-node kernel: zfs             D ffff883f79a38000     0 21118   8250 0x00000080\r\nJan 17 17:26:45 kvm-hardware-node kernel: Call Trace:\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff816ab6d9>] schedule+0x29/0x70\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04e2515>] cv_wait_common+0x125/0x150 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff810b34b0>] ? wake_up_atomic_t+0x30/0x30\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04e2555>] __cv_wait+0x15/0x20 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0765a2f>] txg_wait_synced+0xef/0x140 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0727d50>] ? dsl_dataset_snapshot_check_impl+0x210/0x210 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc073d017>] dsl_sync_task+0x177/0x270 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc07289d0>] ? dsl_dataset_snapshot_sync_impl+0x760/0x760 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0727d50>] ? dsl_dataset_snapshot_check_impl+0x210/0x210 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc07289d0>] ? dsl_dataset_snapshot_sync_impl+0x760/0x760 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0728dc3>] dsl_dataset_snapshot+0x133/0x2e0 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0479157>] ? nvlist_remove_all+0x77/0xd0 [znvpair]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0479655>] ? nvlist_add_common.part.51+0x325/0x430 [znvpair]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff811df99c>] ? __kmalloc_node+0x5c/0x2b0\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04db31d>] ? spl_kmem_alloc_impl+0xcd/0x170 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04db31d>] ? spl_kmem_alloc_impl+0xcd/0x170 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc04db31d>] ? spl_kmem_alloc_impl+0xcd/0x170 [spl]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0479fc2>] ? nvlist_lookup_common.part.71+0xa2/0xb0 [znvpair]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0796868>] zfs_ioc_snapshot+0x348/0x3b0 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffffc0798606>] zfsdev_ioctl+0x1d6/0x650 [zfs]\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff8121710d>] do_vfs_ioctl+0x33d/0x540\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff816b3801>] ? __do_page_fault+0x171/0x450\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff812173b1>] SyS_ioctl+0xa1/0xc0\r\nJan 17 17:26:45 kvm-hardware-node kernel: [<ffffffff816b89fd>] system_call_fastpath+0x16/0x1b\r\n```", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7057/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "beren12": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7056", "title": "Improve snapshot listing error message", "body": "### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Debian\r\nDistribution Version    | 9\r\nLinux Kernel                 | 4.13.13-1~bpo9+1\r\nArchitecture                 | x64\r\nZFS Version                  | 0.7.4\r\nSPL Version                  | 0.7.4\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\nlisting snapshots for a single dataset fails unless -r is used, but this is not mentioned in the error message. -r is not needed to list all snapshots, so it can be a confusing behavior.\r\n\r\n### Describe how to reproduce the problem\r\n\r\n```\r\nzfs list -t snap rpool\r\n```\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n\r\n```\r\nzfs list -t snap rpool\r\ncannot open 'rpool': missing '@' delimiter in snapshot name\r\n```\r\n\r\nCould we amend the error message to also give a hint? Or possibly be consistent and list all snapshots without -r, just as giving no dataset does? Bookmarks might also need the same edit, ike here:\r\n\r\n```diff\r\n--- lib/libzfs/libzfs_dataset.c\t2018-01-17 10:07:12.178817043 -0500\r\n+++ lib/libzfs/libzfs_dataset.c.new\t2018-01-17 10:06:47.307290884 -0500\r\n@@ -175,7 +175,7 @@\r\n \tif (type == ZFS_TYPE_SNAPSHOT && strchr(path, '@') == NULL) {\r\n \t\tif (hdl != NULL)\r\n \t\t\tzfs_error_aux(hdl, dgettext(TEXT_DOMAIN,\r\n-\t\t\t    \"missing '@' delimiter in snapshot name\"));\r\n+\t\t\t    \"missing '@' delimiter in snapshot name, did you mean to use -r?\"));\r\n \t\treturn (0);\r\n \t}\r\n```", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7056/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "behlendorf": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7052", "title": "zfs load-key double free", "body": "### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | CentOS\r\nDistribution Version    | 7\r\nLinux Kernel                 | 3.10.0-693.11.6.1\r\nArchitecture                 | x86_64\r\nZFS Version                  | zfs-0.7.0-246-gd658b2c\r\nSPL Version                  | master\r\n\r\n### Describe the problem you're observing\r\n\r\nWhen zfs is built with `--enable-debug --enable-debuginfo` and an incorrect passphrase is provided to `zfs load-key` followed by an empty one a \"double free or leak\" is reported.  Observed during manual testing.\r\n\r\n### Describe how to reproduce the problem\r\n\r\nAt build time `--enable-debug --enable-debuginfo`, then,\r\n\r\n```sh\r\n$ truncate -s 512M /var/tmp/vdev\r\n$ zpool create tank /var/tmp/vdev\r\n$ zfs create -o encryption=on -o keyformat=passphrase tank/fs\r\nEnter passphrase: password\r\nRe-enter passphrase: password\r\n$ zfs unload-key -a\r\n```\r\n\r\nReload the key giving the wrong password first \"password1\" which is correctly rejected.  Then just hit enter when prompted again.\r\n\r\n```sh\r\n$ zfs load-key -a\r\nEnter passphrase for 'tank/fs': password1\r\nKey load error: Incorrect key provided for 'tank/fs'.\r\nEnter passphrase for 'tank/fs': <empty>\r\nKey load error: Passphrase too short (min 8).\r\n*** Error in `cmd/zfs/.libs/lt-zfs': double free or corruption (fasttop): 0x000000000061f150 ***\r\n======= Backtrace: =========\r\n/lib64/libc.so.6(+0x7c619)[0x2aaaacc65619]\r\nlib/libzfs/.libs/libzfs.so.2(zfs_crypto_load_key+0xf3)[0x2aaaab109023]\r\ncmd/zfs/.libs/lt-zfs[0x406557]\r\ncmd/zfs/.libs/lt-zfs[0x405d41]\r\ncmd/zfs/.libs/lt-zfs[0x408298]\r\ncmd/zfs/.libs/lt-zfs[0x4051ef]\r\n/lib64/libc.so.6(__libc_start_main+0xf5)[0x2aaaacc0ac05]\r\ncmd/zfs/.libs/lt-zfs[0x405318]\r\n...\r\n```", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7052/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7026", "title": "Test case history_004_pos", "body": "### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | all\r\nDistribution Version    | all\r\nLinux Kernel                 | all\r\nArchitecture                 | all\r\nZFS Version                  | zfs-0.7.0-230-gb02beca\r\nSPL Version                  | 0.7\r\n\r\n### Describe the problem you're observing\r\n\r\nRarely observed failure of history_004_pos during automated testing.\r\n\r\n### Describe how to reproduce the problem\r\n\r\nReproducible by the buildbot.\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n\r\n\r\nhttp://build.zfsonlinux.org/builders/Amazon%202%20x86_64%20Release%20%28TEST%29/builds/105/\r\n\r\n```\r\nTest: /usr/share/zfs/zfs-tests/tests/functional/history/history_004_pos (run as root) [00:04] [FAIL]\r\n02:51:58.52 ASSERTION: 'zpool history' can cope with simultaneous commands.\r\n02:52:01.35 umount: testpool/clone3: mountpoint not found\r\n02:52:01.35 cannot unmount 'testpool/clone3': umount failed\r\n02:52:01.55 cannot create 'testpool/clone3': dataset already exists\r\n02:52:01.62 cannot promote 'testpool/clone3': not a cloned filesystem\r\n02:52:01.66 cannot destroy 'testpool/testfs3': filesystem has children\r\n02:52:01.66 use '-r' to destroy the following datasets:\r\n02:52:01.66 testpool/testfs3@snap\r\n02:52:01.81 cannot create 'testpool/testfs3': dataset already exists\r\n02:52:01.92 cannot create snapshot 'testpool/testfs3@snap': dataset already exists\r\n02:52:02.69 The entries count error: entry_count=297  orig_count = 103\r\n02:52:02.69 NOTE: Performing test-fail callback (/usr/share/zfs/zfs-tests/callbacks/zfs_dbgmsg.ksh)\r\n```", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7026/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/3da3488e6339ff2dc5c7f3da8c8a0c552d018d68", "message": "Fix shellcheck v0.4.6 warnings\n\nResolve new warnings reported after upgrading to shellcheck\r\nversion 0.4.6.  This patch contains no functional changes.\r\n\r\n* egrep is non-standard and deprecated. Use grep -E instead. [SC2196]\r\n* Check exit code directly with e.g. 'if mycmd;', not indirectly\r\n  with $?.  [SC2181]  Suppressed.\r\n\r\nReviewed-by: George Melikov <mail@gmelikov.ru>\r\nReviewed-by: Giuseppe Di Natale <dinatale2@llnl.gov>\r\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nCloses #7040"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/e1a0850c3570ae53df5779bc656f17b98b86f160", "message": "Force ztest to always use /dev/urandom\n\nFor ztest, which is solely for testing, using a pseudo random\r\nis entirely reasonable.  Using /dev/urandom ensures the system\r\nentropy pool doesn't get depleted thus stalling the testing.\r\nThis is a particular problem when testing in VMs.\r\n\r\nReviewed-by: Tim Chase <tim@chase2k.com>\r\nReviewed by: Thomas Caputi <tcaputi@datto.com>\r\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nCloses #7017 \r\nCloses #7036"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/fed90353d799acbc5e81b0dfadc6d649b0f2e8b5", "message": "Support -fsanitize=address with --enable-asan\n\nWhen --enable-asan is provided to configure then build all user\r\nspace components with fsanitize=address.  For kernel support\r\nuse the Linux KASAN feature instead.\r\n\r\nhttps://github.com/google/sanitizers/wiki/AddressSanitizer\r\n\r\nWhen using gcc version 4.8 any test case which intentionally\r\ngenerates a core dump will fail when using --enable-asan.\r\nThe default behavior is to disable core dumps and only newer\r\nversions allow this behavior to be controled at run time with\r\nthe ASAN_OPTIONS environment variable.\r\n\r\nAdditionally, this patch includes some build system cleanup.\r\n\r\n* Rules.am updated to set the minimum AM_CFLAGS, AM_CPPFLAGS,\r\n  and AM_LDFLAGS.  Any additional flags should be added on a\r\n  per-Makefile basic.  The --enable-debug and --enable-asan\r\n  options apply to all user space binaries and libraries.\r\n\r\n* Compiler checks consolidated in always-compiler-options.m4\r\n  and renamed for consistency.\r\n\r\n* -fstack-check compiler flag was removed, this functionality\r\n  is provided by asan when configured with --enable-asan.\r\n\r\n* Split DEBUG_CFLAGS in to DEBUG_CFLAGS, DEBUG_CPPFLAGS, and\r\n  DEBUG_LDFLAGS.\r\n\r\n* Moved default kernel build flags in to module/Makefile.in and\r\n  split in to ZFS_MODULE_CFLAGS and ZFS_MODULE_CPPFLAGS.  These\r\n  flags are set with the standard ccflags-y kbuild mechanism.\r\n\r\n* -Wframe-larger-than checks applied only to binaries or\r\n  libraries which include source files which are built in\r\n  both user space and kernel space.  This restriction is\r\n  relaxed for user space only utilities.\r\n\r\n* -Wno-unused-but-set-variable applied only to libzfs and\r\n  libzpool.  The remaining warnings are the result of an\r\n  ASSERT using a variable when is always declared.\r\n\r\n* -D_POSIX_PTHREAD_SEMANTICS and -D__EXTENSIONS__ dropped\r\n  because they are Solaris specific and thus not needed.\r\n\r\n* Ensure $GDB is defined as gdb by default in zloop.sh.\r\n\r\nSigned-off-by: DHE <git@dehacked.net>\r\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nCloses #7027"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/7e7f5132779a04da0070cf6e6ffd8e9b5f7692de", "message": "Disable history_004_pos\n\nOccasionally observed failure of history_004_pos due to the test\r\ncase not being 100% reliable.  In order to prevent false positives\r\ndisable this test case until it can be made reliable.\r\n\r\nReviewed-by: George Melikov <mail@gmelikov.ru>\r\nReviewed-by: Giuseppe Di Natale <dinatale2@llnl.gov>\r\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nIssue #7026 \r\nCloses #7028"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/bfe27ace0de64838d50ff351396423a481de6c84", "message": "Fix unused variable warnings\n\nResolved unused variable warnings observed after restricting\n-Wno-unused-but-set-variable to only libzfs and libzpool.\n\nReviewed-by: DHE <git@dehacked.net>\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\nCloses #6941"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/06401e42221d2f5130065caf70f8276ba4d19acd", "message": "Fix ztest_verify_dnode_bt() test case\n\nIn ztest_verify_dnode_bt the ztest_object_lock must be held in\norder to safely verify the unused bonus space.\n\nReviewed-by: DHE <git@dehacked.net>\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\nCloses #6941"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/b02becaa00aef3d25b30588bf49affbf1e9a84a4", "message": "Reduce codecov PR comments\n\nAttempt to reduce the number of comments posted by codecov\r\nto PR requests.  Based on the codecov documenation setting\r\n\"require_changes=yes\" and \"behavior=once\" should result in\r\na single comment under most circumstances.\r\n\r\nhttps://docs.codecov.io/v4.3.6/docs/pull-request-comments\r\n\r\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nIssue #7022 \r\nCloses #7025"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/0873bb6337452e3e028e40f5dad945b30deab185", "message": "Fix ARC hit rate\n\nWhen the compressed ARC feature was added in commit d3c2ae1\r\nthe method of reference counting in the ARC was modified.  As\r\npart of this accounting change the arc_buf_add_ref() function\r\nwas removed entirely.\r\n\r\nThis would have be fine but the arc_buf_add_ref() function\r\nserved a second undocumented purpose of updating the ARC access\r\ninformation when taking a hold on a dbuf.  Without this logic\r\nin place a cached dbuf would not migrate its associated\r\narc_buf_hdr_t to the MFU list.  This would negatively impact\r\nthe ARC hit rate, particularly on systems with a small ARC.\r\n\r\nThis change reinstates the missing call to arc_access() from\r\ndbuf_hold() by implementing a new arc_buf_access() function.\r\n\r\nReviewed-by: Giuseppe Di Natale <dinatale2@llnl.gov>\r\nReviewed-by: Tony Hutter <hutter2@llnl.gov>\r\nReviewed-by: Tim Chase <tim@chase2k.com>\r\nReviewed by: George Wilson <george.wilson@delphix.com>\r\nReviewed-by: George Melikov <mail@gmelikov.ru>\r\nSigned-off-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nCloses #6171 \r\nCloses #6852 \r\nCloses #6989"}], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6999", "title": "Extend deadman logic", "body": "### Description\r\n\r\nThe intent of this patch is extend the existing deadman code such that it's flexible enough to be used by both ztest and on production systems.  The proposed changes include:\r\n\r\n* Added a new `zfs_deadman_failmode` module option which is used to dynamically control the behavior of the deadman.  It's loosely modeled after, but independant from, the pool failmode property.  It can be set to wait, continue, or panic.\r\n\r\n    * wait     - Wait for the \"hung\" I/O (default)\r\n    * continue - Attempt to recover from a \"hung\" I/O\r\n    * panic    - Panic the system\r\n\r\n* Added a new `zfs_deadman_ziotime_ms` module option which is analogous to zfs_deadman_synctime_ms` except instead of applying to a pool TXG sync it applies to zio_wait().  A   default value of 300s is used to define a \"hung\" zio.\r\n\r\n* The ztest deadman thread has been re-enabled by default, aligned with the upstream OpenZFS code, and then extended to terminate the process when it takes significantly longer to complete than expected.\r\n\r\n* The -G option was added to ztest to print the internal debug log when a fatal error is encountered.  This same option was previously added to zdb in commit fa603f82.  Update zloop.sh to unconditionally pass -G to obtain additional debugging.\r\n\r\n* The FM_EREPORT_ZFS_DELAY event which was previously posted when the deadman detect a \"hung\" pool has been replaced by a new dedicated FM_EREPORT_ZFS_DEADMAN event.\r\n\r\n* The proposed recovery logic attempts to restart a \"hung\"  zio by calling zio_interrupt() on any outstanding leaf zios.  We may want to further restrict this to zios in either the  ZIO_STAGE_VDEV_IO_START or ZIO_STAGE_VDEV_IO_DONE stages.  Calling zio_interrupt() is expected to only be useful for cases when an IO has been submitted to the physical device\r\n  but for some reasonable the completion callback hasn't been called by the lower layers.  This shouldn't be possible but  has been observed and may be caused by kernel/driver bugs.\r\n\r\n* The 'zfs_deadman_synctime_ms' default value was reduced from 1000s to 600s.\r\n\r\n* Depending on how ztest fails there may be no cache file to move.  This should not be considered fatal, collect the logs which are available and carry on.\r\n\r\n### Motivation and Context\r\n\r\nAdd some of the needed infrastructure to make it possible to root cause `ztest` \"hangs\" observed during automated testing.  With this change applied at least basic debugging information will be collected for any \"hangs\".  This change can be further augmented with improvements to the debugging infrastructure.\r\n\r\nIssue #6901.\r\n\r\n### How Has This Been Tested?\r\n\r\nLocally by running `zloop.sh` in-tree for approximated 4 days.  Over this time period the deadman behaved as expected and properly terminated `ztest` when it appeared to be hung.  Further analysis of the debug logs and cores obtained is still needed.  The expectation is they will provide some statistical insight in the most often observed failures.\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [x] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [x] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "OWNER"}], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/147559", "body": "Thanks, I hadn't noticed the rendering issue.  Fixed by commit bbf3a3575c0b5795d3e4ddc27523258dc61ffa88.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/147559/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/195492", "body": "I'm not particularly happy with all this grubbing around in /dev/ either for 'zpool import', but for the moment I view it as a short term solution.  The longer term solution, which is well under way, is to be tightly integrated with libblkid.  There has been a patch submitted upstream and accepted by the maintainers to correctly identify a disk which belongs to a zfs pool.  Once a version of libblkid with this change filters back in to the distributions we can simply consult libblkid for the list of zfs devices and avoid checking /dev/.  In fact all the code on the zfs side is already in place for this.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/195492/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/282533", "body": "- Removed Makefile-sample, with the full integration in the build system it isn't needed.\n- Added all autogen.sh products (Makefile.in, configure) using the following versions of the utils.  Using the same versions of the tools minimizes how much change there is in the autogen products and makes it easier to review.\n  \n  autoconf (GNU Autoconf) 2.63\n  automake (GNU automake) 1.11.1\n  ltmain.sh (GNU libtool) 2.2.6b\n- Added the CDDL header to zvol_id_main.c, including correctly attributing the source.\n- Minor stray whitespace cleanup.\n- Update kmem_free() in zvol_remove_minors() to match  kmem_zalloc()'s use of MAXNAMELEN.  If we fail to do the the memory account code will flag this is a memory leak.  It's critical to ensure you alloc/free both use the same size for the buffer.\n- Add <sys/stat.h> header in zvol_id_main.c, without it my build was failing on RHEL6.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/282533/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/282739", "body": "Sorry!  I've force updated my branch to include the Makefile.in... in and the process obliterated the previous review comments.  We need to figure out how to handle this best, I'd really like to be landing one nice concise commit to fix an issue.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/282739/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/383680", "body": "The zvol will be created with unique /dev/zdN names and then the /dev/zvol/pool/dataset links are created with udev rules.  This is exactly how normal block devices work such as /dev/sda with /dev/disk/by-_/_ links created with udev.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/383680/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/384675", "body": "This behavior is forced by the Linux kernel.  The special device files created under /dev/\\* has certain limitations including a maximum name length and certain reserved characters.  To avoid these limitations the standard solution is to create simple unique names at the top level /dev/\\* and symlink them with udev.  That's why all persistent storage devices work this way.  As you say you should never use these top level devices because their names may change.  This is equally true for /dev/sda, /dev/hda, and /dev/zd1.  The above comment is the code was simply an example test case and does not show a real usage scenario.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/384675/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/409945", "body": "I'm pretty sure dbuf_hold_impl() is called in other contexts.  I've love to revert this too but it's going to take more convincing that this is safe...  but that's for pointing it out, I'd actually forgotten about this particular hack!\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/409945/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/512022", "body": "I didn't either at the time or I would have added it to the original patch.  I only noticed later when it annoyed me.  :)\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/512022/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}], "review_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11254", "body": "This file should be readded exactly for the reasons mentioned in the file.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11254/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11255", "body": "Yes, please remove them.  They are currently unused hooks and they cause compile errors on older platforms.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11255/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11259", "body": "A version of this file was already added to the dracut subdirectory.  If you want to make changes/rewrite it that's fine but let's just keep one copy of it around with the other dracut code.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11259/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}]}, "wphilips": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7050", "title": "zfs-dracut boot failure with out of date zpool.cache - zfs_force not working", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       |  Fedora \r\nDistribution Version    |  26 \r\nLinux Kernel                 |  any (e.g., 4.14.6-200.fc26.x86_64)\r\nArchitecture                 |  x86_64\r\nZFS Version                  |   v0.7.5-1\r\nSPL Version                  |  v0.7.5-1\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\nI have several systems with root and boot on zfs. The systems boot with grub initramfs \r\nis generated by dracut with zfs-dracut-0.7.5-1.fc26.x86_64\r\n\r\nThe problem occurs whenever significant changes are made to the zpools attached to the\r\nsystem, or even when adding empty disks.  Very often, dracut enters the emergency shell\r\nbecause it cannot import the pools based on the zpool.cache file. Even adding zfs_force \r\nas a kernel option does not work. E.g., I tried:\r\n\r\nlinux16 /boot/@/vmlinuz-4.14.13-200.fc26.x86_64 root=zfs:ssd/fc26 boot=ssd ro rd_NO_PLYMOUTH audit=0 zfs_force=1\r\n\r\n\r\nThe reason seems to be that the zpoool.cache file does not reflect the current (changed) configuration of the system. It is not clear why zfs.force  or zfs_force does not work.\r\n\r\n\r\nHere are 2 use cases:\r\n\r\n1. to defragment  the pool on which the zfs root is installed, I attach a new disk, create a new\r\nzpool on it, copy all the data, remove the old disk, reboot and change some grub parameters so\r\nthat it boots the new bool. Before the reboot, zpool.cache refers to the old pool on the old disk.\r\nRunning 'dracut -f ...' will therefore copy the \"old\" zpool.cache into initamfs. After boot, the disks\r\nhave changed and this zpool.cache is outdated. \r\n\r\n2. in a system with 3 rpools, I remove one of the disks which contains a non-essential \r\nrpool (after exporting it). I then add two new empty disks. The system boots into the dracut \r\nshell even though the root pool has not changed. The now missing, but non-essential pool\r\nprevents a normal boot.\r\n\r\n\r\nIt is possible to somewhat prevent these problems by removing zpool.cache, then running\r\ndracut and then rebooting. In this case, often dracut still enters the emergency shell claiming\r\nthat the pool(s) are in use in another system, but by force importing them in the dracut shell\r\nand rebooting it is possible to boot the system. Then it is possible to recreate zpool.cache, \r\nand rerun dracut to create a working system. Alternatively, one can continue to use the initramfs\r\nwith the missing zpool.cache.\r\n\r\nIt is probably also possible to create a zpool.cache file for the future new configuration, but it probably \r\ninvolves deleting the current one and it is easy to make a mistake.\r\n\r\nIn any case, make a simple mistake or  forget to take these  \"preventive\" measures \r\nand you end up with a system which will always enter the dracut emergency shell with \r\nno way to recover (except if you have e.g., a usb boot disk with zfs at hand. Even then\r\nit is really hard to recover).\r\n\r\nIn the good old days it also use to be  possible to fix problems in the dracut shell and then continue to boot. These days, systemd prevents this from working (probably related to the message \"transaction is destructive\")\r\n\r\nWhile fixing the zfs_force option would help, adding a configuration option to dracut to never \r\ncreate zfs.cache and/or adding a kernel command line option to ignore zpool.cache might \r\nalso help.\r\n \r\n\r\nPS. Even better would be to fix dracut or systemd so that a boot can continue after fixing problems \r\nin dracut. For instance, in the emergency shell you would remove the zpool.cache file and \r\nthen type some command to continue boot. However, that is probably a more general (non zfsonlinux)\r\nissue.\r\n\r\n\r\n\r\n\r\n\r\n\r\n### Describe how to reproduce the problem\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n<!-- \r\n*IMPORTANT* - Please mark logs and text output from terminal commands \r\nor else Github will not display them correctly. \r\nAn example is provided below.\r\n\r\nExample:\r\n```\r\nthis is an example how log text should be marked (wrap it with ```)\r\n```\r\n-->\r\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7050/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "jhammond-intel": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7045", "title": "pool suspension due to delayed MMP writes needs a better error message", "body": "### System information\r\nDistribution Name       | *\r\nDistribution Version    | *\r\nLinux Kernel                 | * \r\nArchitecture                 | *\r\nZFS Version                  | 0.7.5\r\nSPL Version                  | 0.7.5\r\n\r\nThis is related to Lustre issue https://jira.hpdd.intel.com/browse/LU-9845.\r\n\r\nWhen an MMP thread suspends a pool because \"no MMP write has succeeded in over mmp_interval * mmp_fail_intervals nanoseconds\" the only message we see on the console is \"WARNING: Pool 'blahblah' has encountered an uncorrectable I/O failure and has been suspended.\" This is not really informative enough and probably a bit misleading. We encountered these mysteriously suspended pool in our test clusters and were only able to attribute this to MMP by setting the pool failure mode to panic.\r\n\r\nI was able to easily reproduce using the Lustre backed zfs setup (VM has hostid set and 2 vCPUs, pool has MMP enabled) using the following:\r\n```\r\nm:~# export FSTYPE=zfs\r\nm:~# bash $LUSTRE/tests/llmount.sh\r\n...\r\nm:~# cat /sys/module/zfs/parameters/zfs_multihost_interval \r\n1000\r\nm:~# echo 100 > /sys/module/zfs/parameters/zfs_multihost_interval # set mmp interval to 100ms\r\nm:~# chrt -f 20 dd if=/dev/zero of=/dev/null &\r\nm:~# chrt -f 20 dd if=/dev/zero of=/dev/null &\r\n```\r\n\r\nI think we should probably keep the message from `zio_suspend()` as is but add a suitable message to `mmp_thread()` before calling `zio_suspend()`.", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7045/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/51d1b58ef3467c3a9711c65458f93063dd17354f", "message": "Emit an error message before MMP suspends pool\n\nIn mmp_thread(), emit an MMP specific error message before calling\r\nzio_suspend() so that the administrator will understand why the pool\r\nis being suspended.\r\n\r\nReviewed-by: Olaf Faaland <faaland1@llnl.gov>\r\nReviewed-by: Giuseppe Di Natale <dinatale2@llnl.gov>\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: John L. Hammond <john.hammond@intel.com>\r\nCloses #7048"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "samuelbernardo": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7042", "title": "BUG: soft lockup - CPU# stuck for 22s! [z_wr_iss]", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Gentoo\r\nDistribution Version    | -\r\nLinux Kernel                 | 4.14.12\r\nArchitecture                 | x86_64\r\nZFS Version                  | 0.7.5\r\nSPL Version                  | 0.7.5\r\n\r\n\r\n### Describe the problem you're observing\r\n\r\nzfs thread lock after some intensive IO. It allows to continue to access data, but all writes won't be commited to disk, since reboot needs ctrl+shift+sysreq reisub. It remains locked after trying soft reboot, and the only solution is a forced reboot with sysreq.\r\nThe zfs lock is registered systematically after some intensive IO on each OS reboot.\r\n\r\n### Describe how to reproduce the problem\r\n\r\nThis is the configuration of zfs volume that has the deadlock (using deduplication and lz4 compression):\r\n\r\nNAME   SIZE  ALLOC   FREE  EXPANDSZ   FRAG    CAP  DEDUP  HEALTH  ALTROOT\r\nzfs  21.8T  5.69T  16.1T         -     6%    26%  1.07x  ONLINE  -\r\n  raidz1  10.9T  2.85T  8.03T         -     6%    26%\r\n    ata-TOSHIBA_DT01ACA300_Z5RS6H0KS      -      -      -         -      -      -\r\n    ata-TOSHIBA_HDWD130_678KR5JAS      -      -      -         -      -      -\r\n    ata-TOSHIBA_DT01ACA300_16QUEEEKS      -      -      -         -      -      -\r\n    ata-TOSHIBA_HDWD130_678KPYLAS      -      -      -         -      -      -\r\n  raidz1  10.9T  2.85T  8.03T         -     6%    26%\r\n    ata-TOSHIBA_HDWD130_678KTDUAS      -      -      -         -      -      -\r\n    ata-TOSHIBA_DT01ACA300_16QUDE3KS      -      -      -         -      -      -\r\n    ata-WDC_WD40EZRX-75SPEB0_WD-WCC4E2YAA98J-part6      -      -      -         -      -      -\r\n    ata-TOSHIBA_HDWD130_678KPP7AS      -      -      -         -      -      -\r\ncache      -      -      -         -      -      -\r\n  sdc   699G  79.7M   699G         -     0%     0%\r\n  sde   699G  78.2M   699G         -     0%     0%\r\n\r\n  pool: zfs\r\n state: ONLINE\r\n  scan: resilvered 75.5G in 0h38m with 0 errors on Mon Oct 16 03:45:53 2017\r\nconfig:\r\n        NAME                                                STATE     READ WRITE CKSUM\r\n        zfs                                                 ONLINE       0     0     0\r\n          raidz1-0                                          ONLINE       0     0     0\r\n            ata-TOSHIBA_DT01ACA300_Z5RS6H0KS                ONLINE       0     0     0\r\n            ata-TOSHIBA_HDWD130_678KR5JAS                   ONLINE       0     0     0\r\n            ata-TOSHIBA_DT01ACA300_16QUEEEKS                ONLINE       0     0     0\r\n            ata-TOSHIBA_HDWD130_678KPYLAS                   ONLINE       0     0     0\r\n          raidz1-1                                          ONLINE       0     0     0\r\n            ata-TOSHIBA_HDWD130_678KTDUAS                   ONLINE       0     0     0\r\n            ata-TOSHIBA_DT01ACA300_16QUDE3KS                ONLINE       0     0     0\r\n            ata-WDC_WD40EZRX-75SPEB0_WD-WCC4E2YAA98J-part6  ONLINE       0     0     0\r\n            ata-TOSHIBA_HDWD130_678KPP7AS                   ONLINE       0     0     0\r\n        cache\r\n          sdc                                               ONLINE       0     0     0\r\n          sde                                               ONLINE       0     0     0\r\n\r\ncapacity  |   operations  |   bandwidth  |  total_wait   |  disk_wait  |  syncq_wait  |  asyncq_wait | scrub\r\n\r\npool |  alloc |  free |  read | write |  read | write |  read | write |  read | write  | read | write |  read | write |  wait \r\n  --- |   --- |   --- |   --- |  --- |   --- |  --- |   --- |  --- |   --- |  ---  |  --- |  --- |   --- |  --- |   --- \r\nzfs     |    5.69T | 16.1T  |   81 |   109 |  500K |  950K |   4us  |  1us  |  4us | 543ns | 187ns  |  2ns  |  1us |   1us | 723ns\r\n\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n```\r\nJan 10 21:57:11 x99 kernel: INFO: rcu_sched detected expedited stalls on CPUs/tasks: { 9-... } 218109 jiffies s: 401 root: 0x200/.\r\nJan 10 21:57:11 x99 kernel: blocking rcu_node structures:\r\nJan 10 21:57:11 x99 kernel: Task dump for CPU 9:\r\nJan 10 21:57:11 x99 kernel: z_wr_iss        R  running task    12256   749      2 0x80000008\r\nJan 10 21:57:11 x99 kernel: Call Trace:\r\nJan 10 21:57:11 x99 kernel:  ? arc_buf_info+0xcc7/0xf80 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? mutex_lock+0x9/0x30\r\nJan 10 21:57:11 x99 kernel:  ? dbuf_rele_and_unlock+0x4cb/0x540 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? mutex_lock+0x9/0x30\r\nJan 10 21:57:11 x99 kernel:  ? mutex_lock+0x9/0x30\r\nJan 10 21:57:11 x99 kernel:  ? zio_worst_error+0x60f/0x1250 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? zio_wait+0x113/0x160 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? dbuf_read+0x617/0xd80 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? __kmalloc_node+0x27d/0x290\r\nJan 10 21:57:11 x99 kernel:  ? spl_kmem_zalloc+0x85/0x150 [spl]\r\nJan 10 21:57:11 x99 kernel:  ? zap_leaf_lookup+0x6d/0x130 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? fzap_length+0x48/0x90 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? zap_name_alloc_uint64+0x50/0x60 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? zap_length_uint64+0x74/0x230 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? ddt_walk+0x31b/0x450 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? ddt_lookup+0xb4/0x190 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? zio_checksum_compute+0x15d/0x2a0 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? spl_kmem_cache_alloc+0x5b/0xb10 [spl]\r\nJan 10 21:57:11 x99 kernel:  ? __kmalloc_node+0x27d/0x290\r\nJan 10 21:57:11 x99 kernel:  ? spl_kmem_alloc+0x8e/0x160 [spl]\r\nJan 10 21:57:11 x99 kernel:  ? spl_kmem_alloc+0x8e/0x160 [spl]\r\nJan 10 21:57:11 x99 kernel:  ? zio_flush+0x867/0xde0 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? zio_push_transform+0x662/0xbe0 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? zio_execute+0x7c/0x430 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? taskq_dispatch_delay+0x51f/0x950 [spl]\r\nJan 10 21:57:11 x99 kernel:  ? wake_up_q+0x70/0x70\r\nJan 10 21:57:11 x99 kernel:  ? zio_interrupt+0x1030/0x1030 [zfs]\r\nJan 10 21:57:11 x99 kernel:  ? kthread+0xf7/0x130\r\nJan 10 21:57:11 x99 kernel:  ? taskq_dispatch_delay+0x2c0/0x950 [spl]\r\nJan 10 21:57:11 x99 kernel:  ? kthread_create_on_node+0x40/0x40\r\nJan 10 21:57:11 x99 kernel:  ? do_group_exit+0x35/0xa0\r\nJan 10 21:57:11 x99 kernel:  ? ret_from_fork+0x1f/0x30\r\nJan 10 21:57:13 x99 kernel: watchdog: BUG: soft lockup - CPU#9 stuck for 22s! [z_wr_iss:749]\r\nJan 10 21:57:13 x99 kernel: Modules linked in: nvidia_uvm(PO) zfs(PO) zunicode(PO) zavl(PO) icp(PO) zcommon(PO) znvpair(PO) spl(O) nv>\r\nJan 10 21:57:13 x99 kernel: CPU: 9 PID: 749 Comm: z_wr_iss Tainted: P        W  O L  4.14.12-gentoox99 #1\r\nJan 10 21:57:13 x99 kernel: Hardware name: ASUS All Series/X99-S, BIOS 3402 08/18/2016\r\nJan 10 21:57:13 x99 kernel: task: ffff880fef778e00 task.stack: ffffc9000a2dc000\r\nJan 10 21:57:13 x99 kernel: RIP: 0010:zap_leaf_lookup+0x92/0x130 [zfs]\r\nJan 10 21:57:13 x99 kernel: RSP: 0018:ffffc9000a2dfa40 EFLAGS: 00000213 ORIG_RAX: ffffffffffffff10\r\nJan 10 21:57:13 x99 kernel: RAX: 0000000000000000 RBX: ffff880d59b78130 RCX: 0000000000000007\r\nJan 10 21:57:13 x99 kernel: RDX: 000000000000000c RSI: ffff880d59b78000 RDI: 5d7f96b690640000\r\nJan 10 21:57:13 x99 kernel: RBP: ffffc9000a2dfa88 R08: 00000000002ebfcb R09: ffff880de2c53800\r\nJan 10 21:57:13 x99 kernel: R10: ffff880de2c53800 R11: ffff880fe497a000 R12: ffff880de2c53800\r\nJan 10 21:57:13 x99 kernel: R13: ffff880c575f3600 R14: ffff880d59b78132 R15: 0000000000000001\r\nJan 10 21:57:13 x99 kernel: FS:  0000000000000000(0000) GS:ffff880fff440000(0000) knlGS:0000000000000000\r\nJan 10 21:57:13 x99 kernel: CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\r\nJan 10 21:57:13 x99 kernel: CR2: 00007f767108b850 CR3: 0000000004823006 CR4: 00000000001606e0\r\nJan 10 21:57:13 x99 kernel: Call Trace:\r\nJan 10 21:57:13 x99 kernel:  fzap_length+0x48/0x90 [zfs]\r\nJan 10 21:57:13 x99 kernel:  ? zap_name_alloc_uint64+0x50/0x60 [zfs]\r\nJan 10 21:57:13 x99 kernel:  zap_length_uint64+0x74/0x230 [zfs]\r\nJan 10 21:57:13 x99 kernel:  ddt_walk+0x31b/0x450 [zfs]\r\nJan 10 21:57:13 x99 kernel:  ddt_lookup+0xb4/0x190 [zfs]\r\nJan 10 21:57:13 x99 kernel:  ? zio_checksum_compute+0x15d/0x2a0 [zfs]\r\nJan 10 21:57:13 x99 kernel:  ? spl_kmem_cache_alloc+0x5b/0xb10 [spl]\r\nJan 10 21:57:13 x99 kernel:  ? __kmalloc_node+0x27d/0x290\r\nJan 10 21:57:13 x99 kernel:  ? spl_kmem_alloc+0x8e/0x160 [spl]\r\nJan 10 21:57:13 x99 kernel:  ? spl_kmem_alloc+0x8e/0x160 [spl]\r\nJan 10 21:57:13 x99 kernel:  zio_flush+0x867/0xde0 [zfs]\r\nJan 10 21:57:13 x99 kernel:  ? zio_push_transform+0x662/0xbe0 [zfs]\r\nJan 10 21:57:13 x99 kernel:  zio_execute+0x7c/0x430 [zfs]\r\nJan 10 21:57:13 x99 kernel:  taskq_dispatch_delay+0x51f/0x950 [spl]\r\nJan 10 21:57:13 x99 kernel:  ? wake_up_q+0x70/0x70\r\nJan 10 21:57:13 x99 kernel:  ? zio_interrupt+0x1030/0x1030 [zfs]\r\nJan 10 21:57:13 x99 kernel:  kthread+0xf7/0x130\r\nJan 10 21:57:13 x99 kernel:  ? taskq_dispatch_delay+0x2c0/0x950 [spl]\r\nJan 10 21:57:13 x99 kernel:  ? kthread_create_on_node+0x40/0x40\r\nJan 10 21:57:13 x99 kernel:  ? do_group_exit+0x35/0xa0\r\nJan 10 21:57:13 x99 kernel:  ret_from_fork+0x1f/0x30\r\nJan 10 21:57:13 x99 kernel: Code: eb 29 0f b7 43 02 4c 8d 73 02 66 83 f8 ff 74 7f 49 8b 8c 24 d8 00 00 00 41 8b 94 24 d0 00 00 00 49 >\r\nJan 10 21:57:18 x99 systemd[1]: Received SIGINT.\r\n```", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7042/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6976", "title": "PANIC: zfs: allocating allocated segment", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Gentoo\r\nDistribution Version    | profile user customized\r\nLinux Kernel                 | 4.9.69\r\nArchitecture                 | x86_64\r\nZFS Version                  | 0.7.3\r\nSPL Version                  | 0.7.3\r\n\r\n\r\n### Describe the problem you're observing\r\n\r\nKernel panic after starting OS with a force reboot and repete same operation that crashed the system before. I was doing a system upgrade and when calculating dependencies for the upgrade, kernel panic appeared.\r\n\r\nAfter kernel panic system seems to be working normally without doing any action.\r\n```\r\nzpool status -x\r\nall pools are healthy\r\n```\r\n```\r\nzpool status -v\r\n  pool: zfs\r\n state: ONLINE\r\nstatus: Some supported features are not enabled on the pool. The pool can\r\n        still be used, but some features are unavailable.\r\naction: Enable all features using 'zpool upgrade'. Once this is done,\r\n        the pool may no longer be accessible by software that does not support\r\n        the features. See zpool-features(5) for details.\r\n  scan: none requested\r\nconfig:\r\n\r\n        NAME                                                STATE     READ WRITE CKSUM\r\n        zfs                                                 ONLINE       0     0     0\r\n          raidz1-0                                          ONLINE       0     0     0\r\n            ata-TOSHIBA_DT01ACA300_Z5RS6H0KS                ONLINE       0     0     0\r\n            ata-TOSHIBA_HDWD130_678KR5JAS                   ONLINE       0     0     0\r\n            ata-TOSHIBA_DT01ACA300_16QUEEEKS                ONLINE       0     0     0\r\n            ata-TOSHIBA_HDWD130_678KPYLAS                   ONLINE       0     0     0\r\n          raidz1-1                                          ONLINE       0     0     0\r\n            ata-TOSHIBA_HDWD130_678KTDUAS                   ONLINE       0     0     0\r\n            ata-TOSHIBA_DT01ACA300_16QUDE3KS                ONLINE       0     0     0\r\n            ata-WDC_WD40EZRX-75SPEB0_WD-WCC4E2YAA98J-part6  ONLINE       0     0     0\r\n            ata-TOSHIBA_HDWD130_678KPP7AS                   ONLINE       0     0     0\r\n        cache\r\n          sdc                                               ONLINE       0     0     0\r\n          sde                                               ONLINE       0     0     0\r\n\r\nerrors: No known data errors\r\n```\r\n\r\n### Describe how to reproduce the problem\r\n\r\nThis is the configuration of zfs volume that had the bug (using deduplication and lz4 compression):\r\n\r\nNAME   SIZE  ALLOC   FREE  EXPANDSZ   FRAG    CAP  DEDUP  HEALTH  ALTROOT\r\nzfs  21.8T  5.69T  16.1T         -     6%    26%  1.07x  ONLINE  -\r\n  raidz1  10.9T  2.85T  8.03T         -     6%    26%\r\n    ata-TOSHIBA_DT01ACA300_Z5RS6H0KS      -      -      -         -      -      -\r\n    ata-TOSHIBA_HDWD130_678KR5JAS      -      -      -         -      -      -\r\n    ata-TOSHIBA_DT01ACA300_16QUEEEKS      -      -      -         -      -      -\r\n    ata-TOSHIBA_HDWD130_678KPYLAS      -      -      -         -      -      -\r\n  raidz1  10.9T  2.85T  8.03T         -     6%    26%\r\n    ata-TOSHIBA_HDWD130_678KTDUAS      -      -      -         -      -      -\r\n    ata-TOSHIBA_DT01ACA300_16QUDE3KS      -      -      -         -      -      -\r\n    ata-WDC_WD40EZRX-75SPEB0_WD-WCC4E2YAA98J-part6      -      -      -         -      -      -\r\n    ata-TOSHIBA_HDWD130_678KPP7AS      -      -      -         -      -      -\r\ncache      -      -      -         -      -      -\r\n  sdc   699G  79.7M   699G         -     0%     0%\r\n  sde   699G  78.2M   699G         -     0%     0%\r\n\r\ncapacity  |   operations  |   bandwidth  |  total_wait   |  disk_wait  |  syncq_wait  |  asyncq_wait | scrub\r\n\r\npool |  alloc |  free |  read | write |  read | write |  read | write |  read | write  | read | write |  read | write |  wait \r\n  --- |   --- |   --- |   --- |  --- |   --- |  --- |   --- |  --- |   --- |  ---  |  --- |  --- |   --- |  --- |   --- \r\nzfs     |    5.69T | 16.1T  |   81 |   109 |  500K |  950K |   4us  |  1us  |  4us | 543ns | 187ns  |  2ns  |  1us |   1us | 723ns\r\n\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n```\r\n[  335.068216] PANIC: zfs: allocating allocated segment(offset=10858229538816 size=8192)\r\n[  335.068221] Showing stack for process 2019\r\n[  335.068223] CPU: 4 PID: 2019 Comm: txg_sync Tainted: P        W  O    4.9.69-gentoox99 #1\r\n[  335.068224] Hardware name: ASUS All Series/X99-S, BIOS 3402 08/18/2016\r\n[  335.068226]  ffffc9002eff3a48 ffffffff81790587 0000000000000003 ffff880fdcae7800\r\n[  335.068228]  ffffc9002eff3a58 ffffffffa0edf1bd ffffc9002eff3b78 ffffffffa0edf302\r\n[  335.068230]  ffff880ff47eb0c0 6c6c61203a73667a 20676e697461636f 657461636f6c6c61\r\n[  335.068232] Call Trace:\r\n[  335.068238]  [<ffffffff81790587>] dump_stack+0x4d/0x66\r\n[  335.068242]  [<ffffffffa0edf1bd>] spl_dumpstack+0x3d/0x40 [spl]\r\n[  335.068245]  [<ffffffffa0edf302>] vcmn_err+0x52/0xf0 [spl]\r\n[  335.068247]  [<ffffffff8122e27c>] ? __slab_free+0xbc/0x300\r\n[  335.068249]  [<ffffffff8122d97e>] ? kmem_cache_alloc+0x12e/0x1c0\r\n[  335.068251]  [<ffffffffa0eda8be>] ? spl_kmem_cache_alloc+0x5e/0xae0 [spl]\r\n[  335.068252]  [<ffffffff8122e25c>] ? __slab_free+0x9c/0x300\r\n[  335.068255]  [<ffffffffa0dc8616>] ? avl_insert+0xb6/0xd0 [zavl]\r\n[  335.068273]  [<ffffffffa138bcba>] zfs_panic_recover+0x5a/0x60 [zfs]\r\n[  335.068286]  [<ffffffffa13740d7>] range_tree_add+0x167/0x2a0 [zfs]\r\n[  335.068298]  [<ffffffffa1373f70>] ? range_tree_destroy+0x60/0x60 [zfs]\r\n[  335.068300]  [<ffffffff8122e67b>] ? kmem_cache_free+0x1bb/0x1e0\r\n[  335.068311]  [<ffffffffa1373f70>] ? range_tree_destroy+0x60/0x60 [zfs]\r\n[  335.068321]  [<ffffffffa1373f70>] ? range_tree_destroy+0x60/0x60 [zfs]\r\n[  335.068331]  [<ffffffffa1374658>] range_tree_vacate+0x48/0xc0 [zfs]\r\n[  335.068341]  [<ffffffffa1373f70>] ? range_tree_destroy+0x60/0x60 [zfs]\r\n[  335.068354]  [<ffffffffa136ff04>] metaslab_sync_done+0x114/0x6c0 [zfs]\r\n[  335.068369]  [<ffffffffa13938b9>] vdev_sync_done+0x39/0x70 [zfs]\r\n[  335.068382]  [<ffffffffa137d7e3>] spa_sync+0x603/0xfd0 [zfs]\r\n[  335.068384]  [<ffffffff81117d4d>] ? default_wake_function+0xd/0x10\r\n[  335.068402]  [<ffffffffa139032c>] txg_rele_to_sync+0x73c/0x8d0 [zfs]\r\n[  335.068415]  [<ffffffffa1390050>] ? txg_rele_to_sync+0x460/0x8d0 [zfs]\r\n[  335.068417]  [<ffffffffa0edc260>] ? __thread_exit+0x20/0xa0 [spl]\r\n[  335.068419]  [<ffffffffa0edc2cd>] __thread_exit+0x8d/0xa0 [spl]\r\n[  335.068421]  [<ffffffff8110d232>] kthread+0xd2/0xf0\r\n[  335.068423]  [<ffffffff8110d160>] ? kthread_park+0x60/0x60\r\n[  335.068424]  [<ffffffff8110d160>] ? kthread_park+0x60/0x60\r\n[  335.068427]  [<ffffffff81fdb112>] ret_from_fork+0x22/0x30\r\n```", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6976/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ltz3317": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7038", "title": "zfs sync hang ", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       |  centos 7.2 \uff0csync hang\r\nDistribution Version    | \r\nLinux Kernel                 | 3.10.0-327.13.1.el7.x86_64 \r\nArchitecture                 | \r\nZFS Version                  | v0.7.5-1\r\nSPL Version                  |  v0.7.5-1\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\nsync hang \uff0cmysql hang\uff0ckworker cpu 100\r\n### Describe how to reproduce the problem\r\nhigh frequency  create/destroy/clone\r\n### Include any warning/errors/backtraces from the system logs\r\ndmsg:\r\n[  189.990968] Adjusting tsc more than 11% (8039035 vs 7759471)\r\n[ 2522.644734] INFO: task mysqld:6608 blocked for more than 120 seconds.\r\n[ 2522.644790] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2522.644854] mysqld          D 0000000000000000     0  6608   5602 0x00000000\r\n[ 2522.644860]  ffff880feb913da0 0000000000000086 ffff881006eac500 ffff880feb913fd8\r\n[ 2522.644865]  ffff880feb913fd8 ffff880feb913fd8 ffff881006eac500 ffff880fffc8a180\r\n[ 2522.644869]  ffff880fffc8a000 ffff880fffc8a188 ffff880fffc8a028 0000000000000000\r\n[ 2522.644873] Call Trace:\r\n[ 2522.644882]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2522.644906]  [<ffffffffa04744d5>] cv_wait_common+0x125/0x150 [spl]\r\n[ 2522.644911]  [<ffffffff810a6ae0>] ? wake_up_atomic_t+0x30/0x30\r\n[ 2522.644922]  [<ffffffffa0474515>] __cv_wait+0x15/0x20 [spl]\r\n[ 2522.644995]  [<ffffffffa062bd7b>] zil_commit.part.12+0x8b/0x830 [zfs]\r\n[ 2522.645006]  [<ffffffffa046d037>] ? spl_kmem_alloc+0xc7/0x170 [spl]\r\n[ 2522.645017]  [<ffffffffa0475cb4>] ? tsd_set+0x324/0x500 [spl]\r\n[ 2522.645022]  [<ffffffff81639082>] ? mutex_lock+0x12/0x2f\r\n[ 2522.645075]  [<ffffffffa062c537>] zil_commit+0x17/0x20 [zfs]\r\n[ 2522.645128]  [<ffffffffa0621a27>] zfs_fsync+0x77/0xf0 [zfs]\r\n[ 2522.645179]  [<ffffffffa0639665>] zpl_fsync+0x65/0x90 [zfs]\r\n[ 2522.645186]  [<ffffffff8120fa45>] do_fsync+0x65/0xa0\r\n[ 2522.645191]  [<ffffffff8120fd10>] SyS_fsync+0x10/0x20\r\n[ 2522.645196]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2522.645202] INFO: task mysqld:7514 blocked for more than 120 seconds.\r\n[ 2522.645245] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2522.645296] mysqld          D ffff880fb554bda0     0  7514   5602 0x00000000\r\n[ 2522.645299]  ffff880fb554bd30 0000000000000086 ffff880ff4c8f300 ffff880fb554bfd8\r\n[ 2522.645303]  ffff880fb554bfd8 ffff880fb554bfd8 ffff880ff4c8f300 ffff880fb554bdb0\r\n[ 2522.645307]  ffff88107ff8dec0 0000000000000002 ffffffff811f9420 ffff880fb554bda0\r\n[ 2522.645312] Call Trace:\r\n[ 2522.645316]  [<ffffffff811f9420>] ? unlock_two_nondirectories+0x60/0x60\r\n[ 2522.645321]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2522.645324]  [<ffffffff811f942e>] inode_wait+0xe/0x20\r\n[ 2522.645328]  [<ffffffff81638cc0>] __wait_on_bit+0x60/0x90\r\n[ 2522.645335]  [<ffffffff812083bf>] __inode_wait_for_writeback+0xaf/0xf0\r\n[ 2522.645339]  [<ffffffff810a6b60>] ? wake_atomic_t_function+0x40/0x40\r\n[ 2522.645345]  [<ffffffff8120b996>] inode_wait_for_writeback+0x26/0x40\r\n[ 2522.645348]  [<ffffffff811fa135>] evict+0x95/0x170\r\n[ 2522.645351]  [<ffffffff811fa985>] iput+0xf5/0x180\r\n[ 2522.645357]  [<ffffffff811ef41e>] do_unlinkat+0x1ae/0x2b0\r\n[ 2522.645362]  [<ffffffff811e3fe1>] ? SyS_readlinkat+0xd1/0x140\r\n[ 2522.645367]  [<ffffffff811f0426>] SyS_unlink+0x16/0x20\r\n[ 2522.645371]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2522.645402] INFO: task sync:2653 blocked for more than 120 seconds.\r\n[ 2522.645443] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2522.645494] sync            D ffffffff8120f8c0     0  2653   1455 0x00000000\r\n[ 2522.645498]  ffff880ffedd7d50 0000000000000082 ffff880f01449700 ffff880ffedd7fd8\r\n[ 2522.645502]  ffff880ffedd7fd8 ffff880ffedd7fd8 ffff880f01449700 ffff880ffedd7e80\r\n[ 2522.645506]  ffff880ffedd7e88 7fffffffffffffff ffff880f01449700 ffffffff8120f8c0\r\n[ 2522.645509] Call Trace:\r\n[ 2522.645515]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2522.645519]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2522.645523]  [<ffffffff81638b39>] schedule_timeout+0x209/0x2d0\r\n[ 2522.645527]  [<ffffffff8109b426>] ? __queue_work+0x136/0x320\r\n[ 2522.645530]  [<ffffffff8109b6da>] ? __queue_delayed_work+0xaa/0x1a0\r\n[ 2522.645534]  [<ffffffff8109ba41>] ? try_to_grab_pending+0xb1/0x160\r\n[ 2522.645538]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2522.645543]  [<ffffffff8163b216>] wait_for_completion+0x116/0x170\r\n[ 2522.645548]  [<ffffffff810b8c30>] ? wake_up_state+0x20/0x20\r\n[ 2522.645552]  [<ffffffff81208987>] sync_inodes_sb+0xb7/0x1e0\r\n[ 2522.645557]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2522.645561]  [<ffffffff8120f8d9>] sync_inodes_one_sb+0x19/0x20\r\n[ 2522.645565]  [<ffffffff811e2182>] iterate_supers+0xb2/0x110\r\n[ 2522.645570]  [<ffffffff8120fb94>] sys_sync+0x44/0xb0\r\n[ 2522.645575]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2642.739175] INFO: task mysqld:6608 blocked for more than 120 seconds.\r\n[ 2642.739228] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2642.739284] mysqld          D 0000000000000000     0  6608   5602 0x00000000\r\n[ 2642.739290]  ffff880feb913da0 0000000000000086 ffff881006eac500 ffff880feb913fd8\r\n[ 2642.739296]  ffff880feb913fd8 ffff880feb913fd8 ffff881006eac500 ffff880fffc8a180\r\n[ 2642.739300]  ffff880fffc8a000 ffff880fffc8a188 ffff880fffc8a028 0000000000000000\r\n[ 2642.739305] Call Trace:\r\n[ 2642.739315]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2642.739340]  [<ffffffffa04744d5>] cv_wait_common+0x125/0x150 [spl]\r\n[ 2642.739345]  [<ffffffff810a6ae0>] ? wake_up_atomic_t+0x30/0x30\r\n[ 2642.739357]  [<ffffffffa0474515>] __cv_wait+0x15/0x20 [spl]\r\n[ 2642.739434]  [<ffffffffa062bd7b>] zil_commit.part.12+0x8b/0x830 [zfs]\r\n[ 2642.739447]  [<ffffffffa046d037>] ? spl_kmem_alloc+0xc7/0x170 [spl]\r\n[ 2642.739460]  [<ffffffffa0475cb4>] ? tsd_set+0x324/0x500 [spl]\r\n[ 2642.739466]  [<ffffffff81639082>] ? mutex_lock+0x12/0x2f\r\n[ 2642.739526]  [<ffffffffa062c537>] zil_commit+0x17/0x20 [zfs]\r\n[ 2642.739587]  [<ffffffffa0621a27>] zfs_fsync+0x77/0xf0 [zfs]\r\n[ 2642.739647]  [<ffffffffa0639665>] zpl_fsync+0x65/0x90 [zfs]\r\n[ 2642.739654]  [<ffffffff8120fa45>] do_fsync+0x65/0xa0\r\n[ 2642.739659]  [<ffffffff8120fd10>] SyS_fsync+0x10/0x20\r\n[ 2642.739665]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2642.739670] INFO: task mysqld:7514 blocked for more than 120 seconds.\r\n[ 2642.739727] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2642.739793] mysqld          D ffff880fb554bda0     0  7514   5602 0x00000000\r\n[ 2642.739798]  ffff880fb554bd30 0000000000000086 ffff880ff4c8f300 ffff880fb554bfd8\r\n[ 2642.739803]  ffff880fb554bfd8 ffff880fb554bfd8 ffff880ff4c8f300 ffff880fb554bdb0\r\n[ 2642.739808]  ffff88107ff8dec0 0000000000000002 ffffffff811f9420 ffff880fb554bda0\r\n[ 2642.739812] Call Trace:\r\n[ 2642.739818]  [<ffffffff811f9420>] ? unlock_two_nondirectories+0x60/0x60\r\n[ 2642.739823]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2642.739826]  [<ffffffff811f942e>] inode_wait+0xe/0x20\r\n[ 2642.739831]  [<ffffffff81638cc0>] __wait_on_bit+0x60/0x90\r\n[ 2642.739839]  [<ffffffff812083bf>] __inode_wait_for_writeback+0xaf/0xf0\r\n[ 2642.739843]  [<ffffffff810a6b60>] ? wake_atomic_t_function+0x40/0x40\r\n[ 2642.739850]  [<ffffffff8120b996>] inode_wait_for_writeback+0x26/0x40\r\n[ 2642.739854]  [<ffffffff811fa135>] evict+0x95/0x170\r\n[ 2642.739857]  [<ffffffff811fa985>] iput+0xf5/0x180\r\n[ 2642.739862]  [<ffffffff811ef41e>] do_unlinkat+0x1ae/0x2b0\r\n[ 2642.739868]  [<ffffffff811e3fe1>] ? SyS_readlinkat+0xd1/0x140\r\n[ 2642.739873]  [<ffffffff811f0426>] SyS_unlink+0x16/0x20\r\n[ 2642.739878]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2642.739897] INFO: task sync:2653 blocked for more than 120 seconds.\r\n[ 2642.739951] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2642.740017] sync            D ffffffff8120f8c0     0  2653   1455 0x00000000\r\n[ 2642.740021]  ffff880ffedd7d50 0000000000000082 ffff880f01449700 ffff880ffedd7fd8\r\n[ 2642.740026]  ffff880ffedd7fd8 ffff880ffedd7fd8 ffff880f01449700 ffff880ffedd7e80\r\n[ 2642.740031]  ffff880ffedd7e88 7fffffffffffffff ffff880f01449700 ffffffff8120f8c0\r\n[ 2642.740036] Call Trace:\r\n[ 2642.740042]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2642.740047]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2642.740051]  [<ffffffff81638b39>] schedule_timeout+0x209/0x2d0\r\n[ 2642.740056]  [<ffffffff8109b426>] ? __queue_work+0x136/0x320\r\n[ 2642.740060]  [<ffffffff8109b6da>] ? __queue_delayed_work+0xaa/0x1a0\r\n[ 2642.740064]  [<ffffffff8109ba41>] ? try_to_grab_pending+0xb1/0x160\r\n[ 2642.740069]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2642.740093]  [<ffffffff8163b216>] wait_for_completion+0x116/0x170\r\n[ 2642.740100]  [<ffffffff810b8c30>] ? wake_up_state+0x20/0x20\r\n[ 2642.740105]  [<ffffffff81208987>] sync_inodes_sb+0xb7/0x1e0\r\n[ 2642.740110]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2642.740116]  [<ffffffff8120f8d9>] sync_inodes_one_sb+0x19/0x20\r\n[ 2642.740121]  [<ffffffff811e2182>] iterate_supers+0xb2/0x110\r\n[ 2642.740127]  [<ffffffff8120fb94>] sys_sync+0x44/0xb0\r\n[ 2642.740134]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2762.834495] INFO: task mysqld:6608 blocked for more than 120 seconds.\r\n[ 2762.834547] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2762.834604] mysqld          D 0000000000000000     0  6608   5602 0x00000000\r\n[ 2762.834609]  ffff880feb913da0 0000000000000086 ffff881006eac500 ffff880feb913fd8\r\n[ 2762.834615]  ffff880feb913fd8 ffff880feb913fd8 ffff881006eac500 ffff880fffc8a180\r\n[ 2762.834619]  ffff880fffc8a000 ffff880fffc8a188 ffff880fffc8a028 0000000000000000\r\n[ 2762.834624] Call Trace:\r\n[ 2762.834634]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2762.834659]  [<ffffffffa04744d5>] cv_wait_common+0x125/0x150 [spl]\r\n[ 2762.834665]  [<ffffffff810a6ae0>] ? wake_up_atomic_t+0x30/0x30\r\n[ 2762.834677]  [<ffffffffa0474515>] __cv_wait+0x15/0x20 [spl]\r\n[ 2762.834748]  [<ffffffffa062bd7b>] zil_commit.part.12+0x8b/0x830 [zfs]\r\n[ 2762.834761]  [<ffffffffa046d037>] ? spl_kmem_alloc+0xc7/0x170 [spl]\r\n[ 2762.834774]  [<ffffffffa0475cb4>] ? tsd_set+0x324/0x500 [spl]\r\n[ 2762.834779]  [<ffffffff81639082>] ? mutex_lock+0x12/0x2f\r\n[ 2762.834843]  [<ffffffffa062c537>] zil_commit+0x17/0x20 [zfs]\r\n[ 2762.834908]  [<ffffffffa0621a27>] zfs_fsync+0x77/0xf0 [zfs]\r\n[ 2762.834971]  [<ffffffffa0639665>] zpl_fsync+0x65/0x90 [zfs]\r\n[ 2762.834978]  [<ffffffff8120fa45>] do_fsync+0x65/0xa0\r\n[ 2762.834983]  [<ffffffff8120fd10>] SyS_fsync+0x10/0x20\r\n[ 2762.834989]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2762.834994] INFO: task mysqld:7514 blocked for more than 120 seconds.\r\n[ 2762.835051] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2762.835118] mysqld          D ffff880fb554bda0     0  7514   5602 0x00000000\r\n[ 2762.835122]  ffff880fb554bd30 0000000000000086 ffff880ff4c8f300 ffff880fb554bfd8\r\n[ 2762.835127]  ffff880fb554bfd8 ffff880fb554bfd8 ffff880ff4c8f300 ffff880fb554bdb0\r\n[ 2762.835132]  ffff88107ff8dec0 0000000000000002 ffffffff811f9420 ffff880fb554bda0\r\n[ 2762.835137] Call Trace:\r\n[ 2762.835143]  [<ffffffff811f9420>] ? unlock_two_nondirectories+0x60/0x60\r\n[ 2762.835148]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2762.835151]  [<ffffffff811f942e>] inode_wait+0xe/0x20\r\n[ 2762.835156]  [<ffffffff81638cc0>] __wait_on_bit+0x60/0x90\r\n[ 2762.835164]  [<ffffffff812083bf>] __inode_wait_for_writeback+0xaf/0xf0\r\n[ 2762.835168]  [<ffffffff810a6b60>] ? wake_atomic_t_function+0x40/0x40\r\n[ 2762.835175]  [<ffffffff8120b996>] inode_wait_for_writeback+0x26/0x40\r\n[ 2762.835179]  [<ffffffff811fa135>] evict+0x95/0x170\r\n[ 2762.835183]  [<ffffffff811fa985>] iput+0xf5/0x180\r\n[ 2762.835188]  [<ffffffff811ef41e>] do_unlinkat+0x1ae/0x2b0\r\n[ 2762.835195]  [<ffffffff811e3fe1>] ? SyS_readlinkat+0xd1/0x140\r\n[ 2762.835199]  [<ffffffff811f0426>] SyS_unlink+0x16/0x20\r\n[ 2762.835205]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2762.835223] INFO: task sync:2653 blocked for more than 120 seconds.\r\n[ 2762.835277] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2762.835343] sync            D ffffffff8120f8c0     0  2653   1455 0x00000000\r\n[ 2762.835348]  ffff880ffedd7d50 0000000000000082 ffff880f01449700 ffff880ffedd7fd8\r\n[ 2762.835352]  ffff880ffedd7fd8 ffff880ffedd7fd8 ffff880f01449700 ffff880ffedd7e80\r\n[ 2762.835357]  ffff880ffedd7e88 7fffffffffffffff ffff880f01449700 ffffffff8120f8c0\r\n[ 2762.835362] Call Trace:\r\n[ 2762.835369]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2762.835374]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2762.835378]  [<ffffffff81638b39>] schedule_timeout+0x209/0x2d0\r\n[ 2762.835382]  [<ffffffff8109b426>] ? __queue_work+0x136/0x320\r\n[ 2762.835386]  [<ffffffff8109b6da>] ? __queue_delayed_work+0xaa/0x1a0\r\n[ 2762.835390]  [<ffffffff8109ba41>] ? try_to_grab_pending+0xb1/0x160\r\n[ 2762.835396]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2762.835409]  [<ffffffff8163b216>] wait_for_completion+0x116/0x170\r\n[ 2762.835417]  [<ffffffff810b8c30>] ? wake_up_state+0x20/0x20\r\n[ 2762.835422]  [<ffffffff81208987>] sync_inodes_sb+0xb7/0x1e0\r\n[ 2762.835427]  [<ffffffff8120f8c0>] ? generic_write_sync+0x60/0x60\r\n[ 2762.835433]  [<ffffffff8120f8d9>] sync_inodes_one_sb+0x19/0x20\r\n[ 2762.835438]  [<ffffffff811e2182>] iterate_supers+0xb2/0x110\r\n[ 2762.835443]  [<ffffffff8120fb94>] sys_sync+0x44/0xb0\r\n[ 2762.835451]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 2882.929813] INFO: task mysqld:6608 blocked for more than 120 seconds.\r\n[ 2882.929861] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[ 2882.929913] mysqld          D 0000000000000000     0  6608   5602 0x00000000\r\n[ 2882.929919]  ffff880feb913da0 0000000000000086 ffff881006eac500 ffff880feb913fd8\r\n[ 2882.929924]  ffff880feb913fd8 ffff880feb913fd8 ffff881006eac500 ffff880fffc8a180\r\n[ 2882.929928]  ffff880fffc8a000 ffff880fffc8a188 ffff880fffc8a028 0000000000000000\r\n[ 2882.929932] Call Trace:\r\n[ 2882.929942]  [<ffffffff8163ae49>] schedule+0x29/0x70\r\n[ 2882.929967]  [<ffffffffa04744d5>] cv_wait_common+0x125/0x150 [spl]\r\n[ 2882.929972]  [<ffffffff810a6ae0>] ? wake_up_atomic_t+0x30/0x30\r\n[ 2882.929983]  [<ffffffffa0474515>] __cv_wait+0x15/0x20 [spl]\r\n[ 2882.930049]  [<ffffffffa062bd7b>] zil_commit.part.12+0x8b/0x830 [zfs]\r\n[ 2882.930059]  [<ffffffffa046d037>] ? spl_kmem_alloc+0xc7/0x170 [spl]\r\n[ 2882.930070]  [<ffffffffa0475cb4>] ? tsd_set+0x324/0x500 [spl]\r\n[ 2882.930075]  [<ffffffff81639082>] ? mutex_lock+0x12/0x2f\r\n[ 2882.930129]  [<ffffffffa062c537>] zil_commit+0x17/0x20 [zfs]\r\n[ 2882.930181]  [<ffffffffa0621a27>] zfs_fsync+0x77/0xf0 [zfs]\r\n[ 2882.930232]  [<ffffffffa0639665>] zpl_fsync+0x65/0x90 [zfs]\r\n[ 2882.930238]  [<ffffffff8120fa45>] do_fsync+0x65/0xa0\r\n[ 2882.930243]  [<ffffffff8120fd10>] SyS_fsync+0x10/0x20\r\n[ 2882.930248]  [<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[ 4802.367346] perf interrupt took too long (2507 > 2500), lowering kernel.perf_event_max_sample_rate to 50000\r\n\r\nsync process stack:\r\n[<ffffffff81208987>] sync_inodes_sb+0xb7/0x1e0\r\n[<ffffffff8120f8d9>] sync_inodes_one_sb+0x19/0x20\r\n[<ffffffff811e2182>] iterate_supers+0xb2/0x110\r\n[<ffffffff8120fb94>] sys_sync+0x44/0xb0\r\n[<ffffffff81645ec9>] system_call_fastpath+0x16/0x1b\r\n[<ffffffffffffffff>] 0xffffffffffffffff\r\n\r\nkworker process stack:\r\n cat /proc/3445/stack \r\n[<ffffffffa058feb5>] dmu_zfetch+0x455/0x4f0 [zfs]\r\n[<ffffffffa05711ea>] dbuf_read+0x8ea/0x9f0 [zfs]\r\n[<ffffffffa0591246>] dnode_hold_impl+0xc6/0xc30 [zfs]\r\n[<ffffffffffffffff>] 0xffffffffffffffff\r\n\r\ncat /proc/3445/stack \r\n[<ffffffffffffffff>] 0xffffffffffffffff\r\n[root@ifcos ~]# cat /proc/3445/stack \r\n[<ffffffffa062879c>] zfs_zget+0xfc/0x250 [zfs]\r\n[<ffffffffa0623db7>] zfs_get_data+0x57/0x2d0 [zfs]\r\n[<ffffffffa062c10c>] zil_commit.part.12+0x41c/0x830 [zfs]\r\n[<ffffffffa062c537>] zil_commit+0x17/0x20 [zfs]\r\n[<ffffffffa06394b6>] zpl_writepages+0xd6/0x170 [zfs]\r\n[<ffffffff811759fe>] do_writepages+0x1e/0x40\r\n[<ffffffff812084e0>] __writeback_single_inode+0x40/0x220\r\n[<ffffffff81208f4e>] writeback_sb_inodes+0x25e/0x420\r\n[<ffffffff8120988f>] wb_writeback+0xff/0x2f0\r\n[<ffffffff8120bac5>] bdi_writeback_workfn+0x115/0x460\r\n[<ffffffff8109d5fb>] process_one_work+0x17b/0x470\r\n[<ffffffff8109e3cb>] worker_thread+0x11b/0x400\r\n[<ffffffff810a5aef>] kthread+0xcf/0xe0\r\n[<ffffffff81645e18>] ret_from_fork+0x58/0x90\r\n[<ffffffffffffffff>] 0xffffffffffffffff\r\n\r\n cat /proc/3445/stack \r\n[<ffffffffa058feb5>] dmu_zfetch+0x455/0x4f0 [zfs]\r\n[<ffffffffa0572fd5>] __dbuf_hold_impl+0x135/0x5a0 [zfs]\r\n[<ffffffffffffffff>] 0xffffffffffffffff\r\n\r\n cat /proc/3445/stack \r\n[<ffffffffa056fa69>] dbuf_find+0x1c9/0x1d0 [zfs]\r\n[<ffffffffa0572ee2>] __dbuf_hold_impl+0x42/0x5a0 [zfs]\r\n[<ffffffffffffffff>] 0xffffffffffffffff\r\n\r\n cat /proc/3445/stack \r\n[<ffffffffa058feb5>] dmu_zfetch+0x455/0x4f0 [zfs]\r\n[<ffffffffa0571056>] dbuf_read+0x756/0x9f0 [zfs]\r\n[<ffffffffa0591246>] dnode_hold_impl+0xc6/0xc30 [zfs]\r\n\r\n<!-- \r\n*IMPORTANT* - Please mark logs and text output from terminal commands \r\nor else Github will not display them correctly. \r\nAn example is provided below.\r\n\r\nExample:\r\n```\r\nthis is an example how log text should be marked (wrap it with ```)\r\n```\r\n-->\r\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7038/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "sempervictus": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7035", "title": "Consider adding mitigations for speculative execution related concerns", "body": "GCC should get retpoline support soon, and Intel seems to be proposing kernel code with barriers to speculative execution - https://patchwork.ozlabs.org/cover/856316/. ZFS is already pretty unhappy from KPTI, but since there's a good deal of user controlled data going into it, this might be worth investigating.", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7035/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "abraunegg": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7034", "title": "Missing parameter descriptions in ZFS-Module-Parameters man page", "body": "The following zfs module parameters are missing from the zfs-module-parameters man page (updated 28th Oct 2017) using ZFS 0.7.5:\r\n\r\n* dbuf_cache_hiwater_pct\r\n* dbuf_cache_lowater_pct\r\n* dbuf_cache_max_bytes\r\n* dbuf_cache_max_shift\r\n* dmu_object_alloc_chunk_shift\r\n* send_holes_without_birth_time\r\n* zfs_abd_scatter_enabled\r\n* zfs_abd_scatter_max_order\r\n* zfs_compressed_arc_enabled\r\n* zfs_sync_taskq_batch_pct\r\n\r\nHappy to create a documentation patch for the man pages if someone can send me the a description of what the module parameter is, what the default should be and what valid options are if it is being changed.\r\n\r\nBest regards,\r\n\r\nAlex", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7034/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "rincebrain": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7024", "title": "zfs send -R | zfs recv can fail in the middle due to a snapshot being taken", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Debian\r\nDistribution Version    | 9.3\r\nLinux Kernel                 | 4.9.0-4-amd64\r\nArchitecture                 | amd64\r\nZFS Version                  | 0.7.3-3\r\nSPL Version                  | 0.7.3-1\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing + how to reproduce the problem\r\nWhen doing a long-running `zfs send -R foo/bar/baz@ten | zfs recv -ds newfoo`, an automated utility helpfully took a recursive snapshot on newfoo, and zfs recv abruptly died with `cannot receive incremental stream: kernel modules must be upgraded to receive this stream.` with newfoo/bar/baz having completed snapshots one, ..., seven and throwing that error on attempting to resume.\r\n\r\nI would have expected the in-progress receiving dataset(s) to have remained immutable until the receives were completed, but apparently this isn't the case.\r\n\r\nDestroying the errant snapshot on newfoo/bar/baz allowed the zfs send to proceed like nothing ever happened.\r\n\r\nSince there's already a number of bugs suggesting that this message should be broken out and detailed further (#6547, #6574), this bug is mostly about the fact that nothing is stopping you from shooting yourself in the foot and not being able to discover why without making dramatic leaps or (presumably) reading zfs/dbgmsg.", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7024/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "h1z1": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7015", "title": "Impact of Intel bug (tm) on ZFS", "body": "Maybe the wrong avenue for this but no doubt like others watching the events of the last few days unfold, I've been asked to comment on the impact to ZFS in our environment.   I'm in a rather odd position as I don't really have the hardware to duplicate an entire production silo, running 4.15.x kernel.   I do however know at least 4.14 will bite us as per #6929.  \r\n\r\nHas anyone tested or confirmed what the impact of this will be going forward?  Would rather not duplicate effort if it's already being addressed.\r\n\r\nThanks", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7015/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "sanjeevbagewadi": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7011", "title": "With \"casesensitivity=mixed\" hitting an assert in ZAP code", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | CentOS release 6.8 (Final)\r\n  ---                                  |     --- \r\nDistribution Name       | CentOS\r\nDistribution Version    | 6.8\r\nLinux Kernel                 | 4.4.14-1.el6\r\nArchitecture                 | x86\r\nZFS Version                  | 0.7.1-1\r\nSPL Version                  |  0.7.1-1\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\n\r\nWith casesensitivity=mixed was running the following test :\r\nroot@NTNX-10-5-137-31-A-FSVM:/home/nutanix# cat names.py\r\n#!/usr/bin/python\r\nimport itertools\r\ns=\"abcdefghijklmnopqrstuvwxyz\"\r\nlength = len(s)\r\nnames = map(''.join, itertools.product(*zip(s.upper(), s.lower())))\r\nfor name in names:\r\n    print name\r\n\r\nroot@NTNX-10-5-137-31-A-FSVM:/home/nutanix# ./names.py | while read file\r\n> do\r\n> touch /test/fs2/dir1/$file\r\n> done\r\n\r\nAnd hit the following panic \r\n-- snip --\r\n[    1.068019] VERIFY(!RW_LOCK_HELD(&l->l_rwlock)) failed\r\n[    1.068077] PANIC at zap.c:407:zap_leaf_evict_sync()\r\n[    1.068113] Showing stack for process 67625\r\n[    1.068116] CPU: 0 PID: 67625 Comm: touch Tainted: P           OE   4.4.14-1.el6.nutanix.10272016.x86_64 #1\r\n[    1.068117] Hardware name: Nutanix AHV, BIOS seabios-1.7.5-11.el6 04/01/2014\r\n[    1.068122]  0000000000000000 ffff88015312b2a8 ffffffff81319ae3 0000000000000001\r\n[    1.068125]  0000000100480b8b ffff88015312b2f8 ffffffffa0b5a9c0 ffff88015312b2b8\r\n[    1.068127]  ffffffffa09918c4 ffff88015312b458 ffffffffa0991aeb 0000000000000040\r\n[    1.068129] Call Trace:\r\n[    1.068136]  [<ffffffff81319ae3>] dump_stack+0x67/0x94\r\n[    1.068146]  [<ffffffffa09918c4>] spl_dumpstack+0x44/0x50 [spl]\r\n[    1.068150]  [<ffffffffa0991aeb>] spl_panic+0xcb/0xe0 [spl]\r\n[    1.068153]  [<ffffffff8132a483>] ? __sg_free_table+0x63/0x90\r\n[    1.068157]  [<ffffffff811e447e>] ? kmem_cache_free+0x1ee/0x210\r\n[    1.068160]  [<ffffffffa098d477>] ? spl_kmem_cache_free+0x117/0x140 [spl]\r\n[    1.068200]  [<ffffffffa0a46ecc>] ? arc_hdr_destroy+0x17c/0x1d0 [zfs]\r\n[    1.068231]  [<ffffffffa0acf457>] zap_leaf_evict_sync+0x57/0x60 [zfs]\r\n[    1.068248]  [<ffffffffa0a4d575>] dbuf_evict_user+0x45/0x70 [zfs]\r\n[    1.068265]  [<ffffffffa0a4f95f>] dbuf_destroy+0x4f/0x330 [zfs]\r\n[    1.068282]  [<ffffffffa0a4f561>] dbuf_rele_and_unlock+0x221/0x3e0 [zfs]\r\n[    1.068313]  [<ffffffffa0ad514f>] ? zap_lockdir+0x7f/0xa0 [zfs]\r\n[    1.068344]  [<ffffffffa0ad15e6>] ? zap_grow_ptrtbl+0x186/0x1a0 [zfs]\r\n[    1.068361]  [<ffffffffa0a4f900>] dbuf_rele+0x40/0x50 [zfs]\r\n[    1.068394]  [<ffffffffa0a4fd1e>] dmu_buf_rele+0xe/0x10 [zfs]\r\n[    1.068427]  [<ffffffffa0acf3dd>] zap_put_leaf+0x3d/0x60 [zfs]\r\n[    1.068460]  [<ffffffffa0ad16c7>] zap_put_leaf_maybe_grow_ptrtbl+0xc7/0x130 [zfs]\r\n[    1.068492]  [<ffffffffa0ad1be8>] fzap_add_cd+0xd8/0x130 [zfs]\r\n[    1.068541]  [<ffffffffa0ad4ce4>] mzap_upgrade+0x194/0x210 [zfs]\r\n[    1.068593]  [<ffffffffa0ad4fba>] zap_lockdir_impl+0x25a/0x370 [zfs]\r\n[    1.068628]  [<ffffffffa0ad514f>] zap_lockdir+0x7f/0xa0 [zfs]\r\n[    1.068664]  [<ffffffffa0ad695b>] zap_add+0x5b/0xa0 [zfs]\r\n[    1.068668]  [<ffffffff810ca871>] ? __raw_callee_save___pv_queued_spin_unlock+0x11/0x20\r\n[    1.068703]  [<ffffffffa0adfcbf>] zfs_link_create+0x37f/0x520 [zfs]\r\n[    1.068761]  [<ffffffffa0b00b2a>] zfs_create+0x62a/0x810 [zfs]\r\n[    1.068764]  [<ffffffff811e76f6>] ? __kmalloc_node+0x1f6/0x2b0\r\n[    1.068798]  [<ffffffffa0b19bf2>] zpl_create+0xb2/0x160 [zfs]\r\n[    1.068802]  [<ffffffff81210424>] vfs_create+0xd4/0x100\r\n[    1.068804]  [<ffffffff8120dc4d>] ? lookup_real+0x1d/0x60\r\n[    1.068806]  [<ffffffff812111e3>] lookup_open+0x173/0x1a0\r\n[    1.068808]  [<ffffffff812138d9>] do_last+0x299/0x760\r\n[    1.068811]  [<ffffffff812056d7>] ? get_empty_filp+0xd7/0x1c0\r\n[    1.068813]  [<ffffffff81213e1c>] path_openat+0x7c/0x140\r\n[    1.068832]  [<ffffffff811b53c2>] ? __pte_alloc+0xe2/0x190\r\n[    1.068834]  [<ffffffff81213f65>] do_filp_open+0x85/0xe0\r\n[    1.068836]  [<ffffffff8120eade>] ? getname_flags+0xce/0x1f0\r\n[    1.068838]  [<ffffffff8120311a>] do_sys_open+0x11a/0x220\r\n[    1.068842]  [<ffffffff81003513>] ? syscall_trace_enter_phase1+0x133/0x150\r\n[    1.068844]  [<ffffffff8120325e>] SyS_open+0x1e/0x20\r\n[    1.068850]  [<ffffffff816cf76e>] entry_SYSCALL_64_fastpath+0x12/0x71\r\n-- snip --\r\n\r\n### Describe how to reproduce the problem\r\n\r\nThe following are the steps\\:\r\n- Create zfs dataset with casesensitivity=mixed\r\n- Run the above listed code.\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n<!-- \r\n*IMPORTANT* - Please mark logs and text output from terminal commands \r\nor else Github will not display them correctly. \r\nAn example is provided below.\r\n\r\nExample:\r\n```\r\nthis is an example how log text should be marked (wrap it with ```)\r\n```\r\n-->", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7011/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/7054", "title": "Handle zap_add() failures in \"casesensitivity=mixed\" mode.", "body": "With \"casesensitivity=mixed\", zap_add() could fail when the number of\r\nfiles/directories with the same name (varying in case) exceed the\r\ncapacity of the leaf node of a Fatzap. This results in a ASSERT()\r\nfailure as zfs_link_create() does not expect zap_add() to fail. The fix\r\nis to handle these failures and rollback the transactions.\r\n\r\nSigned-off-by: Sanjeev Bagewadi <sanjeev.bagewadi@gmail.com>\r\n\r\n<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\nFor a dataset with \"casesensitivity=mixed\", when a large number of files/directories\r\nwith same name (varying only in case e.g: ABCD, ABCd, ABcD and so on) are created\r\nzap_add() could fail. With mixed mode zap_add() normalises the names before the hash\r\nis computed. And all the names would generate the same hash and land in the same leaf.\r\nWhen the number of entries exceed the capacity of the leaf-block, zap_add() tries to split\r\nthe leaf-block which fails as well and zap_add() fails. This trips an ASSERT in zfs_link_create()\r\nas it does not expect zap_add() to fail.\r\n\r\nThe fix does the following :\r\n- fzap_add_cd() : Handle the case when zap_expand_leaf() fails with ENOSPC and bailout\r\n   without calling zap_put_leaf_maybe_grow_ptrtbl(). \r\n- zap_add_impl() : When adding to a micro-zap check if the total number of entries\r\n  with colliding/same hash value can fit into fatzap-leaf-block. This is important because, if/when\r\n  the microzap needs to be upgraded to fatzap, all the entries with the same hash would need to\r\n  fit into the same leaf-block (16K). If the number of such entries donot fit fail the zap_add().\r\n  \r\n   The routine mze_canfit_fzap_leaf() today assumes the MZAP_NAME_LEN for every entry.\r\n   This is erring on the safer side but, ends up accommodating lesser number (127) of entries\r\n    with same hash value in microzap. We could find out the size of name of every mze and that\r\n    would be accurate. But, it is expensive to compute the length every time. Alternatively, we\r\n    could compute the length of each entry and cache it. I felt that the amount of code needed\r\n    for this is not worth the gain. I am open to changing it if necessary.\r\n\r\n- zfs_link_create() : Move the call to zap_add() to the beginning and in case of a failure\r\n  return. This ensures that we can bailout easily before making any other modifications to\r\n  the parent-zap or the child-dnode. Keeps the code simpler.\r\n- ZPL interfaces (zfs_create(), zfs_mkdir(), zfs_symlink()) : Handle the failure of zfs_link_create()\r\n  and rollback the operation.\r\n\r\nWith these changes a call to create a file could fail with ENOSPC. Not the best error value.\r\nBut, this is the closest I found. Any alternate suggestions are welcome.\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\nWith \"casesensitivity=mixed\" it is easy to panic the node with a simple test case\r\nas described in https://github.com/zfsonlinux/zfs/issues/7011\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\nThe following tests were run : \r\n- zfs-testsuite\r\n- ztest\r\n- Unit-test described in the #7011 \r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [x] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "woffs": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7003", "title": "autoreplace = on, but spare not automatically activated on drive error", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Debian\r\nDistribution Version    | Stretch (9)\r\nLinux Kernel                 | 4.9.51\r\nArchitecture                 | x86_64\r\nZFS Version                  | 0.7.3\r\nSPL Version                  | 0.7.3\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\n \r\nA disk was failing, zed reported errors ...\r\n\r\n```\r\nZFS has detected that a device was removed.\r\n\r\n impact: Fault tolerance of the pool may be compromised.\r\n    eid: 71656\r\n  class: statechange\r\n  state: REMOVED\r\n   host: inferno\r\n   time: 2017-12-29 19:57:19+0100\r\n  vpath: /dev/disk/by-vdev/E2-part1\r\n  vguid: 0x8F23CA44FDEBE82C\r\n   pool: 0x83BBC476EFE065A2\r\n```\r\n\r\n```\r\nThe number of I/O errors associated with a ZFS device exceeded\r\nacceptable levels. ZFS has marked the device as faulted.\r\n\r\n impact: Fault tolerance of the pool may be compromised.\r\n    eid: 71662\r\n  class: statechange\r\n  state: FAULTED\r\n   host: inferno\r\n   time: 2017-12-29 19:57:19+0100\r\n  vpath: /dev/disk/by-vdev/E2-part1\r\n  vguid: 0x8F23CA44FDEBE82C\r\n   pool: 0x83BBC476EFE065A2\r\n```\r\n\r\n... but the spare was not activated automatically, although the autoreplace property was set to `on`.\r\n\r\n```\r\n        inferno# zpool status\r\n  [...]\r\n                pool: torx\r\n         state: DEGRADED\r\n        status: One or more devices are faulted in response to persistent errors.\r\n                Sufficient replicas exist for the pool to continue functioning in a\r\n                degraded state.\r\n        action: Replace the faulted device, or use 'zpool clear' to mark the device\r\n                repaired.\r\n                scan: scrub repaired 0B in 188h32m with 0 errors on Sun Dec 17 20:56:54 2017\r\n        config:\r\n\r\n                NAME        STATE     READ WRITE CKSUM\r\n                torx        DEGRADED     0     0     0\r\n                        raidz2-0  DEGRADED     0     0     0\r\n                                E0      ONLINE       0     0     0\r\n                                E1      ONLINE       0     0     0\r\n                                E2      FAULTED      0     0     0  too many errors\r\n                                E3      ONLINE       0     0     0\r\n                                E4      ONLINE       0     0     0\r\n                                E5      ONLINE       0     0     0\r\n                                E6      ONLINE       0     0     0\r\n                                E7      ONLINE       0     0     0\r\n                                E8      ONLINE       0     0     0\r\n                                E9      ONLINE       0     0     0\r\n                spares\r\n                        EA        AVAIL\r\n\r\n        errors: No known data errors\r\n```\r\n\r\nAfter manually issuing `zpool replace torx E2 EA` the resilver to the spare started.\r\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7003/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "krichter722": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7002", "title": "\"VERIFY3(range_tree_space(rt) == space) failed\" after I/O freeze", "body": "### System information\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Ubuntu\r\nDistribution Version    | 17.10\r\nLinux Kernel                 | 4.13.0-21-generic\r\nArchitecture                 | amd64\r\nZFS Version                  | 0.7.0-227_g823d48bfb\r\nSPL Version                  | 0.7.0-22_gc9821f1c\r\n\r\n### Describe the problem you're observing\r\nMy pool consisting of 1 HDD vdev and 1 SSD cache and 1 SSD log device experienced an I/O freeze under heavy load including heavy dedup action (parallel checkout and building of Firefox on docker images) where all commands doing I/O on the pool switched to uninterruptible state and no I/O occured anymore according to `iotop`.\r\n\r\nAfter starting the machine again I'm no longer able to import the pool because the `zpool import` command never returns and after a few seconds of reading a few 100 MB the I/O stops and the stack below is printed in `dmesg`.\r\n\r\nA readonly import is possible. `zfs set mountpoint=none data/docker` fails due to `internal error: out of memory` immediately without any noticable memory issues.\r\n\r\n### Describe how to reproduce the problem\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\nThe I/O freeze was caused by\r\n\r\n```\r\n[27969.280956] VERIFY3(range_tree_space(rt) == space) failed (6922371072 == 6922383360)\r\n[27969.280960] PANIC at space_map.c:127:space_map_load()\r\n[27969.280961] Showing stack for process 13639\r\n[27969.280963] CPU: 5 PID: 13639 Comm: z_wr_iss Tainted: P        W  OE   4.13.0-21-generic #24-Ubuntu\r\n[27969.280964] Hardware name: LENOVO 20221/INVALID, BIOS 71CN51WW(V1.21) 07/12/2013\r\n[27969.280964] Call Trace:\r\n[27969.280970]  dump_stack+0x63/0x8b\r\n[27969.280979]  spl_dumpstack+0x42/0x50 [spl]\r\n[27969.280982]  spl_panic+0xc8/0x110 [spl]\r\n[27969.280985]  ? kmem_cache_free+0x197/0x1c0\r\n[27969.280988]  ? avl_add+0x65/0xb0 [zavl]\r\n[27969.281027]  ? rt_avl_add+0x11/0x20 [zfs]\r\n[27969.281054]  ? range_tree_add_impl+0x2f5/0x440 [zfs]\r\n[27969.281078]  ? dnode_rele+0x39/0x40 [zfs]\r\n[27969.281108]  space_map_load+0x470/0x4f0 [zfs]\r\n[27969.281109]  ? avl_nearest+0x2b/0x30 [zavl]\r\n[27969.281136]  metaslab_load+0x36/0xf0 [zfs]\r\n[27969.281162]  metaslab_activate+0x93/0xc0 [zfs]\r\n[27969.281186]  metaslab_alloc+0x4b9/0x1170 [zfs]\r\n[27969.281217]  zio_dva_allocate+0xac/0x630 [zfs]\r\n[27969.281245]  ? zio_execute+0x8a/0xf0 [zfs]\r\n[27969.281274]  ? vdev_config_sync+0x180/0x180 [zfs]\r\n[27969.281301]  ? vdev_mirror_io_start+0xa4/0x180 [zfs]\r\n[27969.281305]  ? tsd_hash_search.isra.3+0x47/0xa0 [spl]\r\n[27969.281308]  ? tsd_get_by_thread+0x2e/0x40 [spl]\r\n[27969.281311]  ? taskq_member+0x18/0x30 [spl]\r\n[27969.281340]  zio_execute+0x8a/0xf0 [zfs]\r\n[27969.281343]  taskq_thread+0x2aa/0x4d0 [spl]\r\n[27969.281345]  ? wake_up_q+0x80/0x80\r\n[27969.281373]  ? zio_reexecute+0x3e0/0x3e0 [zfs]\r\n[27969.281375]  kthread+0x125/0x140\r\n[27969.281378]  ? taskq_thread_should_stop+0x70/0x70 [spl]\r\n[27969.281379]  ? kthread_create_on_node+0x70/0x70\r\n[27969.281382]  ret_from_fork+0x25/0x30\r\n```\r\nwhich I captured before having to shutdown the machine with the power button. After every reboot the import fails due to\r\n\r\n```\r\n[  274.685568]  dump_stack+0x63/0x8b\r\n[  274.685575]  spl_dumpstack+0x42/0x50 [spl]\r\n[  274.685578]  spl_panic+0xc8/0x110 [spl]\r\n[  274.685581]  ? kmem_cache_free+0x197/0x1c0\r\n[  274.685583]  ? avl_add+0x65/0xb0 [zavl]\r\n[  274.685619]  ? rt_avl_add+0x11/0x20 [zfs]\r\n[  274.685645]  ? range_tree_add_impl+0x2f5/0x440 [zfs]\r\n[  274.685667]  ? dnode_rele+0x39/0x40 [zfs]\r\n[  274.685694]  space_map_load+0x470/0x4f0 [zfs]\r\n[  274.685720]  metaslab_load+0x36/0xf0 [zfs]\r\n[  274.685743]  metaslab_activate+0x93/0xc0 [zfs]\r\n[  274.685766]  metaslab_alloc+0x4b9/0x1170 [zfs]\r\n[  274.685794]  zio_dva_allocate+0xac/0x630 [zfs]\r\n[  274.685795]  ? mutex_lock+0x12/0x40\r\n[  274.685799]  ? tsd_hash_search.isra.3+0x47/0xa0 [spl]\r\n[  274.685802]  ? tsd_get_by_thread+0x2e/0x40 [spl]\r\n[  274.685805]  ? taskq_member+0x18/0x30 [spl]\r\n[  274.685832]  zio_execute+0x8a/0xf0 [zfs]\r\n[  274.685835]  taskq_thread+0x2aa/0x4d0 [spl]\r\n[  274.685837]  ? wake_up_q+0x80/0x80\r\n[  274.685864]  ? zio_reexecute+0x3e0/0x3e0 [zfs]\r\n[  274.685865]  kthread+0x125/0x140\r\n[  274.685869]  ? taskq_thread_should_stop+0x70/0x70 [spl]\r\n[  274.685870]  ? kthread_create_on_node+0x70/0x70\r\n[  274.685871]  ret_from_fork+0x25/0x30\r\n```\r\nalso after a successful readonly import.", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/7002/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "redzhang1990": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6995", "title": "Can ZFS support numa binding?", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Redhat\r\nDistribution Version    | 7.4\r\nLinux Kernel                 | 4.11.0\r\nArchitecture                 | ARM\r\nZFS Version                  | 0.7.1\r\nSPL Version                  | 0.7.1\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\nCan the ZFS support or willing support numa binding?\r\n### Describe how to reproduce the problem\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n<!-- \r\n*IMPORTANT* - Please mark logs and text output from terminal commands \r\nor else Github will not display them correctly. \r\nAn example is provided below.\r\n\r\nExample:\r\n```\r\n```\r\n-->\r\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6995/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "fejesjoco": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6994", "title": "Documentation of ACLs should be fixed", "body": "There are issues in the manpage of zfs(8).\r\n\r\naclinherit talks about ACEs, acltype talks about ACLs, this is inconsistent.\r\n\r\naclinherit doesn't mention what kind of ACEs it's talking about. Since neither regular file permission bits not POSIX ACLs have write_acl/write_owner, this must be NFSv4. So that should be mentioned here explicitly.\r\n\r\nacltype has two values. Again this doesn't say what it's talking about and one can only guess. Does \"off\" turn off both NFSv4 and POSIX ACLs, or just POSIX? Does \"posixacl\" enable both NFSv4 and POSIX, or only POSIX? I can even read it in a way that I can either have POSIX ACLs or no ACLs, which would mean NFSv4 ACLs are not even supported under Linux.\r\n\r\nThe source code has many mentions of an aclmode property but this is not documented anywhere.\r\n\r\nSince the document talks about multiple ACL types, it might be worth mentioning if regular file permission bits work as usual or not (this is especially interesting across dataset mount boundaries).\r\n\r\nIf you can confirm these points, I can volunteer to send a PR.", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6994/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "dechamps": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6988", "title": "zil_itx_needcopy_bytes kstat counter is corrupted", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Debian\r\nDistribution Version    | Unstable\r\nLinux Kernel                 | 4.13.0-1-amd64\r\nArchitecture                 | amd64\r\nZFS Version                  | 0.7.3-3\r\nSPL Version                  | 0.7.3-1\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\n\r\n```\r\n$ cat /proc/spl/kstat/zfs/zil\r\n15 1 0x01 13 624 31503034653 382758011634377\r\nname                            type data\r\nzil_commit_count                4    197902\r\nzil_commit_writer_count         4    197884\r\nzil_itx_count                   4    611431070\r\nzil_itx_indirect_count          4    0\r\nzil_itx_indirect_bytes          4    0\r\nzil_itx_copied_count            4    0\r\nzil_itx_copied_bytes            4    0\r\nzil_itx_needcopy_count          4    611266365\r\nzil_itx_needcopy_bytes          4    18446744072731425348\r\nzil_itx_metaslab_normal_count   4    0\r\nzil_itx_metaslab_normal_bytes   4    0\r\nzil_itx_metaslab_slog_count     4    1169526\r\nzil_itx_metaslab_slog_bytes     4    140983216376\r\n```\r\n\r\nThe `zil_itx_needcopy_bytes` counter is blatantly wrong - I'm pretty sure I did not write 16 exabytes of data in that pool :) Its value is quite close to `UINT64_MAX`, which suggests some kind of overflow or memory corruption.\r\n\r\n### Describe how to reproduce the problem\r\n\r\nNot sure. However I can tell that it started after I did a system upgrade, which included the following version changes:\r\n\r\n- Kernel: 4.12 \u2192 4.13\r\n- SPL: 0.6.5 \u2192 0.7.3\r\n- ZFS: 0.6.5 \u2192 0.7.3\r\n\r\nFor this reason I suspect this might be a regression introduced between SPL/ZFS 0.6.5 and SPL/ZFS 0.7.3.\r\n\r\nThis issue might seem benign, but in my case it's really not because it prevents [Prometheus Node exporter](https://github.com/prometheus/node_exporter) from exporting ZFS metrics correctly. Here's the log message from the node exporter in an attempt to make this issue easier to search for:\r\n\r\n```\r\ntime=\"2017-12-20T22:32:39Z\" level=error msg=\"ERROR: zfs collector failed after 0.000693s: could not parse expected integer value for \\\"kstat.zfs.misc.zil.zil_itx_needcopy_bytes\\\"\" source=\"node_exporter.go:95\"\r\n```", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6988/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374490", "body": "Hmmm\u2026 in fact this line is supposed to be in pull request #384. Seems like I seriously screwed up while doing the merges: all my pull requests show the same commits. What a mess\u2026 git is new to me, I guess this was bound to happen. There should be only one commit in this pull request: 90e1b2108f3b8fd3d2b92bdaa4775fe2321cffa3, so if you're just interested in ZVOL synchronicity, you should check it out. I'm not sure how to fix this, I guess I'll have to recreate the pull requests.\n\nFYI, in the context of #384, this comment means that maybe the discard operation should be added to the log. This is not very important since losing discard operations cannot result in data corruption.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374490/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374498", "body": "That's what I did, basically; the problem is, when updating my master branch from upstream I guessed it would be a good idea to also update individual pull request branches from my master branch. Alas, it was a very bad idea, because my master branch add commits from all my pull requests, so by merging master into each pull request, I merged all commits from all pull requests into each pull request, hence the mess. In the future I'll just let my pull requests alone when I'm done with them.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374498/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374511", "body": "I never commited anything to my master branch, just merges. I wrote the pull request's code into the appropriate pull request branches, as I should. The issue is, I was merging master into my pull requests without realizing what I was doing. The solution is to stop doing that. I just emailed Brian so that we decide what to do about the already messed up pull requests.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374511/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}, "ScaMar": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6985", "title": "\"space map refcount mismatch\" on never used zpool after reboot", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       |  Ubuntu\r\nDistribution Version    |  LTS 16.04.03\r\nLinux Kernel                 |  4.4.0-104-generic\r\nArchitecture                 |  x86_64\r\nZFS Version                  |  0.6.5.6\r\nSPL Version                  |  0.6.5.6\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\n\r\nHi all,\r\non my live zpool i've found the \"space map refcount mismatch\" (error? warning?).\r\nBecause the pool wasn't too big, i've copied data on an external storage, so i've destroyes the zpool then i've recreated it.\r\nI've execute \"zdb <pool>\" and it was ok. After the first reboot (no data were copied/created on zpool), i've executed \"zdb <pool>\" again and i've found the message \"space map refcount mismatch\".\r\n\r\nI've destroyed - recreated the pool several times, always i got the \"space map refcount mismatch\".\r\nEach time before reboot i've tried something like \"zfs unmount <pool>\".\r\nI think the message is related to the first zpool.cache creation.\r\nAfter i've deleted the zpool.cache, the error was not present after the reboot.\r\n\r\nSo my problem are these lines in the zdb output:\r\n```\r\nspace map refcount mismatch: expected 11 != actual 5\r\n```\r\n\r\n### Describe how to reproduce the problem\r\nInstall Ubuntu 16.04. Update it. Create a zpool. Reboot.\r\n\r\n### Questions, considerations, any suggestions?\r\nAbout such issue, i have some questions:\r\n\r\n1) Is it something i need to worry about?\r\n2) Is there a way to recalculate/rebuild space map?\r\n\r\nThere are similar issues about such message someone wrote \"It is a problem in claiming empty space\", some other wrote \"This situation may lead to data corruption\", \"Ignore it if the delta beetwen refcount and space is fixed (if not?)\".\r\nMay we have a clear/human about the consequencies of this error / warning?\r\n\r\nThe only think i know, and sincerily i don't understand a single line (my fault, i'm not a coder), this is the line of code where the counts are compared:\r\n```\r\nstatic int\r\nverify_spacemap_refcounts(spa_t *spa)\r\n{\r\n\tuint64_t expected_refcount = 0;\r\n\tuint64_t actual_refcount;\r\n\r\n\t(void) feature_get_refcount(spa,\r\n\t    &spa_feature_table[SPA_FEATURE_SPACEMAP_HISTOGRAM],\r\n\t    &expected_refcount);\r\n\tactual_refcount = get_dtl_refcount(spa->spa_root_vdev);\r\n\tactual_refcount += get_metaslab_refcount(spa->spa_root_vdev);\r\n\r\n\tif (expected_refcount != actual_refcount) {\r\n\t\t(void) printf(\"space map refcount mismatch: expected %lld != \"\r\n\t\t    \"actual %lld\\n\",\r\n\t\t    (longlong_t)expected_refcount,\r\n\t\t    (longlong_t)actual_refcount);\r\n\t\treturn (2);\r\n\t}\r\n\treturn (0);\r\n}\r\n```\r\nPlease let me know if i must worry about this, so i can evaluate other ways to achieve my personal storage:\r\n1) linux with btrfs\r\n2) OpenIndiana/FreeBSD with ZFS\r\n3) Old but stable md / lvm / xfs (i will risk the cosmic ray bitrotter...)\r\n\r\nThank you,\r\nMarco\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n<!-- \r\n*IMPORTANT* - Please mark logs and text output from terminal commands \r\nor else Github will not display them correctly. \r\nAn example is provided below.\r\n\r\nExample:\r\n```\r\nthis is an example how log text should be marked (wrap it with ```)\r\n```\r\n-->\r\n\r\n\r\n[zdbout.newcreated.txt](https://github.com/zfsonlinux/zfs/files/1571863/zdbout.newcreated.txt)\r\n[zdbout.firstreboot.txt](https://github.com/zfsonlinux/zfs/files/1571864/zdbout.firstreboot.txt)\r\n```\r\nHistory for 'magazzino':\r\n2017-12-19.13:28:20 zpool create magazzino mirror /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K0KA3UYK /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K7NF5E20\r\n2017-12-19.13:28:21 zpool add magazzino mirror /dev/disk/by-id/ata-WDC_WD30EFRX-68EUZN0_WD-WCC4N7UUHR2X /dev/disk/by-id/ata-WDC_WD30EFRX-68EUZN0_WD-WCC4N3CHVS8X\r\n2017-12-19.13:28:22 zpool add magazzino cache /dev/disk/by-id/ata-KINGSTON_SUV400S37120G_50026B77720127CB-part5 /dev/disk/by-id/ata-KINGSTON_SUV400S37120G_50026B776B0175F0-part5\r\n2017-12-19.13:28:22 zpool add magazzino log mirror /dev/disk/by-id/ata-KINGSTON_SUV400S37120G_50026B77720127CB-part6 /dev/disk/by-id/ata-KINGSTON_SUV400S37120G_50026B776B0175F0-part6\r\n2017-12-19.13:28:22 zfs create magazzino/video\r\n2017-12-19.13:28:22 zfs create magazzino/foto\r\n2017-12-19.13:28:23 zfs create magazzino/owncloud\r\n2017-12-19.13:28:29 zpool scrub magazzino\r\n```\r\n--> deleted /etc/zfs/zpool.cache\r\n--> reboot\r\n```\r\n2017-12-19.13:31:24 zpool import -d /dev/disk/by-id -aN\r\n```\r\n--> new reboot withouth deleting zpool.cache\r\n```\r\n2017-12-19.13:37:03 zpool import -c /etc/zfs/zpool.cache -aN\r\n```\r\n--> another reboot withouth deleting zpool.cache\r\n```\r\n2017-12-19.13:41:01 zpool import -c /etc/zfs/zpool.cache -aN\r\n```\r\n\r\n\r\n\r\n\r\n\r\n\r\n ", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6985/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "samis": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6984", "title": "zpool property 'freeing' partially stuck", "body": "### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Gentoo\r\nDistribution Version    | Profile 17.0\r\nLinux Kernel                 | 4.14.5-gentoo\r\nArchitecture                 | X86_64\r\nZFS Version                  | 0.7.0-211_g4e9b1569\r\nSPL Version                  | 0.7.0-21_ged19bcc\r\n\r\n\r\n### Describe the problem you're observing\r\nI recently decided to clean up and delete two unused sparse zvols. After this, the freeing property increased as expected and did initially decrease. However, it's almost 24 hours (and two reboots) later and the property is still reporting the exact same value. \r\n\r\nAs a test, I filled a zvol with 1G of /dev/urandom and then destroyed it. The property increased from it's original value of 14353956864 to 14605664256 but shortly afterwards the data was freed and the value was back to 14353956864. This is similar to #5808 but both the scenario and the behaviour appear to be different, as neither zvol was ever used for NFS purposes.\r\n### Describe how to reproduce the problem\r\nI have not yet reproduced this beyond the above test. I can't be certain that the freeing value was correct before, but the timing seems right for this issue.\r\n### Include any warning/errors/backtraces from the system logs\r\nSo far there have been no warnings, errors or backtraces created as a result of this problem. \r\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6984/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "zielony360": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6979", "title": "Increasing zfs_vdev_aggregation_limit with zvols", "body": "<!--\r\nThank you for reporting an issue.\r\n\r\n*IMPORTANT* - Please search our issue tracker *before* making a new issue.\r\nIf you cannot find a similar issue, then create a new issue.\r\nhttps://github.com/zfsonlinux/zfs/issues \r\n\r\n*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.\r\nPlease search the wiki and the mailing list archives before asking \r\nquestions on the mailing list.\r\nhttps://github.com/zfsonlinux/zfs/wiki/Mailing-Lists\r\n\r\nPlease fill in as much of the template as possible.\r\n-->\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       | Debian\r\nDistribution Version    | 7\r\nLinux Kernel                 | 4.0.4\r\nArchitecture                 |x86_64 \r\nZFS Version                  | 0.6.5.7\r\nSPL Version                  | 0.6.5.7\r\n<!-- \r\nCommands to find ZFS/SPL versions:\r\nmodinfo zfs | grep -iw version\r\nmodinfo spl | grep -iw version \r\n-->\r\n\r\n### Describe the problem you're observing\r\nHello,\r\n\r\nwe have pool consisting 5 x 10-disk raidz2 group and using zvols with volblocksize=128k, shared through LIO FC target. Due to the fact that zfs_vdev_aggregation_limit is limited to 128k too, writes on singular disk are very small, like 13 kB average, what causes performance issues. Unfortunately, there is no large blocks for zvols to prevent it.\r\n\r\nMy questions are:\r\n1. Can I somehow safely increase zfs_vdev_aggregation_limit to 512 kB with existing configuration?\r\n2. If not, how can I migrate to large blocks datasets using the same pool? I mean I would like to create datasets, set recordsize=512k on them, but also raise zfs_vdev_aggregation_limit to make it sensible. For some time zvols will coexist with datasets during such migration.\r\n\r\n### Describe how to reproduce the problem\r\nCreate a pool with wide raidz2 vdevs and use zvols.\r\n\r\n\r\n### Include any warning/errors/backtraces from the system logs\r\n<!-- \r\n*IMPORTANT* - Please mark logs and text output from terminal commands \r\nor else Github will not display them correctly. \r\nAn example is provided below.\r\n\r\nExample:\r\n```\r\nthis is an example how log text should be marked (wrap it with ```)\r\n```\r\n-->\r\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6979/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ThomDietrich": {"issues": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6975", "title": "Different sector size error message wrong or misleading", "body": "Hello everyone.\r\nThe optimal sector size error related to a device replacement is misleading or simply wrong. As you can see below, the error presented doesn't make much sense and is not helpful. What is the alleged \"optimal sector size\", how does a user need to handle that issue? I'd suggest to improve the message as did [another user already](https://github.com/zfsonlinux/zfs/pull/2427#issuecomment-321887912).\r\n\r\n----\r\n\r\nMy case - help would also be appreciated:\r\n\r\nI am in the process of replacing a hard drive when faced with this error:\r\n\r\n```shell\r\n $ sudo zpool replace tank 12849889439322109762 ata-ST2000DM006-2DM164_Z4Z90YHR\r\ncannot replace 12849889439322109762 with ata-ST2000DM006-2DM164_Z4Z90YHR: new device has a different optimal sector size; use the option '-o ashift=N' to override the optimal size\r\n\r\n $ sudo zpool replace -o ashift=12 tank 12849889439322109762 ata-ST2000DM006-2DM164_Z4Z90YHR\r\ncannot replace 12849889439322109762 with ata-ST2000DM006-2DM164_Z4Z90YHR: new device has a different optimal sector size; use the option '-o ashift=N' to override the optimal size\r\n```\r\n\r\n\r\n```shell\r\n $ sudo zpool status\r\n  pool: tank\r\n state: DEGRADED\r\nconfig:\r\n\r\n        NAME                                    STATE     READ WRITE CKSUM\r\n        tank                                    DEGRADED     0     0     0\r\n          raidz1-0                              ONLINE       0     0     0\r\n            ... REDACTED\r\n          raidz1-1                              DEGRADED     0     0     0\r\n            12849889439322109762                UNAVAIL      0     0     0  was /dev/disk/by-id/ata-SAMSUNG_HD204UI_S2H7J1CZ907120-part1\r\n            ata-SAMSUNG_HD204UI_S2H7J90B321120  ONLINE       0     0     0\r\n            ata-SAMSUNG_HD204UI_S2H7J9JB902323  ONLINE       0     0     0\r\n            ata-SAMSUNG_HD204UI_S2H7J9JB902334  ONLINE       0     0     0\r\n          raidz1-2                              ONLINE       0     0     0\r\n            ... REDACTED\r\n        spares\r\n          ata-ST2000DM006-2DM164_Z4Z90YHR       AVAIL\r\n\r\nerrors: No known data errors\r\n```\r\n\r\n(I've tried both with a spare and an external drive with the same effect)\r\n\r\nOther than issues I found on the matter, I payed attention to the 4K issue (I hope) back when the pool was created by specifically setting it up with `ashift=12`, as you can see from zdb:\r\n\r\n```shell\r\n $ sudo zdb tank\r\n...\r\nashift: 12\r\n...\r\n```\r\n\r\nThe obvious difference I can see is, that the new drives are indeed 4K devices, while the old ones weren't.\r\n\r\nOld drive:\r\n\r\n```\r\n $ sudo hdparm -I /dev/disk/by-id/ata-ST2000DL003-9VT166_6YD1HK6W\r\n        Logical/Physical Sector size:           512 bytes\r\n```\r\n\r\nNew drive:\r\n```\r\n $ sudo hdparm -I /dev/disk/by-id/ata-ST2000DM006-2DM164_Z4Z90YHR\r\n        Logical  Sector size:                   512 bytes\r\n        Physical Sector size:                  4096 bytes\r\n        Logical Sector-0 offset:                  0 bytes\r\n```\r\n\r\nWhat can I do about that? Thanks for you work and help!\r\n\r\n\r\n\r\n### System information\r\n<!--  add version after \"|\" character\u00a0-->\r\nType                                | Version/Name\r\n  ---                                  |     --- \r\nDistribution Name       |  Ubuntu\r\nDistribution Version    |  Ubuntu 14.04.5 LTS\r\nLinux Kernel                 |  3.13.0-137-generic\r\nArchitecture                 | x86_64\r\nZFS Version                  |  0.6.5.11-1~trusty\r\nSPL Version                  |  0.6.5.11-1~trusty\r\n\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/6975/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "prometheanfire": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/7da8f8d81bf1fadc2d9dff10f0435fe601e919fa", "message": "Run zfs load-key if needed in dracut\n\n'zfs load-key -a' will only be called if needed.  If a dataset not\r\nneeded for boot does not have its key loaded (home directories for\r\nexample) boot can still continue.\r\n\r\nzfs:AUTO was not working via dracut, so we still need the generator\r\nscript to do its thing.\r\n\r\nReviewed-by: Richard Yao <ryao@gentoo.org>\r\nReviewed-by: Manuel Amador (Rudd-O) <rudd-o@rudd-o.com>\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nReviewed-by: loli10K <ezomori.nozomu@gmail.com>\r\nSigned-off-by: Matthew Thode <mthode@mthode.org>\r\nCloses #6982 \r\nCloses #7004"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/c10cdcb55f81ea773486161b31bc91bb7b58b4c8", "message": "Fix copy-builtin to work with ASAN patch\n\nCommit fed90353 didn't fully update the copy-builtin script\r\nas needed to perform in-kernel builds.  Add the missing\r\noptions and flags.\r\n\r\nReviewed by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: Matthew Thode <mthode@mthode.org>\r\nCloses #7033 \r\nCloses #7037"}], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/7008", "title": "DNM: make zfs-mount service work with encryption", "body": "", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "loli10K": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/79c3270476b7140220c7946dd0a709a31bb9ed1b", "message": "Fix Debian packaging on ARMv7/ARM64\n\nWhen building packages on Debian-based systems specify the target\r\narchitecture used by 'alien' to convert .rpm packages into .deb: this\r\navoids detecting an incorrect value which results in the following\r\nerrors:\r\n\r\n<package>.aarch64.rpm is for architecture aarch64 ; the package cannot be built on this system\r\n<package>.armv7l.rpm is for architecture armel ; the package cannot be built on this system\r\n\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nReviewed-by: George Melikov <mail@gmelikov.ru>\r\nSigned-off-by: loli10K <ezomori.nozomu@gmail.com>\r\nCloses #7046 \r\nCloses #7058"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/390d679acdfa6a2498280a4dcd33b7600ace27ce", "message": "Fix 'zpool add' handling of nested interior VDEVs\n\nWhen replacing a faulted device which was previously handled by a spare\r\nmultiple levels of nested interior VDEVs will be present in the pool\r\nconfiguration; the following example illustrates one of the possible\r\nsituations:\r\n\r\n   NAME                          STATE     READ WRITE CKSUM\r\n   testpool                      DEGRADED     0     0     0\r\n     raidz1-0                    DEGRADED     0     0     0\r\n       spare-0                   DEGRADED     0     0     0\r\n         replacing-0             DEGRADED     0     0     0\r\n           /var/tmp/fault-dev    UNAVAIL      0     0     0  cannot open\r\n           /var/tmp/replace-dev  ONLINE       0     0     0\r\n         /var/tmp/spare-dev1     ONLINE       0     0     0\r\n       /var/tmp/safe-dev         ONLINE       0     0     0\r\n   spares\r\n     /var/tmp/spare-dev1         INUSE     currently in use\r\n\r\nThis is safe and allowed, but get_replication() needs to handle this\r\nsituation gracefully to let zpool add new devices to the pool.\r\n\r\nReviewed-by: George Melikov <mail@gmelikov.ru>\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: loli10K <ezomori.nozomu@gmail.com>\r\nCloses #6678 \r\nCloses #6996"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "kithrup": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/43cb30b3ce6ee3c3041276c93594ae61e7daaf86", "message": "OpenZFS 8959 - Add notifications when a scrub is paused or resumed\n\nAuthored by: Sean Eric Fagan <sef@ixsystems.com>\nReviewed by: Alek Pinchuk <pinchuk.alek@gmail.com>\nReviewed by: Matthew Ahrens <mahrens@delphix.com>\nReviewed-by: George Melikov <mail@gmelikov.ru>\nReviewed-by: Tony Hutter <hutter2@llnl.gov>\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\nApproved by: Gordon Ross <gwr@nexenta.com>\nPorted-by: Giuseppe Di Natale <dinatale2@llnl.gov>\n\nPorting Notes:\n- Brought #defines in eventdefs.h in line with ZFS on Linux format.\n- Updated zfs-events.5 with the new events.\n\nOpenZFS-issue: https://www.illumos.org/issues/8959\nOpenZFS-commit: https://github.com/openzfs/openzfs/commit/c862b93eea\nCloses #7049"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "DeHackEd": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/d658b2caa95726c13d99123874910cdedc7ce866", "message": "Remove l2arc_nocompress from zfs-module-parameters(5)\n\nParameter was removed in d3c2ae1c0806\r\n(OpenZFS 6950 - ARC should cache compressed data)\r\n\r\nReviewed by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: DHE <git@dehacked.net>\r\nCloses #7043"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/460f239e6999195dbcf9b8443c029f07765b21e9", "message": "Fix -fsanitize=address memory leak\n\nkmem_alloc(0, ...) in userspace returns a leakable pointer.\n\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\nSigned-off-by: DHE <git@dehacked.net>\nIssue #6941"}], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6673", "title": "Fail importing if cached config has wrong number of vdev children", "body": "During import compare the labels' configs with the import config\r\nand fail if the labels indicate more vdevs than the cached config\r\n\r\nSigned-off-by: DHE <git@dehacked.net>\r\nFixes #6671\r\n\r\n### Description\r\nWhen the zpool.cache says `vdev_children=X` but the pool actually has `vdev_children=Y` where `X<Y`, blkptr errors will occur during the import process. We detect this specific case and refuse imports from this cache file.\r\n\r\n### Motivation and Context\r\nSee #6671\r\n\r\n### How Has This Been Tested?\r\n`ztest` only\r\n\r\n### Types of changes\r\n- [X] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n- [X] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [ ] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [X] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "yuripv": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/6df9f8ebd73c05da627144bcc3823e6fe980cd75", "message": "OpenZFS 8899 - zpool list property documentation doesn't match actual behaviour\n\nAuthored by: Yuri Pankov <yuri.pankov@nexenta.com>\nReviewed by: Alexander Pyhalov <alp@rsu.ru>\nReviewed-by: George Melikov <mail@gmelikov.ru>\nApproved by: Dan McDonald <danmcd@joyent.com>\nPorted-by: Brian Behlendorf <behlendorf1@llnl.gov>\n\nOpenZFS-issue: https://www.illumos.org/issues/8899\nOpenZFS-commit: https://github.com/openzfs/openzfs/commit/b0e142e57d\nCloses #7032"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/bcb1a8a25e4ee9a94478378710de53b45a9b1517", "message": "OpenZFS 8898 - creating fs with checksum=skein on the boot pools fails ungracefully\n\nAuthored by: Yuri Pankov <yuri.pankov@nexenta.com>\nReviewed by: Toomas Soome <tsoome@me.com>\nReviewed by: Andy Stormont <astormont@racktopsystems.com>\nReviewed-by: George Melikov <mail@gmelikov.ru>\nApproved by: Dan McDonald <danmcd@joyent.com>\nPorted-by: Brian Behlendorf <behlendorf1@llnl.gov>\n\nOpenZFS-issue: https://www.illumos.org/issues/8898\nOpenZFS-commit: https://github.com/openzfs/openzfs/commit/9fa2266d9a\nCloses #7031"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/8198c57b21d5e503f7e72221aa714aaabb2079cc", "message": "OpenZFS 8897 - zpool online -e fails assertion when run on non-leaf vdevs\n\nAuthored by: Yuri Pankov <yuri.pankov@nexenta.com>\nReviewed by: Toomas Soome <tsoome@me.com>\nReviewed by: Igor Kozhukhov <igor@dilos.org>\nReviewed-by: George Melikov <mail@gmelikov.ru>\nApproved by: Dan McDonald <danmcd@joyent.com>\nPorted-by: Brian Behlendorf <behlendorf1@llnl.gov>\n\nOpenZFS-issue: https://www.illumos.org/issues/8897\nOpenZFS-commit: https://github.com/openzfs/openzfs/commit/9a551dd645\nCloses #7030"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "avg-I": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/6a2185660d000c99b14556c7eb1108c5609faf41", "message": "OpenZFS 8930 - zfs_zinactive: do not remove the node if the filesystem is readonly\n\nAuthored by: Andriy Gapon <avg@FreeBSD.org>\nReviewed by: Matthew Ahrens <mahrens@delphix.com>\nReviewed-by: George Melikov <mail@gmelikov.ru>\nApproved by: Gordon Ross <gwr@nexenta.com>\nPorted-by: Brian Behlendorf <behlendorf1@llnl.gov>\n\nOpenZFS-issue: https://www.illumos.org/issues/8930\nOpenZFS-commit: https://github.com/openzfs/openzfs/commit/93c618e0f4\nCloses #7029"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ryao": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/1d53657bf561564162e2ad6449f80fa0140f1dd6", "message": "Fix incompatibility with Reiser4 patched kernels\n\nIn ZFSOnLinux, our sources and build system are self contained such that\r\nwe do not need to make changes to the Linux kernel sources. Reiser4 on\r\nthe other hand exists solely as a kernel tree patch and opts to make\r\nchanges to the kernel rather than adapt to it. After Linux 4.1 made a\r\nVFS change that replaced new_sync_read with do_sync_read, Reiser4's\r\nmaintainer decided to modify the kernel VFS to export the old function.\r\nThis caused our autotools check to misidentify the kernel API as\r\npredating Linux 4.1 on kernels that have been patched with Reiser4\r\nsupport, which breaks our build.\r\n\r\nReiser4 really should be patched to stop doing this, but lets modify our\r\ncheck to be more strict to help the affected users of both filesystems.\r\n\r\nAlso, we were not checking the types of arguments and return value of\r\nnew_sync_read() and new_sync_write() . Lets fix that too.\r\n\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nReviewed-by: Giuseppe Di Natale <dinatale2@llnl.gov>\r\nReviewed-by: George Melikov <mail@gmelikov.ru>\r\nSigned-off-by: Richard Yao <ryao@gentoo.org>\r\nCloses #6241 \r\nCloses #7021"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "nwf": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/cba6fc61a2898395c47380a0c2303f19842a2ff0", "message": "Revert raidz_map and _col structure types\n\nAs part of the refactoring of ab9f4b0b824ab4cc64a4fa382c037f4154de12d6,\r\nseveral uint64_t-s and uint8_t-s were changed to other types.  This\r\ncaused ZoL github issue #6981, an overflow of a size_t on a 32-bit ARM\r\nmachine.  In absense of any strong motivation for the type changes, this\r\nsimply puts them back, modulo the changes accumulated for ABD.\r\n\r\nCompile-tested on amd64 and run-tested on armhf.\r\n\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nReviewed-by: Gvozden Neskovic <neskovic@gmail.com>\r\nSigned-off-by: Nathaniel Wesley Filardo <nwf@cs.jhu.edu>\r\nCloses #6981 \r\nCloses #7023"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/8b20a9f996b90abe439ce14303fc440f26390e38", "message": "zhack: fix getopt return type\n\nThis fixes zhack's command processing on ARM.  On ARM char\r\nis unsigned, and so, in promotion to an int, it will never\r\ncompare equal to -1.\r\n\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: Nathaniel Wesley Filardo <nwf@cs.jhu.edu>\r\nCloses #7016"}], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6209", "title": "[RFC] new zscrub command for offline scrubs in userland", "body": "### Description\r\n\r\nThis PR adds a \"zhack scrub\" subcommand which, in user-land, finds and scrubs a pool.  This has proven useful for experimenting with the scan logic (especially the in-order-scrub patches) without having to reload the kernel module and seems like it may be useful to others.\r\n\r\nAt this point, it is not yet ready to merge -- there are no tests, no docs, &c... but I am curious for anyone's commentary and/or suggestions. :)\r\n\r\n### How Has This Been Tested?\r\n\r\nLimited testing against both files and actual block-device-backed pools.  Scrubs and resilvers appear to work just fine.\r\n\r\n### Types of changes\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [ ] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "gamanakis": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/be54a13c3e7db423ffdb3f7983d4dd1141cc94a0", "message": "Fix percentage styling in zfs-module-parameters.5\n\nReplace \"percent\" with \"%\", add bold to default values.\r\n\r\nReviewed-by: bunder2015 <omfgbunder@gmail.com>\r\nReviewed-by: George Melikov <mail@gmelikov.ru>\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: George Amanakis <gamanakis@gmail.com>\r\nCloses #7018"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "prakashsurya": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/2fe61a7ecc507d031451c21b3077fae549b58ec3", "message": "OpenZFS 8909 - 8585 can cause a use-after-free kernel panic\n\nAuthored by: Prakash Surya <prakash.surya@delphix.com>\nReviewed by: John Kennedy <jwk404@gmail.com>\nReviewed by: Matthew Ahrens <mahrens@delphix.com>\nReviewed by: George Wilson <george.wilson@delphix.com>\nReviewed by: Brad Lewis <brad.lewis@delphix.com>\nReviewed by: Igor Kozhukhov <igor@dilos.org>\nReviewed by: Brian Behlendorf <behlendorf1@llnl.gov>\nApproved by: Robert Mustacchi <rm@joyent.com>\nPorted-by: Prakash Surya <prakash.surya@delphix.com>\n\nPROBLEM\n=======\n\nThere's a race condition that exists if `zil_free_lwb` races with either\n`zil_commit_waiter_timeout` and/or `zil_lwb_flush_vdevs_done`.\n\nHere's an example panic due to this bug:\n\n    > ::status\n    debugging crash dump vmcore.0 (64-bit) from ip-10-110-205-40\n    operating system: 5.11 dlpx-5.2.2.0_2017-12-04-17-28-32b6ba51fb (i86pc)\n    image uuid: 4af0edfb-e58e-6ed8-cafc-d3e9167c7513\n    panic message:\n    BAD TRAP: type=e (#pf Page fault) rp=ffffff0010555970 addr=60 occurred in module \"zfs\" due to a NULL pointer dereference\n    dump content: kernel pages only\n\n    > $c\n    zio_shrink+0x12()\n    zil_lwb_write_issue+0x30d(ffffff03dcd15cc0, ffffff03e0730e20)\n    zil_commit_waiter_timeout+0xa2(ffffff03dcd15cc0, ffffff03d97ffcf8)\n    zil_commit_waiter+0xf3(ffffff03dcd15cc0, ffffff03d97ffcf8)\n    zil_commit+0x80(ffffff03dcd15cc0, 9a9)\n    zfs_write+0xc34(ffffff03dc38b140, ffffff0010555e60, 40, ffffff03e00fb758, 0)\n    fop_write+0x5b(ffffff03dc38b140, ffffff0010555e60, 40, ffffff03e00fb758, 0)\n    write+0x250(42, fffffd7ff4832000, 2000)\n    sys_syscall+0x177()\n\nIf there's an outstanding lwb that's in `zil_commit_waiter_timeout`\nwaiting to timeout, waiting on it's waiter's CV, we must be sure not to\ncall `zil_free_lwb`. If we end up calling `zil_free_lwb`, then that LWB\nmay be freed and can result in a use-after-free situation where the\nstale lwb pointer stored in the `zil_commit_waiter_t` structure of the\nthread waiting on the waiter's CV is used.\n\nA similar situation can occur if an lwb is issued to disk, and thus in\nthe `LWB_STATE_ISSUED` state, and `zil_free_lwb` is called while the\ndisk is servicing that lwb. In this situation, the lwb will be freed by\n`zil_free_lwb`, which will result in a use-after-free situation when the\nlwb's zio completes, and `zil_lwb_flush_vdevs_done` is called.\n\nThis race condition is prevented in `zil_close` by calling `zil_commit`\nbefore `zil_free_lwb` is called, which will ensure all outstanding (i.e.\nall lwb's in the `LWB_STATE_OPEN` and/or `LWB_STATE_ISSUED` states)\nreach the `LWB_STATE_DONE` state before the lwb's are freed\n(`zil_commit` will not return untill all the lwb's are\n`LWB_STATE_DONE`).\n\nFurther, this race condition is prevented in `zil_sync` by only calling\n`zil_free_lwb` for lwb's that do not have their `lwb_buf` pointer set.\nAll lwb's not in the `LWB_STATE_DONE` state will have a non-null value\nfor this pointer; the pointer is only cleared in\n`zil_lwb_flush_vdevs_done`, at which point the lwb's state will be\nchanged to `LWB_STATE_DONE`.\n\nThis race *is* present in `zil_suspend`, leading to this bug.\n\nAt first glance, it would appear as though this would not be true\nbecause `zil_suspend` will call `zil_commit`, just like `zil_close`, but\nthe problem is that `zil_suspend` will set the zilog's `zl_suspend`\nfield prior to calling `zil_commit`. Further, in `zil_commit`, if\n`zl_suspend` is set, `zil_commit` will take a special branch of logic\nand use `txg_wait_synced` instead of performing the normal `zil_commit`\nlogic.\n\nThis call to `txg_wait_synced` might be good enough for the data to\nreach disk safely before it returns, but it does not ensure that all\noutstanding lwb's reach the `LWB_STATE_DONE` state before it returns.\nThis is because, if there's an lwb \"stuck\" in\n`zil_commit_waiter_timeout`, waiting for it's lwb to timeout, it will\nmaintain a non-null value for it's `lwb_buf` field and thus `zil_sync`\nwill not free that lwb. Thus, even though the lwb's data is already on\ndisk, the lwb will be left lingering, waiting on the CV, and will\neventually timeout and be issued to disk even though the write is\nunnecessary.\n\nSo, after `zil_commit` is called from `zil_suspend`, we incorrectly\nassume that there are not outstanding lwb's, and proceed to free all\nlwb's found on the zilog's lwb list. As a result, we free the lwb that\nwill later be used `zil_commit_waiter_timeout`.\n\nSOLUTION\n========\n\nThe solution to this, is to ensure all outstanding lwb's complete before\ncalling `zil_free_lwb` via `zil_destroy` in `zil_suspend`. This patch\naccomplishes this goal by forcing the normal `zil_commit` logic when\ncalled from `zil_sync`.\n\nNow, `zil_suspend` will call `zil_commit_impl` which will always use the\nnormal logic of waiting/issuing lwb's to disk before it returns. As a\nresult, any lwb's outstanding when `zil_commit_impl` is called will be\nguaranteed to reach the `LWB_STATE_DONE` state by the time it returns.\n\nFurther, no new lwb's will be created via `zil_commit` since the zilog's\n`zl_suspend` flag will be set. This will force all new callers of\n`zil_commit` to use `txg_wait_synced` instead of creating and issuing\nnew lwb's.\n\nThus, all lwb's left on the zilog's lwb list when `zil_destroy` is\ncalled will be in the `LWB_STATE_DONE` state, and we'll avoid this race\ncondition.\n\nOpenZFS-issue: https://www.illumos.org/issues/8909\nOpenZFS-commit: https://github.com/openzfs/openzfs/commit/ece62b6f8d\nCloses #6940"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "lidongyang": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/823d48bfb182137c53b9432498f1f0564eaa8bfc", "message": "Call commit callbacks from the tail of the list\n\nOur zfs backed Lustre MDT had soft lockups while under heavy metadata\r\nworkloads while handling transaction callbacks from osd_zfs.\r\n\r\nThe problem is zfs is not taking advantage of the fast path in\r\nLustre's trans callback handling, where Lustre will skip the calls\r\nto ptlrpc_commit_replies() when it already saw a higher transaction\r\nnumber.\r\n\r\nThis patch corrects this, it also has a positive impact on metadata\r\nperformance on Lustre with osd_zfs, plus some cleanup in the headers.\r\n\r\nA similar issue for ext4/ldiskfs is described on:\r\nhttps://jira.hpdd.intel.com/browse/LU-6527\r\n\r\nReviewed-by: Olaf Faaland <faaland1@llnl.gov>\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: Li Dongyang <dongyang.li@anu.edu.au>\r\nCloses #6986"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "tcaputi": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/44b61ea506212c287333e03d2cf8933216810800", "message": "Remove empty files accidentally added by a8b2e306 \n\nThis patch simply removes 2 empty files that were accidentally\r\nadded a part of the scrub priority patch.\r\n\r\nReviewed-by: George Melikov <mail@gmelikov.ru>\r\nReviewed-by: Giuseppe Di Natale <dinatale2@llnl.gov>\r\nSigned-off-by: Tom Caputi <tcaputi@datto.com>\r\nCloses #6990"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/a8b2e30685c9214ccfd0181977540e080340df4e", "message": "Support re-prioritizing asynchronous prefetches\n\nWhen sequential scrubs were merged, all calls to arc_read()\r\n(including prefetch IOs) were given ZIO_PRIORITY_ASYNC_READ.\r\nUnfortunately, this behaves badly with an existing issue where\r\nprefetch IOs cannot be re-prioritized after the issue. The\r\nresult is that synchronous reads end up in the same vdev_queue\r\nas the scrub IOs and can have (in some workloads) multiple\r\nseconds of latency.\r\n\r\nThis patch incorporates 2 changes. The first ensures that all\r\nscrub IOs are given ZIO_PRIORITY_SCRUB to allow the vdev_queue\r\ncode to differentiate between these I/Os and user prefetches.\r\nSecond, this patch introduces zio_change_priority() to provide\r\nthe missing capability to upgrade a zio's priority.\r\n\r\nReviewed by: George Wilson <george.wilson@delphix.com>\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: Tom Caputi <tcaputi@datto.com>\r\nCloses #6921 \r\nCloses #6926"}], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6864", "title": "Encryption and Raw Send Stability Improvements", "body": "The current on-disk format for encrypted datasets protects\r\nnot only the encrypted and authenticated blocks, but also\r\nthe order and interpretation of these blocks. In order to\r\nmake this work while maintaining the ability to do raw sends\r\nthe indirect bps maintain a secure checksum of all the MACs\r\nin the block below it, along with a few other fields that\r\ndetermine how the data is interpretted.\r\n\r\nUnfortunately, the current on-disk format erroniously\r\nincludes some fields which are not portable and thus cannot\r\nsupport raw sends. It is also not possible to easily work\r\naround this issue due to a separate and much smaller bug\r\nwhich causes indirect blocks for encrypted dnodes to not\r\nbe compressed, which conflicts with the previous bug. In\r\naddition, raw send streams do not currently include\r\ndn_maxblkid which is needed in order to ensure that we are\r\ncorrectly maintaining the portable objset MAC.\r\n\r\nThis patch zero's out the offending fields when computing the\r\nbp MAC (as they should have been) and registers an errata for\r\nthe on-disk format bug. We detect the errata by adding a\r\n\"version\" field to newly created DSL Crypto Keys. We allow\r\ndatasets without a version (version 0) to only be mounted for\r\nread so that they can easily be migrated. We also now include\r\ndn_maxblkid in raw send streams to ensure the MAC can be\r\nmaintained correctly.\r\n\r\nNote that this fix has not yet been finalized and should not be used until it is tested, reviewed, and merged unless you are ok with losing your data.\r\n\r\nSigned-off-by: Tom Caputi <tcaputi@datto.com>\r\n\r\n### How Has This Been Tested?\r\nI have added a new test for raw sends that essentially stresses as many edge cases as I could think of. In addition, I have manually tested that the recovery process laid out in https://github.com/zfsonlinux/zfsonlinux.github.com/pull/35 works as advertised, and that both old and new datasets function predictably.\r\n\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [x] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [x] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "tesujimath": {"issues": [], "commits": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/commits/993669a7bf17a26843630c547999be0b27483497", "message": "vdev_id: new slot type ses\n\nThis extends vdev_id to support a new slot type, ses, for SCSI Enclosure\r\nServices.  With slot type ses, the disk slot numbers are determined by\r\nusing the device slot number reported by sg_ses for the device with\r\nmatching SAS address, found by querying all available enclosures.\r\n\r\nThis is primarily of use on systems with a deficient driver omitting\r\nsupport for bay_identifier in /sys/devices.  In my testing, I found that\r\nthe existing slot types of port and id were not stable across disk\r\nreplacement, so an alternative was required.\r\n\r\nReviewed-by: Brian Behlendorf <behlendorf1@llnl.gov>\r\nSigned-off-by: Simon Guest <simon.guest@tesujimath.org>\r\nCloses #6956"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "avw1987": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/7055", "title": "Update README.initramfs.markdown", "body": "Fixed a typo\r\n\r\n<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [x] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [ ] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [ ] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "tonyhutter": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/7051", "title": "zfs-0.7.6 patchset", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\nTest 0.7.6 patchset in buildbot\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [ ] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [ ] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "MEMBER"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "sckobras": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/7007", "title": "Allow to limit zed's syslog chattiness", "body": "### Description\r\n\r\nSome usage patterns like send/recv of replication streams can\r\nproduce a large number of events. In such a case, the current\r\nall-syslog.sh zedlet will hold up to its name, and flood the\r\nlogs with mostly redundant information. To mitigate this\r\nsituation, this changeset introduces two new variables\r\nZED_SYSLOG_SUBCLASS_INCLUDE and ZED_SYSLOG_SUBCLASS_EXCLUDE\r\nto zed.rc that give more control over which event classes end\r\nup in the syslog.\r\n\r\nSigned-off-by: Daniel Kobras <d.kobras@science-computing.de>\r\nCloses: #6886\r\n\r\n### Motivation and Context\r\nIt seems that each time a dataset that also uses =zfs-auto-snapshot= is replicated, a =history_event= for the =com.sun:auto-snapshot-desc= property in each snapshot is logged. This easily spams the logs with thousands of redundant, and rather useless messages as described in #6886, so adding a facility to trim down the noise without disabling the syslog feature altogether seems to be in order.\r\n\r\n### How Has This Been Tested?\r\nTested on EL7.4 with ZoL 0.7.2.\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [x] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "aerusso": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6974", "title": "fstab integration", "body": "Generate a tracked, updateable section in /etc/fstab for zfs filesystems\r\n\r\n### Description\r\nA contrib script fstab-generator is implemented that creates a trackable section in /etc/fstab (or another user-specified file) with fstab syntax reflecting the zfs mount and canmount parameters.\r\n\r\n### Motivation and Context\r\nWhile #4943 implements a per-pool granular import, the user will still \"need to add an entry like this in fstab:\r\n\r\n```rpool/home /home zfs rw,defaults,x-systemd.requires=zpool@rpool.service```\r\n\r\nThis script performs precisely that mechanical task, allowing for filesystem dependencies to be correctly identified, and mounted in time to guarantee their availability. A monolithic import of all zfs filesystems is not required to have system files on native zfs mountpoints. \r\n\r\nMoreover, by including this information in /etc/fstab, tools can fail appropriately if essential mountpoints are unavailable. This helps address the common annoyance where zfs fails to mount an important system directory, files then get placed on the zfs mountpoint, and then zfs will fail to mount on the subsequent boot (because overlay=off) even though the underlying problem was corrected. \r\n\r\n#### Why not a systemd-generator?\r\nBesides the obvious lack of integration for users without systemd, other tools may rely on /etc/fstab to determine what filesystems are present on a system. This approach immediately achieves integration with those tools--e.g., for analogous dependency tracking for other init systems that may develop in the future. Additionally, systemd generators may change syntax in the future, but they will have to remain compatible with /etc/fstab.\r\n\r\n### How Has This Been Tested?\r\nI'm running with the output of this script on a machine that has several `/var/` directories, and `/tmp` with purely zfs mountpoints.\r\n\r\n### RFC\r\nThis is a work in progress.\r\n1. Should this be converted to fstab-generator.in, and use `%sbindir%`, etc?\r\n2. Should this name be changed? Should this be installed elsewhere?\r\n3. How could/should this be integrated with the rest of the tools?\r\n4. Is there some reason `mount -ozfsutil` is ill-advised for zfs filesystems?\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6964", "title": "Use zfs-import.target in contrib/dracut", "body": "### Description\r\nThe new zfs-import.target should be used in place of the zfs-import-*.service units in `contrib/dracut`.\r\n\r\n### Motivation and Context\r\nPR #6764 added `zfs-import.target` to simplify dependency on pool importing. #6822 did some cleanup. The recent #6955 (re: #6953) added RPM support for enabling this units. That bug report has prompted me to grep the code base for zfs-import. The last remaining code section to be updated is under `control/dracut/90zfs`.\r\n\r\nThis PR is  a **work in progress**. I don't think dracut users are exposed to any bug presently, because `sysroot.mount` is still ordered `After=zfs-import-*.service`\r\n\r\nTwo files are affected:\r\n1. `zfs-generator.sh.in` is straightforwardly modified to order `sysroot.mount` `After=zfs-import.target` (instead of each `zfs-import-*.service`). \r\n2. `module-setup.sh.in` is also modified. **I need input, because I don't know how precisely dracut works.** `zfs-import.target` (and each `zfs-import-*.service`) is `dracut_install`-ed (and *unconditionally* `mark_hostonly`-ed). Do we need to build a `zfs-import.target.wants` directory with `zfs-import-*.service` links? Or will that be inherited from the host system?\r\n\r\n### How Has This Been Tested?\r\nThis has NOT been tested. This is a place to centralize discussion about these changes.\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [x] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "dinatale2": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6906", "title": "Add dbuf hash and dbuf cache kstats", "body": "### Description\r\n<!--- Describe your changes in detail -->\r\nIntroduce kstats about the dbuf hash and dbuf cache\r\nto make it easier to inspect state. This should help\r\nwith debugging and understanding of these portions\r\nof the codebase.\r\n\r\nCorrect format of dbuf kstat file.\r\n\r\nIntroduce a dbc column to dbufs kstat to indicate if\r\na dbuf is in the dbuf cache.\r\n\r\nIntroduce field filtering in the dbufstat python script.\r\n\r\nI will also be introducing some basic test cases to test the new dbufstats kstat and other basic scenarios.\r\n\r\n<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\nGain a better understanding how dbufs are cached and provide another useful tool for users/developer.\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\nLocally on a VM.\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [x] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6294", "title": "Enforce request limits on zvols", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\nCurrently, zvols do not handle heavy random IO\r\nworkloads. zvols should limit the number of outstanding\r\nin-flight IO requests. This should improve performance.\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n#6127 \r\n#6278 \r\n\r\n### How Has This Been Tested?\r\nBuilds on my VM. Buildbot will help me test. Hoping to test on hardware soon.\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [x] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "MEMBER"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "dweeezil": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6900", "title": "OpenZFS 7614 - zfs device evacuation/removal", "body": "### Description\r\n<!--- Describe your changes in detail -->\r\nThis project allows top-level vdevs to be removed from the storage pool\r\nwith \"zpool remove\", reducing the total amount of storage in the pool.\r\nThis operation copies all allocated regions of the device to be removed\r\nonto other devices, recording the mapping from old to new location.\r\nAfter the removal is complete, read and free operations to the removed\r\n(now \"indirect\") vdev must be remapped and performed at the new location\r\non disk.  The indirect mapping table is kept in memory whenever the pool\r\nis loaded, so there is minimal performance overhead when doing\r\noperations on the indirect vdev.\r\n\r\nThe size of the in-memory mapping table will be reduced when its entries\r\nbecome \"obsolete\" because they are no longer used by any block pointers\r\nin the pool.  An entry becomes obsolete when all the blocks that use it\r\nare freed.  An entry can also become obsolete when all the snapshots\r\nthat reference it are deleted, and the block pointers that reference it\r\nhave been \"remapped\" in all filesystems/zvols (and clones).  Whenever an\r\nindirect block is written, all the block pointers in it will be\r\n\"remapped\" to their new (concrete) locations if possible.  This process\r\ncan be accelerated by using the \"zfs remap\" command to proactively\r\nrewrite all indirect blocks that reference indirect (removed) vdevs.\r\n\r\nNote that when a device is removed, we do not verify the checksum of the\r\ndata that is copied.  This makes the process much faster, but if it were\r\nused on redundant vdevs (i.e. mirror or raidz vdevs), it would be\r\npossible to copy the wrong data, when we have the correct data on e.g.\r\nthe other side of the mirror.  Therefore, mirror and raidz devices can\r\nnot be removed.\r\n\r\n### Motivation and Context\r\nSee above.\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\n### How Has This Been Tested?\r\nAdditions to the test suite in functional/removal.\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/5925", "title": "OpenZFS - 6363 Add UNMAP/TRIM functionality", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n### Description\r\nAdd TRIM support.  Replacement for #3656.\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\nVarious stress testing with an assortment of vdev types.\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [x] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [ ] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [ ] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n\r\nThis PR should integrate all the recent changes in the upstream patch set.  The stack also includes the separate fixes which were in #3656.  It seems stable so far during some fairly abusive testing on SSDs with various types of vdevs.  It does _not_ include the \"partial\" trim support of the previous PR.", "author_association": "MEMBER"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "scotws": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6892", "title": "Add Python 3 rewrite of arc_summary.py (#6873)", "body": "### Description\r\n\r\nAdd new Python 3 script `arc_summary3.py` as a complete rewrite of `arc_summary.py` to display basic information on the ARC status and various other parameters. This is provided in addition - not as a replacement - to the existing `arc_summary.py` tool. See #6873 for a discussion of the reasoning behind adding a new version of this tool while keeping a legacy version as well.\r\n\r\nNew options:\r\n\r\n        -g/--graph    - Display crude graphic representation of ARC status and quit\r\n        -r/--raw      - Print all available information as minimally formatted list and quit\r\n        -s/--section  - Print a single section. This supersedes -p/--page, which is kept for\r\n                        backwards use but marked as DEPRECIATED\r\n\r\nAdds new sections with information on the ZIL and SPL. \r\n\r\nWe now notify the user if sections L2ARC and VDEV are skipped instead of failing silently; note VDEV caching is currently disabled and slated for possible removal (see source code). Adds information on the ZFS and SPL versions to the header.\r\n\r\nThe **-s/--section** option is intended to replace the page number system, which required the user to remember which page number was of interest. The -p/--page options are still supported, but marked as DEPRECIATED. Current legal sections are `arc archits dmu l2arc spl tunables vdev zil`. It should be easier now to add and modify sections.\r\n\r\nThe **-r/--raw** option is intended to work with other tools such as `grep`. It respects the -a/-d options (alternate output format / descriptions included) where possible. \r\n\r\nThe output of the **-g/--graph** option is intended to give a quick, rough overview as a visual orientation. An example (Ubuntu 16.04 LTS x86_64 with 24 GB RAM, 8 GB ARC max, ZFS stock version 0.6.5.9-2 with `/home` as ZFS mirror pool immediately after starting _Civilization VI_ on Steam on otherwise quiet machine): \r\n```\r\n        ARC: 3.0 GiB (37.5 %)  MFU: 610.5 MiB  MRU: 2.3 GiB\r\n    +----------------------------------------------------------+\r\n    |FFFFRRRRRRRRRRRRRRRRR                                     |\r\n    +----------------------------------------------------------+\r\n```\r\n`F` is for MFU, `R` for MRU, and `O` is used for \"other\" if necessary (not present in this example). \r\n\r\n`arc_summary3.py` was developed for Python 3.5. This follows the version of Python currently installed in Ubuntu 16.04 LTS. Few systems will have Python 3.6 installed yet.\r\n\r\n### Known issues\r\n\r\nThe new script is based on the same internal logic as the original, so any error or issue present there will probably show up here as well. For instance, the number of anonymous hits can be negative the way it is calculated in both scripts; they both simply hide any negative value.\r\n\r\nThis script will probably make a bunch of test suites unhappy where Python 3 is not included. There is no experience with this script under extreme conditions (for example ARC throttling).\r\n\r\n### How Has This Been Tested?\r\n\r\nThere is a unittest script `test_arc_summary3.py` at https://gist.github.com/scotws/aaf5d9c9317081e249b664a371ec4907\r\nMost testing was done in-tree, comparing the output to that of the current `arc_summary.py` version.\r\n\r\nThe L2ARC section has **not seen any real-world use** because I do not have access to a L2ARC device on my machine.\r\n\r\n### Other \r\n\r\nSwitching to Python 3 results in a noticeably smaller file size despite the addition of several new features. Output of `wc` for both scripts:\r\n```\r\n    837    2586   28021 arc_summary3.py\r\n   1020    2593   35538 arc_summary.py\r\n```\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [ ] I have read the **CONTRIBUTING** document.\r\n- [x] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "Blub": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6865", "title": "user namespace bugfixes and features", "body": "This series can be seen as 4 separate \"chunks\":\r\n\r\nChunk 1: setgid mode bugfix & regression test:\r\n* Patch 1 fixes the main issue.\r\n* Patch 2 adds a helper for running user namespace tests. Currently uses a fixed\r\n  user id range. (I saw no reason for anything more complex than that.)\r\n* Patch 3 adds a regression test for the issue fixed in patch 1.\r\n\r\nChunk 2: mounting from user namespaces (RFC):\r\n* Patch 4 is an RFC useful for when a user can have a mount namespace (usually\r\n  in combination with user namespaces. Eg. giving `zfs allow`ing create+mount\r\n  permissions to a container.\r\n* Patch 5 is necessary when including the third chunk but is otherwise there\r\n  since it made writing the test case of patch 6 more convenient.\r\n* Patch 6 tests create+mount permissions with user namespaces.\r\n\r\nChunk 3: mapping user ids when using zfs allow from within user namespaces.\r\n* Patch 7 causes `ZFS_IOC_GET_FSACL` and `ZFS_IOC_SET_FSACL` to perform user id\r\n  mapping (as well as checking!) on the sent/received data. Otherwise root in a\r\n  user namespace would not be able to run `zfs allow` with the user IDs as seen\r\n  from within its namespace, but would have to perform the mapping to real IDs.\r\n  This is also what easily enables users to create allow entries for user IDs\r\n  which do not exist in the host namespace's `/etc/passwd` and therefore would\r\n  show up empty and indistinguishable to the host (making patch 5 a\r\n  requirement).\r\n\r\nChunk 4: change the 'unallow' check:\r\n* Patch 8 allows users who have CAP_SYS_ADMIN in the current namespace (iow.\r\n  root in containers) to remove permissions of others if they're also allowed\r\n  to add the permission.\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements. (at least according to `make checkstyle`)\r\n- [ ] I have updated the documentation accordingly. (not yet)\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [x] I have added tests to cover my changes.\r\n- [x] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ironMann": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6568", "title": "[wip][test] Prefetch dmu", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\nRun testers\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [ ] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [ ] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6107", "title": "LOCK tracking: disable tracking of ARC and dbuf hashmap locks (16384 mutexes)", "body": "Test for zfsonlinux/spl#587\r\n\r\nRequires-spl: refs/pull/587/head\r\n\r\n### Description\r\nDisable tracking of per-bucket locks.\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [ ] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "MEMBER"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "don-brady": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6558", "title": "OpenZFS 7431 - ZFS Channel Programs", "body": "Authored by: Chris Williamson <chris.williamson@delphix.com>\r\nReviewed by: Matthew Ahrens <mahrens@delphix.com>\r\nReviewed by: George Wilson <george.wilson@delphix.com>\r\nReviewed by: John Kennedy <john.kennedy@delphix.com>\r\nReviewed by: Dan Kimmel <dan.kimmel@delphix.com>\r\nApproved by: Garrett D'Amore <garrett@damore.org>\r\nPorted-by: Don Brady <don.brady@delphix.com>\r\nPorted-by: John Kennedy <john.kennedy@delphix.com>\r\n\r\nOpenZFS-issue: https://www.illumos.org/issues/7431\r\nOpenZFS-commit: https://github.com/openzfs/openzfs/commit/dfc11533\r\n\r\nPorting Notes:\r\n* The CLI long option arguments for '-t' and '-m' don't parse on linux\r\n* Switched from kmem_alloc to vmem_alloc in zcp_lua_alloc\r\n* Lua implementation is built as its own module (zlua.ko)\r\n* Lua headers consumed directly by zfs code moved to 'include/sys/lua/'\r\n* There is no native setjmp/longjump available in stock Linux kernel.  Brought over implementation from illumos and FreeBSD\r\n* The get_temporary_prop() was adapted due to VFS platform differences\r\n* Use of in-lining functions in lua parser code to reduce stack usage per nested C call\r\n\r\n### How Has This Been Tested?\r\n#### Manual tests\r\n- running basic get-props channel programs from CLI\r\n- exercised the zfs property get CLI with the envr *ZFS_PROP_DEBUG=1* set\r\n#### Automated tests\r\n- ztest runs that exercise the new ZCP destroy snapshots path\r\n- new ZTS channel_program functional tests\r\n\r\n### Types of changes\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [x] I have added tests to cover my changes.\r\n- [x] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "MEMBER"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "dong-liuliu": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6546", "title": "Use Multi-buffer sha256 support from SPL", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\nLet sha256 checksum using multi-buffer api if it is exported by SPL\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n Using multi-buffer type, performance of sha256 will be increased 2~7 times.\r\nNow a patch for multi-buffer sha256 facility in kernel space is implemented and submitted to SPL.\r\nIts userspace facility and sha512 parts will be following up after this patch is reviewed and commented.\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\nRun FIO sequential write test, on Intel Xeon server (Haswell E5-2699 v3, 18 core), with 6x SSD :\r\n\r\nSha256 | CPU-sys% | BW(MB/s)\r\n-- | -- | --\r\nmulti-buffer version | 27 | 1859\r\nicp version | 71 | 1876\r\n\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [x] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ahrens": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6536", "title": "diff and bookmark enhancements", "body": "\r\n<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\nThis PR includes 3 related features that work well together:\r\n\r\n`zfs diff -a` shows which specific blocks were modified\r\n\r\n`zfs diff` from a bookmark (but it can't show renamed files)\r\n\r\n`zfs bookmark` from a filesystem, creating a bookmark which represents current point in time.  Not useful for `zfs send`, but can be used with `zfs diff`.\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\nThis makes `zfs diff` useful in more situations.  For example, to find which blocks in a database or VDI file were changed.\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n\r\nManual testing only at this point.  I'd like to add test cases to the test suite, but there aren't any tests for \"zfs diff\" at all, so it seems strange to add tests for just the new functionality I'm adding.  I'm open to input on what should be required for this PR.\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [x] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ofaaland": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6479", "title": "Merge SPL into ZFS [WIP]", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\nMerge the SPL into ZFS to eliminate the extra work required when SPL code must change due to kernel or distro changes, and to simplify the build process.\r\n\r\nWork In Progress.\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [x] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [ ] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "Nasf-Fan": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6290", "title": "Project Quota on ZFS", "body": "Project quota is a new ZFS system space/object usage accounting\r\nand enforcement mechanism. Similar as user/group quota, project\r\nquota is another dimension of system quota. It bases on the new\r\nobject attribute - project ID.\r\n\r\nProject ID is a numerical value to indicate to which project an\r\nobject belongs. An object only can belong to one project though\r\nyou (the object owner or privileged user) can change the object\r\nproject ID that can be set/modified via 'chattr -p' explicitly,\r\nor inherited from its parent object when created if such parent\r\nhas the project inherit flag (via 'chattr +P').\r\n\r\nBy accounting the spaces/objects belong to the same project, we\r\ncan know how many spaces/objects used by the project. And if we\r\nset the upper limit then we can control the spaces/objects that\r\nare consumed by such project. It is useful when multiple groups\r\nand users cooperate for the same project, or when an user/group\r\nneeds to participate in multiple projects.\r\n\r\nSupport the following commands and functionalities:\r\n\r\nzfs set projectquota@project\r\nzfs set projectobjquota@project\r\n\r\nzfs get projectquota@project\r\nzfs get projectobjquota@project\r\nzfs get projectused@project\r\nzfs get projectobjused@project\r\n\r\nzfs projectspace\r\n\r\nzfs allow projectquota\r\nzfs allow projectobjquota\r\nzfs allow projectused\r\nzfs allow projectobjused\r\n\r\nzfs unallow projectquota\r\nzfs unallow projectobjquota\r\nzfs unallow projectused\r\nzfs unallow projectobjused\r\n\r\nchattr +/-P\r\nchattr -p project_id\r\nlsattr -p\r\n\r\nSigned-off-by: Fan Yong <fan.yong@intel.com>\r\nChange-Id: Ib4f0544602e03fb61fd46a849d7ba51a6005693c\r\n\r\n<!--- Provide a general summary of your changes in the Title above -->\r\n\r\n<!---\r\nDocumentation on ZFS Buildbot options can be found at\r\nhttps://github.com/zfsonlinux/zfs/wiki/Buildbot-Options\r\n-->\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Documentation (a change to man pages or other documentation)\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [x] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [x] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [x] All commit messages are properly formatted and contain `Signed-off-by`.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "tuxoko": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6277", "title": "[WIP] Add pool prop `partition` to disable auto partition", "body": "### Description\r\n\r\nzfsonlinux always partition disk when it detects the device given is a\r\nwhole disk. This legacy behavior from Illumos, however, has no apparent\r\nbenefit on Linux, but has some down sides besides confusion. E.g.\r\nautoexpand, switching to dm device requires partprobe.\r\n\r\nWe add a pool property `partition` to be set during pool create. It\r\ncurrently has two values, legacy and raw. When setting it to legacy, it\r\nwill behave as it did. When setiing it to raw, it will always use the\r\ndevice as is without partitioning even if it's a whole disk.\r\n\r\nThis property applies to all commands that add disks to pool, so zpool\r\nadd/attach/replace will partition or not partition based on the property\r\non the target pool.\r\n    \r\nA pool without this property will be treated as legacy. Newly created\r\npool will by default have partition=legacy.\r\n\r\nSigned-off-by: Chunwei Chen <david.chen@osnexus.com>\r\n\r\n### Note\r\n\r\nI use PROP_ONETIME for the property, but it seems that this is not enforced at all, so you can still modify it after the fact. But you shouldn't change it after the fact, as it would cause device name appending wrong.", "author_association": "MEMBER"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "inkdot7": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/6078", "title": "Metadata classes wip no accounting", "body": "Please ignore this PR.\r\nI just want to see how the metadata allocation classes behave if the special accounting is removed.  (Which would allow the small-block-size limit to be changed after creation more easily.)\r\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "n1kl": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/5929", "title": "Quality of service for ZFS + improvement through compression", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\nAs part of my master thesis at University of Hamburg I have targeted to improve ZFS through compression. Now I would like to share my 3 feature branches with the community.\r\n\r\n1. lz4fast #5927 \r\n2. autocompression #5928 \r\n3. qos (current)\r\n### Description\r\n<!--- Describe your changes in detail -->\r\nThis patch adds quality of service to ZFS datasets.\r\nzfs set compression=qos-[10,20,30,40,50,+50*n,1000]\r\nThe chosen value sets the throughput in MB/s.\r\nLow values will result in better compression ratio but less throughput.\r\n\r\n### Motivation1\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\nQuality of service is an important aspect in dealing with limited resources.\r\nAt the moment the user can control storage requirement by choosing a compression algorithm like gzip for high compression. Depending on the hardware and the current CPU load the performance might be either poor or well.\r\nBy using the qos compression feature the desired write throughput can be chosen to meet the requirement for the application.\r\nThe qos algorithm keeps track of the compression speed and chooses either lz4 or gzip-[1-9] to speed up / slow down while compressing data. \r\n\r\n<!--- ### How Has This Been Tested? -->\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n### Benchmark1\r\n\r\nCopy file from Tempfs to ZFS into 1 Dataset:\r\n\r\nName | MB/s\t| Ratio\r\n ---   \t|  --- \t| ---\r\ngzip9\t| 11\t| 0.37\r\nqos10\t| 10\t| 0.38\r\nqos20\t| 22\t| 0.41\r\nqos30\t| 35\t| 0.45\r\nqos40\t| 45\t| 0.48\r\nqos50\t| 55\t| 0.50\r\nlz4\t| 71\t| 0.57\r\noff\t| 62\t| 1\r\n\r\n\r\n### Motivation2\r\n\r\nTransactiongroups in ZFS cause simultaneous writes into multiple datasets to wait for each other to complete. The slowest dataset is the limitation to the overall performance.\r\nThe qos feature can prevent this through dataset prioritisation.\r\nThe maximum bandwidth is limited by the disk throughput. Every dataset can request a part of this bandwidth by setting the qos property value.\r\nData can now be organised into low priority datasets with low quality of service requirements (but high compression, see Motivation1) and high priority to which also all non qos datasets belong.\r\nAll inheriting datasets and their parent share the same requested bandwidth. If the value of an inheriting dataset (lower hierarchy) is explicitly changed from \"inherit\" to \"qos\" then this dataset will request its own bandwidth.\r\n\r\n\r\n### Benchmark2\r\n\r\nCopy 2 files from Tempfs to ZFS into 2 Datasets:\r\n\r\nName     \t\t\t|MB/s\t|MB/s\t|Ratio\t|Ratio\t| Comment\r\n--- | --- | --- | --- | --- | ---\r\nqos10/qos10 - qos10/qos10_2\t|5\t|5\t|0.47\t|0.49\t|use of inheritance\r\nqos10 - qos10/qos10\t\t|5\t|5\t|0.49\t|0.47\t|use of inheritance\r\nqos10 - qos10_2\t\t\t|11\t|10\t|0.46\t|0.48\t| \r\nqos10/qos10 - qos10/qos10x\t|11\t|9\t|0.48\t|0.46\t|qos-10 explicit <br>set on qos10x\r\nqos10/qos20 - qos10\t\t|20\t|9\t|0.49\t|0.43\t| \r\nqos30 - qos10\t\t\t|29\t|9\t|0.52\t|0.40\t| \r\nqos40 - qos10\t\t\t|44\t|10\t|0.54\t|0.40\t| \r\nqos50 - qos10\t\t\t|51\t|9\t|0.53\t|0.40\t| \r\nlz4 - qos10\t\t\t|71\t|9\t|0.57\t|0.39\t| lz4 has high priority\r\noff - qos10\t\t\t|62\t|8\t|1\t|0.38\t| \r\ngzip9 - qos10\t\t\t|13\t|5\t|0.37\t|0.39\t| \r\nlz4 - gzip9\t\t\t|10\t|10\t|0.57\t|0.37\t|  lz4 waiting for gzip\r\n\r\n\r\n### Benchmark3\r\n\r\nCopy 2 files from Tempfs to ZFS into 1 Datasets:\r\n\r\nName     \t\t\t|MB/s\t|MB/s\t|Ratio\r\n--- | --- | --- | --- \r\nqos10 - qos10 |\t5\t|5|\t0,38\r\noff - off|\t22|\t22|\t1\r\nlz4 - lz4|\t30|\t27|\t0,57\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n\r\n#### Branch overlapping changes (feature, compress values)\r\nThe patch has read-only backward compatibility by using the new introduced SPA_FEATURE_COMPRESS_QOS feature. The feature activation procedure is equivalent to my other code branches.\r\nRegarding the limited namespace of BP_GET_COMPRESS() (128 values), the\r\nzio_compress enum's first part is for block pointer & dataset values, the second part for dataset values only. Or should I make use of a new property? This is an alternative suggestion to #3908.\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/5928", "title": "auto compression", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\nAs part of my master thesis at University of Hamburg I have targeted to improve ZFS through compression. Now I would like to share my 3 feature branches with the community.\r\n\r\n1. lz4fast #5927 \r\n2. autocompression (current)\r\n3. qos #5929 \r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\nThis patch adds auto as ZFS compression type.\r\nzfs set compression=auto\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\nWhich compression algorithm is best for high throughput? The answer to this depends on the type of hardware in use.\r\nIf compression takes long then the disk remains idle. If compression is faster than the writing speed of the disk then the CPU remains idle as compression and writing to the disk happens in parallel.\r\nAuto compression tries to keep both as busy as possible.\r\nThe disk load is observed through the vdev queue. If the queue is empty a fast compression algorithm like lz4 with low compression rates is used and if the queue is full then gzip-[1-9] can require more CPU time for higher compression rates.\r\nThe already existing zio_dva_throttle might conflict with the concept described above. Therefore it is recommended to deactivate zio_dva_throttle.\r\n\r\n<!--- ### How Has This Been Tested? -->\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\n### Benchmark\r\n\r\nCopy file from Tempfs to ZFS\r\n\r\n\r\n8 Cores:\r\n\r\nName\t|Ratio\t|MB/s\r\n---\t|---\t|---\r\nauto\t|0.44  \t|245\r\ngzip-1\t|0.43  \t|255\r\nlz4\t|0.58  \t|195\r\noff\t|1 \t|99\r\n\r\n\r\n1 Core:\r\n\r\nName\t|Ratio\t|MB/s\r\n---\t|---\t|---\r\nauto\t|0.56 \t|151\r\ngzip-1\t|0.43\t|51\r\nlz4\t|0.58\t|179\r\noff\t|1\t|99\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n\r\n#### Branch overlapping changes (feature, compress values)\r\n\r\nThe patch is has read-only backward compatibility by using the new introduced SPA_FEATURE_COMPRESS_AUTO feature. The feature activation procedure is equivalent to my other code branches.\r\nRegarding the limited namespace of BP_GET_COMPRESS() (128 values), the\r\nzio_compress enum's first part is for block pointer & dataset values, the second part for dataset values only. This is an alternative suggestion to #3908.\r\n\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/5927", "title": "lz4fast compression", "body": "<!--- Provide a general summary of your changes in the Title above -->\r\nAs part of my master thesis at University of Hamburg I have targeted to improve ZFS through compression. Now I would like to share my 3 feature branches with the community.\r\n\r\n1. lz4fast (current)\r\n2. autocompression #5928 \r\n3. qos #5929 \r\n\r\nThis patch updates the lz4 *1 code to version 1.7.3 to make use of lz4 fast compression.\r\nThe lz4 code is based on a seperate project for updating lz4 inside the linux kernel.\r\nThere a few changes were made for an clean implementation and to improve speed that are currently in review *2.\r\n\r\n*1: [https://github.com/lz4/lz4](https://github.com/lz4/lz4)\r\n*2: [https://patchwork.kernel.org/patch/9574745/](https://patchwork.kernel.org/patch/9574745/)\r\n\r\n\r\n### Description\r\n<!--- Describe your changes in detail -->\r\nLZ4-fast capability is now available.\r\nzfs set compression=lz4fast-[1-20,30,+10*n,100]\r\nHigher values result in improved compression speed and less ratio.\r\n\r\n\r\n### Motivation and Context\r\n<!--- Why is this change required? What problem does it solve? -->\r\n<!--- If it fixes an open issue, please link to the issue here. -->\r\nLz4 fast trades in compression ratio for speed. This gives us more flexibility in environments with either low computational power or fast and many SSDs/HDDs where the lz4 is the limiting factor.\r\nAutocompression and qos can also be improved by adding lz4fast algorithms.\r\n\r\n### How Has This Been Tested?\r\n<!--- Please describe in detail how you tested your changes. -->\r\n<!--- Include details of your testing environment, and the tests you ran to -->\r\n<!--- see how your change affects other areas of the code, etc. -->\r\n<!--- If your change is a performance enhancement, please provide benchmarks here. -->\r\nChecksums were made to proof full compatibility between the old and new lz4 compressed files.\r\n\r\n#### Benchmark\r\n\r\nCopy file from Tempfs to ZFS (ZFS also in Tempfs for high disk throughput simulation).\r\n\r\n\r\nName         |Ratio   |MB/s\r\n---          |---     |---\r\nlz4          |0.58    |228\r\nlz4fast-2    |0.62    |249\r\nlz4fast-3    |0.65    |266\r\nlz4fast-4    |0.68    |282\r\nlz4fast-5    |0.71    |298\r\nlz4fast-7    |0.76    |329\r\nlz4fast-10   |0.80    |370\r\nlz4fast-20   |0.97    |469\r\nlz4fast-30   |0.98    |546\r\nlz4fast-50   |0.98    |634\r\nlz4fast-100  |0.99    |690\r\noff          |1       |744\r\n\r\n\r\n### Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] Performance enhancement (non-breaking change which improves efficiency)\r\n- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n\r\n#### Branch overlapping changes (feature, compress values)\r\n\r\nThe patch has read-only backward compatibility by using the new SPA_FEATURE_LZ4FAST_COMPRESS feature. The feature activation procedure is equivalent to my other code branches.\r\nRegarding the limited namespace of BP_GET_COMPRESS() (128 values), the\r\nzio_compress enum's first part is for block pointer & dataset values, the second part for dataset values only. Or should I make use of a new property? This is an alternative suggestion to #3908.\r\n\r\n### Checklist:\r\n<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->\r\n<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->\r\n- [x] My code follows the ZFS on Linux code style requirements.\r\n- [ ] I have updated the documentation accordingly.\r\n- [x] I have read the **CONTRIBUTING** document.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] All new and existing tests passed.\r\n- [ ] Change has been approved by a ZFS on Linux member.\r\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "thegreatgazoo": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/5841", "title": "dRAID vdev driver", "body": "This patch implements the dRAID vdev driver and a new rebuild mechanism (#3497). Most features are complete, except:\r\n- Rebuild stop and resume, and persistant rebuild state.\r\n- Support for HW-accelerated parity routines: The dRAID code uses the raidz parity functions (generation, and reconstruction) but needs a small change. Currently the change has been made only to the original raidz parity functions, i.e. not the new HW-accelerated ones.\r\n\r\nHowever, this is still work in progress: user interface may change, on-disk format may change as well. Also, there's still some crufty hacks I'm going to clean up.\r\n\r\nI've added a [dRAID howto](https://github.com/zfsonlinux/zfs/wiki/dRAID-HOWTO). It contains only basics for now, but I'll continue to update the document.\r\n\r\nPlease report bugs to [the dRAID project](https://github.com/thegreatgazoo/zfs/issues).\r\n\r\nComments, testing, fixes, and porting are greatly appreciated!\r\n\r\nCode structure:\r\n- New code\r\n  - module/zfs/vdev_draid.c: vdev driver for draid and draid spare\r\n  - module/zfs/spa_scan.c: sequential rebuild, for both draid and mirror vdevs\r\n  - cmd/draidcfg/*.[ch]: user space tools, mainly to create permutations\r\n- Changes to existing code\r\n  - module/zfs/vdev_raidz.c: the parity functions need to include draid skip sectors for computation and reconstruction.\r\n  - module/zfs/vdev_mirror.c: minor changes to support mirror_map_t allocated by draid vdev (for hybrid mirror support)\r\n  - module/zfs/metaslab.c: to add support for draid hybrid mirror, also disallow block allocation during rebuild\r\n  - Other changes:\r\n    - Add knowledge about the new vdev types and the new rebuild mechanism\r\n    - draid spare pretends to be a leaf but is actually not. Some code needs to be aware of that, e.g. handling labels on leaf vdevs.\r\n\r\nThe goal is to change existing code in a way that when draid is not in use the effective change is none. Though there's still some cleanups needed.", "author_association": "MEMBER"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ghost": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1276681", "body": "Has this issue been resolved? I'm having the same problem on OpenSolaris with ZFS. The zpool-rpool process is writing on average at 400MB/h on an idle system. I can't seem to find an answer anywhere on the net.\n\nThanks for your help.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1276681/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1277385", "body": "A quick DTrace on what the zpool-rpool process is doing reveals the following kernel function calls, accompanied by the number of times they have been called (the sampling lasted about a minute). Does this mean anything to you?\n\n``` DTrace\nrootnex`rootnex_coredma_allochdl          1\nrootnex`rootnex_dma_allochdl            1\nscsi`scsi_transport                     1\nzfs`buf_hash                            1\nzfs`arc_write_done                      1\nzfs`dbuf_find                           1\nzfs`dbuf_dirty                          1\nzfs`metaslab_ndf_alloc                  1\nzfs`spa_writeable                       1\nzfs`space_map_load                      1\nzfs`vdev_queue_deadline_compare          1\nzfs`vdev_queue_offset_compare           1\nzfs`vdev_queue_io                       1\nzfs`zio_buf_free                        1\nzfs`zio_remove_child                    1\nzfs`zio_destroy                         1\nzfs`zio_vdev_io_done                    1\nzfs`zrl_add                             1\nahci`ahci_check_ctl_handle              1\nsata`sata_scsi_start                    1\nsata`sata_txlt_write                    1\nsd`sdstrategy                           1\nsd`sd_core_iostart                      1\nsd`sd_initpkt_for_buf                   1\nsd`sd_start_cmds                        1\nunix`sep_save                           1\nunix`splr                               1\nunix`tsc_gethrtime                      1\nunix`tsc_scalehrtime                    1\nunix`bcopy                              1\nunix`gdt_update_usegd                   1\nunix`lock_set                           1\nunix`cmt_balance                        1\nunix`swtch                              1\nunix`disp_ratify                        1\nunix`default_lock_backoff               1\nunix`lock_set_spin                      1\ngenunix`avl_walk                        1\ngenunix`avl_rotation                    1\ngenunix`cv_broadcast                    1\ngenunix`ddi_fm_acc_err_get              1\ngenunix`disp_lock_enter                 1\ngenunix`thread_lock                     1\ngenunix`ldi_strategy                    1\ngenunix`copy_pattern                    1\ngenunix`kmem_zalloc                     1\ngenunix`list_create                     1\ngenunix`list_remove                     1\ngenunix`ddi_get_soft_state              1\ngenunix`restorectx                      1\nzfs`buf_hash_insert                     2\nzfs`dnode_diduse_space                  2\nzfs`zio_push_transform                  2\nzfs`zio_walk_parents                    2\nzfs`zio_done                            2\nzfs`zio_checksum_compute                2\nzfs`vdev_disk_io_start                  2\nsha2`SHA256TransformBlocks              2\nsd`sd_mapblockaddr_iostart              2\nsd`sd_add_buf_to_waitq                  2\nsd`ddi_xbuf_qstrategy                   2\nsd`xbuf_iostart                         2\nunix`rw_enter                           2\nunix`disp                               2\nunix`atomic_add_64_nv                   2\ngenunix`avl_remove                      2\ngenunix`avl_numnodes                    2\ngenunix`lbolt_event_driven              2\ngenunix`ddi_fm_dma_err_get              2\ngenunix`kmem_cache_free                 2\ngenunix`memcpy                          2\ngenunix`cpu_update_pct                  2\ngenunix`ndi_fmc_insert                  2\ngenunix`taskq_thread_wait               2\nzfs`arc_write_ready                     3\nzfs`metaslab_alloc_dva                  3\nzfs`vdev_accessible                     3\nzfs`zio_wait_for_children               3\nzfs`zio_notify_parent                   3\nzfs`zio_vdev_io_start                   3\nsd`sd_setup_rw_pkt                      3\nunix`mutex_owner_running                3\nunix`rw_exit                            3\nunix`mutex_vector_enter                 3\nunix`vsnprintf                          3\ngenunix`avl_last                        3\nzfs`space_map_remove                    4\nzfs`zio_execute                         4\nsd`sdinfo                               4\nunix`mutex_exit                         4\nzfs`metaslab_group_alloc                5\nzfs`vdev_queue_io_to_issue              5\nunix`bzero                              5\nunix`disp_getwork                       5\ngenunix`avl_insert                      5\nunix`0xfffffffffb85                     6\nunix`tsc_read                           6\ngenunix`kmem_cache_alloc                6\nunix`do_splx                            7\nzfs`space_map_seg_compare               9\nzfs`metaslab_segsize_compare           10\ngenunix`avl_find                       10\nunix`default_lock_delay                11\nzfs`fletcher_4_native                  12\nunix`mutex_enter                       16\nunix`mutex_delay_default               54\nzfs`lzjb_compress                     151\n```\n\nWe can see that the most called function is by far lzjb_compress. Again, DTrace reveals that all the kernel stacks that lead to lzjb_compress pass through the function zio_write_bp_init, which I assume is the guilty function behind all these writes...\n\nDoes this all mean anything to you?\n\nEdit:  kernel stacks\n\n``` DTrace\n              zfs`zio_compress_data+0x8e\n              zfs`zio_write_bp_init+0x216\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              genunix`taskq_thread+0x248\n              unix`thread_start+0x8\n                1\n\n              zfs`zio_compress_data+0x8e\n              zfs`zio_write_bp_init+0x216\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              genunix`taskq_thread+0x248\n              unix`thread_start+0x8\n                1\n\n              zfs`zio_compress_data+0x8e\n              zfs`zio_write_bp_init+0x216\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n                2\n\n              zfs`zio_compress_data+0x8e\n              zfs`zio_write_bp_init+0x216\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              genunix`taskq_thread+0x248\n              unix`thread_start+0x8\n                5\n\n              zfs`zio_compress_data+0x8e\n              zfs`zio_write_bp_init+0x216\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              genunix`taskq_thread+0x248\n              unix`thread_start+0x8\n                6\n\n              zfs`zio_compress_data+0x8e\n              zfs`zio_write_bp_init+0x216\n              zfs`zio_execute+0x8d\n              zfs`zio_notify_parent+0xa6\n              zfs`zio_ready+0x18b\n              zfs`zio_execute+0x8d\n              genunix`taskq_thread+0x248\n              unix`thread_start+0x8\n               13\n\n              zfs`zio_compress_data+0x8e\n              zfs`zio_write_bp_init+0x216\n              zfs`zio_execute+0x8d\n              genunix`taskq_thread+0x248\n              unix`thread_start+0x8\n               31\n```\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1277385/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1281342", "body": "Here is a list processes which called the write system call on my system, accompanied by the filenames and the total number of bytes written to the files (sampled during one minute):\n\n```\ndtrace -n 'syscall::*write:entry {@[execname, fds[arg0].fi_pathname] = sum (arg2);}'\ndtrace: description 'syscall::*write:entry ' matched 2 probes\n^C\n\n  dtrace                                              /dev/pts/1                                                        1\n  sshd                                                /devices/pseudo/clone@0:ptm                                       1\n  sshd                                                <unknown>                                                        52\n  rsfcli                                              <unknown>                                                       105\n  basename                                            <unknown>                                                       164\n  hostname                                            <unknown>                                                       304\n  syslogd                                             /devices/pseudo/sysmsg@0:sysmsg                                 320\n  awk                                                 <unknown>                                                       331\n  zfs                                                 /devices/pseudo/mm@0:null                                       370\n  java                                                /var/opt/nest/config/site/scheduledjobs/emailnotifications/Notification_ERROR.xml              433\n  java                                                /var/opt/nest/config/site/scheduledjobs/emailnotifications/Notification_WARNING.xml              437\n  java                                                /var/opt/nest/config/site/scheduledjobs/configurationreplications/SiteConfigReplication.xml              511\n  grep                                                <unknown>                                                       725\n  cron                                                /var/cron/log                                                   976\n  java                                                /var/opt/nest/config/site/scheduledjobs/snapshots/Snapshot2290924711711069275.xml             1014\n  java                                                /var/opt/nest/config/site/scheduledjobs/snapshots/Snapshot12337134254217831034.xml             1020\n  java                                                /var/opt/nest/config/site/scheduledjobs/snapshots/Snapshot17476938304947820872.xml             1020\n  java                                                /var/opt/nest/config/site/scheduledjobs/asyncreplications/AsyncReplication13100962750907134551.xml             1056\n  java                                                /var/opt/nest/config/site/scheduledjobs/asyncreplications/AsyncReplication13881922923541859328.xml             1056\n  ksh                                                 <unknown>                                                      1096\n  fcinfo                                              <unknown>                                                      1152\n  zpool                                               <unknown>                                                      1452\n  ksh                                                 /tmp/sf0l.2ol                                                  1650\n  ksh                                                 /tmp/sf0p.gnd                                                  1650\n  ksh                                                 /tmp/sf10.jmu                                                  1650\n  ksh                                                 /tmp/sf1g.3nv                                                  1650\n  ksh                                                 /tmp/sf1i.jvb                                                  1650\n  ksh                                                 /tmp/sf24.5eq                                                  1650\n  ksh                                                 /tmp/sf2f.jop                                                  1650\n  ksh                                                 /tmp/sf3b.beh                                                  1650\n  ksh                                                 /tmp/sf10.ujs                                                  3000\n  ksh                                                 /tmp/sf19.9c4                                                  3000\n  ksh                                                 /tmp/sf2a.o3i                                                  3000\n  ksh                                                 /tmp/sf2p.8d0                                                  3000\n  ksh                                                 /tmp/sf3k.j08                                                  3000\n  svcprop                                             <unknown>                                                      3140\n  format                                              <unknown>                                                      3644\n  sed                                                 <unknown>                                                      3704\n  fmd                                                 /var/fm/fmd/infolog_hival                                      4480\n  nscd                                                <unknown>                                                      5268\n  zfs                                                 <unknown>                                                      5778\n  init                                                /etc/svc/volatile/init-next.state                              9064\n  iostat                                              <unknown>                                                      9102\n  svccfg                                              <unknown>                                                      9801\n  fmtopo                                              <unknown>                                                    429332\n```\n\nIn contrast, for the same duration, here is the list of actual disk writes that were initiated, again accompanied by the filenames and number of bytes.\n\n```\ndtrace -n 'io:::start /args[0]->b_flags & B_WRITE/ {@[execname, args[2]->fi_pathname]=sum(args[0]->b_bcount);}'\ndtrace: description 'io:::start ' matched 6 probes\n^C\n\n  sched                                               /var/opt/nest/config/site/scheduledjobs/configurationreplications/SiteConfigReplication.xml             4096\n  sched                                               /var/opt/nest/config/site/scheduledjobs/emailnotifications/Notification_ERROR.xml             4096\n  sched                                               /var/opt/nest/config/site/scheduledjobs/emailnotifications/Notification_WARNING.xml             4096\n  sched                                               /var/opt/nest/config/site/scheduledjobs/asyncreplications/AsyncReplication13100962750907134551.xml             8192\n  sched                                               /var/opt/nest/config/site/scheduledjobs/asyncreplications/AsyncReplication13881922923541859328.xml             8192\n  sched                                               /var/opt/nest/config/site/scheduledjobs/snapshots/Snapshot12337134254217831034.xml             8192\n  sched                                               /var/opt/nest/config/site/scheduledjobs/snapshots/Snapshot17476938304947820872.xml             8192\n  sched                                               /var/opt/nest/config/site/scheduledjobs/snapshots/Snapshot2290924711711069275.xml             8192\n  zpool-rpool                                         <none>                                                     10463232\n```\n\nThe total number of bytes written to the disk by zpool-rpool alone is much higher than the total of bytes for which the write system call was used. Doesn't that mean that zpool-rpool is acting on its own?\n\nEdit: The two dtrace commands were run in parallel.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1281342/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1283961", "body": "Hmmm it's too bad there isn't a moderately easy way of knowing where all this I/O activity comes from. I tried disabling fmtopo (which is the biggest write-system-call writer) and still, zpool-rpool's io activity didn't seem to lower as significantly as it should have.\n\nAnyway, thanks for your input. I'll post if I find a solution to this on my side.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1283961/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/7731553", "body": "hmm. why not to do it in that way: let O_DIRECT always return true? does it metter that ZFS copies everything in to the ARC cache? let fake a bit an OS. It shouldn't hurt so much.... oh, and that is just my freak idea\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/7731553/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1873708", "body": "Hi - Not sure what's going on here as I don't know much regarding the programming/debugging of zfs but I seems to experience that issue, that is with or without rsync. I never had to read much files on my system as I use zfs for backups storage, however I just had to restore things from the zfs pool and it crashed after a while.. rebooted.. crashed after a while..\n\nHere is the error I found in dmesg/syslog : http://pastebin.com/jMTCNEFy\n\nIf there is anything I can do to help, as far as testings, don't hesitate to let me know.\n\nThanks,\n\nedit: using git from 2011-08-22 on debian squeeze\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/1873708/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/2064709", "body": "Alphalead : I think your trick allowed my rsync session to last longer but after a while it crashed again unfortunately\n\nMessage from syslogd@stor01 at Sep 11 12:18:11 ...\n kernel:[1714241.981661] Oops: 0002 [#1] SMP\n\nMessage from syslogd@stor01 at Sep 11 12:18:11 ...\n kernel:[1714241.981673] last sysfs file: /sys/module/mbcache/initstate\n\nMessage from syslogd@stor01 at Sep 11 12:18:11 ...\n kernel:[1714241.982056] Stack:\n\nMessage from syslogd@stor01 at Sep 11 12:18:11 ...\n kernel:[1714241.982133] Call Trace:\n\nMessage from syslogd@stor01 at Sep 11 12:18:11 ...\n kernel:[1714241.982206] Code: 49 8b 14 04 48 c1 e2 03 e8 83 88 ff ff 85 c0 75 10 48 8d 54 24 70 48 89 de 44 89 ef e8 5b f3 ff ff 48 8b 54 24 50 be d0 00 00 00 <48> c7 02 00 00 00 00 48 8b 54 24 48 48 8b 7c 24 70 e8 7d f6 ff\n\nMessage from syslogd@stor01 at Sep 11 12:18:11 ...\n kernel:[1714241.982346] CR2: 0000000000000000\n\nedit: version used is latest commit (2708f716c0)\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/2064709/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/2006354", "body": "I can confirm that his bug does **not exist** in zfs-fuse for linux. \n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/2006354/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/2352510", "body": "Gunnar Beutner was able to come up with a patch for this. I tested it on my development device and so far it works exactly as intended. We're doing some more testing later this week; at this point I would consider this ready for official evaluation so that it can be committed and this bug closed. I will post back here if we encounter any problems while we are testing this patch.\n\nhttps://gunnar-beutner.de/files/0001-Fixed-invalid-resource-re-use-in-file_find.patch\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/2352510/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/2811567", "body": "zfs-fuse:\n\n<pre>\ndd if=/dev/zero of=/tank/xxx/test.io bs=1024k count=1000\n1000+0 records in\n1000+0 records out\n1048576000 bytes (1.0 GB) copied, 8.48609 s, 124 MB/s\n</pre>\n\nubuntu-zfs:\n\n<pre>\ndd if=/dev/zero of=/tank/xxx/test.io bs=1024k count=1000\n1000+0 records in\n1000+0 records out\n1048576000 bytes (1.0 GB) copied, 114.533 s, 9.2 MB/s\n</pre>\n\nOk, i try recreate pool under ubuntu-zfs\n\n<pre>\n# zpool offline tank sdc\n# zpool detach tank sdc\n# zpool create -f test sdc\n# zpool status test\n  pool: test\n state: ONLINE\n scan: none requested\nconfig:\n\n        NAME        STATE     READ WRITE CKSUM\n        test        ONLINE       0     0     0\n          sdc       ONLINE       0     0     0\n\nerrors: No known data errors\n# zfs create test/xxx\n# dd if=/dev/zero of=/test/xxx/test.io bs=1024k count=1000\n1000+0 records in\n1000+0 records out\n1048576000 bytes (1.0 GB) copied, 53.5897 s, 19.6 MB/s\n</pre>\n\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/2811567/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/3299069", "body": "behlendorf, probably, i had bad results because i was try to use 32 bit OS.\nFresh install ferdora 16 32 bit was the same, but zfs on fedora 16 (x64) shows performance near to raw device.\nThanks.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/3299069/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/11986018", "body": "Please fix this, a year later it is still not working. Rudd-O has an open pull request, can it be pulled into te main branche?\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/11986018/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/3399837", "body": "Pretty much this is how I went about setting up everything.\n\nMy platform is Ubuntu 10.04.3 x86 (also used x64) running as a VMware VM on my laptop (as test).\n\nI downloaded the source and compiled as per the instructions on the ZFS on linux website.\n\nThen I compiled the Linux iSCSI target core backports from linux-iscsi.org. I also compiled the lio-utils and targetcli (the management tools).\n\nAfter I installed the deb packages of everything (iscsi target and ZFS) I created my zpool called (tank) and my zfs vol (fish). Because it was a test I just used the names from the website because it did not matter.\n\nThe command I use were the following;\n\nparted /dev/sdb\nmklabel gpt\nquit\n\nparted /dev/sdc\nmklabel gpt\nquit\n\nzpool create tank mirror /dev/sdb /dev/sdc\n\nzfs create tank/fish -V 18G\n\nAfter that was done I dropped into the targetcli tool and tried to add a block device to the /backstores/iblock section. The targetcli emulates a file system, kind of reminds me of /proc or /sys. When I execute the command \"create disk0 /dev/zd0\" it returns and error to me saying the chosen device is not a valid \"TYPE_DISK\". I am not sure though if \"TYPE_DISK\" is something internal to the target or if it is a Linux thing.\n\nThe only way I could use ZFS with the target was to format the ZFS vol with something like ext4 and then create an image file with dd then use the file_io feature of the target. But the is not only complicated but completely undermines the entire point of using ZFS.\n\nWhen I mentioned that the ZFS vols have no vendor information I was referring to what I see when I run \"parted -l\" and look at /dev/zd0. When compared to the VMware disks there is information about who made the disk or anything, not even faked information just to fill the space. I will add an output when I have a chance.\n\nIf you need anymore info let me know.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/3399837/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/3442037", "body": "I get the code from there git repo. git://risingtidesystems.com/\n\nThe only slightly annoying thing is you have to build several packages before you can build the targetcli tool.\n\nBut everything you need is there.\n\nYou need to build the tools in an similar order to this;\n1. lio-utils\n2. configshell\n3. rtslib\n4. targetcli\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/3442037/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/3707762", "body": "I have small update to announce based on my reported issue, I may have a source of the problem.\n\nI believe the error \"Not TYPE_DISK\" is a problem with the iSCSI target drivers and may have nothing to do with ZFS.\n\nThe reason for the error I hypothoize is because ZFS is not listing it ZVOLs in /dev/disk which is most likely where the iSCSI target is look for them and that would sort of explain the error, because it is say that the ZVOL is not a type of device found is /dev/disk. \n\nSo unless something changes with the iSCSI target drivers before the \"final\" release with kernel v3.4 then ZFS just may have sit out on that one.\n\nI will \"try\" to report the issue to the devs of the iSCSI target but I have not heard anything since before Christmas when I last attempted.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/3707762/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/5439790", "body": "Experiencing the same issues with 2.6.32-41 on 10.04 (AMD X2-555 proc in an ASUS M4A88T MB, 16GB ecc).  No apparent problems with 2.6.32-40.  Sorry for lack of trace info, may have time this weekend.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/5439790/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/5441206", "body": "Correction, 12GB.  Might as well mention this:\nJust did a quick check and BIOS version was latest but release date appeared inconsistent.  So updated BIOS anyway, disabled legacy USB, and booted 2x4GB with just channel A (matched pair).  Checked dmesg and errata message is still there.   There's a sleeping zfs mount -a process (configured automount) and any zpool/zfs commands in a shell hang.  FWIW.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/5441206/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/7986088", "body": "I've installed Fedora 17 to a test System with ZFS due to @Rudd-O  \n+1 to this\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/7986088/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/20962527", "body": "Allow me to shed some light on this.\n\nLet's consider an old-school nfs4 export using a native Linux filesystem, one share called 'pmr':\n\n``` /etc/fstab\n/dev/groups/pmr /storage/pmr      xfs    inode64,logdev=/dev/ssdcache/pmr,logbufs=8  1 2\n/storage/pmr    /exports/pmr      none   rw,bind         0 0\n```\n\n``` /etc/exports\n/exports     [nfs4 export root settings]\n/exports/pmr [per-share settings]\n```\n\nWhen the system is booting, the xfs filesystem will be mounted first, followed by a bind mount from /storage/pmr to /exports/pmr. The latter then is exported via /etc/exports using nfs4 and we're all happy.\n\nNow consider a zfs-based scenario.\n\nSince there are no zfs entries in fstab, it becomes:\n\n``` /etc/fstab\n/storage/pmr    /exports/pmr      none   rw,bind         0 0\n```\n\nWhen the system boots, a bind-type mount will be created from /storage/pmr to /exports/pmr which is effectively mounting the underlying filesystem (most likely / ) to the bind point and exporting that. The clients will see the contents of an empty directory as the exporter uses the / bind mount. On the server, the confused administrator will see the actual zfs and will scratch their head.\n\nI don't think this is a bug in zfs rather a race condition between the distribution's native localfs init script and zfs. Perhaps localfs should depend on zfs and not the other way around.\n\nAlternatively, the zfs service should parse some file that will tell it how the binds go and bind after mounting the zfs filesystem. Perhaps a file in /etc/zfs/ like 'binds' would work.\n\nPersonally (sysadmin cap on) /etc/zfs/binds would work for me (together with a bit of parsing in /etc/init.d/zfs) as it's sufficiently low-tech and doesn't require changes in the actual zfs stack.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/20962527/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/20965023", "body": "Proposed patch (only lsb script, others are most likely derivative):\n\n``` patch\n--- etc/init.d/zfs.lsb.in.orig  2013-07-15 12:47:20.055257882 +0100\n+++ etc/init.d/zfs.lsb.in       2013-07-15 12:49:44.732137370 +0100\n@@ -29,6 +29,7 @@\n ZFS=\"@sbindir@/zfs\"\n ZPOOL=\"@sbindir@/zpool\"\n ZPOOL_CACHE=\"@sysconfdir@/zfs/zpool.cache\"\n+ZFS_NFS4_BINDS=\"@sysconfdir@/zfs/binds\"\n\n # Source zfs configuration.\n [ -r '/etc/default/zfs' ] &&  . /etc/default/zfs\n@@ -78,6 +79,26 @@\n                log_end_msg $?\n        fi\n\n+        # Create (optional) binds to the NFS4 export tree\n+        if [ -e \"$ZFS_NFS4_BINDS\" ] ; then\n+                log_begin_msg \"Binding NFS4 mounts\"\n+                sed -e \"s/#.*//\" -e \"/^$/d\" $ZFS_NFS4_BINDS | while read LINE\n+                do\n+                        MODE=\"`echo $LINE | awk '{print $1}'`\"\n+                        SRC=\"`echo $LINE | awk '{print $2}'`\"\n+                        DEST=\"`echo $LINE | awk '{print $3}'`\"\n+                        case $MODE in\n+                                bind)   MOUNTPOINT=\"`zfs get mountpoint $SRC | grep \"$SRC\" | awk '{print $3}'`\"\n+                                        mount -o $MODE $MOUNTPOINT $DEST\n+                                        log_end_msg $?\n+                                        ;;\n+                                *)      echo \"Unknown bind mode ($MODE) in $ZFS_NFS4_BINDS. Aborting.\"\n+                                        exit 4\n+                                        ;;\n+                        esac\n+                done\n+        fi\n+\n        touch \"$LOCKFILE\"\n }\n\n@@ -85,6 +106,25 @@\n {\n        [ ! -f \"$LOCKFILE\" ] && return 3\n\n+       if [ -e \"$ZFS_NFS4_BINDS\" ] ; then\n+                log_begin_msg \"Detaching NFS4 binds\"\n+                sed -e \"s/#.*//\" -e \"/^$/d\" $ZFS_NFS4_BINDS | while read LINE\n+                do\n+                        MODE=\"`echo $LINE | awk '{print $1}'`\"\n+                        SRC=\"`echo $LINE | awk '{print $2}'`\"\n+                        DEST=\"`echo $LINE | awk '{print $3}'`\"\n+                        case $MODE in\n+                                bind)   MOUNTPOINT=\"`zfs get mountpoint $SRC | grep \"$SRC\" | awk '{print $3}'`\"\n+                                        umount $DEST\n+                                        log_end_msg $?\n+                                        ;;\n+                                *)      echo \"Unknown bind mode ($MODE) in $ZFS_NFS4_BINDS. Aborting.\"\n+                                        exit 4\n+                                        ;;\n+                        esac\n+                done\n+        fi\n+\n        log_begin_msg \"Unmounting ZFS filesystems\"\n        \"$ZFS\" umount -a\n        log_end_msg $?\n```\n\n$MODE may look redundant but perhaps could be kept for future expansion, maybe there could be other bind types.\n\nThe /etc/zfs/binds file would look like this:\n\n``` /etc/zfs/binds\n#    zpool[/dataset]        mountpoint\nbind storage/pmr            /exports/pmr\n```\n\nOf course the distribution source would only contain the first line. I believe this is consistent with other files in /etc/zfs.\n\nCheers,\ngrok\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/20965023/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/45432317", "body": "@FransUrbo `/etc/rc.local` does not exist and is not called in all distributions. Even more, `systemd` based distributions (good luck finding one without it these days) won't have it by definition.\n\nAre you suggesting that instead of editing a config file (present, documented) you would rather ask everyone to roll their own code, manually create bind mounts? That doesn't sound like a sane systems management practice.\n\nWhen ZoL filesystem needs to be exported over NFS4, a bind mount must be created. No standard mechanism in GNU/Linux will allow for it if the filesystem is not present in `/etc/fstab`. Since it's ZFS that's 'special', I will argue that it is its own responsibility to provide the functionality required for other parts of the system to continue to function.\n\nIf you don't like my solution, that's fine, please provide a better one or show where exactly am I incorrect. Saying something is 'hackish' and then suggesting that sysadmins 'sort it out in rc.local' isn't constructive.\n\nRegards,\njz\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/45432317/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/45433327", "body": "@FransUrbo \n\nWhat use is a filesystem that cannot be exported over network?\n\nNFS4 exports are different from NFS3 exports. There is a certain, established standard of creating them in GNU/Linux, there exists a well documented process that is different from Solaris-isms still present in ZoL.\n\nI wasn't aware `zfs set sharenfs=on` is able to produce NFS4 mounts. Could you please quote options required to make that happen? How do you define the mount tree? This is different from NFS3.\n\nWhat bugs in other software are you referring to? Exporting NFS4 works perfectly fine in GNU/Linux. Since ZoL provides PV, VG and LV management as well as filesystem mount points in a way that is abstracted from the current device paradigm on Linux, certain steps need to be taken to make those two work together.\n\nWhile you are free to disagree, I still haven't seen a patch that solves the problem. GNU/Linux nfs-kernel-server (and this is ZFS on _Linux_) requires mount points bound into a central exports tree. Since binding is done early (and you can't make the `zfs` init script depend on `$localfs`) ZoL needs to catch up. \n\nNFS4 provides capabilities like idmapd (how would you propose to integrate `zfs set sharenfs` with starting `idmapd`, are there hooks for that? How do I call them?), caching, subtree checks, consistent filesystem IDs and performance improvements over NFS3.\n\nThe logical way to do it (and I have consulted this with a number of Linux Sysadmins before presenting it here) is for the init script to have a mechanism to create the required bound mounts to the exports tree. The section in the init script is self-contained, fails safe (no action if the config file isn't present) and does introduce required compatibility with the host operating system. In one file that is owned by the ZFS package.\n\nIf you continue to disagree, please produce a patch that solves the issue for NFS4 and ZoL or provide a way of exporting NFS4, including all the required export options like the following excerpt from a production environment:\n\n``` /etc/exports\n/exports     172.5.125.0/24(ro,async,wdelay,insecure,root_squash,no_subtree_check,fsid=0)\n/exports     172.5.124.0/25(ro,async,wdelay,insecure,root_squash,no_subtree_check,fsid=0)\n/exports/pmr 172.5.125.0/24(rw,async,wdelay,root_squash,no_subtree_check)\n/exports/pmr 172.5.124.0/25(rw,sync,wdelay,no_root_squash,no_subtree_check)\n```\n\nPlease understand, `rc.local` is the last resort, it isn't available on all distributions, some don't even have an equivalent script and requiring systems administrators to manually do those steps is error-prone. Perhaps one can do it on their home computer but hardly in an enterprise environment where consistency and sustainability is key.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/45433327/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/45434151", "body": "@FransUrbo \n\nThe issue #1029 you referred me to is highlighting the problem I've solved; no way to correctly set up NFS4 shares using Solaris-isms under Linux.\n\n> > Could you please quote options required to make that happen?\n> \n> I did. You need to slow down and read what's given to you.\n\nUnless you meant the four dots at the end of `zfs set sharenfs=on`, I must have missed it.\n\nI'm not going to continue this conversation with you as it's no longer productive.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/45434151/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/73043264", "body": ":+1: \n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/73043264/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/10101505", "body": "oh, how embarrassing.. adding autogen.sh to my weekly routine. Thanks!\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/10101505/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/13097318", "body": "Hey, so while apt-get update automatically chooses 3.6.0-23-virtual for the chroot , I should rather install 3.6.0-29-generic which is the same as the hosts?  Gotcha.\nJust worth noting that i've followed the HOW TO step-by-step and that a virtual kernel (different from the hosts) gets installed by default when installing ubuntu-minimal in a chroot environment.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/13097318/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/13114557", "body": "Thanks for the replies, No objections behlendorf. \nCheers\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/13114557/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/17124603", "body": "http://zfsonlinux.org/faq.html#WhyShouldIUseA64BitSystem\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/17124603/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/39197997", "body": "Some testing on SLES11 SP3 (obs build instance):\n\nThe `path_lookup()` is also triggered on SLES' 3.0.101 kernel so it looks like a proper autoconf check is required.\n\n@Milan-Benes:\n\nSince `spl_kern_path_parent` macro can expand to either `path_lookup(path, LOOKUP_PARENT, nd)`, `kern_path_parent_fn(path, nd)` or `kern_path_parent(path, nd)`, a _quick and very, very dirty_ fix would be to manually patch and build if you're desperate for the functionality. \n\nNote that the `kern_` functions use 2 arguments and not 3 so (I'm going to hell for this!) the middle one needs to go.\n\nSo after applying https://github.com/zfsonlinux/zfs/pull/1655 to 0.6.2 you can try something like this:\n\n``` patch\n--- module/zfs/zfs_ctldir.c.orig        2014-04-01 12:48:37.756605773 +0100\n+++ module/zfs/zfs_ctldir.c     2014-04-01 12:50:58.674195921 +0100\n@@ -997,8 +997,8 @@\n                goto out_path_buff;\n        }\n\n-       error = path_lookup(path_buff, LOOKUP_FOLLOW | LOOKUP_DIRECTORY, &nd);\n-       if (!error)\n+       error = kern_path_parent(path_buff, &nd);\n+       if (!error)\n                path_put(&nd.path);\n\n out_path_buff:\n```\n\nIt builds but **be warned**, may eat your gerbil.\n\n**Edit:** \n\n```\nZFS: snapshot home/tank@auto_daily-2014-03-27-1600 auto mounted at /home/tank/.zfs/snapshot/auto_daily-2014-03-27-1600 unexpectedly unmounted\n```\n\nAnd a nice NULL pointer:\n\n```\nApr  1 13:32:24 hematus kernel: [   83.305579] ZFS: snapshot home/tank@auto_daily-2014-03-27-1600 auto mounted at /home/tank/.zfs/snapshot/auto_daily-2014-03-27-1600 unexpectedly unmounted\nApr  1 13:35:00 hematus kernel: [  239.301971] BUG: unable to handle kernel NULL pointer dereference at 0000000000000020\nApr  1 13:35:00 hematus kernel: [  239.301978] IP: [<ffffffffa065e3a6>] zfsctl_lookup_snapshot_path+0x1a6/0x2c0 [zfs]\nApr  1 13:35:00 hematus kernel: [  239.302022] PGD 0\nApr  1 13:35:00 hematus kernel: [  239.302024] Oops: 0000 [#1] SMP\nApr  1 13:35:00 hematus kernel: [  239.302027] CPU 10\nApr  1 13:35:00 hematus kernel: [  239.302028] Modules linked in: md5 nfsd autofs4 binfmt_misc edd nfs lockd fscache auth_rpcgss nfs_acl sunrpc mpt3sas mpt2sas scsi_transport_sas raid_class mptctl mptbase bonding mperf microcode ext3 jbd mbcache loop flashcache(FN) pciehp zfs(PFN) zcommon(PFN) znvpair(PFN) zavl(PFN) zunicode(PFN) spl(FN) ipv6 ipv6_lib zlib_deflate ixgbe joydev usbhid hid igb usb_storage dca ptp dcdbas(X) pcspkr shpchp pci_hotplug sr_mod mei ses iTCO_wdt cdrom enclosure iTCO_vendor_support button wmi acpi_power_meter rtc_cmos pps_core acpi_pad sg mdio xfs dm_mirror dm_region_hash dm_log linear ehci_hcd usbcore usb_common sd_mod crc_t10dif processor thermal_sys hwmon scsi_dh_rdac scsi_dh_hp_sw scsi_dh_emc scsi_dh_alua scsi_dh dm_snapshot dm_mod ahci libahci libata megaraid_sas scsi_mod\nApr  1 13:35:00 hematus kernel: [  239.302072] Supported: No, Proprietary and Unsupported modules are loaded\nApr  1 13:35:00 hematus kernel: [  239.302074]\nApr  1 13:35:00 hematus kernel: [  239.302076] Pid: 7433, comm: nfsd Tainted: PF          NX 3.0.101-0.15-default #1 Dell Inc. PowerEdge R720/0X3D66\nApr  1 13:35:00 hematus kernel: [  239.302080] RIP: 0010:[<ffffffffa065e3a6>]  [<ffffffffa065e3a6>] zfsctl_lookup_snapshot_path+0x1a6/0x2c0 [zfs]\nApr  1 13:35:00 hematus kernel: [  239.302099] RSP: 0018:ffff8817dbee99e0  EFLAGS: 00010246\nApr  1 13:35:00 hematus kernel: [  239.302100] RAX: 0000000000000000 RBX: ffff8817f116c000 RCX: 0000000000000020\nApr  1 13:35:00 hematus kernel: [  239.302102] RDX: ffff8817f116e4c8 RSI: 0000000000001000 RDI: ffff8817dbee9ab0\nApr  1 13:35:00 hematus kernel: [  239.302104] RBP: 0000000000000da2 R08: e848000000000000 R09: 1200000000000000\nApr  1 13:35:00 hematus kernel: [  239.302106] R10: 0000000000000000 R11: ffffffff8120f630 R12: ffff8817dbee9b60\nApr  1 13:35:00 hematus kernel: [  239.302108] R13: ffff8817f116e4c8 R14: ffff8817f116c000 R15: 0000000000000006\nApr  1 13:35:00 hematus kernel: [  239.302110] FS:  0000000000000000(0000) GS:ffff88187faa0000(0000) knlGS:0000000000000000\nApr  1 13:35:00 hematus kernel: [  239.302112] CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b\nApr  1 13:35:00 hematus kernel: [  239.302114] CR2: 0000000000000020 CR3: 0000000001a09000 CR4: 00000000001407e0\nApr  1 13:35:00 hematus kernel: [  239.302116] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000\nApr  1 13:35:00 hematus kernel: [  239.302118] DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400\nApr  1 13:35:00 hematus kernel: [  239.302120] Process nfsd (pid: 7433, threadinfo ffff8817dbee8000, task ffff8817dbee6380)\nApr  1 13:35:00 hematus kernel: [  239.302122] Stack:\nApr  1 13:35:00 hematus kernel: [  239.302123]  0000000000011800 ffff8817dbee9c44 ffff88187f429a00 0000000000000da2\nApr  1 13:35:00 hematus kernel: [  239.302129]  ffff8817dbee9bd8 0000000000000004 0000000000000004 00000000000000a8\nApr  1 13:35:00 hematus kernel: [  239.302133]  00000000000000a8 ffffffff81145a8e ffff8817f420d400 ffff8817f1656800\nApr  1 13:35:00 hematus kernel: [  239.302137] Call Trace:\nApr  1 13:35:00 hematus kernel: [  239.302221]  [<ffffffffa065e52b>] zfsctl_lookup_objset+0x6b/0x90 [zfs]\nApr  1 13:35:00 hematus kernel: [  239.302284]  [<ffffffffa0672241>] zfs_vget+0xf1/0x350 [zfs]\nApr  1 13:35:00 hematus kernel: [  239.302356]  [<ffffffffa068edf1>] zpl_fh_to_dentry+0x41/0x60 [zfs]\nApr  1 13:35:00 hematus kernel: [  239.302420]  [<ffffffff811d69df>] exportfs_decode_fh+0x6f/0x290\nApr  1 13:35:00 hematus kernel: [  239.302429]  [<ffffffffa086198d>] nfsd_set_fh_dentry+0x17d/0x380 [nfsd]\nApr  1 13:35:00 hematus kernel: [  239.302440]  [<ffffffffa0861d6b>] fh_verify+0x1db/0x2b0 [nfsd]\nApr  1 13:35:00 hematus kernel: [  239.302448]  [<ffffffffa0870b41>] nfsd4_proc_compound+0x341/0x520 [nfsd]\nApr  1 13:35:00 hematus kernel: [  239.302463]  [<ffffffffa085e381>] nfsd_dispatch+0xb1/0x250 [nfsd]\nApr  1 13:35:00 hematus kernel: [  239.302474]  [<ffffffffa07826a3>] svc_process_common+0x333/0x620 [sunrpc]\nApr  1 13:35:00 hematus kernel: [  239.302488]  [<ffffffffa0782ce1>] svc_process+0x101/0x160 [sunrpc]\nApr  1 13:35:00 hematus kernel: [  239.302500]  [<ffffffffa085eb3d>] nfsd+0xcd/0x150 [nfsd]\nApr  1 13:35:00 hematus kernel: [  239.302505]  [<ffffffff81082966>] kthread+0x96/0xa0\nApr  1 13:35:00 hematus kernel: [  239.302511]  [<ffffffff81469ee4>] kernel_thread_helper+0x4/0x10\nApr  1 13:35:00 hematus kernel: [  239.302514] Code: 00 00 00 00 00 48 8b 87 c8 34 00 00 4c 8d af c8 24 00 00 48 8d bc 24 d0 00 00 00 be 00 10 00 00 4c 89 ea 48 89 84 24 d0 00 00 00\nApr  1 13:35:00 hematus kernel: <48>[  239.302527]  8b 40 20 48 89 84 24 d8 00 00 00 e8 49 fd ff ff 85 c0 0f 84\nApr  1 13:35:00 hematus kernel: [  239.302533] RIP  [<ffffffffa065e3a6>] zfsctl_lookup_snapshot_path+0x1a6/0x2c0 [zfs]\nApr  1 13:35:00 hematus kernel: [  239.302551]  RSP <ffff8817dbee99e0>\nApr  1 13:35:00 hematus kernel: [  239.302552] CR2: 0000000000000020\nApr  1 13:35:00 hematus kernel: [  239.302554] ---[ end trace c16be50e3596fc64 ]---\n```\n\nSo yeah, doesn't work just yet.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/39197997/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/39320535", "body": "@andrey-ve \n\nI grepped `/usr/src/linux/include` on a current SLES11 SP3 (and do bear in mind SuSE patches their kernels heavily so the 3.0.101 has interfaces probably similar to 3.6 vanilla) shows no 'HAVE_MOUNT_*' strings.\n\nThe only thing in the region of that was:\n\n```\n$ grep -Ri MOUNT_NODEV *\nlinux/fs.h:extern struct dentry *mount_nodev(struct file_system_type *fs_type,\n```\n\nit's defined as:\n\n``` h\nextern struct dentry *mount_nodev(struct file_system_type *fs_type,\n        int flags, void *data,\n        int (*fill_super)(struct super_block *, void *, int));\n```\n\nThere's also:\n\n``` h\n#define MNT_NODEV       0x02\n```\n\nin `linux/mount.h`.\n\nJust in case, I've put the src.rpm for the stock SLES11 SP3 kernel source at https://anorien.csc.warwick.ac.uk/kernel-source-3.0.76-0.11.1.x86_64.rpm - it will produce the /usr/src/linux used for building on SLES. \n\nHope this helps anyway, don't hesitate to ask if you need more information.\n(edit: updated rpm url)\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/issues/comments/39320535/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "JakeWharton": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/147018", "body": "These two lines should have four spaces before them so they are rendered like this:\n\n```\n$ ./configure\n$ make pkg\n```\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/147018/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "review_comments": []}, "rdylina": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/194382", "body": "Would it not be better to treat this somewhat like a security issue by blacklisting all known devices that are definitely not available to be used as block devices? Somehow seems safer to me.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/194382/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "review_comments": []}, "fajarnugraha": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/282697", "body": "Brian, cmd/zvol_id/Makefile.am is missing. Could you please upload it? Thanks.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/282697/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/282698", "body": "Sorry, I mean cmd/zvol_id/Makefile.in\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/282698/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/282796", "body": "Create another branch, then copy previous comments manually?\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/282796/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/283041", "body": "Copying previous note from email:\n\n<pre>\nfrom    : behlendorf <noreply@github.com>\ndate    : Fri, Feb 25, 2011 at 3:36 AM\nsubject : Re: [GitHub] Use udev to create /dev/zvol/[dataset_name] links [behlendorf/zfs feaf4b2]\n</pre>\n\n- Removed Makefile-sample, with the full integration in the build system it isn't needed.\n- Added all autogen.sh products (Makefile.in, configure) using the following versions of the utils.  Using the same versions of the tools minimizes how much change there is in the autogen products and makes it easier to review.\n  \n  autoconf (GNU Autoconf) 2.63\n  automake (GNU automake) 1.11.1\n  ltmain.sh (GNU libtool) 2.2.6b\n- Added the CDDL header to zvol_id_main.c, including correctly attributing the source.\n- Minor stray whitespace cleanup.\n- Update kmem_free() in zvol_remove_minors() to match  kmem_zalloc()'s use of MAXNAMELEN.  If we fail to do the the memory account code will flag this is a memory leak.  It's critical to ensure you alloc/free both use the same size for the buffer.\n- Add <sys/stat.h> header in zvol_id_main.c, without it my build was failing on RHEL6.\n\nhttps://github.com/behlendorf/zfs/commit/feaf4b287322d6123336f139049686114f6c6ee8#commitcomment-282533\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/283041/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "review_comments": []}, "nedbass": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/333338", "body": "Mixing tabs and spaces here\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/333338/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/333382", "body": "Done.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/333382/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/334541", "body": "Darn, missed this misaligned fi!  Oh well, I'll commit a new fix\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/334541/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/409893", "body": "Yay for killing abominable code!  Not sure if dbuf_hold_impl() is in the same call path, but \nfc5bb51f08a6c91ff9ad3559d0266eeeab0b1f61 employs the same hack to reduce its stack.\nYou may want to check if it can now be safely reverted as well.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/409893/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/413647", "body": "Opened Issue #263 to track this.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/413647/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}], "review_comments": []}, "Rudd-O": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/333340", "body": "## Fix it in your tree, pullrequest, then I will commit later on. \n\nSent from my Android phone with K-9 Mail. Please excuse my brevity.\n\nnedbass reply@reply.github.com wrote:\n\nMixing tabs and spaces here -- Reply to this email directly or view it on GitHub: https://github.com/behlendorf/zfs/commit/6583dcacdcca2aad7eaec51f31797a3533845099#commitcomment-333338\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/333340/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "review_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11071", "body": "don't hardcode the paths, please.  otherwise it will fail depending on where the utilities are installed.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11071/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11072", "body": "we sync.  we expect no unmounting to happen here since it either will fail if core file systems are mounted and have files open, or successfully unmount the file systems only to make the later initscripts crap out horribly because core file systems are not available anymore.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11072/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11073", "body": "show better status here\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11073/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11251", "body": "what should I do with these two lines?  Remove them?\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11251/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11252", "body": "should I re-add this file?\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11252/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11289", "body": "I will add this right now.\n\nEl Wednesday, March 23, 2011, behlendorf escribi\u00f3:\n\n> > @@ -1,6 +0,0 @@\n> > \n> > ## -Stub file for 'make dist' distdir rule.\n> > \n> > -This file is directly referenced by ../Makefile.am as a source\n> > -file and thus will be expected by 'make dist'.  To avoid this\n> \n> This file should be readded exactly for the reasons mentioned in the file.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11289/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11290", "body": "The file has been re-added as of commit 9549dd1 and pushed too.\n\nNow onto the next revision.\n\nEl Wednesday, March 23, 2011, behlendorf escribi\u00f3:\n\n> > @@ -1,6 +0,0 @@\n> > \n> > ## -Stub file for 'make dist' distdir rule.\n> > \n> > -This file is directly referenced by ../Makefile.am as a source\n> > -file and thus will be expected by 'make dist'.  To avoid this\n> \n> This file should be readded exactly for the reasons mentioned in the file.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11290/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11291", "body": "Commit 5469b88, just pushed, removes those by simply cherry-picking your own \ncommit on top of the merge.\n\nEl Wednesday, March 23, 2011, behlendorf escribi\u00f3:\n\n> > @@ -204,6 +204,8 @@ const struct super_operations zpl_super_operations =\n> > {\n> > \n> > ```\n> > .put_super  = zpl_put_super,\n> > .write_super    = NULL,\n> > .sync_fs    = zpl_sync_fs,\n> > ```\n> > -   .freeze_fs  = NULL,\n> \n> Yes, please remove them.  They are currently unused hooks and they cause\n> compile errors on older platforms.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11291/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11294", "body": "File removed.  Commit pushed.  Let me refresh the page to see how the merge \ndiff will look like.  You should do the same.\n\nEl Wednesday, March 23, 2011, behlendorf escribi\u00f3:\n\n> > @@ -0,0 +1,59 @@\n> > +put the dracut/90zfs directory in /usr/share/dracut/modules.d (or\n> > symlink it)\n> \n> A version of this file was already added to the dracut subdirectory.  If\n> you want to make changes/rewrite it that's fine but let's just keep one\n> copy of it around with the other dracut code.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/11294/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}, "baryluk": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/383541", "body": "$ mkfs.ext3 /dev/zd0\n$ resize2fs /dev/zd0\n\nI hope you mean\n$ mkfs.ext3 /dev/tank/zd0\n$ resize2fs /dev/tank/zd0\n\nHaving full volume path as well pool name under dev is crucial to prevent conflicts. I would even like to have it under /dev/zvols/tank/zd0, to not conflict with default devices. Consider doing zpool create sda /dev/sda, zfs create -V 10g sda/sda. Horrible.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/383541/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/383556", "body": "See https://github.com/behlendorf/zfs/issues/152#issuecomment-1162158 for some more discussion.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/383556/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/383557", "body": "Probably releated to https://github.com/behlendorf/zfs/commit/4c0d8e50b99b4f3b4a9b7bc67ac7fc4e406f5755\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/383557/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/383767", "body": "Hmm. For me, more natural and more reliable will be to do this in opposite direction. Create device node in from start /dev/zvol/pool/dataset and then create symlink /dev/zd\\* (this actually can be skipped, as is in most practical cases useless beyond eventually symlinking to it from somewhere) and in /dev/disk/by-*/xxx pointing to /dev/zvol/pool/dataset. Is there any reasons or limitations of other tools (kernel, udev, sysfs?, creating DOS partitions on zvols? etc) that you want to put devices directly in the /dev/ directory? It is not necessary to put them there directly. \n\nPS. Hmm. I just checked open-iscsi, and do the same as you. First create /dev/sdX, and then symlink it into /dev/disk/by-path/ip-X.X.X.X:PP-iscsi-iqn-XYZ by udev. So you are right. IMHO it is remenescent of archaic structure of /dev/ directory. Not best possible and easy way, but looks to be standard in Linux. Neverthless /dev/zd\\* shouldn't be used anyway in such tools like fstab, mount, fdisk, fsck, mkfs.*, etc., as this names are unstable, for example doing zfs create -V 10g tank/zd1, will still create /dev/zd0 (at least if this was first volume create/mounted after reboot right?), and symlink in /dev/zvol/tank/zd1 -> ../../zd0. It is pretty confusing. This is the reason why I was somehow against it.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/383767/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "review_comments": []}, "dajhorn": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/461576", "body": "Kernel parameters are subject to decimal/octal/hexadecimal interpretation, so this example should be `spl_hostid=0x00bab10c`.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/461576/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/545339", "body": "zfsonlinux/zfs#370\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/545339/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/545340", "body": "zfsonlinux/zfs#370\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/545340/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/545341", "body": "zfsonlinux/zfs#370\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/545341/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/545343", "body": "zfsonlinux/zfs#370\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/545343/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}], "review_comments": []}, "kylef": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/511969", "body": "I didn't think about that.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/comments/511969/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "review_comments": []}, "rlaager": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374212", "body": "What do you mean by this?\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374212/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374494", "body": "I've found this approach works best: Start from a checkout of upstream trunk. Then `git branch TOPIC; git checkout TOPIC`. Make your changes and commit. Push that branch to github. Repeat as necessary for the other features, starting from a checkout of upstream trunk each time. Then, do a pull request for each branch.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374494/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374507", "body": "The easiest solution is probably to leave your master tracking upstream master (i.e. you should not commit anything to master). Use a separate branch to combine your topic branches.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/374507/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354255", "body": "domain should be 256 (255 + NUL). As a result, the other fields might need changing. I haven't looked closely.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354255/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354257", "body": "Is \"EPOH\" supposed to be \"epoch\"?\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354257/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354259", "body": "This should be checked for NUL-termination correctness.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354259/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354260", "body": "This should be checked for NUL-termination correctness.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354260/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354264", "body": "This should probably const char *.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354264/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354267", "body": "By \"EOL\", you probably meant \"NUL\"?\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354267/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354268", "body": "Like in the SMB patch, this usage of a function named file_is_executable() is really confusing.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354268/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354271", "body": "You're just blindly returning OK here. Should something be done?\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354271/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354272", "body": "What should this function do? Maybe I or someone can help flesh it out.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354272/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354276", "body": "You shouldn't be calling strlen() in a loop like this. This should be rewritten more like this (untested):\n\n```\nfor (c = line ; *c ; c++) {\n    if (*c == '\\r' || *c == '\\n') {\n      c = '\\0';\n      break;\n    }\n}\n```\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354276/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354281", "body": "The code inside this should be indented another level. (Is Github hiding that in the diff, maybe? I didn't check.)\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354281/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354285", "body": "What's the purpose of this check? I don't understand why /dev/zvol is hardcoded.\n", "reactions": {"url": "https://api.github.com/repos/zfsonlinux/zfs/pulls/comments/354285/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}}}}